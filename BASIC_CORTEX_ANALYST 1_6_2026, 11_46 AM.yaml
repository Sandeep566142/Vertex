DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB
 / 
AI_POC
 / 
DIAGNOSTIC_TOOL(VARCHAR, VARCHAR, VARCHAR)

 
 
 # Note: Use POST, not GET
            response = _snowflake.send_snow_api_request(
                "POST", 
                "/api/v2/cortex/threads", 
                {"Content-Type": "application/json"}, 
                {}, 
                {"origin_application": "my_app"}, 
                None, 
                30000
            )

            print(response)



 # Note: Use POST, not GET
            response = _snowflake.send_snow_api_request(
                "POST", 
                "/api/v2/cortex/threads", 
                {"Content-Type": "application/json"}, 
                {}, 
                {"origin_application": "my_app"}, 
                None, 
                30000
            )

            print(response)
            
name: BASIC_CORTEX_ANALYST
tables:
  - name: ARD_GIACO_TM_HCP_ACUTE_MKT_WEEKLY_LAAD
    description: The table contains records of healthcare provider performance metrics in acute care settings, tracked on a weekly basis. Each record represents a healthcare provider's acute episode activity within specific territories and includes details about provider characteristics, geographic location, product categories, and territorial assignments.
    base_table:
      database: DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB
      schema: REPORTING
      table: ARD_GIACO_TM_HCP_ACUTE_MKT_WEEKLY_LAAD
    dimensions:
      - name: BRANDED_FLAG
        description: Indicates whether the product is a branded medication.
        expr: BRANDED_FLAG
        data_type: VARCHAR(16777216)
        sample_values:
          - 'N'
          - 'Y'
      - name: GOLDEN_ID
        description: A unique identifier used to link and track healthcare providers across different systems and databases.
        expr: GOLDEN_ID
        data_type: VARCHAR(16777216)
        sample_values:
          - GLD004700470057009305
          - GLD000900090008008206
          - GLD999909691076060401
      - name: HCP_ID
        description: Unique identifier for healthcare providers in the system.
        expr: HCP_ID
        data_type: VARCHAR(32)
        sample_values:
          - 2bb17ea9ca26bb191254a298da5e5b31
          - e78d13c51088736b6ad0abcfb0db5496
          - 232e71209a7c50de00969cff0164f64f
      - name: HCP_SPECIALTY
        description: Healthcare provider medical specialty or professional designation.
        expr: HCP_SPECIALTY
        data_type: VARCHAR(16777216)
        sample_values:
          - GERIATRIC MEDICINE (INTERNAL MEDICINE)
          - COLON & RECTAL SURGERY
          - GENERAL SURGERY
      - name: HCP_SPECIALTY_GROUP
        description: Healthcare provider specialty groups categorizing medical practice areas.
        expr: HCP_SPECIALTY_GROUP
        data_type: VARCHAR(16777216)
        sample_values:
          - SURGERY
          - MEDICINE
          - ALL OTHER
      - name: NPI
        description: National Provider Identifier numbers for healthcare providers.
        expr: NPI
        data_type: VARCHAR(16777216)
        sample_values:
          - '1568438992'
          - '1093197857'
          - '1710410949'
      - name: ONEKEY_HCP_ID
        description: Unique identifier for healthcare professionals in the OneKey system.
        expr: ONEKEY_HCP_ID
        data_type: VARCHAR(16777216)
        sample_values:
          - WUSM00274580
          - WUSR03862562
          - WUSM01303609
      - name: PRACTICE_SETTING
        description: The type of healthcare practice setting where medical services are provided.
        expr: PRACTICE_SETTING
        data_type: VARCHAR(256)
        sample_values:
          - RETAIL
          - DISCHARGE
      - name: PROCEDURE_GROUP
        description: Medical procedure categories or groupings used for classification purposes.
        expr: PROCEDURE_GROUP
        data_type: VARCHAR(256)
        sample_values:
          - LAPAROSCOPIC UROLOGIC PROCEDURES
          - OB/GYN PROCEDURES
          - JOINT REPAIR
      - name: PRODUCT_CATEGORY
        description: Categories of pharmaceutical pain management products used in acute care markets.
        expr: PRODUCT_CATEGORY
        data_type: VARCHAR(256)
        sample_values:
          - ANALGESICS-SEDATIVE COMBINATION
          - DERMATOLOGICAL LOCAL TOPICAL ANESTHETIC
          - MODERATE OPIOID COMBINATIONS
      - name: PRODUCT_FAMILY_GROUP
        description: Pharmaceutical product family groups used for pain management and treatment.
        expr: PRODUCT_FAMILY_GROUP
        data_type: VARCHAR(256)
        sample_values:
          - IBUPROFEN
          - DICLOFENAC
          - MELOXICAM
      - name: PTAM_TERRITORY_ID
        description: Unique identifier for a PTAM (Pain Territory Account Manager) territory.
        expr: PTAM_TERRITORY_ID
        data_type: VARCHAR(255)
        sample_values:
          - V1NAUSA-5733506
          - V1NAUSA-5733204
          - V1NAUSA-5733403
      - name: ROA
        description: Route of administration for the medication or treatment.
        expr: ROA
        data_type: VARCHAR(256)
        sample_values:
          - ORAL
          - Sales territory identifier used to designate specific geographicTOPICAL
          - TOPICAL-PATCH
      - name: SAL_TERRITORY_ID
        description:  or organizational sales regions.
        expr: SAL_TERRITORY_ID
        data_type: VARCHAR(255)
        sample_values:
          - V1NAUSA-5720008
          - V1NAUSA-5720014
          - V1NAUSA-5720013
      - name: SITE_OF_CARE_ZIP_CODE
        description: ZIP codes for healthcare facility locations.
        expr: SITE_OF_CARE_ZIP_CODE
        data_type: VARCHAR(16777216)
        sample_values:
          - '80911'
          - '76903'
          - '32771'
      - name: VERTEX_ID
        description: Unique identifier for a vertex in the healthcare provider network.
        expr: VERTEX_ID
        data_type: VARCHAR(16777216)
        sample_values:
          - '14811523'
          - '14821592'
          - '17503007'
      - name: ZIP_CODE
        description: Postal ZIP codes for geographic locations.
        expr: ZIP_CODE
        data_type: VARCHAR(16777216)
        sample_values:
          - '14621'
          - '01805'
          - '95337'
    time_dimensions:
      - name: DATE_KEY
        description: A date used as a key identifier in the healthcare provider acute market weekly reporting data.
        expr: DATE_KEY
        data_type: DATE
        sample_values:
          - '2025-02-14'
          - '2024-11-15'
          - '2022-11-11'
    facts:
      - name: ACUTE_CALENDAR_DAYS_LAAD
        description: The number of calendar days in the acute care period for look-alike-alike drug analysis.
        expr: ACUTE_CALENDAR_DAYS_LAAD
        data_type: NUMBER(38,5)
        access_modifier: public_access
        sample_values:
          - '1.00000'
          - '3.00000'
          - '10.00000'
      - name: ACUTE_EPISODES_LAAD
        description: The number of acute episodes within the look-ahead period.
        expr: ACUTE_EPISODES_LAAD
        data_type: NUMBER(18,0)
        access_modifier: public_access
        sample_values:
          - '1'
          - '4'
          - '2'
      - name: ACUTE_PROCEDURES_LAAD
        description: The number of acute procedures performed using laparoscopic-assisted abdominal delivery techniques.
        expr: ACUTE_PROCEDURES_LAAD
        data_type: NUMBER(18,0)
        access_modifier: public_access
        sample_values:
          - '1'
          - '3'
          - '2'
      - name: ACUTE_REFILLS_LAAD
        description: The number of acute medication refills within the look-ahead period.
        expr: ACUTE_REFILLS_LAAD
        data_type: NUMBER(13,0)
        access_modifier: public_access
        sample_values:
          - '2'
          - '4'
          - '1'
      - name: ACUTE_TRX_LAAD
        description: The number of acute transactions for the last-as-advertised date period.
        expr: ACUTE_TRX_LAAD
        data_type: NUMBER(18,0)
        access_modifier: public_access
        sample_values:
          - '5'
          - '1'
          - '3'
      - name: ACUTE_TX_DAYS_LAAD
        description: The number of days for acute treatment based on LAAD (Last Available Actual Data).
        expr: ACUTE_TX_DAYS_LAAD
        data_type: NUMBER(38,5)
        access_modifier: public_access
        sample_values:
          - '5.00000'
          - '10.00000'
          - '30.00000'
      - name: ACUTE_UNITS_LAAD
        description: Acute care units measured as a look-ahead average demand.
        expr: ACUTE_UNITS_LAAD
        data_type: NUMBER(38,5)
        access_modifier: public_access
        sample_values:
          - '9.00000'
          - '20.00000'
          - '90.00000'
      - name: WEEK_DT
        description: The date representing the week in the healthcare provider acute market reporting period.
        expr: WEEK_DT
        data_type: NUMBER(10,0)
        access_modifier: public_access
        sample_values:
          - '20240524'
          - '20250418'
          - '20250606'
  - name: TD_GEO_CITY
    description: The table contains records of cities and their geographic information. Each record represents a single city and includes hierarchical location details such as state and country associations, along with precise coordinate data.
    base_table:
      database: DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB
      schema: REPORTING
      table: TD_GEO_CITY
    dimensions:
      - name: GEO_CITY_KEY
        description: A unique identifier key for geographic city records.
        expr: GEO_CITY_KEY
        data_type: VARCHAR(32)
        sample_values:
          - cb004e0c1c429625db774a086579bd3b
          - 3de4110deff030eca4c2da9e8e85ae39
          - 6b5b3307241b5195dd6bfef7630d834e
      - name: GEO_CITY_NAME
        description: The name of a geographic city location.
        expr: GEO_CITY_NAME
        data_type: VARCHAR(16777216)
        sample_values:
          - BELLEVUE
          - MATTAPAN
          - TALLAHASSEE FALLS
      - name: GEO_COUNTRY_CD
        description: Geographic country code representing the country where the city is located.
        expr: GEO_COUNTRY_CD
        data_type: VARCHAR(16777216)
        sample_values:
          - US
      - name: GEO_COUNTRY_NAME
        description: The name of the country in a geographic location.
        expr: GEO_COUNTRY_NAME
        data_type: VARCHAR(16777216)
        sample_values:
          - UNITED STATES
      - name: GEO_STATE_CD
        description: State codes for geographic locations.
        expr: GEO_STATE_CD
        data_type: VARCHAR(16777216)
        sample_values:
          - XX
          - VT
          - FL
      - name: GEO_STATE_NAME
        description: The name of the state within the United States.
        expr: GEO_STATE_NAME
        data_type: VARCHAR(16777216)
        sample_values:
          - SOUTH CAROLINA
          - TENNESSEE
          - NEBRASKA
    facts:
      - name: GEO_COUNTRY_KEY
        description: A unique identifier for countries in the geographic data structure.
        expr: GEO_COUNTRY_KEY
        data_type: NUMBER(38,0)
        access_modifier: public_access
        sample_values:
          - '1'
      - name: GEO_LATITUDE
        description: Geographic latitude coordinate in decimal degrees.
        expr: GEO_LATITUDE
        data_type: NUMBER(11,8)
        access_modifier: public_access
      - name: GEO_LONGITUDE
        description: Geographic longitude coordinate expressed in decimal degrees.
        expr: GEO_LONGITUDE
        data_type: NUMBER(11,8)
        access_modifier: public_access
      - name: GEO_STATE_KEY
        description: Numeric identifier for geographic states.
        expr: GEO_STATE_KEY
        data_type: NUMBER(38,0)
        access_modifier: public_access
        sample_values:
          - '21'
          - '22'
          - '53'
  - name: TD_GEO_LOC
    description: The table contains records of geographic locations with their complete address and coordinate information. Each record represents a specific location and includes hierarchical geographic details from address lines through city, state, postal code, and country levels, as well as precise latitude and longitude coordinates.
    base_table:
      database: DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB
      schema: REPORTING
      table: TD_GEO_LOC
    dimensions:
      - name: GEO_CITY_KEY
        description: A unique identifier key for geographic cities.
        expr: GEO_CITY_KEY
        data_type: VARCHAR(32)
        sample_values:
          - e190c59f3d88823cb626962e558314df
          - 21bb6ea0074b193b6643355e6b83aec2
          - a6a0645ce9ac1995532b4bb9f28ce04c
      - name: GEO_CITY_NAME
        description: Geographic city names.
        expr: GEO_CITY_NAME
        data_type: VARCHAR(16777216)
        sample_values:
          - HARRISBURG
          - SAINT LOUIS
          - DEER LODGE
      - name: GEO_COUNTRY_CD
        description: Geographic country code representing the country location.
        expr: GEO_COUNTRY_CD
        data_type: VARCHAR(16777216)
        sample_values:
          - US
      - name: GEO_COUNTRY_NAME
        description: The name of the country in a geographic location.
        expr: GEO_COUNTRY_NAME
        data_type: VARCHAR(16777216)
        sample_values:
          - UNITED STATES
      - name: GEO_LOC_KEY
        description: A unique identifier for geographic location records.
        expr: GEO_LOC_KEY
        data_type: VARCHAR(32)
        sample_values:
          - 96a44f5985fb18551e9c45db3d75f237
          - 40665982fb20e15ee0b1e0bde8b43330
          - 512d454f090f878a6e8175cad706cecc
      - name: GEO_POSTAL_CD
        description: Postal codes for geographic locations.
        expr: GEO_POSTAL_CD
        data_type: VARCHAR(16777216)
        sample_values:
          - '45459'
          - '92037'
          - '33175'
      - name: GEO_POSTAL_CD_EXT
        description: A column holding data of type VARCHAR(16777216).
        expr: GEO_POSTAL_CD_EXT
        data_type: VARCHAR(16777216)
      - name: GEO_POSTAL_KEY
        description: A unique identifier key for postal geographic locations.
        expr: GEO_POSTAL_KEY
        data_type: VARCHAR(32)
        sample_values:
          - c3195f6d307dd319bf1275b8f98dca51
          - 1a1c1e45309875960a48106f0b73a0b9
          - f8ca2b7549985685fb5a1275bfcced43
      - name: GEO_STATE_CD
        description: State codes for geographic locations.
        expr: GEO_STATE_CD
        data_type: VARCHAR(16777216)
        sample_values:
          - FL
          - MI
          - MA
      - name: GEO_STATE_NAME
        description: The name of the state within the United States.
        expr: GEO_STATE_NAME
        data_type: VARCHAR(16777216)
        sample_values:
          - SOUTH CAROLINA
          - MONTANA
          - PENNSYLVANIA
      - name: LOC_ADDR_LINE_1
        description: Street addresses including house numbers and street names.
        expr: LOC_ADDR_LINE_1
        data_type: VARCHAR(16777216)
        sample_values:
          - 12110 NE 64TH PL
          - 1920 LENLAND AVE
          - 210 BAXTER ST
      - name: LOC_ADDR_LINE_2
        description: Secondary address information such as suite numbers, apartment numbers, or room designations.
        expr: LOC_ADDR_LINE_2
        data_type: VARCHAR(16777216)
        sample_values:
          - UNIT B
          - APT 206
      - name: LOC_ADDR_LINE_3
        description: The third line of a location's address.
        expr: LOC_ADDR_LINE_3
        data_type: VARCHAR(16777216)
      - name: LOC_ADDR_LINE_4
        description: The fourth line of a location's address.
        expr: LOC_ADDR_LINE_4
        data_type: VARCHAR(16777216)
    facts:
      - name: GEO_COUNTRY_KEY
        description: A unique identifier for countries in the geographic location dimension.
        expr: GEO_COUNTRY_KEY
        data_type: NUMBER(38,0)
        access_modifier: public_access
        sample_values:
          - '1'
      - name: GEO_LATITUDE
        description: Geographic latitude coordinate expressed in decimal degrees.
        expr: GEO_LATITUDE
        data_type: NUMBER(11,8)
        access_modifier: public_access
      - name: GEO_LONGITUDE
        description: Geographic longitude coordinate expressed in decimal degrees.
        expr: GEO_LONGITUDE
        data_type: NUMBER(11,8)
        access_modifier: public_access
      - name: GEO_STATE_KEY
        description: Unique identifier for geographic states.
        expr: GEO_STATE_KEY
        data_type: NUMBER(38,0)
        access_modifier: public_access
        sample_values:
          - '59'
          - '22'
          - '30'
  - name: TD_GEO_POSTAL
    description: The table contains records of geographic postal code areas with their associated location hierarchies. Each record represents a postal code and includes details about the corresponding state and country jurisdictions as well as precise geographic coordinates.
    base_table:
      database: DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB
      schema: REPORTING
      table: TD_GEO_POSTAL
    dimensions:
      - name: GEO_COUNTRY_CD
        description: Geographic country code representing the country associated with a postal location.
        expr: GEO_COUNTRY_CD
        data_type: VARCHAR(16777216)
        sample_values:
          - US
      - name: GEO_COUNTRY_KEY
        description: A unique identifier for geographic countries.
        expr: GEO_COUNTRY_KEY
        data_type: NUMBER(38,0)
        sample_values:
          - '1'
      - name: GEO_COUNTRY_NAME
        description: The name of the country in a geographic location.
        expr: GEO_COUNTRY_NAME
        data_type: VARCHAR(16777216)
        sample_values:
          - UNITED STATES
      - name: GEO_POSTAL_CD
        description: Postal codes for geographic locations.
        expr: GEO_POSTAL_CD
        data_type: VARCHAR(16777216)
        sample_values:
          - '25205'
          - '62545'
          - '78675'
      - name: GEO_POSTAL_KEY
        description: A unique identifier key for geographic postal code records.
        expr: GEO_POSTAL_KEY
        data_type: VARCHAR(32)
        sample_values:
          - 794d1a9eee30d774236a5186a2b55bf9
          - 0eec7bab53a4751845b83ff0ce77c5a1
          - 728b5b967aeb1d257948dc6e622bbc95
      - name: GEO_STATE_CD
        description: State codes for geographic locations.
        expr: GEO_STATE_CD
        data_type: VARCHAR(16777216)
        sample_values:
          - TX
          - WV
          - MS
      - name: GEO_STATE_KEY
        description: Unique identifier for geographic states within the system.
        expr: GEO_STATE_KEY
        data_type: NUMBER(38,0)
        sample_values:
          - '75'
          - '59'
          - '28'
      - name: GEO_STATE_NAME
        description: The name of the geographic state or territory.
        expr: GEO_STATE_NAME
        data_type: VARCHAR(16777216)
        sample_values:
          - GEORGIA
          - NEW JERSEY
          - TEXAS
    facts:
      - name: GEO_LATITUDE
        description: Geographic latitude coordinate expressed in decimal degrees.
        expr: GEO_LATITUDE
        data_type: NUMBER(11,8)
        access_modifier: public_access
      - name: GEO_LONGITUDE
        description: Geographic longitude coordinate expressed in decimal degrees.
        expr: GEO_LONGITUDE
        data_type: NUMBER(11,8)
        access_modifier: public_access
  - name: TD_GEO_STATE
    description: The table contains records of geographic states and their associated countries. Each record includes location identifiers, geographic coordinates, and hierarchical relationships between states and countries.
    base_table:
      database: DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB
      schema: REPORTING
      table: TD_GEO_STATE
    dimensions:
      - name: GEO_COUNTRY_CD
        description: Geographic country code.
        expr: GEO_COUNTRY_CD
        data_type: VARCHAR(16777216)
        sample_values:
          - US
      - name: GEO_COUNTRY_NAME
        description: The name of the country in a geographic location.
        expr: GEO_COUNTRY_NAME
        data_type: VARCHAR(16777216)
        sample_values:
          - UNITED STATES
      - name: GEO_STATE_CD
        description: Geographic state codes used to identify states or territories.
        expr: GEO_STATE_CD
        data_type: VARCHAR(16777216)
        sample_values:
          - NC
          - XX
          - DE
      - name: GEO_STATE_NAME
        description: Names of US states and territories.
        expr: GEO_STATE_NAME
        data_type: VARCHAR(16777216)
        sample_values:
          - SOUTH CAROLINA
          - DELAWARE
          - NEBRASKA
    facts:
      - name: GEO_COUNTRY_KEY
        description: Geographic country key used as a unique identifier for countries.
        expr: GEO_COUNTRY_KEY
        data_type: NUMBER(38,0)
        access_modifier: public_access
        sample_values:
          - '1'
      - name: GEO_LATITUDE
        description: Geographic latitude coordinates for state locations.
        expr: GEO_LATITUDE
        data_type: NUMBER(11,8)
        access_modifier: public_access
        sample_values:
          - '39.00040000'
          - '34.00040000'
      - name: GEO_LONGITUDE
        description: Geographic longitude coordinates for state locations.
        expr: GEO_LONGITUDE
        data_type: NUMBER(11,8)
        access_modifier: public_access
        sample_values:
          - '-86.25030000'
          - '-71.49980000'
          - '-123.04600000'
      - name: GEO_STATE_KEY
        description: Unique identifier for geographic state records.
        expr: GEO_STATE_KEY
        data_type: NUMBER(38,0)
        access_modifier: public_access
        sample_values:
          - '21'
          - '261'
          - '22'
  - name: TD_HCO
    description: The table contains records of healthcare organizations with their identifying information and regulatory details. Each record includes organizational names, business identifiers, operational status, and licensing information including DEA registrations and HIN numbers across multiple categories.
    base_table:
      database: DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB
      schema: REPORTING
      table: TD_HCO
    dimensions:
      - name: HCO_BUSINESS_NAME
        description: Healthcare organization business name.
        expr: HCO_BUSINESS_NAME
        data_type: VARCHAR(16777216)
        sample_values:
          - CSC COMMUNITY PHARMACY
          - ENDOSCOPY AND SURGICAL CARE SUITE
      - name: HCO_CD
        description: Healthcare organization codes used to identify specific healthcare entities.
        expr: HCO_CD
        data_type: VARCHAR(16777216)
        sample_values:
          - '1438'
          - '22740441'
          - '30819949'
      - name: HCO_KEY
        description: A unique identifier key for healthcare organizations.
        expr: HCO_KEY
        data_type: VARCHAR(32)
        sample_values:
          - f40f52d91c6e993b6c7c5af4716c359b
          - 27e97cbb80be61e0fb616254104d33b3
          - a9322f73290eae0c74ca2d7b98379369
      - name: HCO_LEGAL_NAME
        description: The legal name of the healthcare organization.
        expr: HCO_LEGAL_NAME
        data_type: VARCHAR(16777216)
        sample_values:
          - BINUR, NIR, OFFICE
          - ALTAMED PHARMACY BOYLE HEIGHTS
          - ONE HEALTH GASTROENTEROLOGY AND HEPATOLOGY
      - name: HCO_NAME
        description: Names of healthcare organizations.
        expr: HCO_NAME
        data_type: VARCHAR(16777216)
        sample_values:
          - MYCARE PHARMACY
          - FERRER, OLGA M, OFFICE
          - COSHOCTON REGIONAL MEDICAL CENTER INTENSIVE CARE UNIT
      - name: HCO_P_DEA_LIC_STATUS_CD
        description: Healthcare organization Drug Enforcement Administration license status code.
        expr: HCO_P_DEA_LIC_STATUS_CD
        data_type: VARCHAR(16777216)
      - name: HCO_P_DEA_NUM
        description: Drug Enforcement Administration number for healthcare organizations.
        expr: HCO_P_DEA_NUM
        data_type: VARCHAR(16777216)
        sample_values:
          - FV5496244
          - FG5718347
      - name: HCO_P_GLN_NUM
        description: Healthcare organization primary Global Location Number (GLN).
        expr: HCO_P_GLN_NUM
        data_type: VARCHAR(16777216)
      - name: HCO_P_HIN_NUM
        description: A column holding data of type VARCHAR(16777216).
        expr: HCO_P_HIN_NUM
        data_type: VARCHAR(16777216)
        sample_values:
          - L89YW0W00
          - 38G06QNF1
          - 8N302YY00
      - name: HCO_P_NCPDP_NUM
        description: A column holding data of type VARCHAR(16777216).
        expr: HCO_P_NCPDP_NUM
        data_type: VARCHAR(16777216)
      - name: HCO_P_NPI_NUM
        description: Healthcare organization primary National Provider Identifier number.
        expr: HCO_P_NPI_NUM
        data_type: VARCHAR(16777216)
      - name: HCO_S_DEA_LIC_STATUS_CD
        description: Healthcare organization Drug Enforcement Administration license status code.
        expr: HCO_S_DEA_LIC_STATUS_CD
        data_type: VARCHAR(16777216)
      - name: HCO_S_DEA_NUM
        description: Drug Enforcement Administration number for healthcare organizations.
        expr: HCO_S_DEA_NUM
        data_type: VARCHAR(16777216)
        sample_values:
          - FM3749629
          - FP5150862
      - name: HCO_S_GLN_NUM
        description: Healthcare organization Global Location Number (GLN) used for unique identification in supply chain and healthcare transactions.
        expr: HCO_S_GLN_NUM
        data_type: VARCHAR(16777216)
      - name: HCO_S_HIN_NUM
        description: A column holding data of type VARCHAR(16777216).
        expr: HCO_S_HIN_NUM
        data_type: VARCHAR(16777216)
      - name: HCO_S_NCPDP_NUM
        description: A column holding data of type VARCHAR(16777216).
        expr: HCO_S_NCPDP_NUM
        data_type: VARCHAR(16777216)
      - name: HCO_S_NPI_NUM
        description: National Provider Identifier number for healthcare organizations.
        expr: HCO_S_NPI_NUM
        data_type: VARCHAR(16777216)
      - name: HCO_SDESC
        description: Names of healthcare organizations.
        expr: HCO_SDESC
        data_type: VARCHAR(16777216)
        sample_values:
          - CASPER COLLEGE STUDENT HEALTH SERVICES
          - ROYAL SUPPLIES
          - AVERA SURGICAL ASSOCIATES ENDOSCOPY
      - name: HCO_SRC_ID_IMS
        description: Healthcare organization source identifier from IMS data system.
        expr: HCO_SRC_ID_IMS
        data_type: VARCHAR(16777216)
        sample_values:
          - WUSH00158767
          - '2705090'
          - '22740441'
      - name: HCO_SRC_ID_P_SCRUB
        description: A column holding data of type VARCHAR(16777216).
        expr: HCO_SRC_ID_P_SCRUB
        data_type: VARCHAR(16777216)
      - name: HCO_SRC_ID_P_SFA
        description: A column holding data of type VARCHAR(16777216).
        expr: HCO_SRC_ID_P_SFA
        data_type: VARCHAR(16777216)
      - name: HCO_SRC_ID_S_SCRUB
        description: Healthcare organization source identifier after data scrubbing processes.
        expr: HCO_SRC_ID_S_SCRUB
        data_type: VARCHAR(16777216)
        sample_values:
          - WUSF00046723
          - WUSE01155990
          - WUSF00100048
      - name: HCO_SRC_ID_S_SFA
        description: A column holding data of type VARCHAR(16777216).
        expr: HCO_SRC_ID_S_SFA
        data_type: VARCHAR(16777216)
      - name: HCO_SRC_ID_T_SCRUB
        description: A column holding data of type VARCHAR(16777216).
        expr: HCO_SRC_ID_T_SCRUB
        data_type: VARCHAR(16777216)
      - name: HCO_SRC_ID_T_SFA
        description: A column holding data of type VARCHAR(16777216).
        expr: HCO_SRC_ID_T_SFA
        data_type: VARCHAR(16777216)
      - name: HCO_SRC_ID_WKH
        description: A column holding data of type VARCHAR(16777216).
        expr: HCO_SRC_ID_WKH
        data_type: VARCHAR(16777216)
      - name: HCO_T_DEA_LIC_STATUS_CD
        description: Healthcare organization Drug Enforcement Administration license status code.
        expr: HCO_T_DEA_LIC_STATUS_CD
        data_type: VARCHAR(16777216)
      - name: HCO_T_DEA_NUM
        description: A column holding data of type VARCHAR(16777216).
        expr: HCO_T_DEA_NUM
        data_type: VARCHAR(16777216)
        sample_values:
          - HV00789
          - RM0314790
      - name: HCO_T_GLN_NUM
        description: Healthcare organization trading partner Global Location Number (GLN).
        expr: HCO_T_GLN_NUM
        data_type: VARCHAR(16777216)
      - name: HCO_T_HIN_NUM
        description: A column holding data of type VARCHAR(16777216).
        expr: HCO_T_HIN_NUM
        data_type: VARCHAR(16777216)
      - name: HCO_T_NCPDP_NUM
        description: A column holding data of type VARCHAR(16777216).
        expr: HCO_T_NCPDP_NUM
        data_type: VARCHAR(16777216)
      - name: HCO_T_NPI_NUM
        description: Healthcare organization National Provider Identifier number.
        expr: HCO_T_NPI_NUM
        data_type: VARCHAR(16777216)
    time_dimensions:
      - name: HCO_P_DEA_EXP_DT
        description: The expiration date of the healthcare organization's Drug Enforcement Administration registration.
        expr: HCO_P_DEA_EXP_DT
        data_type: DATE
      - name: HCO_S_DEA_EXP_DT
        description: The expiration date of the healthcare organization's Drug Enforcement Administration registration.
        expr: HCO_S_DEA_EXP_DT
        data_type: DATE
      - name: HCO_T_DEA_EXP_DT
        description: The expiration date of the healthcare organization's Drug Enforcement Administration registration.
        expr: HCO_T_DEA_EXP_DT
        data_type: DATE
    facts:
      - name: HCO_STATUS_KEY
        description: Healthcare organization status identifier key.
        expr: HCO_STATUS_KEY
        data_type: NUMBER(38,0)
        access_modifier: public_access
        sample_values:
          - '1'
      - name: HCO_SUBTYPE_KEY
        description: The unique identifier for the healthcare organization subtype.
        expr: HCO_SUBTYPE_KEY
        data_type: NUMBER(38,0)
        access_modifier: public_access
        sample_values:
          - '35'
          - '30'
          - '39'
  - name: TD_HCO_SUBTYPE
    description: The table contains records of healthcare organization subtypes and their corresponding parent types. Each record represents a specific subtype classification with descriptive information and links to broader organizational type categories.
    base_table:
      database: DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB
      schema: REPORTING
      table: TD_HCO_SUBTYPE
    dimensions:
      - name: HCO_SUBTYPE_CD
        description: Healthcare organization subtype codes that classify different types of medical entities and payer organizations.
        expr: HCO_SUBTYPE_CD
        data_type: VARCHAR(16777216)
        sample_values:
          - VA CMOP
          - PAYER_REG
          - PBM
      - name: HCO_SUBTYPE_DESC
        description: Healthcare organization subtype descriptions that categorize different types of medical entities and payers.
        expr: HCO_SUBTYPE_DESC
        data_type: VARCHAR(16777216)
        sample_values:
          - MCO PBM
          - IDN
          - MCO NATIONAL PAYER
      - name: HCO_SUBTYPE_KEY
        description: Unique identifier for healthcare organization subtypes.
        expr: HCO_SUBTYPE_KEY
        data_type: NUMBER(38,0)
        sample_values:
          - '1'
          - '2'
          - '3'
      - name: HCO_TYPE_CD
        description: Healthcare organization type code indicating the classification of the healthcare organization.
        expr: HCO_TYPE_CD
        data_type: VARCHAR(16777216)
        sample_values:
          - ORG
          - MCO
      - name: HCO_TYPE_DESC
        description: Healthcare organization type description indicating the category or classification of the healthcare entity.
        expr: HCO_TYPE_DESC
        data_type: VARCHAR(16777216)
        sample_values:
          - ORGANIZATION
          - MANAGED CARE ORGANIZATION
      - name: HCO_TYPE_KEY
        description: A unique identifier for healthcare organization types.
        expr: HCO_TYPE_KEY
        data_type: NUMBER(38,0)
        sample_values:
          - '1'
          - '2'
    primary_key:
      columns:
        - HCO_SUBTYPE_KEY
  - name: TD_HCP
    description: The table contains records of healthcare professionals and their personal and professional information. Each record represents an individual healthcare provider and includes demographic details, contact information, educational background, and various status indicators related to communication preferences and professional classifications.
    base_table:
      database: DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB
      schema: REPORTING
      table: TD_HCP
    dimensions:
      - name: AMA_NO_CONTACT
        description: American Medical Association no contact indicator.
        expr: AMA_NO_CONTACT
        data_type: VARCHAR(1)
        sample_values:
          - 'N'
          - 'Y'
      - name: EMAIL_ADDR_P
        description: Email addresses for healthcare professionals.
        expr: EMAIL_ADDR_P
        data_type: VARCHAR(16777216)
        sample_values:
          - ATELIS1150730@WM.PROVIDENCEDIRECT.ORG
          - KATYDM7@HOTMAIL.COM
          - GRANTJSULLIVAN@ATT.NET
      - name: EMAIL_ADDR_S
        description: Email addresses of healthcare providers.
        expr: EMAIL_ADDR_S
        data_type: VARCHAR(16777216)
        sample_values:
          - T.THOMAS@ARCHILDRENS.ORG
          - EHUANG@POST.HARVARD.EDU
          - CGOODWIN@UMC.EDU
      - name: EMAIL_ADDR_T
        description: Email addresses for healthcare providers.
        expr: EMAIL_ADDR_T
        data_type: VARCHAR(16777216)
      - name: HCP_DEGREE
        description: The degree or credential held by the healthcare professional.
        expr: HCP_DEGREE
        data_type: VARCHAR(16777216)
        sample_values:
          - PHT
          - RPH
          - NP
      - name: HCP_FIRST_NAME
        description: The first name of the healthcare provider.
        expr: HCP_FIRST_NAME
        data_type: VARCHAR(16777216)
        sample_values:
          - SHANE
          - ROYAL
          - CASIANNE
      - name: HCP_GENDER
        description: The gender of the healthcare provider.
        expr: HCP_GENDER
        data_type: VARCHAR(255)
        sample_values:
          - FEMALE
          - UNKNOWN
      - name: HCP_GRAD_YR
        description: The year when the healthcare provider graduated from their medical program.
        expr: HCP_GRAD_YR
        data_type: VARCHAR(16777216)
        sample_values:
          - '1967'
          - '2019'
          - '1965'
      - name: HCP_KEY
        description: A unique identifier for healthcare providers in the system.
        expr: HCP_KEY
        data_type: VARCHAR(32)
        sample_values:
          - 10f535a03919512d15df722bdf50f8fe
          - 59c026c2a4da8798332fd8140066c866
          - cce70a032d441fc7cf17357da57ffa3e
      - name: HCP_LAST_NAME
        description: Healthcare provider last names.
        expr: HCP_LAST_NAME
        data_type: VARCHAR(16777216)
        sample_values:
          - FULP
          - GERBER
          - DIGGINS
      - name: HCP_ME_NUM
        description: Healthcare provider medical education number used for identification purposes.
        expr: HCP_ME_NUM
        data_type: VARCHAR(16777216)
        sample_values:
          - '4950901017'
          - '0230178074'
      - name: HCP_MID_NAME
        description: Middle names of healthcare providers.
        expr: HCP_MID_NAME
        data_type: VARCHAR(16777216)
        sample_values:
          - ANN
          - DARLENE
          - TUCKER
      - name: HCP_P_DEA_BUSINESS_ACTIVITY_CD
        description: Healthcare provider Drug Enforcement Administration business activity code.
        expr: HCP_P_DEA_BUSINESS_ACTIVITY_CD
        data_type: VARCHAR(16777216)
      - name: HCP_P_DEA_DRUG_SCHEDULE
        description: A column holding data of type VARCHAR(16777216).
        expr: HCP_P_DEA_DRUG_SCHEDULE
        data_type: VARCHAR(16777216)
      - name: HCP_P_DEA_LIC_STATUS_CD
        description: The status code indicating whether a healthcare provider's Drug Enforcement Administration license is active or inactive.
        expr: HCP_P_DEA_LIC_STATUS_CD
        data_type: VARCHAR(16777216)
        sample_values:
          - ACTIVE
      - name: HCP_P_DEA_NUM
        description: Drug Enforcement Administration number assigned to healthcare providers for prescribing controlled substances.
        expr: HCP_P_DEA_NUM
        data_type: VARCHAR(16777216)
        sample_values:
          - AB7255272
          - BB3188833
      - name: HCP_P_DEA_STATE_OF_LICENSURE
        description: The state where the healthcare provider's Drug Enforcement Administration license is issued.
        expr: HCP_P_DEA_STATE_OF_LICENSURE
        data_type: VARCHAR(16777216)
        sample_values:
          - TX
          - MA
          - LA
      - name: HCP_P_HIN
        description: A column holding data of type VARCHAR(16777216).
        expr: HCP_P_HIN
        data_type: VARCHAR(16777216)
      - name: HCP_P_MA_ID
        description: A column holding data of type VARCHAR(16777216).
        expr: HCP_P_MA_ID
        data_type: VARCHAR(16777216)
        sample_values:
          - '216513'
          - '166691'
          - '169135'
      - name: HCP_P_NPI_NUM
        description: National Provider Identifier (NPI) numbers for healthcare providers.
        expr: HCP_P_NPI_NUM
        data_type: VARCHAR(16777216)
        sample_values:
          - '1134821382'
          - '1235525957'
          - '1558956375'
      - name: HCP_P_STATE_LIC_NUM
        description: Healthcare provider state license numbers.
        expr: HCP_P_STATE_LIC_NUM
        data_type: VARCHAR(16777216)
        sample_values:
          - PA2022-0048
          - '107955'
          - '238052'
      - name: HCP_P_STATE_LIC_STATE_CD
        description: State code where the healthcare provider holds their professional license.
        expr: HCP_P_STATE_LIC_STATE_CD
        data_type: VARCHAR(16777216)
        sample_values:
          - AR
          - NV
          - TX
      - name: HCP_P_STATE_LIC_STATUS
        description: The status of a healthcare provider's professional state license.
        expr: HCP_P_STATE_LIC_STATUS
        data_type: VARCHAR(16777216)
        sample_values:
          - INACTIVE
          - ACTIVE
      - name: HCP_PDRP_OPTOUT_IND
        description: Healthcare provider Patient Data Request Program opt-out indicator.
        expr: HCP_PDRP_OPTOUT_IND
        data_type: VARCHAR(16777216)
        sample_values:
          - 'Y'
          - 'N'
      - name: HCP_PHONE_HOME_P
        description: Healthcare provider's home phone number.
        expr: HCP_PHONE_HOME_P
        data_type: VARCHAR(16777216)
      - name: HCP_PHONE_MOBILE_P
        description: Mobile phone number for the healthcare provider.
        expr: HCP_PHONE_MOBILE_P
        data_type: VARCHAR(16777216)
      - name: HCP_PHONE_WORK_P
        description: Work phone numbers for healthcare providers.
        expr: HCP_PHONE_WORK_P
        data_type: VARCHAR(16777216)
        sample_values:
          - '3604862900'
          - '2183486888'
          - '9155323937'
      - name: HCP_S_DEA_BUSINESS_ACTIVITY_CD
        description: Drug Enforcement Administration business activity code for healthcare providers.
        expr: HCP_S_DEA_BUSINESS_ACTIVITY_CD
        data_type: VARCHAR(16777216)
      - name: HCP_S_DEA_DRUG_SCHEDULE
        description: A column holding data of type VARCHAR(16777216).
        expr: HCP_S_DEA_DRUG_SCHEDULE
        data_type: VARCHAR(16777216)
      - name: HCP_S_DEA_LIC_STATUS_CD
        description: Healthcare provider Drug Enforcement Administration license status code.
        expr: HCP_S_DEA_LIC_STATUS_CD
        data_type: VARCHAR(16777216)
        sample_values:
          - ACTIVE
      - name: HCP_S_DEA_NUM
        description: Drug Enforcement Administration number assigned to healthcare providers for prescribing controlled substances.
        expr: HCP_S_DEA_NUM
        data_type: VARCHAR(16777216)
        sample_values:
          - FG6124919
          - FF8289161
      - name: HCP_S_DEA_STATE_OF_LICENSURE
        description: The state where the healthcare provider's Drug Enforcement Administration license was issued.
        expr: HCP_S_DEA_STATE_OF_LICENSURE
        data_type: VARCHAR(16777216)
        sample_values:
          - VA
          - NE
      - name: HCP_S_HIN
        description: A column holding data of type VARCHAR(16777216).
        expr: HCP_S_HIN
        data_type: VARCHAR(16777216)
      - name: HCP_S_MA_ID
        description: Healthcare provider master agreement identifier.
        expr: HCP_S_MA_ID
        data_type: VARCHAR(16777216)
        sample_values:
          - '381767'
          - '808700'
          - '469231'
      - name: HCP_S_NPI_NUM
        description: National Provider Identifier number for healthcare providers.
        expr: HCP_S_NPI_NUM
        data_type: VARCHAR(16777216)
        sample_values:
          - '1003443490'
          - '1396321816'
          - '1295437895'
      - name: HCP_S_STATE_LIC_NUM
        description: State license numbers for healthcare providers.
        expr: HCP_S_STATE_LIC_NUM
        data_type: VARCHAR(16777216)
        sample_values:
          - RN528086L
          - 053978-23
          - '22566'
      - name: HCP_S_STATE_LIC_STATE_CD
        description: State code where the healthcare provider holds their professional license.
        expr: HCP_S_STATE_LIC_STATE_CD
        data_type: VARCHAR(16777216)
        sample_values:
          - CT
          - WI
      - name: HCP_S_STATE_LIC_STATUS
        description: The status of a healthcare provider's state license.
        expr: HCP_S_STATE_LIC_STATUS
        data_type: VARCHAR(16777216)
        sample_values:
          - PROBATION
          - ACTIVE
      - name: HCP_SRC_ID_10_IMS2
        description: Healthcare provider source identifier from IMS database system.
        expr: HCP_SRC_ID_10_IMS2
        data_type: VARCHAR(16777216)
        sample_values:
          - '7692967'
          - '24968143'
          - '8098879'
      - name: HCP_SRC_ID_3_SCRUB
        description: Healthcare provider source identifier from the third data source after data scrubbing processes.
        expr: HCP_SRC_ID_3_SCRUB
        data_type: VARCHAR(16777216)
        sample_values:
          - WUSM01621661
          - WUSR06017841
          - WUSP00548392
      - name: HCP_SRC_ID_4_SFA
        description: A column holding data of type VARCHAR(16777216).
        expr: HCP_SRC_ID_4_SFA
        data_type: VARCHAR(16777216)
      - name: HCP_SRC_ID_5_SFA
        description: A column holding data of type VARCHAR(16777216).
        expr: HCP_SRC_ID_5_SFA
        data_type: VARCHAR(16777216)
      - name: HCP_SRC_ID_CF_SPDI
        description: A column holding data of type VARCHAR(16777216).
        expr: HCP_SRC_ID_CF_SPDI
        data_type: VARCHAR(16777216)
      - name: HCP_SRC_ID_IMS
        description: Healthcare provider source identifier from IMS data system.
        expr: HCP_SRC_ID_IMS
        data_type: VARCHAR(16777216)
        sample_values:
          - '7182700'
          - '1292510'
          - '2851684'
      - name: HCP_SRC_ID_OH_TDDD
        description: A column holding data of type VARCHAR(16777216).
        expr: HCP_SRC_ID_OH_TDDD
        data_type: VARCHAR(16777216)
        sample_values:
          - '020363900'
          - '021366000'
      - name: HCP_SRC_ID_P_CLIENT
        description: A column holding data of type VARCHAR(16777216).
        expr: HCP_SRC_ID_P_CLIENT
        data_type: VARCHAR(16777216)
      - name: HCP_SRC_ID_P_COPROMO
        description: A column holding data of type VARCHAR(16777216).
        expr: HCP_SRC_ID_P_COPROMO
        data_type: VARCHAR(16777216)
      - name: HCP_SRC_ID_P_SCRUB
        description: Healthcare provider source identifier after data scrubbing processes.
        expr: HCP_SRC_ID_P_SCRUB
        data_type: VARCHAR(16777216)
        sample_values:
          - '13322122'
          - '15733078'
      - name: HCP_SRC_ID_P_SFA
        description: A column holding data of type VARCHAR(16777216).
        expr: HCP_SRC_ID_P_SFA
        data_type: VARCHAR(16777216)
      - name: HCP_SRC_ID_P_SP
        description: A column holding data of type VARCHAR(16777216).
        expr: HCP_SRC_ID_P_SP
        data_type: VARCHAR(16777216)
      - name: HCP_SRC_ID_S_CLIENT
        description: A column holding data of type VARCHAR(16777216).
        expr: HCP_SRC_ID_S_CLIENT
        data_type: VARCHAR(16777216)
      - name: HCP_SRC_ID_S_COPROMO
        description: A column holding data of type VARCHAR(16777216).
        expr: HCP_SRC_ID_S_COPROMO
        data_type: VARCHAR(16777216)
      - name: HCP_SRC_ID_S_SCRUB
        description: Healthcare provider source identifier after data scrubbing processes.
        expr: HCP_SRC_ID_S_SCRUB
        data_type: VARCHAR(16777216)
        sample_values:
          - WUSM05200310
          - WUSM04669326
          - WUSM00017540
      - name: HCP_SRC_ID_S_SFA
        description: A column holding data of type VARCHAR(16777216).
        expr: HCP_SRC_ID_S_SFA
        data_type: VARCHAR(16777216)
      - name: HCP_SRC_ID_S_SP
        description: A column holding data of type VARCHAR(16777216).
        expr: HCP_SRC_ID_S_SP
        data_type: VARCHAR(16777216)
      - name: HCP_SRC_ID_SHA
        description: A column holding data of type VARCHAR(16777216).
        expr: HCP_SRC_ID_SHA
        data_type: VARCHAR(16777216)
      - name: HCP_SRC_ID_T_COPROMO
        description: A column holding data of type VARCHAR(16777216).
        expr: HCP_SRC_ID_T_COPROMO
        data_type: VARCHAR(16777216)
      - name: HCP_SRC_ID_T_SFA
        description: A column holding data of type VARCHAR(16777216).
        expr: HCP_SRC_ID_T_SFA
        data_type: VARCHAR(16777216)
      - name: HCP_SRC_ID_T_SP
        description: A column holding data of type VARCHAR(16777216).
        expr: HCP_SRC_ID_T_SP
        data_type: VARCHAR(16777216)
      - name: HCP_SUFFIX
        description: Healthcare provider name suffix such as senior or junior designations.
        expr: HCP_SUFFIX
        data_type: VARCHAR(16777216)
        sample_values:
          - JR
          - II
          - SR
      - name: HCP_T_DEA_BUSINESS_ACTIVITY_CD
        description: Drug Enforcement Administration business activity code for healthcare providers.
        expr: HCP_T_DEA_BUSINESS_ACTIVITY_CD
        data_type: VARCHAR(16777216)
      - name: HCP_T_DEA_DRUG_SCHEDULE
        description: A column holding data of type VARCHAR(16777216).
        expr: HCP_T_DEA_DRUG_SCHEDULE
        data_type: VARCHAR(16777216)
      - name: HCP_T_DEA_LIC_STATUS_CD
        description: Healthcare provider Drug Enforcement Administration license status code.
        expr: HCP_T_DEA_LIC_STATUS_CD
        data_type: VARCHAR(16777216)
        sample_values:
          - ACTIVE
      - name: HCP_T_DEA_NUM
        description: Drug Enforcement Administration number for healthcare providers.
        expr: HCP_T_DEA_NUM
        data_type: VARCHAR(16777216)
        sample_values:
          - FK9444655
          - FB3199975
      - name: HCP_T_DEA_STATE_OF_LICENSURE
        description: The state where the healthcare provider's Drug Enforcement Administration license was issued.
        expr: HCP_T_DEA_STATE_OF_LICENSURE
        data_type: VARCHAR(16777216)
        sample_values:
          - SD
          - TN
      - name: HCP_T_HIN
        description: A column holding data of type VARCHAR(16777216).
        expr: HCP_T_HIN
        data_type: VARCHAR(16777216)
      - name: HCP_T_MA_ID
        description: A column holding data of type VARCHAR(16777216).
        expr: HCP_T_MA_ID
        data_type: VARCHAR(16777216)
        sample_values:
          - '634359'
          - '526408'
      - name: HCP_T_NPI_NUM
        description: National Provider Identifier number for healthcare providers.
        expr: HCP_T_NPI_NUM
        data_type: VARCHAR(16777216)
      - name: HCP_T_STATE_LIC_NUM
        description: Healthcare provider state license numbers.
        expr: HCP_T_STATE_LIC_NUM
        data_type: VARCHAR(16777216)
        sample_values:
          - '0810007329'
          - '23410'
      - name: HCP_T_STATE_LIC_STATE_CD
        description: The state code where the healthcare provider holds their license.
        expr: HCP_T_STATE_LIC_STATE_CD
        data_type: VARCHAR(16777216)
        sample_values:
          - MD
          - FL
      - name: HCP_T_STATE_LIC_STATUS
        description: The status of a healthcare provider's state license.
        expr: HCP_T_STATE_LIC_STATUS
        data_type: VARCHAR(16777216)
        sample_values:
          - INACTIVE
          - ACTIVE
      - name: HCP_TITLE
        description: Healthcare provider professional title or designation.
        expr: HCP_TITLE
        data_type: VARCHAR(16777216)
      - name: KOL_IND
        description: Key opinion leader indicator flag.
        expr: KOL_IND
        data_type: VARCHAR(16777216)
      - name: NO_SEE_IND
        description: A column holding data of type VARCHAR(16777216).
        expr: NO_SEE_IND
        data_type: VARCHAR(16777216)
      - name: SAMPLEABILITY_IND
        description: An indicator of whether the healthcare provider can be sampled.
        expr: SAMPLEABILITY_IND
        data_type: VARCHAR(16777216)
    time_dimensions:
      - name: HCP_BIRTH_DT
        description: Healthcare provider birth dates.
        expr: HCP_BIRTH_DT
        data_type: DATE
        sample_values:
          - '1968-01-01'
          - '1971-01-01'
          - '1978-01-01'
      - name: HCP_P_DEA_EXP_DT
        description: The expiration date of the healthcare provider's Drug Enforcement Administration registration.
        expr: HCP_P_DEA_EXP_DT
        data_type: DATE
        sample_values:
          - '2028-01-31'
          - '2028-05-31'
          - '2027-02-28'
      - name: HCP_P_STATE_LIC_EXP_DT
        description: The expiration date of the healthcare provider's state license.
        expr: HCP_P_STATE_LIC_EXP_DT
        data_type: DATE
        sample_values:
          - '2027-08-31'
          - '2028-08-31'
          - '2025-11-30'
      - name: HCP_P_STATE_LIC_ISSUE_DT
        description: The date when the healthcare provider's state license was issued.
        expr: HCP_P_STATE_LIC_ISSUE_DT
        data_type: DATE
        sample_values:
          - '2022-07-01'
          - '2020-02-13'
          - '2024-06-23'
      - name: HCP_PDRP_OPTOUT_DT
        description: The date when a healthcare provider opted out of the Prescription Drug Reporting Program.
        expr: HCP_PDRP_OPTOUT_DT
        data_type: DATE
        sample_values:
          - '2008-12-04'
          - '2008-11-27'
      - name: HCP_S_DEA_EXP_DT
        description: The expiration date of the healthcare provider's Drug Enforcement Administration registration.
        expr: HCP_S_DEA_EXP_DT
        data_type: DATE
        sample_values:
          - '2026-07-31'
          - '2026-12-31'
          - '2026-03-31'
      - name: HCP_S_STATE_LIC_EXP_DT
        description: The expiration date of the healthcare provider's state license.
        expr: HCP_S_STATE_LIC_EXP_DT
        data_type: DATE
        sample_values:
          - '2026-04-05'
          - '2026-02-04'
          - '2027-03-01'
      - name: HCP_S_STATE_LIC_ISSUE_DT
        description: The date when the healthcare provider's state license was issued.
        expr: HCP_S_STATE_LIC_ISSUE_DT
        data_type: DATE
        sample_values:
          - '2019-04-23'
          - '2021-05-14'
      - name: HCP_T_DEA_EXP_DT
        description: The expiration date of the healthcare provider's Drug Enforcement Administration registration.
        expr: HCP_T_DEA_EXP_DT
        data_type: DATE
        sample_values:
          - '2028-04-30'
          - '2026-08-31'
          - '2027-10-31'
      - name: HCP_T_STATE_LIC_EXP_DT
        description: The expiration date of the healthcare provider's state license.
        expr: HCP_T_STATE_LIC_EXP_DT
        data_type: DATE
        sample_values:
          - '2026-10-31'
          - '2025-12-31'
          - '2026-09-30'
      - name: HCP_T_STATE_LIC_ISSUE_DT
        description: The date when the healthcare provider's state license was issued.
        expr: HCP_T_STATE_LIC_ISSUE_DT
        data_type: DATE
        sample_values:
          - '2002-05-08'
          - '2022-02-18'
      - name: SAMPLEABILITY_DT
        description: The date when sampleability status was determined or last updated.
        expr: SAMPLEABILITY_DT
        data_type: DATE
    facts:
      - name: HCP_STATUS_KEY
        description: Healthcare provider status identifier used as a foreign key reference.
        expr: HCP_STATUS_KEY
        data_type: NUMBER(38,0)
        access_modifier: public_access
        sample_values:
          - '1'
      - name: HCP_SUBTYPE_KEY
        description: Healthcare provider subtype identifier key.
        expr: HCP_SUBTYPE_KEY
        data_type: NUMBER(38,0)
        access_modifier: public_access
        sample_values:
          - '9'
          - '10'
          - '13'
    primary_key:
      columns:
        - HCP_KEY
  - name: TD_PROD_BRAND
    description: The table contains records of product brand and categorization information used for sales performance reporting. Each record represents a product hierarchy structure that includes market segments, category groupings, individual categories, family groupings, and product families with their corresponding identifiers and descriptions.
    base_table:
      database: DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB
      schema: REPORTING
      table: TD_PROD_BRAND
    dimensions:
      - name: PROD_BRAND_CD
        description: Product brand codes for pharmaceutical and medical products.
        expr: PROD_BRAND_CD
        data_type: VARCHAR(256)
        sample_values:
          - ANOLOR 300
          - CHILDRENS Q-PAP
          - TENCON
      - name: PROD_BRAND_DESC
        description: Brand names of pharmaceutical pain management products along with their associated market categories.
        expr: PROD_BRAND_DESC
        data_type: VARCHAR(256)
        sample_values:
          - BUFFERED ASPIRIN EXTRA S BRAND (VERTEX ACUTE MARKET)
          - LIDOPRIL XR BRAND (ACUTE HEOR MARKET)
          - RA ORASOL BRAND (VERTEX ACUTE MARKET)
      - name: PROD_BRAND_KEY
        description: A unique identifier key for product brands.
        expr: PROD_BRAND_KEY
        data_type: VARCHAR(32)
        sample_values:
          - a96f921f9adcf6357022ae1d77e0036e
          - 77238a2664c2da30f3763020cc9f64a1
          - a3013ea55958b130a8be56287a23ac84
      - name: PROD_BRAND_SDESC
        description: Product brand short description or name.
        expr: PROD_BRAND_SDESC
        data_type: VARCHAR(256)
        sample_values:
          - RECTASMOOTHE
          - LIDOVIX L
          - NUVAKAAN-II
      - name: PROD_BRAND_UCD
        description: Brand names of pharmaceutical and over-the-counter medical products.
        expr: PROD_BRAND_UCD
        data_type: VARCHAR(256)
        sample_values:
          - CAPSAICIN TOPICAL PAIN P
          - PAIN-EZE PLUS
          - PRILO PATCH II
      - name: PROD_CAT_CD
        description: Pharmaceutical product category codes indicating the therapeutic classification of medical products.
        expr: PROD_CAT_CD
        data_type: VARCHAR(256)
        sample_values:
          - DERMATOLOGICAL TOPICAL ANESTHETIC COMBINATIONS
          - LIDOCAINE - ANESTHETIC
          - AMIDES
      - name: PROD_CAT_DESC
        description: Product category descriptions for pharmaceutical pain management treatments.
        expr: PROD_CAT_DESC
        data_type: VARCHAR(256)
        sample_values:
          - ANALGESICS-SEDATIVE COMBINATION CATEGORY (ANY PAIN MARKET)
          - LIDOCAINE - ANESTHETIC CATEGORY (VERTEX ACUTE MARKET)
          - DENTAL LOCAL ANESTHETIC CATEGORY (ANY PAIN MARKET)
      - name: PROD_CAT_KEY
        description: A unique identifier key for product categories.
        expr: PROD_CAT_KEY
        data_type: VARCHAR(32)
        sample_values:
          - 12bc423a463b94db26c110a7b5f35c2b
          - 51d89477c08fab581269b5cd07cc9249
          - 6cdf4a9156745f9ceab6a9d55493f62f
      - name: PROD_CAT_SDESC
        description: Product category short descriptions for pharmaceutical and medical products.
        expr: PROD_CAT_SDESC
        data_type: VARCHAR(256)
        sample_values:
          - RHEUMATOID ARTHRITIS
          - DERMATOLOGICAL TOPICAL ANESTHETIC
          - SSRI
      - name: PROD_CATGRP_CD
        description: Product category group codes representing different pharmaceutical and medical product classifications.
        expr: PROD_CATGRP_CD
        data_type: VARCHAR(256)
        sample_values:
          - OSTEOARTHRITIS
          - ANESTHETIC
          - DENTALS
      - name: PROD_CATGRP_DESC
        description: Product category group descriptions for pharmaceutical products in acute care markets.
        expr: PROD_CATGRP_DESC
        data_type: VARCHAR(256)
        sample_values:
          - OTHER CATEGORY GROUP (ANY PAIN MARKET)
          - DERMATOLOGICAL CATEGORY GROUP (VERTEX ACUTE MARKET)
          - NON-NARCOTIC ANALGESIC CATEGORY GROUP (VERTEX ACUTE MARKET)
      - name: PROD_CATGRP_KEY
        description: A unique identifier key for product category groups.
        expr: PROD_CATGRP_KEY
        data_type: VARCHAR(32)
        sample_values:
          - ae4d74c1255ef3b525bf3ee4914ed273
          - a9946aba572bb08c111e94c3c36c84f7
          - d8cad3b14468ba5121e210028e133b00
      - name: PROD_CATGRP_SDESC
        description: Product category group short description indicating the therapeutic classification or type of pharmaceutical product.
        expr: PROD_CATGRP_SDESC
        data_type: VARCHAR(256)
        sample_values:
          - ANESTHETIC
          - DENTALS
          - NON-NARCOTIC ANALGESIC
      - name: PROD_FAM_CD
        description: Product family codes used to categorize and group related products.
        expr: PROD_FAM_CD
        data_type: VARCHAR(256)
        sample_values:
          - HYCOGESIC
          - PAMPRIN
          - ENDOLOR
      - name: PROD_FAM_DESC
        description: Product family descriptions for pain relief medications and treatments.
        expr: PROD_FAM_DESC
        data_type: VARCHAR(256)
        sample_values:
          - EFFEXOR XR FAMILY (ACUTE HEOR MARKET)
          - ENDOLOR FAMILY (ANY PAIN MARKET)
          - DYNAMIC FAMILY (ANY PAIN MARKET)
      - name: PROD_FAM_KEY
        description: A unique identifier key for product families.
        expr: PROD_FAM_KEY
        data_type: VARCHAR(32)
        sample_values:
          - 10738f1513e6f471c10da189c7b6db7c
          - 5e208a4effc1cd0786bed71851c6964f
          - 1ab075c96c0468e9796a665631ad472e
      - name: PROD_FAM_SDESC
        description: Pharmaceutical product family short descriptions or names.
        expr: PROD_FAM_SDESC
        data_type: VARCHAR(256)
        sample_values:
          - CHLORASEPTIC SR THRT
          - CHILDRENS Q-PAP
          - SYNOFLEX
      - name: PROD_FAMGRP_CD
        description: Active pharmaceutical ingredients or drug compounds used in pain management products.
        expr: PROD_FAMGRP_CD
        data_type: VARCHAR(256)
        sample_values:
          - CAPSAICIN-MENTHOL - DERMATOLOGICAL TOPICAL ANESTHETIC COMBINATIONS
          - HYDROCODONE
          - BENZOCAINE-ZINC CHLORIDE
      - name: PROD_FAMGRP_DESC
        description: Pharmaceutical product family group descriptions indicating drug types and their associated pain market categories.
        expr: PROD_FAMGRP_DESC
        data_type: VARCHAR(256)
        sample_values:
          - CAPSAICIN FAMILY GROUP (ANY PAIN MARKET)
          - BENZOCAINE-ZINC CHLORIDE FAMILY GROUP (ANY PAIN MARKET)
          - OXYCODONE COMBINATIONS FAMILY GROUP (ACUTE HEOR MARKET)
      - name: PROD_FAMGRP_KEY
        description: A unique identifier key for product family groups represented as a hash value.
        expr: PROD_FAMGRP_KEY
        data_type: VARCHAR(32)
        sample_values:
          - e86d9067df720cbe38d87f1d1e6ba4bb
          - 2d8609830dfd91355e0f57b69a124265
          - 2c25349bf27be50f2527bb0084f0f4d2
      - name: PROD_FAMGRP_SDESC
        description: Pharmaceutical product family group short descriptions indicating the active ingredient or drug category.
        expr: PROD_FAMGRP_SDESC
        data_type: VARCHAR(256)
        sample_values:
          - DESIPRAMINE
          - BENZOCAINE - DERMATOLOGICAL TOPICAL ANESTHETIC COMBINATIONS
          - LIDOCAINE - DERMATOLOGICAL TOPICAL ANESTHETIC COMBINATIONS
      - name: PROD_MKT_CD
        description: Product marketing code identifying the specific marketing category or segment for the product brand.
        expr: PROD_MKT_CD
        data_type: VARCHAR(256)
        sample_values:
          - ACUTE HEOR
          - ANY PAIN
          - VERTEX ACUTE
      - name: PROD_MKT_DESC
        description: Product market description indicating the specific market segment or category for the product.
        expr: PROD_MKT_DESC
        data_type: VARCHAR(256)
        sample_values:
          - VERTEX ACUTE MARKET
          - ACUTE HEOR MARKET
          - ANY PAIN MARKET
      - name: PROD_MKT_KEY
        description: A unique marketing key identifier for products.
        expr: PROD_MKT_KEY
        data_type: VARCHAR(32)
        sample_values:
          - da0dacac9831661226335a3eb0b04274
          - 89cf3596760b4a79df67736f2272a1b7
          - c8c606d1c69b2144eea5bbe3157289b6
      - name: PROD_MKT_SDESC
        description: Product marketing short description for pharmaceutical pain management brands.
        expr: PROD_MKT_SDESC
        data_type: VARCHAR(256)
        sample_values:
          - ACUTE HEOR
          - ANY PAIN
          - VERTEX ACUTE
    primary_key:
      columns:
        - PROD_BRAND_KEY
  - name: TM_ARD_HCP_ACUTE_MKT_WEEKLY_XPO
    description: The table contains records of healthcare provider prescription activity in acute care settings, tracked on a weekly basis. Each record represents prescription exposure data for a specific healthcare provider and includes provider identifiers, specialty information, territorial assignments, and prescription metrics for acute care treatments.
    base_table:
      database: DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB
      schema: REPORTING
      table: TM_ARD_HCP_ACUTE_MKT_WEEKLY_XPO
    dimensions:
      - name: BRANDED_FLAG
        description: A flag indicating whether the product is branded or not.
        expr: BRANDED_FLAG
        data_type: VARCHAR(16777216)
        sample_values:
          - 'N'
          - 'Y'
      - name: GOLDEN_ID
        description: A unique identifier used to link and track healthcare providers across different systems and databases.
        expr: GOLDEN_ID
        data_type: VARCHAR(16777216)
        sample_values:
          - GLD000600060001002101
          - GLD999900180020002401
          - GLD021402140287037101
      - name: HCP_ID
        description: Unique identifier for healthcare providers.
        expr: HCP_ID
        data_type: VARCHAR(32)
        sample_values:
          - b53fb88ce1b284c55206728afb2a9da6
          - e32c570ee80606057196f62cf5b6e502
          - 132c4377c0b6eee2172aefb7d046b30e
      - name: HCP_SPECIALTY
        description: Medical specialty or practice area of the healthcare provider.
        expr: HCP_SPECIALTY
        data_type: VARCHAR(16777216)
        sample_values:
          - ADULT RECONSTRUCTIVE ORTHOPEDICS
          - EMERGENCY MEDICINE
          - DENTIST
      - name: HCP_SPECIALTY_GROUP
        description: Healthcare provider specialty groups categorizing medical professionals by their area of practice.
        expr: HCP_SPECIALTY_GROUP
        data_type: VARCHAR(16777216)
        sample_values:
          - MEDICINE
          - PHYSICIAN EXTENDERS
          - ORTHOPEDICS AND SPORTS MEDICINE
      - name: NPI
        description: National Provider Identifier numbers for healthcare providers.
        expr: NPI
        data_type: VARCHAR(16777216)
        sample_values:
          - '1194281006'
          - '1659465573'
          - '1396203352'
      - name: ONEKEY_HCP_ID
        description: Unique identifier for healthcare providers in the OneKey system.
        expr: ONEKEY_HCP_ID
        data_type: VARCHAR(16777216)
        sample_values:
          - WUSD00201756
          - WUSM00530772
          - WUSM00311233
      - name: PRODUCT_CATEGORY
        description: Categories of pharmaceutical products used for pain management and treatment.
        expr: PRODUCT_CATEGORY
        data_type: VARCHAR(256)
        sample_values:
          - NSAID
          - STRONG OPIOID AGONIST
          - ANTICONVULSANTS MISC.
      - name: PRODUCT_FAMILY_GROUP
        description: Pharmaceutical product family groups categorizing related medications and therapeutic compounds.
        expr: PRODUCT_FAMILY_GROUP
        data_type: VARCHAR(256)
        sample_values:
          - LIDOCAINE - DERMATOLOGICAL LOCAL TOPICAL ANESTHETIC
          - MELOXICAM
          - HYDROCODONE COMBINATIONS
      - name: PTAM_TERRITORY_ID
        description: Unique identifier for a PTAM (Pain Territory Account Manager) territory.
        expr: PTAM_TERRITORY_ID
        data_type: VARCHAR(255)
        sample_values:
          - V1NAUSA-5733101
          - V1NAUSA-5733602
          - V1NAUSA-5733604
      - name: ROA
        description: Route of administration for pharmaceutical products.
        expr: ROA
        data_type: VARCHAR(256)
        sample_values:
          - ORAL
          - TOPICAL
          - TOPICAL-PATCH
      - name: SAL_TERRITORY_ID
        description: Sales territory identifier used to designate specific geographic or organizational sales regions.
        expr: SAL_TERRITORY_ID
        data_type: VARCHAR(255)
        sample_values:
          - V1NAUSA-5720008
          - V1NAUSA-5720014
      - name: SITE_OF_CARE_ZIP_CODE
        description: ZIP codes for healthcare facility locations.
        expr: SITE_OF_CARE_ZIP_CODE
        data_type: VARCHAR(16777216)
        sample_values:
          - '73118'
          - '43228'
          - '37027'
      - name: VERTEX_ID
        description: Unique identifier for a vertex in the healthcare provider network.
        expr: VERTEX_ID
        data_type: VARCHAR(16777216)
        sample_values:
          - '15670811'
          - '14499271'
      - name: ZIP_CODE
        description: Postal ZIP codes for geographic locations.
        expr: ZIP_CODE
        data_type: VARCHAR(16777216)
        sample_values:
          - '20850'
          - '33912'
          - '90262'
    time_dimensions:
      - name: DATE_KEY
        description: The date associated with each record in the healthcare provider acute market weekly exposure data.
        expr: DATE_KEY
        data_type: DATE
        sample_values:
          - '2024-05-17'
          - '2024-12-06'
          - '2025-02-07'
    facts:
      - name: ACUTE_NRX_XPO
        description: Acute new prescription exposure index for healthcare providers in the market.
        expr: ACUTE_NRX_XPO
        data_type: NUMBER(38,10)
        access_modifier: public_access
        sample_values:
          - '2.0320000000'
          - '0.9650000000'
          - '1.0420000000'
      - name: ACUTE_TRX_XPO
        description: Acute transaction exposure metric for healthcare providers in the market.
        expr: ACUTE_TRX_XPO
        data_type: NUMBER(38,10)
        access_modifier: public_access
        sample_values:
          - '1.6080000000'
          - '1.0300000000'
          - '0.9630000000'
      - name: ACUTE_TX_DAYS_XPO
        description: The number of days of acute treatment exposure.
        expr: ACUTE_TX_DAYS_XPO
        data_type: NUMBER(38,10)
        access_modifier: public_access
        sample_values:
          - '4.2033678514'
          - '3.2592136056'
          - '24.4437444312'
      - name: ACUTE_UNITS_XPO
        description: Acute care units exposure metric.
        expr: ACUTE_UNITS_XPO
        data_type: NUMBER(38,10)
        access_modifier: public_access
        sample_values:
          - '61.1900000000'
          - '160.0900000000'
          - '30.0000000000'
      - name: WEEK_DT
        description: The date representing a specific week in the healthcare provider acute market reporting period.
        expr: WEEK_DT
        data_type: NUMBER(10,0)
        access_modifier: public_access
        sample_values:
          - '20251024'
          - '20241220'
          - '20250321'
relationships:
  # Relationship between Weekly LAAD Facts and HCP Dimension
  - name: laad_weekly_to_hcp
    left_table: ARD_GIACO_TM_HCP_ACUTE_MKT_WEEKLY_LAAD
    right_table: TD_HCP
    relationship_columns:
      - left_column: HCP_ID
        right_column: HCP_KEY
    join_type: left_outer
    relationship_type: many_to_one

  # Relationship between Weekly Exposure (XPO) Facts and HCP Dimension
  - name: xpo_weekly_to_hcp
    left_table: TM_ARD_HCP_ACUTE_MKT_WEEKLY_XPO
    right_table: TD_HCP
    relationship_columns:
      - left_column: HCP_ID
        right_column: HCP_KEY
    join_type: left_outer
    relationship_type: many_to_one

  # Relationship between Weekly LAAD Facts and Postal Geography
  # Connecting via ZIP Code as the common identifier
  - name: laad_weekly_to_postal
    left_table: ARD_GIACO_TM_HCP_ACUTE_MKT_WEEKLY_LAAD
    right_table: TD_GEO_POSTAL
    relationship_columns:
      - left_column: ZIP_CODE
        right_column: GEO_POSTAL_CD
    join_type: left_outer
    relationship_type: many_to_one

  # Relationship between Weekly Exposure (XPO) Facts and Postal Geography
  # Connecting via ZIP Code as the common identifier
  - name: xpo_weekly_to_postal
    left_table: TM_ARD_HCP_ACUTE_MKT_WEEKLY_XPO
    right_table: TD_GEO_POSTAL
    relationship_columns:
      - left_column: ZIP_CODE
        right_column: GEO_POSTAL_CD
    join_type: left_outer
    relationship_type: many_to_one

  # Relationship between Cities and States (Geographic Hierarchy)
  - name: city_to_state
    left_table: TD_GEO_CITY
    right_table: TD_GEO_STATE
    relationship_columns:
      - left_column: GEO_STATE_KEY
        right_column: GEO_STATE_KEY
    join_type: left_outer
    relationship_type: many_to_one

  # Relationship between Postal Codes and States (Geographic Hierarchy)
  - name: postal_to_state
    left_table: TD_GEO_POSTAL
    right_table: TD_GEO_STATE
    relationship_columns:
      - left_column: GEO_STATE_KEY
        right_column: GEO_STATE_KEY
    join_type: left_outer
    relationship_type: many_to_one

  # Relationship between Specific Locations and Cities (Geographic Hierarchy)
  - name: location_to_city
    left_table: TD_GEO_LOC
    right_table: TD_GEO_CITY
    relationship_columns:
      - left_column: GEO_CITY_KEY
        right_column: GEO_CITY_KEY
    join_type: left_outer
    relationship_type: many_to_one

  # Relationship between Specific Locations and Postal Codes (Geographic Hierarchy)
  - name: location_to_postal
    left_table: TD_GEO_LOC
    right_table: TD_GEO_POSTAL
    relationship_columns:
      - left_column: GEO_POSTAL_KEY
        right_column: GEO_POSTAL_KEY
    join_type: left_outer
    relationship_type: many_to_one

  # Relationship between Specific Locations and States (Geographic Hierarchy)
  - name: location_to_state
    left_table: TD_GEO_LOC
    right_table: TD_GEO_STATE
    relationship_columns:
      - left_column: GEO_STATE_KEY
        right_column: GEO_STATE_KEY
    join_type: left_outer
    relationship_type: many_to_one
def main(session: Session, user_query: str, parent_node_ids_json: str, tree_id: str = ''Pharma_Master_v1''):
    try:
        log_debug(session, "MAIN_ENTRY", f"TreeID: {tree_id}, Query: {user_query}")

        # 1. Load Decision Tree Structure
        tree_row = session.sql("SELECT GRAPH_JSON FROM DECISION_TREE_STORE_NEW WHERE TREE_ID = ?", params=[tree_id]).collect()
        
        if not tree_row: 
            return json.dumps({"error": f"Tree ID not found: {tree_id}"})
        
        full_json = json.loads(tree_row[0][''GRAPH_JSON''])
        graph = full_json.get(''graph'', full_json)
        
        # Build Lookup Maps
        all_nodes_map = {n[''id'']: n for n in graph.get(''nodes'', [])}
        name_to_node_map = {n[''metric'']: n for n in graph.get(''nodes'', [])}
        all_edges = graph.get(''edges'', [])

        # 2. Determine Strategy (Search vs Drill)
        targets_phase_1 = []
        
        # Robust Null Check
        is_drill_mode = (
            parent_node_ids_json is not None and 
            parent_node_ids_json != '''' and 
            parent_node_ids_json.upper() != ''NULL'' and 
            parent_node_ids_json != ''[]''
        )

        if not is_drill_mode and user_query:
            log_debug(session, "STRATEGY", "Vector Search (No parent IDs provided)")
            # Vector Search for Entry Point
            vec_sql = """
            SELECT METRIC_NAME FROM KPI_KNOWLEDGE_BASE_NEW 
            ORDER BY VECTOR_L2_DISTANCE(SNOWFLAKE.CORTEX.EMBED_TEXT_768(''snowflake-arctic-embed-m-v1.5'', ?), KPI_EMBEDDING) ASC 
            LIMIT 1
            """
            kb_row = session.sql(vec_sql, params=[user_query]).collect()
            if kb_row and kb_row[0][''METRIC_NAME''] in name_to_node_map:
                found_metric = kb_row[0][''METRIC_NAME'']
                targets_phase_1.append(name_to_node_map[found_metric])
                log_debug(session, "ANCHOR_FOUND", f"Matched: {found_metric}")

        elif is_drill_mode:
            log_debug(session, "STRATEGY", "Drill Down (Parent IDs provided)")
            try:
                p_ids = json.loads(parent_node_ids_json)
                if not isinstance(p_ids, list): p_ids = [p_ids]
                parent_set = set(p_ids)
                
                # Find children of provided parents
                for edge in all_edges:
                    if edge[''source''] in all_nodes_map and edge[''target''] in parent_set:
                         # Note: Depending on edge direction (source->target), adjust accordingly.
                         # Assuming Source=Parent, Target=Child? Or Source=Metric, Target=Root?
                         # Usually standard DAG is Parent -> Child. 
                         # If input is ''Parent Nodes'', we want their children.
                         # CHECK: Your previous code checked ''target'' in parent_set. 
                         # If Edge is Source(Parent)->Target(Child), then Target in ParentSet means we are looking for parents?
                         # Let''s assume the previous logic was correct: "Find nodes connected to these parents"
                         if edge[''target''] in parent_set:
                             targets_phase_1.append(all_nodes_map[edge[''source'']])
            except Exception as e:
                log_debug(session, "DRILL_ERROR", str(e))

        # 3. Execute Phase 1 (Entry Nodes)
        results_phase_1 = execute_batch(session, targets_phase_1, user_query)

        # 4. Execute Phase 2 (Greedy Traversal of "Bad" Nodes)
        bad_ids = {r[''id''] for r in results_phase_1 if r.get(''status'') == ''bad''}
        targets_phase_2 = []
        
        if bad_ids:
            log_debug(session, "PHASE_2", f"Expanding bad nodes: {list(bad_ids)}")
            for edge in all_edges:
                # If a node was bad, check its relationships
                if edge[''target''] in bad_ids and edge[''source''] in all_nodes_map:
                    targets_phase_2.append(all_nodes_map[edge[''source'']])
        
        results_phase_2 = execute_batch(session, targets_phase_2, user_query)

        # 5. Final Output
        return json.dumps({
            "nodes_analyzed": results_phase_1 + results_phase_2,
            "edges_traversed": [e for e in all_edges if e[''target''] in bad_ids or e[''source''] in bad_ids]
        })

    except Exception as e:
        log_debug(session, "MAIN_CRASH", str(e))
        return json.dumps({"error": "Critical Procedure Error", "details": str(e), "trace": traceback.format_exc()})
';
    left_table: TD_HCO
    right_table: TD_HCO_SUBTYPE
    relationship_columns:
      - left_column: HCO_SUBTYPE_KEY
        right_column: HCO_SUBTYPE_KEY
    join_type: left_outer
    relationship_type: many_to_one
-- 1. Create the Raw Load Table
CREATE OR REPLACE TABLE RAW_PHARMA_SALES (
    ONEKEY_ID VARCHAR(50),
    HCP_ID VARCHAR(50),
    HCP_ZIP_CODE VARCHAR(20),
    TERRITORY_ID VARCHAR(50),
    HCO_NAME VARCHAR(255),
    HCP_NAME VARCHAR(255),
    PRIMARY_SPECIALTY_METRIC VARCHAR(255),
    HCP_STATE VARCHAR(50),
    HCP_CITY VARCHAR(100),
    ID VARCHAR(50),
    GEO_STATE_CD VARCHAR(10),
    GEO_CITY_NAME VARCHAR(100),
    LOC_ADDR_LINE_1 VARCHAR(255),
    LOC_ADDR_LINE_2 VARCHAR(255),
    LOC_ADDR_LINE_3 VARCHAR(255),
    PTAM_TERRITORY_ID VARCHAR(50),
    PROD_FAMGRP_CD VARCHAR(50),
    PROD_CATGRP_CD VARCHAR(50),
    PRODUCT_FAMILY_GROUP VARCHAR(100),
    PRODUCT_CATEGORY VARCHAR(100),
    ACUTE_TRX_LAAD NUMBER,
    ACUTE_NRX_XPO NUMBER,
    ACUTE_TRX_XPO NUMBER,
    HCO_NAME_2 VARCHAR(255),
    HCO_SUBTYPE_CD VARCHAR(50)
);
COPY INTO RAW_PHARMA_SALES
FROM'@"DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB"."AI_POC"."MY_EXCEL_STAGE"/data_sample.csv'
FILE_FORMAT = (TYPE = 'CSV' FIELD_OPTIONALLY_ENCLOSED_BY = '"' SKIP_HEADER = 1)
ON_ERROR = 'CONTINUE'; -- Keeps loading even if a few rows have errors
-- 2. Create the Requested View
CREATE OR REPLACE VIEW MASTER_DB_SAMPLE_DATA AS 
SELECT * FROM RAW_PHARMA_SALES;

-- 3. Clear Previous Knowledge Base Data
TRUNCATE TABLE KPI_KNOWLEDGE_BASE_NEW;
TRUNCATE TABLE DECISION_TREE_STORE_NEW;

INSERT INTO KPI_KNOWLEDGE_BASE_NEW (KPI_ID, METRIC_NAME, DESCRIPTION, SQL_QUERY, FEW_SHOT_EXAMPLES, KPI_EMBEDDING)

-- LEVEL 1: Market & Totals
SELECT 'K1', 'Total Market Volume (TRX)', 'Total volume of all acute prescriptions across the entire market.', 
'SELECT SUM(ACUTE_TRX_XPO) FROM MASTER_DB_SAMPLE_DATA', 
PARSE_JSON('[]'), SNOWFLAKE.CORTEX.EMBED_TEXT_768('snowflake-arctic-embed-m', 'Total Market Volume TRX all sales')

UNION ALL
SELECT 'K2', 'Total New Starts (NRX)', 'Total volume of new-to-therapy prescriptions, indicating market growth.', 
'SELECT SUM(ACUTE_NRX_XPO) FROM MASTER_DB_SAMPLE_DATA', 
PARSE_JSON('[]'), SNOWFLAKE.CORTEX.EMBED_TEXT_768('snowflake-arctic-embed-m', 'Total New Starts NRX growth')

-- LEVEL 2: Categories
UNION ALL
SELECT 'K3', 'Opioid Category Volume', 'Total prescriptions for the Opioid drug class (e.g., Tramadol).', 
'SELECT SUM(ACUTE_TRX_XPO) FROM MASTER_DB_SAMPLE_DATA WHERE PRODUCT_CATEGORY = ''OPIOID''', 
PARSE_JSON('[]'), SNOWFLAKE.CORTEX.EMBED_TEXT_768('snowflake-arctic-embed-m', 'Opioid Category Volume pain meds')

UNION ALL
SELECT 'K4', 'NSAID Category Volume', 'Total prescriptions for the NSAID drug class (e.g., Diclofenac).', 
'SELECT SUM(ACUTE_TRX_XPO) FROM MASTER_DB_SAMPLE_DATA WHERE PRODUCT_CATEGORY = ''NSAID''', 
PARSE_JSON('[]'), SNOWFLAKE.CORTEX.EMBED_TEXT_768('snowflake-arctic-embed-m', 'NSAID Category Volume anti inflammatory')

-- LEVEL 3: Products
UNION ALL
SELECT 'K5', 'Tramadol Brand Volume', 'Total prescriptions specifically for the Tramadol product family.', 
'SELECT SUM(ACUTE_TRX_XPO) FROM MASTER_DB_SAMPLE_DATA WHERE PRODUCT_FAMILY_GROUP = ''TRAMADOL''', 
PARSE_JSON('[]'), SNOWFLAKE.CORTEX.EMBED_TEXT_768('snowflake-arctic-embed-m', 'Tramadol Brand Volume product specific')

UNION ALL
SELECT 'K6', 'Diclofenac Brand Volume', 'Total prescriptions specifically for the Diclofenac product family.', 
'SELECT SUM(ACUTE_TRX_XPO) FROM MASTER_DB_SAMPLE_DATA WHERE PRODUCT_FAMILY_GROUP = ''DICLOFENAC''', 
PARSE_JSON('[]'), SNOWFLAKE.CORTEX.EMBED_TEXT_768('snowflake-arctic-embed-m', 'Diclofenac Brand Volume product specific')

-- LEVEL 4: Product Performance Metrics (New vs Refill)
UNION ALL
SELECT 'K7', 'Tramadol New Growth (NRX)', 'New patient prescriptions for Tramadol. Key indicator of sales force effectiveness.', 
'SELECT SUM(ACUTE_NRX_XPO) FROM MASTER_DB_SAMPLE_DATA WHERE PRODUCT_FAMILY_GROUP = ''TRAMADOL''', 
PARSE_JSON('[]'), SNOWFLAKE.CORTEX.EMBED_TEXT_768('snowflake-arctic-embed-m', 'Tramadol New Growth NRX new patients')

UNION ALL
SELECT 'K8', 'Tramadol Retention (Refills)', 'Volume of Tramadol refills (TRX minus NRX), indicating patient retention.', 
'SELECT SUM(ACUTE_TRX_XPO) - SUM(ACUTE_NRX_XPO) FROM MASTER_DB_SAMPLE_DATA WHERE PRODUCT_FAMILY_GROUP = ''TRAMADOL''', 
PARSE_JSON('[]'), SNOWFLAKE.CORTEX.EMBED_TEXT_768('snowflake-arctic-embed-m', 'Tramadol Retention Refills loyal patients')

UNION ALL
SELECT 'K9', 'Diclofenac New Growth (NRX)', 'New patient prescriptions for Diclofenac.', 
'SELECT SUM(ACUTE_NRX_XPO) FROM MASTER_DB_SAMPLE_DATA WHERE PRODUCT_FAMILY_GROUP = ''DICLOFENAC''', 
PARSE_JSON('[]'), SNOWFLAKE.CORTEX.EMBED_TEXT_768('snowflake-arctic-embed-m', 'Diclofenac New Growth NRX')

-- LEVEL 5: Specialist & Geography Segments
UNION ALL
SELECT 'K10', 'Orthopedic Tramadol Starts', 'New Tramadol prescriptions written specifically by Orthopedic Surgeons.', 
'SELECT SUM(ACUTE_NRX_XPO) FROM MASTER_DB_SAMPLE_DATA WHERE PRODUCT_FAMILY_GROUP = ''TRAMADOL'' AND PRIMARY_SPECIALTY_METRIC LIKE ''%Orthopedic%''', 
PARSE_JSON('[]'), SNOWFLAKE.CORTEX.EMBED_TEXT_768('snowflake-arctic-embed-m', 'Orthopedic Tramadol Starts surgeon new rx')

UNION ALL
SELECT 'K11', 'PCP Tramadol Starts', 'New Tramadol prescriptions written by Primary Care/Internal Medicine.', 
'SELECT SUM(ACUTE_NRX_XPO) FROM MASTER_DB_SAMPLE_DATA WHERE PRODUCT_FAMILY_GROUP = ''TRAMADOL'' AND PRIMARY_SPECIALTY_METRIC IN (''Other PCP Specialties'', ''Internal Medicine'')', 
PARSE_JSON('[]'), SNOWFLAKE.CORTEX.EMBED_TEXT_768('snowflake-arctic-embed-m', 'PCP Tramadol Starts primary care')

UNION ALL
SELECT 'K12', 'NC Market Volume', 'Total prescription volume in North Carolina, a key territory.', 
'SELECT SUM(ACUTE_TRX_XPO) FROM MASTER_DB_SAMPLE_DATA WHERE HCP_STATE = ''NC''', 
PARSE_JSON('[]'), SNOWFLAKE.CORTEX.EMBED_TEXT_768('snowflake-arctic-embed-m', 'NC Market Volume north carolina state')

UNION ALL
SELECT 'K13', 'AR Market Volume', 'Total prescription volume in Arkansas.', 
'SELECT SUM(ACUTE_TRX_XPO) FROM MASTER_DB_SAMPLE_DATA WHERE HCP_STATE = ''AR''', 
PARSE_JSON('[]'), SNOWFLAKE.CORTEX.EMBED_TEXT_768('snowflake-arctic-embed-m', 'AR Market Volume arkansas state')

UNION ALL
SELECT 'K14', 'High Volume Writers (>10)', 'Prescriptions coming from HCPs with more than 10 total scripts.', 
'SELECT SUM(ACUTE_TRX_XPO) FROM MASTER_DB_SAMPLE_DATA WHERE ACUTE_TRX_XPO > 10', 
PARSE_JSON('[]'), SNOWFLAKE.CORTEX.EMBED_TEXT_768('snowflake-arctic-embed-m', 'High Volume Writers top prescribers')

UNION ALL
SELECT 'K15', 'NP/PA Segment Contribution', 'Volume generated by Nurse Practitioners and Physician Assistants.', 
'SELECT SUM(ACUTE_TRX_XPO) FROM MASTER_DB_SAMPLE_DATA WHERE PRIMARY_SPECIALTY_METRIC = ''NP/PA''', 
PARSE_JSON('[]'), SNOWFLAKE.CORTEX.EMBED_TEXT_768('snowflake-arctic-embed-m', 'NP PA Segment Contribution nurse practitioner');


INSERT INTO DECISION_TREE_STORE_NEW (TREE_ID, GRAPH_JSON) 
SELECT 'Pharma_Master_v1', PARSE_JSON($$
{
    "graph": {
        "nodes": [
            { "id": "K1", "metric": "Total Market Volume (TRX)" },
            { "id": "K2", "metric": "Total New Starts (NRX)" },
            { "id": "K3", "metric": "Opioid Category Volume" },
            { "id": "K4", "metric": "NSAID Category Volume" },
            { "id": "K5", "metric": "Tramadol Brand Volume" },
            { "id": "K6", "metric": "Diclofenac Brand Volume" },
            { "id": "K7", "metric": "Tramadol New Growth (NRX)" },
            { "id": "K8", "metric": "Tramadol Retention (Refills)" },
            { "id": "K9", "metric": "Diclofenac New Growth (NRX)" },
            { "id": "K10", "metric": "Orthopedic Tramadol Starts" },
            { "id": "K11", "metric": "PCP Tramadol Starts" },
            { "id": "K12", "metric": "NC Market Volume" },
            { "id": "K13", "metric": "AR Market Volume" },
            { "id": "K14", "metric": "High Volume Writers (>10)" },
            { "id": "K15", "metric": "NP/PA Segment Contribution" }
        ],
        "edges": [
            { "source": "K3", "target": "K1" }, 
            { "source": "K4", "target": "K1" }, 
            { "source": "K5", "target": "K3" }, 
            { "source": "K6", "target": "K4" }, 
            { "source": "K7", "target": "K5" }, 
            { "source": "K8", "target": "K5" }, 
            { "source": "K9", "target": "K6" }, 
            { "source": "K10", "target": "K7" }, 
            { "source": "K11", "target": "K7" }, 
            { "source": "K15", "target": "K4" }
        ]




  import _snowflake
import json
import time
import snowflake.snowpark as snowpark
from snowflake.snowpark.exceptions import SnowparkSQLException

# ==========================================
# HELPER 1: FAST FEEDBACK SUBMISSION (SQL)
# ==========================================
def submit_feedback_sql(session: snowpark.Session, user_id: str, text: str, is_positive: bool):
    try:
        # Simple SQL-safe string escape
        clean_text = text.replace("'", "''")
        query = f"""
            INSERT INTO feedback_staging 
            (user_id, feedback_text, feedback_rating)
            VALUES ('{user_id}', '{clean_text}', {is_positive})
        """
        session.sql(query).collect()
        print(f" Feedback submitted for: {user_id}")
    except Exception as e:
        print(f" Submit Error: {e}")

# ==========================================
# HELPER 2: CALL AGENT VIA INTERNAL API
# ==========================================
def call_cortex_agent_internal(session: snowpark.Session, user_id: str, user_query: str):
    print(f"\n--- Calling Agent for {user_id} ---")
    
    # --- CONFIGURATION ---
    # Endpoint for stateless agent execution
    AGENT_ENDPOINT_URL = f"/api/v2/databases/''DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB''/schemas/''AI_POC''/agent/''FEEDBACK_TEST'':run"
    TIMEOUT_MS = 180_000 # 3 minutes

    # 1. Retrieve Memory (Fast Lookup)
    try:
        mem_df = session.sql(f"SELECT current_summary FROM user_memory WHERE user_id = '{user_id}'").collect()
        retrieved_memory = mem_df[0]['CURRENT_SUMMARY'] if mem_df and mem_df[0]['CURRENT_SUMMARY'] else "No prior context."
        print(f" Memory Found: {len(retrieved_memory) > 20} (Length: {len(retrieved_memory)})")
    except:
         retrieved_memory = "No prior context."

    # 2. Define Instructions
    # Logic rules for the "brain"
    orchestration_rules = """
    You are a helpful corporate analyst agent.
    - Never fabricate data.
    - If you use a tool to get data, rely ONLY on that data.
    - CRITICAL: You must adhere to the USER CONTEXT provided below in your logic.
    """
    # Style rules for the "voice"
    response_rules = """
    - Be professional and concise.
    - Use Markdown for formatting.
    """

    # 3. Construct the Payload (using AgentInstruction schema)
    # We inject the retrieved memory directly into the orchestration block.
    payload = {
        "model": "claude-3-5-sonnet", # Or your preferred supported model
        "instructions": {
            "orchestration": f"{orchestration_rules}\n\n### USER CONTEXT ###\n{retrieved_memory}",
            "response": response_rules
        },
        "messages": [
            {"role": "user", "content": [{"type": "text", "text": user_query}]}
        ],
        "stream": False
    }

    # Headers for internal API call
    headers = {
        "Content-Type": "application/json",
        "Accept": "application/json"
    }

    # 4. Make the internal API request
    try:
        response_dict = _snowflake.send_snow_api_request(
            "POST",
            AGENT_ENDPOINT_URL,
            headers,
            {}, # query params
            json.dumps(payload),
            {}, # cookies
            TIMEOUT_MS
        )

        # Parse the response body
        response_content = response_dict.get("content", "")
        if not response_content:
             return "Error: Empty response from agent API."
             
        parsed_response = json.loads(response_content)

        # Extract the final text response.
        # Handle standard blocking response format
        if isinstance(parsed_response, dict) and 'message' in parsed_response:
            content_items = parsed_response['message'].get('content', [])
            for item in reversed(content_items):
                if isinstance(item, dict) and item.get("type") == "text":
                    return item.get("text", "No text found in response.")
        
        # Handle potential streaming-style chunks in blocking response
        if isinstance(parsed_response, list) and len(parsed_response) > 0:
             item = parsed_response[-1] # Get last chunk
             if 'message' in item and 'content' in item['message']:
                 content_block = item['message']['content'][-1]
                 if content_block.get('type') == 'text':
                     return content_block.get('text')

        return f"Could not parse response. Raw: {str(parsed_response)[:200]}..."

    except Exception as e:
        return f"An error occurred calling the agent API: {str(e)}"

# ==========================================
# MAIN HANDLER FUNCTION
# ==========================================
def main(session: snowpark.Session):
    # Generate a unique user ID for this test run
    test_user_id = f"worksheet_user_{int(time.time())}"
    test_query = "When does the fiscal year start? Please list the months of Q1."

    print(f"Starting Test Run for User: {test_user_id}")

    # --- PART 1: BEFORE FEEDBACK ---
    print("\n PART 1: BASELINE (Before Feedback) ")
    # The agent should give a generic answer.
    response_before = call_cortex_agent_internal(session, test_user_id, test_query)
    print(f"\n[AGENT REPLY BEFORE]:\n{response_before}\n")


    # --- PART 2: SUBMIT FEEDBACK & WAIT ---
    print("\n PART 2: TEACHING THE SYSTEM ")
    fb_text = "Global Rule: Our fiscal year begins on February 1st. User Preference: Use bullet points for lists."
    print(f"Submitting Feedback: '{fb_text}'")
    # Submit negative feedback to initiate the correction loop
    submit_feedback_sql(session, test_user_id, fb_text, is_positive=False)

    print("\n--- Waiting 130 seconds for background tasks to process... ---")
    # Wait for Classifier Task (1 min) + Summarizer Task (1 min) to finish cycles.
    # This allows data to flow from Staging -> Logs -> Memory.
    time.sleep(130) 
    print("--- Wait complete. Memory should be updated. ---")


    # --- PART 3: AFTER FEEDBACK ---
    print("\n PART 3: VERIFICATION (After Feedback) ")
    # Run the exact same query. The agent should now use the new memory.
    response_after = call_cortex_agent_internal(session, test_user_id, test_query)
    print(f"\n[AGENT REPLY AFTER]:\n{response_after}\n")

    return "Test Complete. Check output panel for results."
    }
}
$$);
Could not parse response. Raw: {'status': 500, 'content': '{\n\t"code":\t"300014",\n\t"message":\t"Cannot construct instance of `com.snowflake.snowapi.cortexliteagent.model.AgentRunRequest` (although at least one Creator exists): n...
[AGENT REPLY BEFORE]:
{'status': 500, 'content': '{\n\t"code":\t"300014",\n\t"message":\t"Cannot construct instance of `com.snowflake.snowapi.cortexdataagent.model.DataAgentRunRequest` (although at least one Creator exists): no String-argument constructor/factory method to deserialize from String value (\'{\"model\": \"claude-3-5-sonnet\", \"instructions\": {\"orchestration\": \"\\n    You are a helpful corporate analyst agent.\\n    - Never fabricate data.\\n    - If you use a tool to get data, rely ONLY on that data.\\n    - CRITICAL: You must adhere to the USER CONTEXT provided below in your logic.\\n    \\n\\n### USER CONTEXT ###\\nNo prior context.\", \"response\": \"\\n    - Be professional and concise.\\n    - Use Markdown for formatting.\\n    \"}, \"messages\": [{\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": \"When does the fiscal year start? Please list the months of Q1.\"}]}], \"stream\": false}\')\n at [Source: (org.eclipse.jetty.server.HttpInputOverHTTP); line: 1, column: 1]",\n\t"request_id":\t"e1c38c66-6845-47f6-8f80-51c409533c1d",\n\t"error_code":\t"300014"\n}', 'headers': {'\nContent-Length': '1033', '\nDate': 'Thu, 08 Jan 2026 18:40:37 GMT', '\nX-Snowflake-Request-ID': 'e1c38c66-6845-47f6-8f80-51c409533c1d', '\nContent-Type': 'application/json'}}
 PART 2: TEACHING THE SYSTEM 
Submitting Feedback: 'Global Rule: Our fiscal year begins on February 1st. User Preference: Use bullet points for lists.'
 Feedback submitted for: worksheet_user_1767897637
--- Waiting 130 seconds for background tasks to process... ---
--- Wait complete. Memory should be updated. ---
 PART 3: VERIFICATION (After Feedback) 
--- Calling Agent for worksheet_user_1767897637 ---
 Memory Found: False (Length: 17)
[AGENT REPLY AFTER]:
{'status': 500, 'content': '{\n\t"code":\t"300014",\n\t"message":\t"Cannot construct instance of `com.snowflake.snowapi.cortexdataagent.model.DataAgentRunRequest` (although at least one Creator exists): no String-argument constructor/factory method to deserialize from String value (\'{\"model\": \"claude-3-5-sonnet\", \"instructions\": {\"orchestration\": \"\\n    You are a helpful corporate analyst agent.\\n    - Never fabricate data.\\n    - If you use a tool to get data, rely ONLY on that data.\\n    - CRITICAL: You must adhere to the USER CONTEXT provided below in your logic.\\n    \\n\\n### USER CONTEXT ###\\nNo prior context.\", \"response\": \"\\n    - Be professional and concise.\\n    - Use Markdown for formatting.\\n    \"}, \"messages\": [{\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": \"When does the fiscal year start? Please list the months of Q1.\"}]}], \"stream\": false}\')\n at [Source: (org.eclipse.jetty.server.HttpInputOverHTTP); line: 1, column: 1]",\n\t"request_id":\t"2f23c5b9-1174-402f-ba88-64f165fd5e2a",\n\t"error_code":\t"300014"\n}', 'headers': {'\nContent-Type': 'application/json', '\nContent-Length': '1033', '\nDate': 'Thu, 08 Jan 2026 18:42:48 GMT', '\nX-Snowflake-Request-ID': '2f23c5b9-1174-402f-ba88-64f165fd5e2a'}}


Skip to main content
Skip to editor
Skip to results
Site





Worksheets
Selection deleted
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
    
    # --- CONFIGURATION ---
    # Endpoint for stateless agent execution - FIX THE QUOTES
    AGENT_ENDPOINT_URL = "/api/v2/databases/DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB/schemas/AI_POC/agents/FEEDBACK_NEW:run"
    TIMEOUT_MS = 180_000  # 3 minutes

    # 1. Retrieve Memory (Fast Lookup)
    try:
        mem_df = session.sql(f"SELECT current_summary FROM user_memory WHERE user_id = '{user_id}'").collect()
        retrieved_memory = mem_df[0]['CURRENT_SUMMARY'] if mem_df and mem_df[0]['CURRENT_SUMMARY'] else "No prior context."
        print(f" Memory Found: {len(retrieved_memory) > 20} (Length: {len(retrieved_memory)})")
    except:
        retrieved_memory = "No prior context."

    # 2. Define Instructions
    # Logic rules for the "brain"
    orchestration_rules = """
    You are a helpful corporate analyst agent.
    - Never fabricate data.
    - If you use a tool to get data, rely ONLY on that data.
    - CRITICAL: You must adhere to the USER CONTEXT provided below in your logic.
    """
    # Style rules for the "voice"
    response_rules = """
    - Be professional and concise.
    - Use Markdown for formatting.
    """

    # 3. Construct the Payload (using AgentInstruction schema)
    # We inject the retrieved memory directly into the orchestration block.
    payload = {
        "model": "claude-3-5-sonnet",  # Or your preferred supported model
        "instructions": {
            "orchestration": f"{orchestration_rules}\n\n### USER CONTEXT ###\n{retrieved_memory}",
            "response": response_rules
        },
        "messages": [
            {"role": "user", "content": [{"type": "text", "text": user_query}]}
        ],
        "stream": False
    }

    # Headers for internal API call
    headers = {
        "Content-Type": "application/json",
        "Accept": "application/json"
    }

    # 4. Make the internal API request
    try:
        response_dict = _snowflake.send_snow_api_request(
            "POST",
            AGENT_ENDPOINT_URL,
            headers,
            {},  # query params
            payload,
            {},  # cookies
            TIMEOUT_MS
        )
        print("Hi")
        # Parse the response body
        response_content = response_dict.get("content")
        # if not response_content:
        #     return "Error: Empty response from agent API."
        print(response_dict)    
        parsed_response = json.loads(response_content)

        # Extract the final text response.
        # Handle standard blocking response format
        if isinstance(parsed_response, dict) and 'message' in parsed_response:
            content_items = parsed_response['message'].get('content', [])
            for item in reversed(content_items):
                if isinstance(item, dict) and item.get("type") == "text":
                    return item.get("text", "No text found in response.")
        
        # Handle potential streaming-style chunks in blocking response
        if isinstance(parsed_response, list) and len(parsed_response) > 0:
            item = parsed_response[-1]  # Get last chunk
            if 'message' in item and 'content' in item['message']:
                content_block = item['message']['content'][-1]
                if content_block.get('type') == 'text':
                    return content_block.get('text')

        return f"Could not parse response. Raw: {str(parsed_response)[:200]}..."

    except Exception as e:
        return f"An error occurred calling the agent API: {str(e)}"
Starting Test Run for User: worksheet_user_1767899167
 PART 1: BASELINE (Before Feedback) 
--- Calling Agent for worksheet_user_1767899167 ---
 Memory Found: False (Length: 17)
Hi
{'status': 200, 'content': '[{\n\t\t"event":\t"response.text.delta",\n\t\t"data":\t{\n\t\t\t"content_index":\t0,\n\t\t\t"text":\t"The"\n\t\t}\n\t}, {\n\t\t"event":\t"response.text.delta",\n\t\t"data":\t{\n\t\t\t"content_index":\t0,\n\t\t\t"text":\t" fiscal year start"\n\t\t}\n\t}, {\n\t\t"event":\t"response.text.delta",\n\t\t"data":\t{\n\t\t\t"content_index":\t0,\n\t\t\t"text":\t" date varies"\n\t\t}\n\t}, {\n\t\t"event":\t"response.text.delta",\n\t\t"data":\t{\n\t\t\t"content_index":\t0,\n\t\t\t"text":\t" depending"\n\t\t}\n\t}, {\n\t\t"event":\t"response.text.delta",\n\t\t"data":\t{\n\t\t\t"content_index":\t0,\n\t\t\t"text":\t" on the organization"\n\t\t}\n\t}, {\n\t\t"event":\t"response.text.delta",\n\t\t"data":\t{\n\t\t\t"content_index":\t0,\n\t\t\t"text":\t" and country:"\n\t\t}\n\t}, {\n\t\t"event":\t"response.text.delta",\n\t\t"data":\t{\n\t\t\t"content_index":\t0,\n\t\t\t"text":\t"\n\n**Most"\n\t\t}\n\t}, {\n\t\t"event":\t"response.text.delta",\n\t\t"data":\t{\n\t\t\t"content_index":\t0,\n\t\t\t"text":\t" common"\n\t\t}\n\t}, {\n\t\t"event":\t"response.text.delta",\n\t\t"data":\t{\n\t\t\t"content_index":\t0,\n\t\t\t"text":\t" fiscal"\n\t\t}\n\t}, {\n\t\t"event":\t"response.text.delta",\n\t\t"data":\t{\n\t\t\t"content_index":\t0,\n\t\t\t"text":\t" year starts"\n\t\t}\n\t}, {\n\t\t"event":\t"response.text.delta",\n\t\t"data":\t{\n\t\t\t"content_index":\t0,\n\t\t\t"text":\t":**\n- **October"\n\t\t}\n\t}, {\n\t\t"event":\t"response.text.delta",\n\t\t"data":\t{\n\t\t\t"content_index":\t0,\n\t\t\t"text":\t" 1** (U"\n\t\t}\n\t}, {\n\t\t"event":\t"response.text.delta",\n\t\t"data":\t{\n\t\t\t"content_index":\t0,\n\t\t\t"text":\t".S. federal"\n\t\t}\n\t}, {\n\t\t"event":\t"response.text.delta",\n\t\t"data":\t{\n\t\t\t"content_index":\t0,\n\t\t\t"text":\t" government)\n- **April"\n\t\t}\n\t}, {\n\t\t"event":\t"response.text.delta",\n\t\t"data":\t{\n\t\t\t"content_index":\t0,\n\t\t\t"text":\t" 1** (many"\n\t\t}\n\t}, {\n\t\t"event":\t"response.text.delta",\n\t\t"data":\t{\n\t\t\t"content_index":\t0,\n\t\t\t"text":\t" countries including"\n\t\t}\n\t}, {\n\t\t"event":\t"response.text.delta",\n\t\t"data":\t{\n\t\t\t"content_index":\t0,\n\t\t\t"text":\t" Japan"\n\t\t}\n\t}, {\n\t\t"event":\t"response.text.delta",\n\t\t"data":\t{\n\t\t\t"content_index":\t0,\n\t\t\t"text":\t", India"\n\t\t}\n\t}, {\n\t\t"event":\t"response.text.delta",\n\t\t"data":\t{\n\t\t\t"content_index":\t0,\n\t\t\t"text":\t", UK"\n\t\t}\n\t}, {\n\t\t"event":\t"response.text.delta",\n\t\t"data":\t{\n\t\t\t"content_index":\t0,\n\t\t\t"text":\t")"\n\t\t}\n\t}, {\n\t\t"event":\t"response.text.delta",\n\t\t"data":\t{\n\t\t\t"content_index":\t0,\n\t\t\t"text":\t"\n- **January 1** ("\n\t\t}\n\t}, {\n\t\t"event":\t"response.text.delta",\n\t\t"data":\t{\n\t\t\t"content_index":\t0,\n\t\t\t"text":\t"calendar"\n\t\t}\n\t}, {\n\t\t"event":\t"response.text.delta",\n\t\t"data":\t{\n\t\t\t"content_index":\t0,\n\t\t\t"text":\t" year -"\n\t\t}\n\t}, {\n\t\t"event":\t"response.text.delta",\n\t\t"data":\t{\n\t\t\t"content_index":\t0,\n\t\t\t"text":\t" many"\n\t\t}\n\t}, {\n\t\t"event":\t"response.text.delta",\n\t\t"data":\t{\n\t\t\t"content_index":\t0,\n\t\t\t"text":\t" businesses"\n\t\t}\n\t}, {\n\t\t"event":\t"response.text.delta",\n\t\t"data":\t{\n\t\t\t"content_index":\t0,\n\t\t\t"text":\t")"\n\t\t}\n\t}, {\n\t\t"event":\t"response.text.delta",\n\t\t"data":\t{\n\t\t\t"content_index":\t0,\n\t\t\t"text":\t"\n- **July 1** (some"\n\t\t}\n\t}, {\n\t\t"event":\t"response.text.delta",\n\t\t"data":\t{\n\t\t\t"content_index":\t0,\n\t\t\t"text":\t" states"\n\t\t}\n\t}, {\n\t\t"event":\t"response.text.delta",\n\t\t"data":\t{\n\t\t\t"content_index":\t0,\n\t\t\t"text":\t" an"\n\t\t}\n\t}, {\n\t\t"event":\t"response.text.delta",\n\t\t"data":\t{\n\t\t\t"content_index":\t0,\n\t\t\t"text":\t"d organizations"\n\t\t}\n\t}, {\n\t\t"event":\t"response.text.delta",\n\t\t"data":\t{\n\t\t\t"content_index":\t0,\n\t\t\t"text":\t")\n\n**Q"\n\t\t}\n\t}, {\n\t\t"event":\t"response.text.delta",\n\t\t"data":\t{\n\t\t\t"content_index":\t0,\n\t\t\t"text":\t"1 months"\n\t\t}\n\t}, {\n\t\t"event":\t"response.text.delta",\n\t\t"data":\t{\n\t\t\t"content_index":\t0,\n\t\t\t"text":\t" for"\n\t\t}\n\t}, {\n\t\t"event":\t"response.text.delta",\n\t\t"data":\t{\n\t\t\t"content_index":\t0,\n\t\t\t"text":\t" each"\n\t\t}\n\t}, {\n\t\t"event":\t"response.text.delta",\n\t\t"data":\t{\n\t\t\t"content_index":\t0,\n\t\t\t"text":\t":**"\n\t\t}\n\t}, {\n\t\t"event":\t"response.text.delta",\n\t\t"data":\t{\n\t\t\t"content_index":\t0,\n\t\t\t"text":\t"\n\n-"\n\t\t}\n\t}, {\n\t\t"event":\t"response.text.delta",\n\t\t"data":\t{\n\t\t\t"content_index":\t0,\n\t\t\t"text":\t" **October"\n\t\t}\n\t}, {\n\t\t"event":\t"response.text.delta",\n\t\t"data":\t{\n\t\t\t"content_index":\t0,\n\t\t\t"text":\t" start"\n\t\t}\n\t}, {\n\t\t"event":\t"response.text.delta",\n\t\t"data":\t{\n\t\t\t"content_index":\t0,\n\t\t\t"text":\t":** Q"\n\t\t}\n\t}, {\n\t\t"event":\t"response.text.delta",\n\t\t"data":\t{\n\t\t\t"content_index":\t0,\n\t\t\t"text":\t"1 ="\n\t\t}\n\t}, {\n\t\t"event":\t"response.text.delta",\n\t\t"data":\t{\n\t\t\t"content_index":\t0,\n\t\t\t"text":\t" October,"\n\t\t}\n\t}, {\n\t\t"event":\t"response.text.delta",\n\t\t"data":\t{\n\t\t\t"content_index":\t0,\n\t\t\t"text":\t" November"\n\t\t}\n\t}, {\n\t\t"event":\t"response.text.delta",\n\t\t"data":\t{\n\t\t\t"content_index":\t0,\n\t\t\t"text":\t", December\n- **April start:**"\n\t\t}\n\t}, {\n\t\t"event":\t"response.text.delta",\n\t\t"data":\t{\n\t\t\t"content_index":\t0,\n\t\t\t"text":\t" Q1 = April, May,"\n\t\t}\n\t}, {\n\t\t"event":\t"response.text.delta",\n\t\t"data":\t{\n\t\t\t"content_index":\t0,\n\t\t\t"text":\t" June  "\n\t\t}\n\t}, {\n\t\t"event":\t"response.text.delta",\n\t\t"data":\t{\n\t\t\t"content_index":\t0,\n\t\t\t"text":\t"\n- **January start:** Q1"\n\t\t}\n\t}, {\n\t\t"event":\t"response.text.delta",\n\t\t"data":\t{\n\t\t\t"content_index":\t0,\n\t\t\t"text":\t" = January, February, March"\n\t\t}\n\t}, {\n\t\t"event":\t"response.text.delta",\n\t\t"data":\t{\n\t\t\t"content_index":\t0,\n\t\t\t"text":\t"\n- **July start:** Q1 "\n\t\t}\n\t}, {\n\t\t"event":\t"response.text.delta",\n\t\t"data":\t{\n\t\t\t"content_index":\t0,\n\t\t\t"text":\t"= July, August, September\n\nIf"\n\t\t}\n\t}, {\n\t\t"event":\t"response.text.delta",\n\t\t"data":\t{\n\t\t\t"content_index":\t0,\n\t\t\t"text":\t" you\'re asking about a specific organization"\n\t\t}\n\t}, {\n\t\t"event":\t"response.text.delta",\n\t\t"data":\t{\n\t\t\t"content_index":\t0,\n\t\t\t"text":\t" or country, I"\n\t\t}\n\t}, {\n\t\t"event":\t"response.text.delta",\n\t\t"data":\t{\n\t\t\t"content_index":\t0,\n\t\t\t"text":\t"\'d be happy to provide"\n\t\t}\n\t}, {\n\t\t"event":\t"response.text.delta",\n\t\t"data":\t{\n\t\t\t"content_index":\t0,\n\t\t\t"text":\t" more targete"\n\t\t}\n\t}, {\n\t\t"event":\t"response.text.delta",\n\t\t"data":\t{\n\t\t\t"content_index":\t0,\n\t\t\t"text":\t"d information!"\n\t\t}\n\t}, {\n\t\t"event":\t"response.text",\n\t\t"data":\t{\n\t\t\t"content_index":\t0,\n\t\t\t"text":\t"The fiscal year start date varies depending on the organization and country:\n\n**Most common fiscal year starts:**\n- **October 1** (U.S. federal government)\n- **April 1** (many countries including Japan, India, UK)\n- **January 1** (calendar year - many businesses)\n- **July 1** (some states and organizations)\n\n**Q1 months for each:**\n\n- **October start:** Q1 = October, November, December\n- **April start:** Q1 = April, May, June  \n- **January start:** Q1 = January, February, March\n- **July start:** Q1 = July, August, September\n\nIf you\'re asking about a specific organization or country, I\'d be happy to provide more targeted information!"\n\t\t}\n\t}, {\n\t\t"event":\t"response",\n\t\t"data":\t{\n\t\t\t"content":\t[{\n\t\t\t\t\t"text":\t"The fiscal year start date varies depending on the organization and country:\n\n**Most common fiscal year starts:**\n- **October 1** (U.S. federal government)\n- **April 1** (many countries including Japan, India, UK)\n- **January 1** (calendar year - many businesses)\n- **July 1** (some states and organizations)\n\n**Q1 months for each:**\n\n- **October start:** Q1 = October, November, December\n- **April start:** Q1 = April, May, June  \n- **January start:** Q1 = January, February, March\n- **July start:** Q1 = July, August, September\n\nIf you\'re asking about a specific organization or country, I\'d be happy to provide more targeted information!",\n\t\t\t\t\t"type":\t"text"\n\t\t\t\t}],\n\t\t\t"metadata":\t{\n\t\t\t\t"usage":\t{\n\t\t\t\t\t"tokens_consumed":\t[{\n\t\t\t\t\t\t\t"context_window":\t200000,\n\t\t\t\t\t\t\t"input_tokens":\t{\n\t\t\t\t\t\t\t\t"cache_read":\t0,\n\t\t\t\t\t\t\t\t"cache_write":\t0,\n\t\t\t\t\t\t\t\t"total":\t78,\n\t\t\t\t\t\t\t\t"uncached":\t78\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t"model_name":\t"claude-4-sonnet",\n\t\t\t\t\t\t\t"output_tokens":\t{\n\t\t\t\t\t\t\t\t"total":\t175\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}]\n\t\t\t\t}\n\t\t\t},\n\t\t\t"role":\t"assistant",\n\t\t\t"schema_version":\t"v2"\n\t\t}\n\t}, {\n\t\t"event":\t"done",\n\t\t"data":\t"[DONE]"\n\t}]', 'headers': {'\nDate': 'Thu, 08 Jan 2026 19:06:08 GMT', '\nX-Snowflake-Request-ID': '32911316-3d54-4627-a217-a074a4a3fd52', '\nContent-Type': 'application/json', '\nTransfer-Encoding': 'chunked'}}
[AGENT REPLY BEFORE]:
Could not parse response. Raw: [{'event': 'response.text.delta', 'data': {'content_index': 0, 'text': 'The'}}, {'event': 'response.text.delta', 'data': {'content_index': 0, 'text': ' fiscal year start'}}, {'event': 'response.text.d...

Starting Test Run for User: worksheet_user_1767900217


import _snowflake
import json
import time
import snowflake.snowpark as snowpark
from snowflake.snowpark.exceptions import SnowparkSQLException

# ==========================================
# HELPER 1: FAST FEEDBACK SUBMISSION (SQL)
# ==========================================
def submit_feedback_sql(session: snowpark.Session, user_id: str, text: str, is_positive: bool):
    try:
        # Simple SQL-safe string escape
        clean_text = text.replace("'", "''")
        query = f"""
            INSERT INTO feedback_staging 
            (user_id, feedback_text, feedback_rating)
            VALUES ('{user_id}', '{clean_text}', {is_positive})
        """
        session.sql(query).collect()
        print(f" Feedback submitted for: {user_id}")
    except Exception as e:
        print(f" Submit Error: {e}")

# ==========================================
# HELPER 2: CALL AGENT VIA INTERNAL API
# ==========================================
def call_cortex_agent_internal(session: snowpark.Session, user_id: str, user_query: str):
    print(f"\n--- Calling Agent for {user_id} ---")
    
    # --- CONFIGURATION ---
    # Endpoint for stateless agent execution - FIX THE QUOTES
    AGENT_ENDPOINT_URL = "/api/v2/databases/DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB/schemas/AI_POC/agents/FEEDBACK_NEW:run"
    TIMEOUT_MS = 180_000  # 3 minutes

    # 1. Retrieve Memory (Fast Lookup)
    try:
        mem_df = session.sql(f"SELECT current_summary FROM user_memory WHERE user_id = '{user_id}'").collect()
        retrieved_memory = mem_df[0]['CURRENT_SUMMARY'] if mem_df and mem_df[0]['CURRENT_SUMMARY'] else "No prior context."
        print(f" Memory Found: {len(retrieved_memory) > 20} (Length: {len(retrieved_memory)})")
    except:
        retrieved_memory = "No prior context."

    # 2. Define Instructions
    # Logic rules for the "brain"
    orchestration_rules = """
    You are a helpful corporate analyst agent.
    - Never fabricate data.
    - If you use a tool to get data, rely ONLY on that data.
    - CRITICAL: You must adhere to the USER CONTEXT provided below in your logic.
    """
    # Style rules for the "voice"
    response_rules = """
    - Be professional and concise.
    - Use Markdown for formatting.
    """

    # 3. Construct the Payload (using AgentInstruction schema)
    # We inject the retrieved memory directly into the orchestration block.
    payload = {
        "model": "claude-3-5-sonnet",  # Or your preferred supported model
        "instructions": {
            "orchestration": f"{orchestration_rules}\n\n### USER CONTEXT ###\n{retrieved_memory}",
            "response": response_rules
        },
        "messages": [
            {"role": "user", "content": [{"type": "text", "text": user_query}]}
        ],
        "stream": False
    }

    # Headers for internal API call
    headers = {
        "Content-Type": "application/json",
        "Accept": "application/json"
    }

    # 4. Make the internal API request
    try:
        response_dict = _snowflake.send_snow_api_request(
            "POST",
            AGENT_ENDPOINT_URL,
            headers,
            {},  # query params
            payload,
            {},  # cookies
            TIMEOUT_MS
        )

        # Parse the response body
        response_content = response_dict.get("content", "")
        if not response_content:
            return "Error: Empty response from agent API."
             
        parsed_response = json.loads(response_content)

        # Extract the final text response.
        # Handle standard blocking response format
        if isinstance(parsed_response, dict) and 'message' in parsed_response:
            content_items = parsed_response['message'].get('content', [])
            for item in reversed(content_items):
                if isinstance(item, dict) and item.get("type") == "text":
                    return item.get("text", "No text found in response.")
        
        # Handle potential streaming-style chunks in blocking response
        if isinstance(parsed_response, list) and len(parsed_response) > 0:
            item=parsed_response
            print(parsed_response)
            if 'event' in item and 'response' in item['event']:
                content_block = item['data']['content'][-1]
                if content_block.get('type') == 'text':
                    return content_block.get('text')

        return f"Could not parse response. Raw: {str(parsed_response)[:200]}..."

    except Exception as e:
        return f"An error occurred calling the agent API: {str(e)}"

# ==========================================
# MAIN HANDLER FUNCTION
# ==========================================
def main(session: snowpark.Session):
    # Generate a unique user ID for this test run
    test_user_id = f"worksheet_user_{int(time.time())}"
    test_query = "When does the fiscal year start? Please list the months of Q1."

    print(f"Starting Test Run for User: {test_user_id}")

    # --- PART 1: BEFORE FEEDBACK ---
    print("\n PART 1: BASELINE (Before Feedback) ")
    # The agent should give a generic answer.
    response_before = call_cortex_agent_internal(session, test_user_id, test_query)
    print(f"\n[AGENT REPLY BEFORE]:\n{response_before}\n")

    # # --- PART 2: SUBMIT FEEDBACK & WAIT ---
    # print("\n PART 2: TEACHING THE SYSTEM ")
    # fb_text = "Global Rule: Our fiscal year begins on February 1st. User Preference: Use bullet points for lists."
    # print(f"Submitting Feedback: '{fb_text}'")
    # # Submit negative feedback to initiate the correction loop
    # submit_feedback_sql(session, test_user_id, fb_text, is_positive=False)

    # print("\n--- Waiting 130 seconds for background tasks to process... ---")
    # # Wait for Classifier Task (1 min) + Summarizer Task (1 min) to finish cycles.
    # # This allows data to flow from Staging -> Logs -> Memory.
    # time.sleep(130) 
    # print("--- Wait complete. Memory should be updated. ---")

    # # --- PART 3: AFTER FEEDBACK ---
    # print("\n PART 3: VERIFICATION (After Feedback) ")
    # # Run the exact same query. The agent should now use the new memory.
    # response_after = call_cortex_agent_internal(session, test_user_id, test_query)
    # print(f"\n[AGENT REPLY AFTER]:\n{response_after}\n")

    # return "Test Complete. Check output panel for results."

 PART 1: BASELINE (Before Feedback) 
--- Calling Agent for worksheet_user_1767900217 ---
 Memory Found: False (Length: 17)
[{'event': 'response.text.delta', 'data': {'content_index': 0, 'text': 'The'}}, {'event': 'response.text.delta', 'data': {'content_index': 0, 'text': ' fiscal year start'}}, {'event': 'response.text.delta', 'data': {'content_index': 0, 'text': ' date varies'}}, {'event': 'response.text.delta', 'data': {'content_index': 0, 'text': ' depending'}}, {'event': 'response.text.delta', 'data': {'content_index': 0, 'text': ' on the organization'}}, {'event': 'response.text.delta', 'data': {'content_index': 0, 'text': ' or'}}, {'event': 'response.text.delta', 'data': {'content_index': 0, 'text': ' country:'}}, {'event': 'response.text.delta', 'data': {'content_index': 0, 'text': '\n\n**Common'}}, {'event': 'response.text.delta', 'data': {'content_index': 0, 'text': ' fiscal year start dates:**\n- **'}}, {'event': 'response.text.delta', 'data': {'content_index': 0, 'text': 'October'}}, {'event': 'response.text.delta', 'data': {'content_index': 0, 'text': ' 1** (U'}}, {'event': 'response.text.delta', 'data': {'content_index': 0, 'text': '.S. federal government)\n-'}}, {'event': 'response.text.delta', 'data': {'content_index': 0, 'text': ' **April'}}, {'event': 'response.text.delta', 'data': {'content_index': 0, 'text': ' 1** (many'}}, {'event': 'response.text.delta', 'data': {'content_index': 0, 'text': ' countries including'}}, {'event': 'response.text.delta', 'data': {'content_index': 0, 'text': ' Japan'}}, {'event': 'response.text.delta', 'data': {'content_index': 0, 'text': ', India'}}, {'event': 'response.text.delta', 'data': {'content_index': 0, 'text': ', UK'}}, {'event': 'response.text.delta', 'data': {'content_index': 0, 'text': ')'}}, {'event': 'response.text.delta', 'data': {'content_index': 0, 'text': '\n- **January 1** ('}}, {'event': 'response.text.delta', 'data': {'content_index': 0, 'text': 'calendar'}}, {'event': 'response.text.delta', 'data': {'content_index': 0, 'text': ' year, use'}}, {'event': 'response.text.delta', 'data': {'content_index': 0, 'text': 'd by many'}}, {'event': 'response.text.delta', 'data': {'content_index': 0, 'text': ' businesses'}}, {'event': 'response.text.delta', 'data': {'content_index': 0, 'text': ')\n- **July 1**'}}, {'event': 'response.text.delta', 'data': {'content_index': 0, 'text': ' (some'}}, {'event': 'response.text.delta', 'data': {'content_index': 0, 'text': ' states'}}, {'event': 'response.text.delta', 'data': {'content_index': 0, 'text': ' an'}}, {'event': 'response.text.delta', 'data': {'content_index': 0, 'text': 'd organizations'}}, {'event': 'response.text.delta', 'data': {'content_index': 0, 'text': ')\n\n**Q'}}, {'event': 'response.text.delta', 'data': {'content_index': 0, 'text': '1 months'}}, {'event': 'response.text.delta', 'data': {'content_index': 0, 'text': ' depen'}}, {'event': 'response.text.delta', 'data': {'content_index': 0, 'text': 'd on the'}}, {'event': 'response.text.delta', 'data': {'content_index': 0, 'text': ' fiscal'}}, {'event': 'response.text.delta', 'data': {'content_index': 0, 'text': ' year start'}}, {'event': 'response.text.delta', 'data': {'content_index': 0, 'text': ':**'}}, {'event': 'response.text.delta', 'data': {'content_index': 0, 'text': '\n\n-'}}, {'event': 'response.text.delta', 'data': {'content_index': 0, 'text': ' If'}}, {'event': 'response.text.delta', 'data': {'content_index': 0, 'text': ' fiscal'}}, {'event': 'response.text.delta', 'data': {'content_index': 0, 'text': ' year starts **'}}, {'event': 'response.text.delta', 'data': {'content_index': 0, 'text': 'October 1**:'}}, {'event': 'response.text.delta', 'data': {'content_index': 0, 'text': ' Q1 ='}}, {'event': 'response.text.delta', 'data': {'content_index': 0, 'text': ' October,'}}, {'event': 'response.text.delta', 'data': {'content_index': 0, 'text': ' November'}}, {'event': 'response.text.delta', 'data': {'content_index': 0, 'text': ', December\n- If fiscal year starts'}}, {'event': 'response.text.delta', 'data': {'content_index': 0, 'text': ' **April 1**: Q1 '}}, {'event': 'response.text.delta', 'data': {'content_index': 0, 'text': '= April, May, June  '}}, {'event': 'response.text.delta', 'data': {'content_index': 0, 'text': '\n- If fiscal year starts **January'}}, {'event': 'response.text.delta', 'data': {'content_index': 0, 'text': ' 1**: Q1 = January'}}, {'event': 'response.text.delta', 'data': {'content_index': 0, 'text': ', February, March\n- If fiscal'}}, {'event': 'response.text.delta', 'data': {'content_index': 0, 'text': ' year starts **July 1**: Q'}}, {'event': 'response.text.delta', 'data': {'content_index': 0, 'text': '1 = July, August, September'}}, {'event': 'response.text.delta', 'data': {'content_index': 0, 'text': '\n\nThe'}}, {'event': 'response.text.delta', 'data': {'content_index': 0, 'text': ' most'}}, {'event': 'response.text.delta', 'data': {'content_index': 0, 'text': ' common fiscal'}}, {'event': 'response.text.delta', 'data': {'content_index': 0, 'text': ' year for'}}, {'event': 'response.text.delta', 'data': {'content_index': 0, 'text': ' the'}}, {'event': 'response.text.delta', 'data': {'content_index': 0, 'text': ' U.S. federal'}}, {'event': 'response.text.delta', 'data': {'content_index': 0, 'text': ' government starts'}}, {'event': 'response.text.delta', 'data': {'content_index': 0, 'text': ' October'}}, {'event': 'response.text.delta', 'data': {'content_index': 0, 'text': ' 1,'}}, {'event': 'response.text.delta', 'data': {'content_index': 0, 'text': ' so'}}, {'event': 'response.text.delta', 'data': {'content_index': 0, 'text': ' Q1 woul'}}, {'event': 'response.text.delta', 'data': {'content_index': 0, 'text': 'd be October, November, an'}}, {'event': 'response.text.delta', 'data': {'content_index': 0, 'text': 'd December.'}}, {'event': 'response.text', 'data': {'content_index': 0, 'text': 'The fiscal year start date varies depending on the organization or country:\n\n**Common fiscal year start dates:**\n- **October 1** (U.S. federal government)\n- **April 1** (many countries including Japan, India, UK)\n- **January 1** (calendar year, used by many businesses)\n- **July 1** (some states and organizations)\n\n**Q1 months depend on the fiscal year start:**\n\n- If fiscal year starts **October 1**: Q1 = October, November, December\n- If fiscal year starts **April 1**: Q1 = April, May, June  \n- If fiscal year starts **January 1**: Q1 = January, February, March\n- If fiscal year starts **July 1**: Q1 = July, August, September\n\nThe most common fiscal year for the U.S. federal government starts October 1, so Q1 would be October, November, and December.'}}, {'event': 'response', 'data': {'content': [{'text': 'The fiscal year start date varies depending on the organization or country:\n\n**Common fiscal year start dates:**\n- **October 1** (U.S. federal government)\n- **April 1** (many countries including Japan, India, UK)\n- **January 1** (calendar year, used by many businesses)\n- **July 1** (some states and organizations)\n\n**Q1 months depend on the fiscal year start:**\n\n- If fiscal year starts **October 1**: Q1 = October, November, December\n- If fiscal year starts **April 1**: Q1 = April, May, June  \n- If fiscal year starts **January 1**: Q1 = January, February, March\n- If fiscal year starts **July 1**: Q1 = July, August, September\n\nThe most common fiscal year for the U.S. federal government starts October 1, so Q1 would be October, November, and December.', 'type': 'text'}], 'metadata': {'usage': {'tokens_consumed': [{'context_window': 200000, 'input_tokens': {'cache_read': 0, 'cache_write': 0, 'total': 78, 'uncached': 78}, 'model_name': 'claude-4-sonnet', 'output_tokens': {'total': 211}}]}}, 'role': 'assistant', 'schema_version': 'v2'}}, {'event': 'done', 'data': '[DONE]'}]
[AGENT REPLY BEFORE]:
Could not parse response. Raw: [{'event': 'response.text.delta', 'data': {'content_index': 0, 'text': 'The'}}, {'event': 'response.text.delta', 'data': {'content_index': 0, 'text': ' fiscal year start'}}, {'event': 'response.text.d...
Checking Task History (Last 5 runs)...
    [INCREMENTAL_MEMORY_TASK] State: SCHEDULED
    [BACKEND_CLASSIFIER_TASK] State: FAILED
       Error: Cannot execute task , USAGE privilege on the task's warehouse must be granted to owner role
    [INCREMENTAL_MEMORY_TASK] State: FAILED
       Error: Cannot execute task , USAGE privilege on the task's warehouse must be granted to owner role
    [BACKEND_CLASSIFIER_TASK] State: FAILED
       Error: Cannot execute task , USAGE privilege on the task's warehouse must be granted to owner role
GRANT USAGE ON WAREHOUSE DEV_PAIN_SALES_PERFORMANCE_B_WH TO ROLE FR_PRJ_DEV_PAIN_SALES_RW;
print(grant_permission)

-- 3. Grant permission to execute tasks (just in case)
GRANT EXECUTE TASK ON ACCOUNT TO ROLE SYSADMIN;


# # import _snowflake
# # import json
# # import time
# # import snowflake.snowpark as snowpark
# # from snowflake.snowpark.exceptions import SnowparkSQLException

# # # ==========================================
# # # HELPER 1: FAST FEEDBACK SUBMISSION (SQL)
# # # ==========================================
# # def submit_feedback_sql(session: snowpark.Session, user_id: str, text: str, is_positive: bool):
# #     try:
# #         # Simple SQL-safe string escape
# #         clean_text = text.replace("'", "''")
# #         query = f"""
# #             INSERT INTO feedback_staging 
# #             (user_id, feedback_text, feedback_rating)
# #             VALUES ('{user_id}', '{clean_text}', {is_positive})
# #         """
# #         session.sql(query).collect()
# #         print(f" Feedback submitted for: {user_id}")
# #     except Exception as e:
# #         print(f" Submit Error: {e}")

# # # ==========================================
# # # HELPER 2: CALL AGENT VIA INTERNAL API
# # # ==========================================
# # def call_cortex_agent_internal(session: snowpark.Session, user_id: str, user_query: str):
# #     print(f"\n--- Calling Agent for {user_id} ---")
    
# #     # --- CONFIGURATION ---
# #     # Endpoint for stateless agent execution
# #     AGENT_ENDPOINT_URL = "/api/v2/databases/DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB/schemas/AI_POC/agents/FEEDBACK_NEW:run"
# #     TIMEOUT_MS = 180_000  # 3 minutes

# #     # 1. Retrieve Memory (Fast Lookup)
# #     try:
# #         mem_df = session.sql(f"SELECT current_summary FROM user_memory WHERE user_id = '{user_id}'").collect()
# #         print(mem_df)
# #         retrieved_memory = mem_df[0]['CURRENT_SUMMARY'] if mem_df and mem_df[0]['CURRENT_SUMMARY'] else "No prior context."
# #         print(f" Memory Found: {len(retrieved_memory) > 20} (Length: {len(retrieved_memory)})")
# #     except:
# #         retrieved_memory = "No prior context."

# #     # 2. Define Instructions
# #     orchestration_rules = """
# #     You are a helpful corporate analyst agent.
# #     - Never fabricate data.
# #     - If you use a tool to get data, rely ONLY on that data.
# #     - CRITICAL: You must adhere to the USER CONTEXT provided below in your logic.
# #     """
# #     response_rules = """
# #     - Be professional and concise.
# #     - Use Markdown for formatting.
# #     """

# #     # 3. Construct the Payload
# #     payload = {
# #         "model": "claude-3-5-sonnet", 
# #         "instructions": {
# #             "orchestration": f"{orchestration_rules}\n\n### USER CONTEXT ###\n{retrieved_memory}",
# #             "response": response_rules
# #         },
# #         "messages": [
# #             {"role": "user", "content": [{"type": "text", "text": user_query}]}
# #         ],
# #         "stream": False
# #     }

# #     headers = {
# #         "Content-Type": "application/json",
# #         "Accept": "application/json"
# #     }

# #     # 4. Make the internal API request
# #     try:
# #         response_dict = _snowflake.send_snow_api_request(
# #             "POST",
# #             AGENT_ENDPOINT_URL,
# #             headers,
# #             {}, 
# #             payload,
# #             {}, 
# #             TIMEOUT_MS
# #         )

# #         response_content = response_dict.get("content", "")
# #         if not response_content:
# #             return "Error: Empty response from agent API."
            
# #         parsed_response = json.loads(response_content)

# #         # --- PARSING LOGIC START ---
        
# #         # Case A: Standard Dictionary Response (Blocking)
# #         if isinstance(parsed_response, dict) and 'message' in parsed_response:
# #             content_items = parsed_response['message'].get('content', [])
# #             for item in reversed(content_items):
# #                 if isinstance(item, dict) and item.get("type") == "text":
# #                     return item.get("text", "No text found in response.")
        
# #         # Case B: List of Events (Streaming/SSE captured as list)
# #         # This is the format matching your raw output log
# #         elif isinstance(parsed_response, list):
            
# #             # Priority 1: Look for the final 'response' event which contains the complete answer
# #             for item in parsed_response:
# #                 if item.get('event') == 'response':
# #                     try:
# #                         # Extract content list from data
# #                         content_list = item.get('data', {}).get('content', [])
# #                         # Look for the text part
# #                         for part in content_list:
# #                             if part.get('type') == 'text':
# #                                 return part.get('text')
# #                     except Exception:
# #                         continue

# #             # Priority 2: Look for 'response.text' event (aggregated text)
# #             for item in parsed_response:
# #                 if item.get('event') == 'response.text':
# #                     return item.get('data', {}).get('text')

# #             # Priority 3: Reconstruct from 'response.text.delta' events
# #             chunks = []
# #             for item in parsed_response:
# #                 if item.get('event') == 'response.text.delta':
# #                     chunks.append(item.get('data', {}).get('text', ''))
            
# #             if chunks:
# #                 return "".join(chunks)

# #         return f"Could not parse response. Raw structure unexpected."
# #         # --- PARSING LOGIC END ---

# #     except Exception as e:
# #         return f"An error occurred calling the agent API: {str(e)}"

# # # ==========================================
# # # MAIN HANDLER FUNCTION
# # # ==========================================
# # def main(session: snowpark.Session):
# #     # Generate a unique user ID for this test run
# #     test_user_id = f"worksheet_user_{int(time.time())}"
# #     test_query = "When does the fiscal year start? Please list the months of Q1."

# #     print(f"Starting Test Run for User: {test_user_id}")

# #     # --- PART 1: BEFORE FEEDBACK ---
# #     print("\n PART 1: BASELINE (Before Feedback) ")
# #     # The agent should give a generic answer.
# #     response_before = call_cortex_agent_internal(session, test_user_id, test_query)
# #     print(f"\n[AGENT REPLY BEFORE]:\n{response_before}\n")

# #     # --- PART 2: SUBMIT FEEDBACK & WAIT ---
# #     print("\n PART 2: TEACHING THE SYSTEM ")
# #     fb_text = "Global Rule: Our fiscal year begins on February 1st. User Preference: Use bullet points for lists."
# #     print(f"Submitting Feedback: '{fb_text}'")
# #     # Submit negative feedback to initiate the correction loop
# #     submit_feedback_sql(session, test_user_id, fb_text, is_positive=False)

# #     # print("\n--- Waiting 130 seconds for background tasks to process... ---")
# #     # # Wait for Classifier Task (1 min) + Summarizer Task (1 min) to finish cycles.
# #     # # This allows data to flow from Staging -> Logs -> Memory.
# #     # time.sleep(130) 
# #     # print("--- Wait complete. Memory should be updated. ---")

# #     # # --- PART 3: AFTER FEEDBACK ---
# #     # print("\n PART 3: VERIFICATION (After Feedback) ")
# #     # # Run the exact same query. The agent should now use the new memory.
# #     # response_after = call_cortex_agent_internal(session, test_user_id, test_query)
# #     # print(f"\n[AGENT REPLY AFTER]:\n{response_after}\n")

# #     # return "Test Complete. Check output panel for results."

I don't have access to information about your organization's fiscal year start date. Fiscal years vary significantly between different companies, organizations, and countries. 

To find out when your fiscal year starts, you could:
- Check with your finance/accounting department
- Look at recent financial statements or annual reports
- Review your employee handbook or internal documentation
- Ask your HR department or manager

Is there anything else I can help you with regarding fiscal year planning or budgeting concepts in general?



-- ================================================
-- SELF-CORRECTING AGENT: BACKEND SETUP CREATE
-- ================================================

-- ================================================
-- 2. STORAGE LAYER (TABLES)
-- ================================================

-- A. The "Fast Inbox" (Staging)
-- Your backend inserts here instantly. No processing happens on insert.
CREATE OR REPLACE TABLE feedback_staging (
    stage_id STRING DEFAULT UUID_STRING(),
    user_id STRING NOT NULL,
    feedback_text STRING,
    feedback_rating BOOLEAN, -- True=Positive, False=Negative (needs correction)
    created_at TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP()
);

-- B. The "Raw Journal" (Permanent Logs)
-- Data moves here AFTER the AI procedure classifies the scope.
CREATE OR REPLACE TABLE feedback_logs (
    log_id STRING DEFAULT UUID_STRING(),
    user_id STRING,
    feedback_text STRING,
    feedback_rating BOOLEAN,
    scope STRING,            -- 'USER' or 'GLOBAL' (Determined by AI)
    created_at TIMESTAMP_NTZ,
    processed_at TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP()
);

-- C. The "Active Memory" (Hybrid Table)
-- Optimized for ultra-fast, single-row lookups during agent runtime.
-- Requires an account enabled for Hybrid Tables.
CREATE OR REPLACE HYBRID TABLE user_memory (
    user_id STRING PRIMARY KEY,
    current_summary STRING,
    last_updated TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP()
);

-- ================================================
-- 3. CHANGE DETECTION (STREAMS)
-- ================================================

-- Stream tracking new insertions into the Inbox
CREATE OR REPLACE STREAM feedback_staging_stream ON TABLE feedback_staging;

-- Stream tracking new validated entries in the Journal
CREATE OR REPLACE STREAM feedback_logs_stream ON TABLE feedback_logs;

-- ================================================
-- 4. PROCESSING LAYER (AI STORED PROCEDURES)
-- ================================================

-- PROCEDURE 1: CLASSIFIER (Staging -> Logs)
-- Reads new staging data, uses small LLM to classify scope, inserts into logs.
CREATE OR REPLACE PROCEDURE process_staging_to_logs()
RETURNS STRING
LANGUAGE PYTHON
RUNTIME_VERSION = '3.10'
PACKAGES = ('snowflake-snowpark-python')
HANDLER = 'run_classification'
AS
$$
import pandas as pd

def run_classification(session):
    # 1. Read new INSERT data from the staging stream
    raw_df = session.sql("""
        SELECT user_id, feedback_text, feedback_rating, created_at
        FROM feedback_staging_stream
        WHERE metadata$action = 'INSERT'
    """).to_pandas()
    
    if raw_df.empty:
        return "Skipping: No new staging data detected."

    processed_rows = []
    
    # 2. Iterate and classify
    for _, row in raw_df.iterrows():
        text = row['FEEDBACK_TEXT']
        rating = row['FEEDBACK_RATING']
        user_id = row['USER_ID']
        created_at = row['CREATED_AT']
        
        detected_scope = 'USER' # Default assumption

        # Only execute AI classification for negative, textual feedback
        if rating == False and text and text.strip():
             # Escape for SQL safety in prompt
             safe_text_prompt = text.replace("'", "\\'").replace('"', '\\"')
             
             prompt = f"""
             <snowflake_prompt_trigger>
             Task: Classify feedback scope for an AI Agent.
             Definitions:
             - GLOBAL: Factual errors, wrong math, hallucinations, business logic bugs. (Applies to everyone).
             - USER: Tone preferences, formatting requests, language style. (Applies only to this user).
             
             Feedback: "{safe_text_prompt}"
             
             Output: Reply ONLY with the single word 'GLOBAL' or 'USER'.
             </snowflake_prompt_trigger>
             """
             
             try:
                # Use a fast, cheap model for simple classification
                cmd = "SELECT SNOWFLAKE.CORTEX.COMPLETE('llama3-8b', ?)"
                result_df = session.sql(cmd, params=[prompt]).collect()
                ai_response = result_df[0][0].strip().upper()
                
                if ai_response in ['GLOBAL', 'USER']:
                    detected_scope = ai_response
                # Else keep default 'USER' if LLM response is weird
             except Exception as e:
                 print(f"Classification error for user {user_id}: {e}")
                 # Keep default 'USER' on error

        # Prepare string for bulk insert
        safe_text_insert = text.replace("'", "''") if text else ""
        processed_rows.append(
            f"('{user_id}', '{safe_text_insert}', {rating}, '{detected_scope}', '{created_at}')"
        )

    # 3. Bulk Insert into Final Logs
    if processed_rows:
        values_str = ",".join(processed_rows)
        insert_sql = f"""
            INSERT INTO feedback_logs (user_id, feedback_text, feedback_rating, scope, created_at)
            VALUES {values_str}
        """
        session.sql(insert_sql).collect()

    return f"Success: Classified and moved {len(processed_rows)} rows to logs."
$$;

-- PROCEDURE 2: SUMMARIZER (Logs -> Active Memory)
-- Reads new logs, aggregates by user, merges with existing memory, summarizes using large LLM.
CREATE OR REPLACE PROCEDURE process_incremental_batch()
RETURNS STRING
LANGUAGE PYTHON
RUNTIME_VERSION = '3.10'
PACKAGES = ('snowflake-snowpark-python')
HANDLER = 'run_summarization'
AS
$$
from snowflake.snowpark.functions import col, lit, listagg
import pandas as pd

def run_summarization(session):
    # 1. Aggregate new logs by User ID into a single text block
    # We limit the aggregated string length to avoid overflowing LLM context windows unnecessarily.
    new_feedback_df = session.sql("""
        SELECT 
            user_id, 
            SUBSTR(LISTAGG('[' || scope || '] ' || feedback_text, ' | SELECT NEW_LINE'), 0, 20000) as new_notes 
        FROM feedback_logs_stream 
        WHERE metadata$action = 'INSERT' 
        GROUP BY user_id
    """)
    
    count_df = new_feedback_df.count()
    if count_df == 0:
         return "Skipping: No new logs to summarize."

    # 2. Join with Current Memory (Hybrid Table) to get the "Old State"
    # We use a LEFT JOIN to handle new users who don't have memory yet.
    batch_df = new_feedback_df.join(
        session.table("user_memory"), 
        new_feedback_df.col("user_id") == session.table("user_memory").col("user_id"), 
        "left"
    ).select(
        new_feedback_df.col("user_id"),
        new_feedback_df.col("new_notes"),
        col("current_summary")
    )

    # 3. Vectorized AI Call (SQL-based parallel execution)
    # We construct the prompt within SQL and pass it to Cortex in bulk.
    # Using a larger model (llama3-70b) for complex summarization.
    prompt_template = """
    You are an expert memory manager for an AI agent.
    Task: Update the user's profile based on new feedback.
    
    ### OLD PROFILE:
    ' || NVL(current_summary, 'No prior profile.') || '
    
    ### NEW FEEDBACK TO INTEGRATE:
    ' || new_notes || '
    
    ### INSTRUCTIONS:
    1. Consolidate the new feedback into the old profile.
    2. Resolve conflicts: New feedback overrides old profile data.
    3. Categorize clearly between "GLOBAL RULES" (facts/logic) and "USER PREFERENCES" (style/tone).
    4. Be concise. Output ONLY the updated profile text.
    """
    
    source_query = f"""
    SELECT 
        user_id,
        SNOWFLAKE.CORTEX.COMPLETE('llama3-70b', '{prompt_template}') as new_sum
    FROM ({batch_df.queries['queries'][0]})
    """

    # 4. Execute MERGE (Upsert) into Hybrid Table
    merge_sql = f"""
        MERGE INTO user_memory AS target
        USING ({source_query}) AS source
        ON target.user_id = source.user_id
        WHEN MATCHED THEN 
            UPDATE SET current_summary = source.new_sum, last_updated = CURRENT_TIMESTAMP()
        WHEN NOT MATCHED THEN 
            INSERT (user_id, current_summary) VALUES (source.user_id, source.new_sum)
    """
    
    session.sql(merge_sql).collect()
    return f"Success: Updated memory for {count_df} users."
$$;

-- ================================================
-- 5. AUTOMATION (TASKS)
-- ================================================

-- Task 1: The Classifier (Checks staging stream every minute)
CREATE OR REPLACE TASK backend_classifier_task
    WAREHOUSE = 'DEV_IMPACT_WH' -- Replace with your warehouse
    SCHEDULE = '1 MINUTE'
    WHEN SYSTEM$STREAM_HAS_DATA('feedback_staging_stream')
AS
    CALL process_staging_to_logs();

-- Task 2: The Summarizer (Checks logs stream every minute)
CREATE OR REPLACE TASK incremental_memory_task
    WAREHOUSE = 'DEV_IMPACT_WH' -- Replace with your warehouse
    SCHEDULE = '1 MINUTE'
    WHEN SYSTEM$STREAM_HAS_DATA('feedback_logs_stream')
AS
    CALL process_incremental_batch();

-- Start the automation tasks
ALTER TASK backend_classifier_task RESUME;
ALTER TASK incremental_memory_task RESUME;


 # Note: Use POST, not GET
            response = _snowflake.send_snow_api_request(
                "POST", 
                "/api/v2/cortex/threads", 
                {"Content-Type": "application/json"}, 
                {}, 
                {"origin_application": "my_app"}, 
                None, 
                30000
            )

            print(response)
            
-- ================================================
-- SETUP COMPLETE
-- ================================================


 # Note: Use POST, not GET
            response = _snowflake.send_snow_api_request(
                "POST", 
                "/api/v2/cortex/threads", 
                {"Content-Type": "application/json"}, 
                {}, 
                {"origin_application": "my_app"}, 
                None, 
                30000
            )

            print(response)


CREATE OR REPLACE PROCEDURE DIAGNOSTIC_TOOL(
    USER_QUERY VARCHAR,
    PARENT_NODE_IDS_JSON VARCHAR,
    TREE_ID VARCHAR
)
RETURNS VARCHAR
LANGUAGE PYTHON
RUNTIME_VERSION = '3.10'
PACKAGES = ('snowflake-snowpark-python', 'pandas', 'simplejson', 'pydantic')
HANDLER = 'main'
EXECUTE AS OWNER
AS $$
import simplejson as json
import concurrent.futures
import traceback
from pydantic import BaseModel, Field
from snowflake.snowpark import Session

# ==========================================
# 1. DATA MODELS
# ==========================================
class SqlGenerationResponse(BaseModel):
    sql_query: str = Field(description="The executable Snowflake SQL query")
    filters_applied: list[str] = Field(description="List of specific filters applied from the user request")

class StatusCheckResponse(BaseModel):
    is_bad: bool = Field(description="True if the metric value indicates a negative business outcome")
    reason: str = Field(description="Concise business reason (max 10 words)")

# ==========================================
# 2. HELPER FUNCTIONS
# ==========================================
def log_debug(session: Session, step_name: str, message: str):
    """Logs debug information to the database securely using Dollar Quoting."""
    try:
        DQ = "$" + "$"
        safe_msg = str(message)[:100000]
        safe_step = str(step_name)[:50]
        query = (
            "INSERT INTO DIAGNOSTIC_TOOL_DB_VERTEX.DIAGNOSTIC.DEBUG_LOGS_NEW "
            "(STEP_NAME, LOG_MESSAGE) VALUES (" + DQ + safe_step + DQ + ", " + DQ + safe_msg + DQ + ")"
        )
        session.sql(query).collect()
    except Exception:
        pass # Fail silently to strictly avoid interrupting main flow

# ==========================================
# 3. CORE LOGIC: PROCESS SINGLE NODE
# ==========================================
def process_node(session: Session, node: dict, user_query: str, meta_map: dict) -> dict:
    metric_name = node['metric']
    node_id = node['id']
    polarity = node.get('polarity', 0)
    DQ = "$" + "$"

    # --- Step 0: Validation ---
    log_debug(session, f"NODE_START_{node_id}", f"Processing Metric: {metric_name}")
    
    meta = meta_map.get(metric_name)
    if not meta:
        error_msg = f"Metadata missing for metric: {metric_name}"
        log_debug(session, f"NODE_ERROR_{node_id}", error_msg)
        return {"id": node_id, "status": "error", "error": error_msg}

    static_query = meta['SQL_QUERY']
    final_query = static_query
    query_type = "static"
    executed_sql = static_query

    # --- Step 1: Dynamic SQL Generation (GPT-4o) ---
    if user_query and len(user_query) > 5:
        try:
            log_debug(session, f"GEN_SQL_START_{node_id}", "Initiating prompt construction...")
            
            # Build Few-Shot Examples
            examples_text = ""
            ex_json = meta.get('FEW_SHOT_EXAMPLES')
            if ex_json:
                ex_list = json.loads(ex_json) if isinstance(ex_json, str) else ex_json
                for i, ex in enumerate(ex_list):
                    examples_text += "\nExample {}: User Request='{}' -> SQL='{}'".format(i+1, ex['question'], ex['sql'])

            # Expert Prompt Engineering
            prompt_content = """
            You are an expert Snowflake SQL Architect. 
            Your goal is to adapt a Standard SQL Logic to answer a specific User Request.

            **Context:**
            - Metric Name: {}
            - Standard Logic: {}
            - User Request: "{}"

            **Guidelines:**
            1. Keep the base logic of the Standard Logic (tables, joins, core calculations).
            2. Apply filters (WHERE clauses) based on the User Request (e.g., date ranges, regions, segments).
            3. Ensure the syntax is valid Snowflake SQL.
            4. If the User Request is irrelevant to this metric, return the Standard Logic unchanged.

            **Reference Examples:**
            {}
            """.format(metric_name, static_query, user_query, examples_text)

            # Sanitize Prompt
            safe_prompt = prompt_content.replace(DQ, "")
            
            # Define Output Schema
            options_str = json.dumps({
                "type": "json",
                "schema": {
                    "type": "object",
                    "properties": {
                        "sql_query": { "type": "string" },
                        "filters_applied": { "type": "array", "items": { "type": "string" } }
                    },
                    "required": ["sql_query", "filters_applied"],
                    "additionalProperties": False  # <--- ADD THIS LINE
                }
            })

            # Call Cortex (openai-gpt-4.1)
            cmd = (
                "SELECT AI_COMPLETE("
                "model => 'openai-gpt-4.1', "
                "prompt => " + DQ + safe_prompt + DQ + ", "
                "response_format => PARSE_JSON(" + DQ + options_str + DQ + ")"
                ")"
            )
            
            resp = session.sql(cmd).collect()
            raw_result = resp[0][0]
            log_debug(session, f"GEN_SQL_RESPONSE_{node_id}", str(raw_result))

            # Parse Response
            if isinstance(raw_result, str):
                parsed = SqlGenerationResponse.model_validate_json(raw_result)
            else:
                parsed = SqlGenerationResponse.model_validate(raw_result)
                
            final_query = parsed.sql_query
            query_type = "dynamic"
            
        except Exception as e:
            log_debug(session, f"GEN_SQL_FAIL_{node_id}", f"Error: {str(e)}. Fallback to static.")
            final_query = static_query
            query_type = "static_fallback"

    # --- Step 2: Query Execution ---
    val = "No Data"
    executed_sql = final_query
    
    try:
        log_debug(session, f"EXEC_START_{node_id}", f"Running SQL: {final_query}")
        df = session.sql(final_query).to_pandas()
        val = df.iloc[0,0] if not df.empty else "No Data"
        log_debug(session, f"EXEC_SUCCESS_{node_id}", f"Result Value: {val}")
        
    except Exception as e:
        log_debug(session, f"EXEC_FAIL_{node_id}", f"Primary SQL failed. Attempting recovery with static query. Error: {str(e)}")
        try:
            df = session.sql(static_query).to_pandas()
            val = df.iloc[0,0] if not df.empty else "No Data"
            executed_sql = static_query
            query_type = "static_recovery"
            log_debug(session, f"EXEC_RECOVERY_{node_id}", f"Recovery Value: {val}")
        except Exception as e2:
            return {"id": node_id, "status": "error", "error": f"Execution failed: {str(e2)}"}

    # --- Step 3: Status Analysis (openai-gpt-4.1) ---
    try:
        pol_txt = "Higher is BAD" if polarity == -1 else "Lower is BAD" if polarity == 1 else "Context dependent"
        
        status_prompt = """
        You are a Business Intelligence Analyst.
        Analyze the following metric result to determine if it represents a negative business outcome ('Bad').

        - Metric: {}
        - Value: {}
        - Business Rule: {}
        - User Context: "{}"

        Determine if this is 'Bad' for the business. Provide a concise reason.
        """.format(metric_name, val, pol_txt, user_query)

        safe_status_prompt = status_prompt.replace(DQ, "")
        
        status_options_str = json.dumps({
            "type": "json",
            "schema": {
                "type": "object",
                "properties": {
                    "is_bad": { "type": "boolean" },
                    "reason": { "type": "string" }
                },
                "required": ["is_bad", "reason"],
                "additionalProperties": False  # <--- ADD THIS LINE
            }
        })

        cmd = (
            "SELECT AI_COMPLETE("
            "model => 'openai-gpt-4.1', "
            "prompt => " + DQ + safe_status_prompt + DQ + ", "
            "response_format => PARSE_JSON(" + DQ + status_options_str + DQ + ")"
            ")"
        )
        
        resp = session.sql(cmd).collect()
        raw_result = resp[0][0]
        
        if isinstance(raw_result, str):
            status_obj = StatusCheckResponse.model_validate_json(raw_result)
        else:
            status_obj = StatusCheckResponse.model_validate(raw_result)
            
        status = "bad" if status_obj.is_bad else "good"
        
        return {
            "id": node_id,
            "name": metric_name,
            "value": str(val),
            "status": status,
            "reason": status_obj.reason,
            "query_type": query_type,
            "executed_sql": executed_sql
        }
        
    except Exception as e:
        log_debug(session, f"STATUS_FAIL_{node_id}", str(e))
        return {
            "id": node_id, 
            "name": metric_name, 
            "value": str(val), 
            "status": "unknown", 
            "error": "Status check failed",
            "query_type": query_type,
            "executed_sql": executed_sql
        }

# ==========================================
# 4. BATCH EXECUTOR
# ==========================================
def execute_batch(session: Session, nodes_list: list, user_query: str) -> list:
    if not nodes_list: 
        return []
    
    log_debug(session, "BATCH_START", f"Processing batch of {len(nodes_list)} nodes")
    
    # Efficient Metadata Loading
    DQ = "$" + "$"
    safe_names = [f"{DQ}{n['metric']}{DQ}" for n in nodes_list]
    names_str = ",".join(safe_names)
    
    meta_sql = f"SELECT METRIC_NAME, SQL_QUERY, FEW_SHOT_EXAMPLES FROM KPI_KNOWLEDGE_BASE_NEW WHERE METRIC_NAME IN ({names_str})"
    meta_df = session.sql(meta_sql).to_pandas()
    meta_map = {row['METRIC_NAME']: row.to_dict() for _, row in meta_df.iterrows()}
    
    results = []
    # Parallel Processing
    with concurrent.futures.ThreadPoolExecutor(max_workers=16) as executor:
        futures = [executor.submit(process_node, session, n, user_query, meta_map) for n in nodes_list]
        for f in concurrent.futures.as_completed(futures):
            results.append(f.result())
            
    return results

# ==========================================
# 5. MAIN ENTRY POINT
# ==========================================
def main(session: Session, user_query: str, parent_node_ids_json: str, tree_id: str):
    try:
        log_debug(session, "MAIN_ENTRY", f"TreeID: {tree_id}, Query: {user_query}")

        # 1. Load Decision Tree Structure
        tree_row = session.sql("SELECT GRAPH_JSON FROM DECISION_TREE_STORE_NEW WHERE TREE_ID = ?", params=[tree_id]).collect()
        
        if not tree_row: 
            return json.dumps({"error": f"Tree ID not found: {tree_id}"})
        
        full_json = json.loads(tree_row[0]['GRAPH_JSON'])
        graph = full_json.get('graph', full_json)
        
        # Build Lookup Maps
        all_nodes_map = {n['id']: n for n in graph.get('nodes', [])}
        name_to_node_map = {n['metric']: n for n in graph.get('nodes', [])}
        all_edges = graph.get('edges', [])

        # 2. Determine Strategy (Search vs Drill)
        targets_phase_1 = []
        
        # Robust Null Check
        is_drill_mode = (
            parent_node_ids_json is not None and 
            parent_node_ids_json != '' and 
            parent_node_ids_json.upper() != 'NULL' and 
            parent_node_ids_json != '[]'
        )

        if not is_drill_mode and user_query:
            log_debug(session, "STRATEGY", "Vector Search (No parent IDs provided)")
            # Vector Search for Entry Point
            vec_sql = """
            SELECT METRIC_NAME FROM KPI_KNOWLEDGE_BASE_NEW 
            ORDER BY VECTOR_L2_DISTANCE(SNOWFLAKE.CORTEX.EMBED_TEXT_768('snowflake-arctic-embed-m-v1.5', ?), KPI_EMBEDDING) ASC 
            LIMIT 1
            """
            kb_row = session.sql(vec_sql, params=[user_query]).collect()
            if kb_row and kb_row[0]['METRIC_NAME'] in name_to_node_map:
                found_metric = kb_row[0]['METRIC_NAME']
                targets_phase_1.append(name_to_node_map[found_metric])
                log_debug(session, "ANCHOR_FOUND", f"Matched: {found_metric}")

        elif is_drill_mode:
            log_debug(session, "STRATEGY", "Drill Down (Parent IDs provided)")
            try:
                p_ids = json.loads(parent_node_ids_json)
                if not isinstance(p_ids, list): p_ids = [p_ids]
                parent_set = set(p_ids)
                
                # Find children of provided parents
                for edge in all_edges:
                    if edge['source'] in all_nodes_map and edge['target'] in parent_set:
                         # Note: Depending on edge direction (source->target), adjust accordingly.
                         # Assuming Source=Parent, Target=Child? Or Source=Metric, Target=Root?
                         # Usually standard DAG is Parent -> Child. 
                         # If input is 'Parent Nodes', we want their children.
                         # CHECK: Your previous code checked 'target' in parent_set. 
                         # If Edge is Source(Parent)->Target(Child), then Target in ParentSet means we are looking for parents?
                         # Let's assume the previous logic was correct: "Find nodes connected to these parents"
                         if edge['target'] in parent_set:
                             targets_phase_1.append(all_nodes_map[edge['source']])
            except Exception as e:
                log_debug(session, "DRILL_ERROR", str(e))

        # 3. Execute Phase 1 (Entry Nodes)
        results_phase_1 = execute_batch(session, targets_phase_1, user_query)

        # 4. Execute Phase 2 (Greedy Traversal of "Bad" Nodes)
        bad_ids = {r['id'] for r in results_phase_1 if r.get('status') == 'bad'}
        targets_phase_2 = []
        
        if bad_ids:
            log_debug(session, "PHASE_2", f"Expanding bad nodes: {list(bad_ids)}")
            for edge in all_edges:
                # If a node was bad, check its relationships
                if edge['target'] in bad_ids and edge['source'] in all_nodes_map:
                    targets_phase_2.append(all_nodes_map[edge['source']])
        
        results_phase_2 = execute_batch(session, targets_phase_2, user_query)

        # 5. Final Output
        return json.dumps({
            "nodes_analyzed": results_phase_1 + results_phase_2,
            "edges_traversed": [e for e in all_edges if e['target'] in bad_ids or e['source'] in bad_ids]
        })

    except Exception as e:
        log_debug(session, "MAIN_CRASH", str(e))
        return json.dumps({"error": "Critical Procedure Error", "details": str(e), "trace": traceback.format_exc()})
$$;



DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB
 / 
AI_POC
 / 
DIAGNOSTIC_TOOL(VARCHAR, VARCHAR, VARCHAR)


**Role & Objective**
You are an **Autonomous Root Cause Analysis Agent** designed to traverse a metric decision tree from the root node down to the leaf nodes. Your goal is to identify specific "bad" metrics driving a business problem by systematically drilling down into the data.

ALWAYS USE tree_id as Pharma_Master_v1.

**Available Tools**
You have access to a single diagnostic tool. You must use this tool for all data retrieval.

* `Diagnostic_tool(USER_QUERY: str, PARENT_NODE_IDS_JSON: str)`
* **Description:** Retrieves metric status for a given context. It operates in two modes:
1. **Search Mode:** Used to find the starting "Root" node based on a user's question.
2. **Drill Mode:** Used to find the children of specific parent nodes to investigate "bad" metrics further.


* **Arguments:**
* `USER_QUERY`: The user's natural language question (e.g., "Why is cost high?"). Set to `NULL` during Drill Mode.
* `PARENT_NODE_IDS_JSON`: A JSON string list of Node IDs (e.g., `'["node_123", "node_456"]'`). Set to `NULL` during Search Mode.


**Operational Procedure (The Analysis Loop)**
You must strictly follow this recursive logic for every user request:

**Step 1: Initialization (Find the Root)**

* If this is the start of the conversation, call `Diagnostic_tool` in **Search Mode**.
* **Action:** Call `Diagnostic_tool(USER_QUERY=user_question, PARENT_NODE_IDS_JSON=NULL)`.
* **Next:** Proceed to Step 2 with the results.

**Step 2: Status Evaluation & Decision**
Analyze the list of nodes returned by the tool. Focus **only** on nodes where `"status": "bad"`.

* **Check:** For every "bad" node, do you see its children in the current list?
* **Condition A (Drill Needed):** If a node is "bad" and you do **not** see its children, you must drill down. Collect these Node IDs.
* **Condition B (Keep Going):** If a node is "bad" but you **already** see its children, ignore it and evaluate the children instead.
* **Condition C (Stop):** If you find "bad" nodes but they have no children (empty results from a drill), these are your **Root Causes**.

**Step 3: Execution (Drill Down)**

* If Condition A occurred: Call `Diagnostic_tool` in **Drill Mode**.
* **Action:** Call `Diagnostic_tool(USER_QUERY=NULL, PARENT_NODE_IDS_JSON='["ID_1", "ID_2"]')`.


* **Next:** Recursively repeat Step 2 with the new output.
* If Condition C occurred: Present the final root causes to the user.

**Constraints**

* **Never** guess the status of a metric; always use the tool.
* **Never** stop at a "bad" node if it has unexplored children; you must find the leaf node.
* Output your reasoning briefly before calling the tool.

---

### **Few-Shot Example: Root Cause Analysis**

**User:** "Why is profitability down?"

**Assistant:**
*Thought: The user is asking a high-level question about a metric. I need to find the starting node and its immediate children to see what is happening.*
**Tool Use:** `Diagnostic_tool(USER_QUERY='Why is profitability down?', PARENT_NODE_IDS_JSON=NULL)`

**Tool Output:**

```json
[
  {"id": "N0", "metric": "Profitability", "status": "bad"},
  {"id": "N1", "metric": "Revenue", "status": "good"},
  {"id": "N2", "metric": "Total Cost", "status": "bad"}
]

```

**Assistant:**
*Thought: I have the initial results. `N0` (Profitability) is "bad", which confirms the user's issue. I see two children: `N1` (Revenue) is "good", so that branch is healthy. However, `N2` (Total Cost) is "bad". Since I do not see the children of `N2` in the current list, I must drill down into `N2` to understand what is driving the high cost.*
**Tool Use:** `Diagnostic_tool(USER_QUERY=NULL, PARENT_NODE_IDS_JSON='["N2"]')`

**Tool Output:**

```json
[
  {"id": "N3", "metric": "Fixed Cost", "status": "good"},
  {"id": "N4", "metric": "Variable Cost", "status": "bad"}
]

```

**Assistant:**
*Thought: I have drilled into Total Cost. `N3` (Fixed Cost) is "good", so I can ignore it. `N4` (Variable Cost) is "bad". I do not see the children of `N4` yet. I need to drill deeper to see if there is a more specific cause.*
**Tool Use:** `Diagnostic_tool(USER_QUERY=NULL, PARENT_NODE_IDS_JSON='["N4"]')`

**Tool Output:**

```json
[]

```

**Assistant:**
*Thought: The tool returned an empty list for `N4`. This indicates that `N4` (Variable Cost) is a leaf node in the decision tree. I have reached the bottom of the "bad" chain. I can now conclude the diagnosis.*
**Final Answer:** Profitability is down because **Variable Cost (N4)** is performing poorly. While Revenue and Fixed Costs are stable, the high Variable Cost is driving the overall decline.


**Response Structure (STRICT)**
You must output exactly two sections in the following order. Do not include any conversational filler before or after these sections.

#### **SECTION 1: Diagnostic Executive Summary**

* **Tone:** Professional, constructive, and polite. Even if metrics are "bad," frame the insights objectively (e.g., instead of "Critical Failure," use "Performance Deviation").
* **Headline:** State the Root Cause clearly (e.g., *"Root Cause Identified: [Deepest Bad Metric Name]"*).
* **The Narrative:** Briefly explain the chain of events in simple English. Start from the top node and explain the path of "bad" metrics that led to the root cause. Mention which branches were ruled out because they were "stable" or "good."
* **Actionable Insight:** Based on the metadata or description of the root node, suggest a generic, helpful next step.

---

#### **SECTION 2: React Flow JSON Artifact**

You must generate a valid JSON object inside a Markdown code block (`json ... `). You act as the layout engine.

**1. Coordinate Logic (The "Mental Layout"):**
Assign `position: {x, y}` to nodes based on their hierarchy level to ensure a clean tree structure:

* **Level 0 (Root):** `x: 0, y: 0`
* **Level 1 Children:** `y: 150`. Spread `x` widely (e.g., `-300` and `300`).
* **Level 2 Grandchildren:** `y: 300`. Spread `x` relative to their parent (e.g., `parent_x - 100` and `parent_x + 100`).
* **Level 3+:** Increase `y` by `150` for each level.

**2. Visual Style Logic:**

* **Red (`#FFE2E5`):** Status is "bad", "high", or "error".
* **Green (`#CDE8E6`):** Status is "good", "normal", or "stable".
* **Orange (`#FFCCBC`):** The **Root Cause** (the deepest "bad" node in the chain with no "bad" children).
* **White (`#FFFFFF`):** Unexplored or neutral nodes.

**3. Edge Labeling Logic:**

* Every edge must have a `label` explaining the relationship.
* If Parent is Bad and Child is Bad, label = "contributes to impact".
* If Parent is Bad and Child is Good, label = "stable factor".

**4. JSON Schema (Must Follow Exactly):**
Construct the JSON using this structure. Ensure all strings are double-quoted.

```json
{
  "nodes": [
    {
      "id": "N0",
      "type": "default",
      "data": { "label": "Metric Name: Value" },
      "position": { "x": 0, "y": 0 },
      "style": { 
         "background": "#FFE2E5", 
         "width": 180, 
         "color": "#333", 
         "border": "1px solid #777", 
         "borderRadius": "8px" 
      }
    }
  ],
  "edges": [
    {
      "id": "e-N0-N1",
      "source": "N0",
      "target": "N1",
      "label": "driven by",
      "animated": true,
      "style": { "stroke": "#555", "strokeWidth": 2 }
    }
  ]
}

```

---

### **Few-Shot Example**

**User:** "Visualize the results for the Profitability analysis."
*(Context provided: Profit is down, Revenue is stable, Cost is up, Variable Cost is up)*

**Assistant:**

#### **SECTION 1: Diagnostic Executive Summary**

**Root Cause Identified: Variable Cost (N3)**
We have completed the analysis of your Profitability metrics. The investigation began with **Profitability**, which is currently tracking below target. To understand why, we analyzed its two main drivers: **Revenue** and **Total Cost**.

We found that Revenue is stable and performing well, which is great news. However, **Total Cost** is higher than expected. By drilling deeper into the cost structure, we identified that while Fixed Costs are normal, **Variable Costs** are significantly elevated.

**Actionable Insight:** We recommend reviewing the primary components of your variable spend, such as raw material procurement or hourly labor efficiency, to identify potential savings.

---

#### **SECTION 2: React Flow JSON Artifact**

```json
{
  "nodes": [
    {
      "id": "N0",
      "type": "default",
      "data": { "label": "Profitability: -15%" },
      "position": { "x": 0, "y": 0 },
      "style": { "background": "#FFE2E5", "width": 180, "border": "1px solid #777", "borderRadius": "8px" }
    },
    {
      "id": "N1",
      "type": "default",
      "data": { "label": "Revenue: $1.2M" },
      "position": { "x": -300, "y": 150 },
      "style": { "background": "#CDE8E6", "width": 180, "border": "1px solid #777", "borderRadius": "8px" }
    },
    {
      "id": "N2",
      "type": "default",
      "data": { "label": "Total Cost: $900k" },
      "position": { "x": 300, "y": 150 },
      "style": { "background": "#FFE2E5", "width": 180, "border": "1px solid #777", "borderRadius": "8px" }
    },
    {
      "id": "N3",
      "type": "default",
      "data": { "label": "Variable Cost: $600k" },
      "position": { "x": 300, "y": 300 },
      "style": { "background": "#FFCCBC", "width": 180, "border": "1px solid #777", "borderRadius": "8px" }
    }
  ],
  "edges": [
    {
      "id": "e-N0-N1",
      "source": "N0",
      "target": "N1",
      "label": "stable factor",
      "animated": false
    },
    {
      "id": "e-N0-N2",
      "source": "N0",
      "target": "N2",
      "label": "driven by",
      "animated": true,
      "style": { "stroke": "#FF0000", "strokeWidth": 2 }
    },
    {
      "id": "e-N2-N3",
      "source": "N2",
      "target": "N3",
      "label": "primary driver",
      "animated": true,
      "style": { "stroke": "#FF0000", "strokeWidth": 2 }
    }
  ]
}

```


 response_dict = _snowflake.send_snow_api_request(
            "POST",
            AGENT_ENDPOINT_URL,
            headers,
            {}, 
            payload, 
            {}, 
            TIMEOUT_MS
        )
        
        response_content = response_dict.get("content", "")
        if not response_content: return "Error: Empty response"
            
        parsed_response = json.loads(response_content)

        # --- PARSING ---
        if isinstance(parsed_response, dict) and 'message' in parsed_response:
            content_items = parsed_response['message'].get('content', [])
            for item in reversed(content_items):
                if isinstance(item, dict) and item.get("type") == "text":
                    return item.get("text")
        
        # Fallback for list/stream format
        elif isinstance(parsed_response, list):
            for item in parsed_response:
                if item.get('event') == 'response':
                    try:
                        content_list = item.get('data', {}).get('content', [])
                        for part in content_list:
                            if part.get('type') == 'text':
                                return part.get('text')
                    except Exception: continue
            
            # Simple Text Delta reconstruction
            chunks = []
            for item in parsed_response:
                if item.get('event') == 'response.text.delta':
                    chunks.append(item.get('data', {}).get('text', ''))
            if chunks: return "".join(chunks)

        return "Could not parse response."
100357 (P0000): Cannot create a Python function with the specified packages. Please check your packages specification and try again.






import json
import logging
import _snowflake # Native Snowflake module for internal API calls
from typing import List, Dict, Any, Optional, Literal
from pydantic import BaseModel, Field
from snowflake.snowpark import Session

# ==========================================
# 1. PYDANTIC MODELS
# ==========================================

class PlannerDecision(BaseModel):
    """
    Structured output from the Planner Agent.
    """
    route: Literal['diagnostic', 'clarify'] = Field(..., description="The designated agent to handle the request")
    query: str = Field(..., description="The refined query to pass to the agent")
    reasoning: str = Field(..., description="Why this route was chosen")

class DiagnosticResult(BaseModel):
    """
    Structured output from the Diagnostic Agent.
    """
    summary_text: str = Field(..., description="Executive summary of findings")
    react_flow_json: Optional[Dict] = Field(None, description="The visual graph data")
    clarifying_question: Optional[str] = Field(None, description="Question to ask user if intent is unclear")

class AgentConfig(BaseModel):
    model: str = "claude-4-sonnet"
    diagnostic_udf: str = "DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.AI_POC.DIAGNOSTIC_TOOL"
    warehouse: str = "DEV_IMPACT_WH"

# ==========================================
# 2. CORTEX API WRAPPER (Native _snowflake)
# ==========================================

def invoke_cortex_agent(session: Session, payload: Dict) -> Dict:
    """
    Invokes the Cortex Agent API using the internal _snowflake module.
    Parses specific event streams for text, charts, tables, and tool results.
    """
    AGENT_ENDPOINT_URL = "/api/v2/cortex/agent:run"
    TIMEOUT_MS = 90000  # 90 seconds
    
    # Construct headers - Authorization is handled internally by _snowflake but headers dict is required
    headers = {
        "Content-Type": "application/json",
        "Accept": "text/event-stream"
    }

    try:
        # Native Snowflake API call
        response_dict = _snowflake.send_snow_api_request(
            "POST",
            AGENT_ENDPOINT_URL,
            headers,
            {}, 
            payload, 
            {}, 
            TIMEOUT_MS
        )
        
        response_content = response_dict.get("content", "")
        if not response_content:
            return {"error": "Empty response from Agent API"}
            
        # The internal API often returns the stream as a valid JSON list of event objects
        # or a single JSON object if not streaming.
        try:
            parsed_response = json.loads(response_content)
        except json.JSONDecodeError:
            return {"error": "Failed to decode JSON response content"}

        # --- COMPREHENSIVE PARSING ---
        # We need to extract all artifacts: Text, Tables, Charts, Tool info, etc.
        extracted = {
            "text": "",
            "tables": [],
            "charts": [],
            "tool_uses": [],
            "annotations": [],
            "debug_trace": [] # For thinking, status, etc.
        }

        # Helper to process a content list (from final 'response' or individual events)
        def process_content_list(content_items):
            for item in content_items:
                c_type = item.get("type")
                if c_type == "text":
                    extracted["text"] += item.get("text", "")
                    if item.get("annotations"):
                        extracted["annotations"].extend(item["annotations"])
                elif c_type == "table":
                    extracted["tables"].append(item.get("result_set", {}))
                elif c_type == "chart":
                    extracted["charts"].append(item.get("chart", {}))
                elif c_type == "tool_use":
                    extracted["tool_uses"].append(item)

        # 1. Handle List of Events (Streaming format)
        if isinstance(parsed_response, list):
            # First pass: Look for the final 'response' event which is the aggregation
            final_response_event = next((item for item in parsed_response if item.get('event') == 'response'), None)
            
            if final_response_event:
                # Best Case: We have the fully aggregated response
                data = final_response_event.get('data', {})
                process_content_list(data.get('content', []))
            else:
                # Fallback: Reconstruct from deltas
                text_parts = []
                for item in parsed_response:
                    evt = item.get('event')
                    data = item.get('data', {})
                    
                    if evt == 'response.text.delta':
                        text_parts.append(data.get('text', ''))
                    elif evt == 'response.text.annotation':
                        extracted["annotations"].append(data.get('annotation'))
                    elif evt == 'response.chart':
                        extracted["charts"].append(data.get('chart') or data.get('chart_spec'))
                    elif evt == 'response.table':
                        extracted["tables"].append(data.get('result_set'))
                    elif evt == 'response.tool_use':
                        extracted["tool_uses"].append(data)
                    elif evt == 'response.thinking.delta':
                        extracted["debug_trace"].append(f"Thinking: {data.get('text')}")
                    elif evt == 'response.status':
                        extracted["debug_trace"].append(f"Status: {data.get('status')}")
                    elif evt == 'error':
                        return {"error": f"Agent Error: {data.get('message')}"}
                
                extracted["text"] = "".join(text_parts)

        # 2. Handle Single Object (Non-streaming or final format)
        elif isinstance(parsed_response, dict):
            if 'message' in parsed_response:
                process_content_list(parsed_response['message'].get('content', []))
            elif 'choices' in parsed_response: # Legacy/Standard REST format
                process_content_list(parsed_response['choices'][0]['message'].get('content', []))

        return extracted

    except Exception as e:
        return {"error": f"API Execution Exception: {str(e)}"}

# ==========================================
# 3. PAYLOAD FACTORY
# ==========================================

class PayloadFactory:
    @staticmethod
    def create(
        query: str,
        instructions: Dict[str, str],
        tools: List[Dict] = None,
        tool_resources: Dict = None,
        history: List[Dict] = None
    ) -> Dict:
        config = AgentConfig()
        messages = history if history else []
        messages.append({"role": "user", "content": [{"type": "text", "text": query}]})

        return {
            # "thread_id": 0,
            # "parent_message_id": 0,
            "messages": messages,
            "tool_choice": {"type": "auto"},
            "models": {"orchestration": config.model},
            "instructions": instructions,
            "tools": tools or [],
            "tool_resources": tool_resources or {}
        }

# ==========================================
# 4. AGENT LOGIC
# ==========================================

class AgentManager:
    def __init__(self, session: Session):
        self.session = session
        self.config = AgentConfig()

    def run_rephraser(self, query: str, history: List[Dict]) -> str:
        """Step 1: Rephrase Query"""
        instructions = {
            "system": "You are a sophisticated Query Refinement Engine.",
            "response": "Output ONLY the final rephrased string. Do not include prefixes like 'Rephrased:'.",
            "orchestration": (
                "Your goal is to transform the user's latest input into a fully standalone, unambiguous query.\n"
                "1. Resolve all pronouns (it, they, that, this) using the conversation history.\n"
                "2. If the user refers to a specific metric or ID from history, explicitly include it.\n"
                "3. If the query is already clear, return it unchanged.\n\n"
                "**Few-Shot Examples:**\n"
                "- Context: [User: 'How is Revenue?'] -> Input: 'Why did it drop?' -> Output: 'Why did Revenue drop?'\n"
                "- Context: [] -> Input: 'Explain the dip in Profit' -> Output: 'Explain the dip in Profit'\n"
                "- Context: [Asst: 'Cost is high'] -> Input: 'Drill down' -> Output: 'Drill down into Cost'"
            )
        }
        
        payload = PayloadFactory.create(
            f"Rephrase this to be standalone: {query}",
            instructions,
            history=history
        )
        
        resp = invoke_cortex_agent(self.session, payload)
        
        # Extracted text is at the top level now
        return resp.get('text', query).strip() or query

    def run_planner(self, query: str) -> PlannerDecision:
        """Step 2: Plan Route"""
        schema_hint = '{"route": "diagnostic" | "clarify", "query": "string", "reasoning": "string"}'
        instructions = {
            "system": "You are a Strategic Intent Classifier.",
            "response": f"Respond ONLY with valid JSON matching: {schema_hint}",
            "orchestration": (
                "Analyze the user's input to determine the precise analytical needs.\n"
                "**Routing Logic:**\n"
                "1. **diagnostic**: Use for questions seeking explanations, root causes, drivers, or specific metric analysis (e.g., 'Why', 'What caused', 'Analyze', 'Drill down').\n"
                "2. **clarify**: Use for vague inputs, greetings, or when the metric/topic is completely missing (e.g., 'Hello', 'Help', 'Data').\n\n"
                "**Few-Shot Examples:**\n"
                "- Input: 'Why is Net Income trending down?' -> Route: 'diagnostic'\n"
                "- Input: 'Can you explain the variance in COGS?' -> Route: 'diagnostic'\n"
                "- Input: 'Hi, how are you?' -> Route: 'clarify'\n"
                "- Input: 'What is the root cause?' -> Route: 'diagnostic'"
            )
        }
        
        payload = PayloadFactory.create(f"Analyze this query: {query}", instructions)
        resp = invoke_cortex_agent(self.session, payload)
        
        try:
            raw_text = resp.get('text', '')
            clean_json = raw_text.replace("```json", "").replace("```", "").strip()
            return PlannerDecision.model_validate_json(clean_json)
        except Exception:
            return PlannerDecision(route="diagnostic", query=query, reasoning="Fallback error")

    def run_diagnostic_agent(self, query: str) -> DiagnosticResult:
        """Step 3: Run Diagnostic Tool"""
        response_format_instruction = """
        You must output a JSON object with these exact keys:
        {
            "summary_text": "The executive summary...",
            "react_flow_json": { ... valid React Flow JSON object ... },
            "clarifying_question": null or "Question string if needed"
        }
        """

        instructions = {
            "system": "You are an Autonomous Root Cause Analysis Agent.",
            "orchestration": f"""**Role & Objective**

You are an **Autonomous Root Cause Analysis Agent** designed to traverse a metric decision tree from the root node down to the leaf nodes. Your goal is to identify specific "bad" metrics driving a business problem by systematically drilling down into the data.



ALWAYS USE tree_id as Pharma_Master_v1.



**Available Tools**

You have access to a single diagnostic tool. You must use this tool for all data retrieval.



* `Diagnostic_tool(USER_QUERY: str, PARENT_NODE_IDS_JSON: str)`

* **Description:** Retrieves metric status for a given context. It operates in two modes:

1. **Search Mode:** Used to find the starting "Root" node based on a user's question.

2. **Drill Mode:** Used to find the children of specific parent nodes to investigate "bad" metrics further.





* **Arguments:**

* `USER_QUERY`: The user's natural language question (e.g., "Why is cost high?"). Set to `NULL` during Drill Mode.

* `PARENT_NODE_IDS_JSON`: A JSON string list of Node IDs (e.g., `'["node_123", "node_456"]'`). Set to `NULL` during Search Mode.





**Operational Procedure (The Analysis Loop)**

You must strictly follow this recursive logic for every user request:



**Step 1: Initialization (Find the Root)**



* If this is the start of the conversation, call `Diagnostic_tool` in **Search Mode**.

* **Action:** Call `Diagnostic_tool(USER_QUERY=user_question, PARENT_NODE_IDS_JSON=NULL)`.

* **Next:** Proceed to Step 2 with the results.



**Step 2: Status Evaluation & Decision**

Analyze the list of nodes returned by the tool. Focus **only** on nodes where `"status": "bad"`.



* **Check:** For every "bad" node, do you see its children in the current list?

* **Condition A (Drill Needed):** If a node is "bad" and you do **not** see its children, you must drill down. Collect these Node IDs.

* **Condition B (Keep Going):** If a node is "bad" but you **already** see its children, ignore it and evaluate the children instead.

* **Condition C (Stop):** If you find "bad" nodes but they have no children (empty results from a drill), these are your **Root Causes**.



**Step 3: Execution (Drill Down)**



* If Condition A occurred: Call `Diagnostic_tool` in **Drill Mode**.

* **Action:** Call `Diagnostic_tool(USER_QUERY=NULL, PARENT_NODE_IDS_JSON='["ID_1", "ID_2"]')`.





* **Next:** Recursively repeat Step 2 with the new output.

* If Condition C occurred: Present the final root causes to the user.



**Constraints**



* **Never** guess the status of a metric; always use the tool.

* **Never** stop at a "bad" node if it has unexplored children; you must find the leaf node.

* Output your reasoning briefly before calling the tool.



---



### **Few-Shot Example: Root Cause Analysis**



**User:** "Why is profitability down?"



**Assistant:**

*Thought: The user is asking a high-level question about a metric. I need to find the starting node and its immediate children to see what is happening.*

**Tool Use:** `Diagnostic_tool(USER_QUERY='Why is profitability down?', PARENT_NODE_IDS_JSON=NULL)`



**Tool Output:**



```json

[

  {"id": "N0", "metric": "Profitability", "status": "bad"},

  {"id": "N1", "metric": "Revenue", "status": "good"},

  {"id": "N2", "metric": "Total Cost", "status": "bad"}

]



```



**Assistant:**

*Thought: I have the initial results. `N0` (Profitability) is "bad", which confirms the user's issue. I see two children: `N1` (Revenue) is "good", so that branch is healthy. However, `N2` (Total Cost) is "bad". Since I do not see the children of `N2` in the current list, I must drill down into `N2` to understand what is driving the high cost.*

**Tool Use:** `Diagnostic_tool(USER_QUERY=NULL, PARENT_NODE_IDS_JSON='["N2"]')`



**Tool Output:**



```json

[

  {"id": "N3", "metric": "Fixed Cost", "status": "good"},

  {"id": "N4", "metric": "Variable Cost", "status": "bad"}

]



```



**Assistant:**

*Thought: I have drilled into Total Cost. `N3` (Fixed Cost) is "good", so I can ignore it. `N4` (Variable Cost) is "bad". I do not see the children of `N4` yet. I need to drill deeper to see if there is a more specific cause.*

**Tool Use:** `Diagnostic_tool(USER_QUERY=NULL, PARENT_NODE_IDS_JSON='["N4"]')`



**Tool Output:**



```json

[]



```



**Assistant:**

*Thought: The tool returned an empty list for `N4`. This indicates that `N4` (Variable Cost) is a leaf node in the decision tree. I have reached the bottom of the "bad" chain. I can now conclude the diagnosis.*

**Final Answer:** Profitability is down because **Variable Cost (N4)** is performing poorly. While Revenue and Fixed Costs are stable, the high Variable Cost is driving the overall decline.
""",
            "response": f"""**Response Structure (STRICT)**

You must output exactly two sections in the following order. Do not include any conversational filler before or after these sections.



#### **SECTION 1: Diagnostic Executive Summary**



* **Tone:** Professional, constructive, and polite. Even if metrics are "bad," frame the insights objectively (e.g., instead of "Critical Failure," use "Performance Deviation").

* **Headline:** State the Root Cause clearly (e.g., *"Root Cause Identified: [Deepest Bad Metric Name]"*).

* **The Narrative:** Briefly explain the chain of events in simple English. Start from the top node and explain the path of "bad" metrics that led to the root cause. Mention which branches were ruled out because they were "stable" or "good."

* **Actionable Insight:** Based on the metadata or description of the root node, suggest a generic, helpful next step.



---



#### **SECTION 2: React Flow JSON Artifact**



You must generate a valid JSON object inside a Markdown code block (`json ... `). You act as the layout engine.



**1. Coordinate Logic (The "Mental Layout"):**

Assign `position: {x, y}` to nodes based on their hierarchy level to ensure a clean tree structure:



* **Level 0 (Root):** `x: 0, y: 0`

* **Level 1 Children:** `y: 150`. Spread `x` widely (e.g., `-300` and `300`).

* **Level 2 Grandchildren:** `y: 300`. Spread `x` relative to their parent (e.g., `parent_x - 100` and `parent_x + 100`).

* **Level 3+:** Increase `y` by `150` for each level.



**2. Visual Style Logic:**



* **Red (`#FFE2E5`):** Status is "bad", "high", or "error".

* **Green (`#CDE8E6`):** Status is "good", "normal", or "stable".

* **Orange (`#FFCCBC`):** The **Root Cause** (the deepest "bad" node in the chain with no "bad" children).

* **White (`#FFFFFF`):** Unexplored or neutral nodes.



**3. Edge Labeling Logic:**



* Every edge must have a `label` explaining the relationship.

* If Parent is Bad and Child is Bad, label = "contributes to impact".

* If Parent is Bad and Child is Good, label = "stable factor".



**4. JSON Schema (Must Follow Exactly):**

Construct the JSON using this structure. Ensure all strings are double-quoted.



```json

{

  "nodes": [

    {

      "id": "N0",

      "type": "default",

      "data": { "label": "Metric Name: Value" },

      "position": { "x": 0, "y": 0 },

      "style": { 

         "background": "#FFE2E5", 

         "width": 180, 

         "color": "#333", 

         "border": "1px solid #777", 

         "borderRadius": "8px" 

      }

    }

  ],

  "edges": [

    {

      "id": "e-N0-N1",

      "source": "N0",

      "target": "N1",

      "label": "driven by",

      "animated": true,

      "style": { "stroke": "#555", "strokeWidth": 2 }

    }

  ]

}



```



---



### **Few-Shot Example**



**User:** "Visualize the results for the Profitability analysis."

*(Context provided: Profit is down, Revenue is stable, Cost is up, Variable Cost is up)*



**Assistant:**



#### **SECTION 1: Diagnostic Executive Summary**



**Root Cause Identified: Variable Cost (N3)**

We have completed the analysis of your Profitability metrics. The investigation began with **Profitability**, which is currently tracking below target. To understand why, we analyzed its two main drivers: **Revenue** and **Total Cost**.



We found that Revenue is stable and performing well, which is great news. However, **Total Cost** is higher than expected. By drilling deeper into the cost structure, we identified that while Fixed Costs are normal, **Variable Costs** are significantly elevated.



**Actionable Insight:** We recommend reviewing the primary components of your variable spend, such as raw material procurement or hourly labor efficiency, to identify potential savings.



---



#### **SECTION 2: React Flow JSON Artifact**



```json

{

  "nodes": [

    {

      "id": "N0",

      "type": "default",

      "data": { "label": "Profitability: -15%" },

      "position": { "x": 0, "y": 0 },

      "style": { "background": "#FFE2E5", "width": 180, "border": "1px solid #777", "borderRadius": "8px" }

    },

    {

      "id": "N1",

      "type": "default",

      "data": { "label": "Revenue: $1.2M" },

      "position": { "x": -300, "y": 150 },

      "style": { "background": "#CDE8E6", "width": 180, "border": "1px solid #777", "borderRadius": "8px" }

    },

    {

      "id": "N2",

      "type": "default",

      "data": { "label": "Total Cost: $900k" },

      "position": { "x": 300, "y": 150 },

      "style": { "background": "#FFE2E5", "width": 180, "border": "1px solid #777", "borderRadius": "8px" }

    },

    {

      "id": "N3",

      "type": "default",

      "data": { "label": "Variable Cost: $600k" },

      "position": { "x": 300, "y": 300 },

      "style": { "background": "#FFCCBC", "width": 180, "border": "1px solid #777", "borderRadius": "8px" }

    }

  ],

  "edges": [

    {

      "id": "e-N0-N1",

      "source": "N0",

      "target": "N1",

      "label": "stable factor",

      "animated": false

    },

    {

      "id": "e-N0-N2",

      "source": "N0",

      "target": "N2",

      "label": "driven by",

      "animated": true,

      "style": { "stroke": "#FF0000", "strokeWidth": 2 }

    },

    {

      "id": "e-N2-N3",

      "source": "N2",

      "target": "N3",

      "label": "primary driver",

      "animated": true,

      "style": { "stroke": "#FF0000", "strokeWidth": 2 }

    }

  ]

}



```.

Ensure your final answer is strictly valid JSON matching: {response_format_instruction}"""
        }

        tools = [{
            "tool_spec": {
                "type": "generic",
                "name": "Diagnostic_tool",
                "description": "Retrieves metric status. Search Mode or Drill Mode.",
                "input_schema": {
                    "type": "object",
                    "properties": {
                        "USER_QUERY": {"type": "string", "description": "Query or NULL"},
                        "PARENT_NODE_IDS_JSON": {"type": "string", "description": "NULL or list of IDs"},
                        "TREE_ID": {"type": "string", "description": "Always 'Pharma_Master_v1'"}
                    },
                    "required": ["USER_QUERY", "PARENT_NODE_IDS_JSON", "TREE_ID"]
                }
            }
        }]

        tool_resources = {
            "Diagnostic_tool": {
                "type": "procedure",
                "execution_environment": {
                    "type": "warehouse",
                    "warehouse": self.config.warehouse
                },
                "identifier": self.config.diagnostic_udf
            }
        }

        payload = PayloadFactory.create(query, instructions, tools, tool_resources)
        resp = invoke_cortex_agent(self.session, payload)
        print(resp)
        try:
            # The agent returns the JSON structure inside the 'text' field
            raw_text = resp.get('text', '')
            clean_content = raw_text.replace("```json", "").replace("```", "").strip()
            return DiagnosticResult.model_validate_json(clean_content)
        except Exception as e:
            return DiagnosticResult(
                summary_text=f"Analysis failed to format correctly. Agent Output: {resp.get('text', '')}", 
                react_flow_json=None
            )

# ==========================================
# 5. MAIN HANDLER
# ==========================================

def main(session: Session):
    manager = AgentManager(session)
    user_query = "Why is the Total Market Volume being driven by the Opioid Category , specifically Tramadol which is seeing massive New Growth, yet the Orthopedic Segment historically the core driver for this drugis contributing less than 7% of that growth?"
    # Simulating a conversation where the user previously asked about performance
    history = [
        {"role": "user", "content": [{"type": "text", "text": "How is the overall Profitability looking?"}]},
        {"role": "assistant", "content": [{"type": "text", "text": "Profitability is currently down by 15% compared to last month."}]}
    ]
    
    # 1. Rephrase
    rephrased = manager.run_rephraser(user_query, history)
    print(rephrased)
    # 2. Plan
    decision = manager.run_planner(rephrased)
    print(decision)
    
    final_output = {}

    if decision.route == "diagnostic":
        # 3. Diagnose
        result = manager.run_diagnostic_agent(decision.query)
        
        if result.clarifying_question:
            final_output = {"type": "clarification", "message": result.clarifying_question}
        else:
            final_output = {
                "type": "diagnostic_report",
                "summary": result.summary_text,
                "graph": result.react_flow_json
            }
    elif decision.route == "clarify":
        final_output = {"type": "clarification", "message": decision.reasoning}

    return final_output



import json
import logging
import _snowflake # Native Snowflake module for internal API calls
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import List, Dict, Any, Optional, Literal
from pydantic import BaseModel, Field
from snowflake.snowpark import Session

# ==========================================
# 1. PYDANTIC CONFIGURATION & MODELS
# ==========================================

class AgentConfig(BaseModel):
    """Configuration for the agent execution"""
    model: str = "claude-4-sonnet"
    # Update paths as per your environment
    diagnostic_udf: str = "DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.AI_POC.DIAGNOSTIC_TOOL"
    # Updated to point to an existing Cortex Analyst Object (Semantic Model)
    cortex_analyst_object: str = "DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.AI_POC.LATEST_MASTER_VIEW"
    warehouse: str = "DEV_IMPACT_WH"

class PlannerDecision(BaseModel):
    """
    Structured output from the Planner Agent.
    Allows for parallel execution by defining multiple query targets.
    """
    sql_query: Optional[str] = Field(None, description="Query for data analysis, metrics, or lists. Null if not needed.")
    diagnostic_query: Optional[str] = Field(None, description="Query for root cause analysis or deep dives. Null if not needed.")
    clarification: Optional[str] = Field(None, description="Question to ask user if intent is completely vague.")
    reasoning: str = Field(..., description="Why these routes were chosen")

class DiagnosticResult(BaseModel):
    """Structured output from the Diagnostic Agent"""
    summary_text: str = Field(..., description="Executive summary of findings")
    react_flow_json: Optional[Dict] = Field(None, description="The visual graph data")
    clarifying_question: Optional[str] = Field(None, description="Question to ask user if intent is unclear")

class SqlResult(BaseModel):
    """Structured output from the Cortex Analyst (SQL Agent)"""
    answer_text: str = Field(..., description="The text response from the analyst")
    tables: List[Any] = Field(default_factory=list, description="List of result sets (raw data)")
    charts: List[Dict] = Field(default_factory=list, description="List of Vega-Lite specs")
    # Extended Metadata Fields
    sql_generated: Optional[str] = Field(None, description="The generated SQL query")
    sql_explanation: Optional[str] = Field(None, description="Explanation of the generated SQL")
    is_verified_query: bool = Field(False, description="Whether a verified query was used")
    reasoning_trace: Optional[str] = Field(None, description="The thinking process of the analyst")

# Global Config Instance
CONFIG = AgentConfig()

# ==========================================
# 2. DEBUGGING / CHECKPOINT HELPER
# ==========================================

def log_checkpoint(step: str, details: Any):
    """
    Prints checkpoint info to stdout. Handles Pydantic models serialization.
    """
    print(f"\n{'='*50}")
    print(f" CHECKPOINT: {step}")
    print(f"{'-'*50}")
    
    if isinstance(details, BaseModel):
        print(details.model_dump_json(indent=2))
    elif isinstance(details, (dict, list)):
        print(json.dumps(details, indent=2))
    else:
        print(str(details))
    print(f"{'='*50}\n")

# ==========================================
# 3. CORTEX API WRAPPER
# ==========================================

def invoke_cortex_agent(session: Session, payload: Dict, agent_name: str) -> Dict:
    """
    Invokes the Cortex Agent API via _snowflake.send_snow_api_request.
    Includes robust parsing for streaming, especially Analyst Deltas.
    """
    AGENT_ENDPOINT_URL = "/api/v2/cortex/agent:run"
    TIMEOUT_MS = 120 * 1000  # 120 seconds
    
    headers = {
        "Content-Type": "application/json",
        "Accept": "text/event-stream"
    }

    log_checkpoint(f"INVOKING AGENT: {agent_name}", {
        "model": payload.get("models", {}).get("orchestration"),
        "tools": [t['tool_spec']['name'] for t in payload.get("tools", [])]
    })

    try:
        response_dict = _snowflake.send_snow_api_request(
            "POST",
            AGENT_ENDPOINT_URL,
            headers,
            {}, 
            payload, 
            {}, 
            TIMEOUT_MS
        )
        
        response_content = response_dict.get("content", "")
        if not response_content:
            return {"error": "Empty response from Agent API"}
            
        # Try parsing as JSON
        try:
            parsed_response = json.loads(response_content)
        except json.JSONDecodeError:
            return {"error": "Failed to decode JSON response content"}

        # Extraction container
        extracted = {
            "text": "",
            "tables": [],
            "charts": [],
            "annotations": [],
            "tool_uses": [],
            "debug_trace": [],
            "sql_generated": None,
            "sql_explanation": None,
            "is_verified": False
        }

        # Helper to process a content list (from final 'response')
        def process_content_list(content_items):
            for item in content_items:
                c_type = item.get("type")
                if c_type == "text":
                    extracted["text"] += item.get("text", "")
                    if item.get("annotations"):
                        extracted["annotations"].extend(item["annotations"])
                elif c_type == "table":
                    extracted["tables"].append(item.get("result_set", {}))
                elif c_type == "chart":
                    extracted["charts"].append(item.get("chart", {}))
                elif c_type == "tool_use":
                    extracted["tool_uses"].append(item)

        # 1. Handle List of Events (Streaming format)
        if isinstance(parsed_response, list):
            # First pass: Look for the final 'response' event
            final_response_event = next((item for item in parsed_response if item.get('event') == 'response'), None)
            
            if final_response_event:
                data = final_response_event.get('data', {})
                process_content_list(data.get('content', []))
                
                # Even if we have final response, sometimes metadata like 'verified_query_used' 
                # is best captured from the deltas if the final aggregation missed detailed tool props.
                # So we scan deltas for analyst specifics below.
            
            # Scan deltas for reconstruction and metadata extraction
            text_parts = []
            for item in parsed_response:
                evt = item.get('event')
                data = item.get('data', {})
                
                if evt == 'response.text.delta':
                    text_parts.append(data.get('text', ''))
                elif evt == 'response.text.annotation':
                    extracted["annotations"].append(data.get('annotation'))
                elif evt == 'response.chart':
                    extracted["charts"].append(data.get('chart') or data.get('chart_spec'))
                elif evt == 'response.table':
                    extracted["tables"].append(data.get('result_set'))
                elif evt == 'response.tool_use':
                    extracted["tool_uses"].append(data)
                elif evt == 'response.thinking.delta':
                    extracted["debug_trace"].append(f"Think: {data.get('text')}")
                
                # --- CRITICAL: ANALYST TOOL DELTA PARSING ---
                elif evt == 'response.tool_result.analyst.delta':
                    delta = data.get('delta', {})
                    
                    # 1. SQL Code
                    if delta.get('sql'):
                        extracted["sql_generated"] = delta.get('sql')
                    
                    # 2. Explanation
                    if delta.get('sql_explanation'):
                        extracted["sql_explanation"] = delta.get('sql_explanation')
                    
                    # 3. Verified Query Flag
                    if 'verified_query_used' in delta:
                        extracted["is_verified"] = delta.get('verified_query_used')
                    
                    # 4. Result Set (The Table Data)
                    if delta.get('result_set'):
                        # Ensure we don't duplicate if response.table already caught it
                        # Simple check: if not in tables yet
                        rs = delta.get('result_set')
                        if rs not in extracted["tables"]:
                            extracted["tables"].append(rs)
                    
                    # 5. Reasoning/Think
                    if delta.get('think'):
                        extracted["debug_trace"].append(f"Analyst Think: {delta.get('think')}")
                    
                    # 6. Suggestions (Optional, appended to debug for now)
                    if delta.get('suggestions'):
                        sug = delta.get('suggestions')
                        extracted["debug_trace"].append(f"Suggestion: {sug.get('delta')}")

                elif evt == 'error':
                    return {"error": f"Agent Error: {data.get('message')}"}
            
            if not extracted["text"]:
                extracted["text"] = "".join(text_parts)

        # 2. Handle Single Object (Non-streaming)
        elif isinstance(parsed_response, dict):
            if 'message' in parsed_response:
                process_content_list(parsed_response['message'].get('content', []))
            elif 'choices' in parsed_response:
                process_content_list(parsed_response['choices'][0]['message'].get('content', []))

        return extracted

    except Exception as e:
        return {"error": f"API Execution Exception: {str(e)}"}

# ==========================================
# 4. PAYLOAD FACTORY
# ==========================================

class PayloadFactory:
    @staticmethod
    def create(query: str, instructions: Dict[str, str], tools: List[Dict] = None, tool_resources: Dict = None, history: List[Dict] = None) -> Dict:
        messages = history if history else []
        messages.append({"role": "user", "content": [{"type": "text", "text": query}]})

        return {
            "messages": messages,
            "tool_choice": {"type": "auto"},
            "models": {"orchestration": CONFIG.model},
            "instructions": instructions,
            "tools": tools or [],
            "tool_resources": tool_resources or {}
        }

# ==========================================
# 5. AGENT MANAGERS
# ==========================================

class AgentManager:
    def __init__(self, session: Session):
        self.session = session

    def run_rephraser(self, query: str, history: List[Dict] = None) -> str:
        """Step 1: Rephrase"""
        log_checkpoint("START STEP 1: Rephraser", f"Input: {query}")

        instructions = {
            "system": "You are a sophisticated Query Refinement Engine.",
            "response": "Output ONLY the final rephrased string.",
            "orchestration": (
                "Transform the user's input into a standalone query.\n"
                "1. Resolve pronouns (it, they, that).\n"
                "2. Preserve metrics and IDs.\n"
            )
        }
        
        payload = PayloadFactory.create(f"Rephrase this to be standalone: {query}", instructions, history=history)
        resp = invoke_cortex_agent(self.session, payload, "Rephraser")
        
        result = resp.get('text', query).strip() or query
        log_checkpoint("END STEP 1: Rephraser", f"Output: {result}")
        return result

    def run_planner(self, query: str) -> PlannerDecision:
        """Step 2: Plan Route"""
        log_checkpoint("START STEP 2: Planner", f"Input: {query}")

        # Schema defining optional fields for both routes
        schema_hint = '{"sql_query": "string or null", "diagnostic_query": "string or null", "clarification": "string or null", "reasoning": "string"}'
        
        instructions = {
            "system": "You are a Strategic Intent Classifier.",
            "response": f"Respond ONLY with a valid JSON object matching: {schema_hint}",
            "orchestration": (
                "Analyze the user's input.\n"
                "1. If the user asks for **Data/Lists/Aggregations** ('Show me', 'What is', 'List'), set `sql_query`.\n"
                "2. If the user asks for **Causes/Reasons/Explanations** ('Why', 'Explain', 'Drill down'), set `diagnostic_query`.\n"
                "3. If the query requires BOTH (e.g., 'What is revenue and why did it drop?'), fill BOTH fields.\n"
                "4. If vague, set `clarification`.\n"
                "5. **Visualize:** If sql_query is set, append ' and generate a table and chart' to it."
            )
        }
        
        payload = PayloadFactory.create(f"Plan this query: {query}", instructions)
        resp = invoke_cortex_agent(self.session, payload, "Planner")
        
        try:
            raw = resp.get('text', '')
            clean = raw.replace("```json", "").replace("```", "").strip()
            return PlannerDecision.model_validate_json(clean)
        except Exception:
            # Fallback assumption
            return PlannerDecision(diagnostic_query=query, reasoning="Fallback error during planning")

    def run_sql_agent(self, query: str) -> SqlResult:
        """Step 3b: Run Cortex Analyst (SQL Agent)"""
        log_checkpoint("START STEP 3b: SQL Agent", f"Input: {query}")

        instructions = {
            "system": "You are an expert Data Analyst.",
            "orchestration": "Use the analyst_tool to answer. Always generate a table for data requests. If specific numeric comparisons or trends are found, generate a chart.",
            "response": "Provide a summary. Tables/Charts are handled by the system."
        }

        tools = [{
            "tool_spec": {
                "type": "cortex_analyst_text_to_sql",
                "name": "analyst_tool"
            }
        }]

        tool_resources = {
            "analyst_tool": {
                "type": "cortex_analyst_text_to_sql",
                "semantic_view": CONFIG.cortex_analyst_object,
                "execution_environment": {"type": "warehouse", "warehouse": CONFIG.warehouse}
            }
        }

        payload = PayloadFactory.create(query, instructions, tools, tool_resources)
        resp = invoke_cortex_agent(self.session, payload, "SQL Agent")

        # Map parsed fields to SqlResult
        result = SqlResult(
            answer_text=resp.get('text', ''),
            tables=resp.get('tables', []),
            charts=resp.get('charts', []),
            sql_generated=resp.get('sql_generated'),
            sql_explanation=resp.get('sql_explanation'),
            is_verified_query=resp.get('is_verified', False),
            reasoning_trace="\n".join(resp.get('debug_trace', []))
        )
        
        log_checkpoint("END STEP 3b: SQL Agent", result)
        return result

    def run_diagnostic_agent(self, query: str) -> DiagnosticResult:
        """Step 3a: Run Diagnostic Tool"""
        log_checkpoint("START STEP 3a: Diagnostic", f"Input: {query}")

        response_format = '{"summary_text": "string", "react_flow_json": {}, "clarifying_question": null}'
        instructions = {
            "system": "You are an Autonomous Root Cause Analysis Agent.",
            "orchestration": "Use Diagnostic_tool. Loop: Search -> Evaluate -> Drill.",
            "response": f"Ensure valid JSON matching: {response_format}"
        }

        tools = [{
            "tool_spec": {
                "type": "generic",
                "name": "Diagnostic_tool",
                "description": "Retrieves metric status.",
                "input_schema": {
                    "type": "object",
                    "properties": {
                        "USER_QUERY": {"type": "string"},
                        "PARENT_NODE_IDS_JSON": {"type": "string"},
                        "TREE_ID": {"type": "string"}
                    },
                    "required": ["USER_QUERY", "PARENT_NODE_IDS_JSON", "TREE_ID"]
                }
            }
        }]

        tool_resources = {
            "Diagnostic_tool": {
                "type": "procedure",
                "execution_environment": {"type": "warehouse", "warehouse": CONFIG.warehouse},
                "identifier": CONFIG.diagnostic_udf
            }
        }

        payload = PayloadFactory.create(query, instructions, tools, tool_resources)
        resp = invoke_cortex_agent(self.session, payload, "Diagnostic Agent")

        try:
            raw = resp.get('text', '{}')
            clean = raw.replace("```json", "").replace("```", "").strip()
            result = DiagnosticResult.model_validate_json(clean)
        except Exception as e:
            result = DiagnosticResult(summary_text=f"Error: {str(e)} - Raw: {raw}", react_flow_json=None)

        log_checkpoint("END STEP 3a: Diagnostic", result)
        return result

# ==========================================
# 6. MAIN EXECUTION (PARALLEL)
# ==========================================

def main(session: Session):
    manager = AgentManager(session)
    history = []
    
    # Example Input
    user_query = "show ME all the health care providers in arizona and Why is the Total Market Volume being driven by the Opioid Category , specifically Tramadol which is seeing massive New Growth, yet the Orthopedic Segment historically the core driver for this drugis contributing less than 7% of that growth?."
    
    log_checkpoint("CONTEXT", {"history": history, "current_query": user_query})
    
    # 1. Rephrase
    rephrased = manager.run_rephraser(user_query, history)
    
    # 2. Plan
    decision = manager.run_planner(rephrased)
    
    final_output = {
        "original_query": user_query,
        "processed_query": rephrased,
        "execution_plan": decision.model_dump(),
        "results": []
    }
    log_checkpoint("FINAL ANSWER BEFORE EXECUTION",{"final_output_before_execution":final_output})
    # 3. Parallel Execution
    if decision.clarification:
        final_output["results"].append({"type": "clarification", "message": decision.clarification})
    
    else:
        with ThreadPoolExecutor(max_workers=2) as executor:
            future_sql = None
            future_diag = None
            
            # Submit Tasks based on Planner Decision
            if decision.sql_query:
                future_sql = executor.submit(manager.run_sql_agent, decision.sql_query)
            
            if decision.diagnostic_query:
                future_diag = executor.submit(manager.run_diagnostic_agent, decision.diagnostic_query)
            
            # Collect Results
            if future_sql:
                try:
                    res = future_sql.result()
                    final_output["results"].append({
                        "type": "sql_analysis",
                        "summary": res.answer_text,
                        "tables": res.tables,
                        "charts": res.charts,
                        "metadata": {
                            "sql": res.sql_generated,
                            "explanation": res.sql_explanation,
                            "is_verified": res.is_verified_query
                        }
                    })
                except Exception as e:
                    final_output["results"].append({"type": "sql_error", "message": str(e)})

            if future_diag:
                try:
                    res = future_diag.result()
                    final_output["results"].append({
                        "type": "diagnostic_analysis",
                        "summary": res.summary_text,
                        "graph": res.react_flow_json
                    })
                except Exception as e:
                    final_output["results"].append({"type": "diagnostic_error", "message": str(e)})

    # Final Result Checkpoint
    log_checkpoint("FINAL ORCHESTRATOR OUTPUT", final_output)
    return final_output







import json
import logging
import _snowflake # Native Snowflake module for internal API calls
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import List, Dict, Any, Optional, Literal
from pydantic import BaseModel, Field
from snowflake.snowpark import Session

# ==========================================
# 1. PYDANTIC CONFIGURATION & MODELS
# ==========================================

class AgentConfig(BaseModel):
    """Configuration for the agent execution"""
    model: str = "claude-4-sonnet"
    # Update paths as per your environment
    diagnostic_udf: str = "DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.AI_POC.DIAGNOSTIC_TOOL"
    # Updated to point to an existing Cortex Analyst Object (Semantic Model)
    cortex_analyst_object: str = "DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.AI_POC.LATEST_MASTER_VIEW"
    warehouse: str = "DEV_IMPACT_WH"

class PlannerDecision(BaseModel):
    """
    Structured output from the Planner Agent.
    Allows for parallel execution by defining multiple query targets.
    """
    sql_question: Optional[str] = Field(None, description="Question for data analysis, metrics, or lists (The 'Show Me' part). Null if not needed.")
    diagnostic_question: Optional[str] = Field(None, description="Question for root cause analysis or deep dives (The 'Why' part). Null if not needed.")
    clarification: Optional[str] = Field(None, description="Question to ask user if intent is completely vague.")
    reasoning: str = Field(..., description="Why these routes were chosen")

class DiagnosticResult(BaseModel):
    """Structured output from the Diagnostic Agent"""
    summary_text: str = Field(..., description="Executive summary of findings")
    react_flow_json: Optional[Dict] = Field(None, description="The visual graph data")
    clarifying_question: Optional[str] = Field(None, description="Question to ask user if intent is unclear")

class SqlResult(BaseModel):
    """Structured output from the Cortex Analyst (SQL Agent)"""
    answer_text: str = Field(..., description="The text response from the analyst")
    tables: List[Any] = Field(default_factory=list, description="List of result sets (raw data)")
    charts: List[Dict] = Field(default_factory=list, description="List of Vega-Lite specs")
    # Extended Metadata Fields extracted from Analyst Delta
    sql_generated: Optional[str] = Field(None, description="The generated SQL query")
    sql_explanation: Optional[str] = Field(None, description="Explanation of the generated SQL")
    is_verified_query: bool = Field(False, description="Whether a verified query was used")
    reasoning_trace: Optional[str] = Field(None, description="The thinking process of the analyst")

# Global Config Instance
CONFIG = AgentConfig()

# ==========================================
# 2. DEBUGGING / CHECKPOINT HELPER
# ==========================================

def log_checkpoint(step: str, details: Any):
    """
    Prints checkpoint info to stdout. Handles Pydantic models serialization.
    """
    print(f"\n{'='*50}")
    print(f" CHECKPOINT: {step}")
    print(f"{'-'*50}")
    
    if isinstance(details, BaseModel):
        print(details.model_dump_json(indent=2))
    elif isinstance(details, (dict, list)):
        print(json.dumps(details, indent=2))
    else:
        print(str(details))
    print(f"{'='*50}\n")

# ==========================================
# 3. CORTEX API WRAPPER
# ==========================================

def invoke_cortex_agent(session: Session, payload: Dict, agent_name: str) -> Dict:
    """
    Invokes the Cortex Agent API via _snowflake.send_snow_api_request.
    Includes robust parsing for streaming, especially Analyst Deltas.
    """
    AGENT_ENDPOINT_URL = "/api/v2/cortex/agent:run"
    TIMEOUT_MS = 120 * 1000  # 120 seconds
    
    headers = {
        "Content-Type": "application/json",
        "Accept": "text/event-stream"
    }

    log_checkpoint(f"INVOKING AGENT: {agent_name}", {
        "model": payload.get("models", {}).get("orchestration"),
        "tools": [t['tool_spec']['name'] for t in payload.get("tools", [])]
    })

    try:
        response_dict = _snowflake.send_snow_api_request(
            "POST",
            AGENT_ENDPOINT_URL,
            headers,
            {}, 
            payload, 
            {}, 
            TIMEOUT_MS
        )
        
        response_content = response_dict.get("content", "")
        if not response_content:
            return {"error": "Empty response from Agent API"}
            
        # Try parsing as JSON
        try:
            parsed_response = json.loads(response_content)
        except json.JSONDecodeError:
            return {"error": "Failed to decode JSON response content"}

        # Extraction container
        extracted = {
            "text": "",
            "tables": [],
            "charts": [],
            "annotations": [],
            "tool_uses": [],
            "debug_trace": [],
            "sql_generated": None,
            "sql_explanation": None,
            "is_verified": False
        }

        # Helper to process a content list (from final 'response')
        def process_content_list(content_items):
            for item in content_items:
                c_type = item.get("type")
                if c_type == "text":
                    extracted["text"] += item.get("text", "")
                    if item.get("annotations"):
                        extracted["annotations"].extend(item["annotations"])
                elif c_type == "table":
                    extracted["tables"].append(item.get("result_set", {}))
                elif c_type == "chart":
                    extracted["charts"].append(item.get("chart", {}))
                elif c_type == "tool_use":
                    extracted["tool_uses"].append(item)

        # 1. Handle List of Events (Streaming format)
        if isinstance(parsed_response, list):
            # First pass: Look for the final 'response' event
            final_response_event = next((item for item in parsed_response if item.get('event') == 'response'), None)
            
            if final_response_event:
                data = final_response_event.get('data', {})
                process_content_list(data.get('content', []))
            
            # Scan deltas for reconstruction and metadata extraction
            # This is crucial for capturing 'sql', 'verified_query_used' which appear in tool_result.analyst.delta
            text_parts = []
            for item in parsed_response:
                evt = item.get('event')
                data = item.get('data', {})
                
                if evt == 'response.text.delta':
                    text_parts.append(data.get('text', ''))
                elif evt == 'response.text.annotation':
                    extracted["annotations"].append(data.get('annotation'))
                elif evt == 'response.chart':
                    extracted["charts"].append(data.get('chart') or data.get('chart_spec'))
                elif evt == 'response.table':
                    extracted["tables"].append(data.get('result_set'))
                elif evt == 'response.tool_use':
                    extracted["tool_uses"].append(data)
                elif evt == 'response.thinking.delta':
                    extracted["debug_trace"].append(f"Think: {data.get('text')}")
                
                # --- CRITICAL: ANALYST TOOL DELTA PARSING ---
                elif evt == 'response.tool_result.analyst.delta':
                    delta = data.get('delta', {})
                    
                    # 1. SQL Code
                    if delta.get('sql'):
                        extracted["sql_generated"] = delta.get('sql')
                    
                    # 2. Explanation
                    if delta.get('sql_explanation'):
                        extracted["sql_explanation"] = delta.get('sql_explanation')
                    
                    # 3. Verified Query Flag
                    if 'verified_query_used' in delta:
                        extracted["is_verified"] = delta.get('verified_query_used')
                    
                    # 4. Result Set (The Table Data)
                    if delta.get('result_set'):
                        # Check to avoid duplication if response.table handled it
                        rs = delta.get('result_set')
                        if rs not in extracted["tables"]:
                            extracted["tables"].append(rs)
                    
                    # 5. Reasoning/Think
                    if delta.get('think'):
                        extracted["debug_trace"].append(f"Analyst Think: {delta.get('think')}")
                    
                    # 6. Suggestions
                    if delta.get('suggestions'):
                        sug = delta.get('suggestions')
                        extracted["debug_trace"].append(f"Suggestion: {sug.get('delta')}")

                elif evt == 'error':
                    return {"error": f"Agent Error: {data.get('message')}"}
            
            if not extracted["text"]:
                extracted["text"] = "".join(text_parts)

        # 2. Handle Single Object (Non-streaming)
        elif isinstance(parsed_response, dict):
            if 'message' in parsed_response:
                process_content_list(parsed_response['message'].get('content', []))
            elif 'choices' in parsed_response:
                process_content_list(parsed_response['choices'][0]['message'].get('content', []))

        return extracted

    except Exception as e:
        return {"error": f"API Execution Exception: {str(e)}"}

# ==========================================
# 4. PAYLOAD FACTORY
# ==========================================

class PayloadFactory:
    @staticmethod
    def create(query: str, instructions: Dict[str, str], tools: List[Dict] = None, tool_resources: Dict = None, history: List[Dict] = None) -> Dict:
        messages = history if history else []
        messages.append({"role": "user", "content": [{"type": "text", "text": query}]})

        return {
            "messages": messages,
            "tool_choice": {"type": "auto"},
            "models": {"orchestration": CONFIG.model},
            "instructions": instructions,
            "tools": tools or [],
            "tool_resources": tool_resources or {}
        }

# ==========================================
# 5. AGENT MANAGERS
# ==========================================

class AgentManager:
    def __init__(self, session: Session):
        self.session = session

    def run_rephraser(self, query: str, history: List[Dict] = None) -> str:
        """Step 1: Rephrase"""
        log_checkpoint("START STEP 1: Rephraser", f"Input: {query}")

        instructions = {
            "system": "You are a sophisticated Query Refinement Engine.",
            "response": "Output ONLY the final rephrased string.",
            "orchestration": "Transform the user's input into a standalone query. Resolve pronouns (it, they, that). Preserve metrics and IDs."
        }
        
        payload = PayloadFactory.create(f"Rephrase this to be standalone: {query}", instructions, history=history)
        resp = invoke_cortex_agent(self.session, payload, "Rephraser")
        
        result = resp.get('text', query).strip() or query
        log_checkpoint("END STEP 1: Rephraser", f"Output: {result}")
        return result

    def run_planner(self, query: str) -> PlannerDecision:
        """Step 2: Plan Route"""
        log_checkpoint("START STEP 2: Planner", f"Input: {query}")

        schema_hint = '{"sql_question": "string or null", "diagnostic_question": "string or null", "clarification": "string or null", "reasoning": "string"}'
        
        instructions = {
            "system": "You are a Strategic Intent Classifier.",
            "response": f"Respond ONLY with a valid JSON object matching: {schema_hint}",
            "orchestration": ("Analyze the user's input and SPLIT it into distinct **NATURAL LANGUAGE** questions. **YOU MUST NOT GENERATE NOT generate SQL code.**\n\n"
                "**1. SQL Analysis (`sql_question`):**\n"
                "   - Extract the part asking for Data, 'Show me', 'List', or 'What is'.\n"
                "   - Keep it as a plain English question. Do not write SELECT statements.\n"
                "   - Append ' and generate a table and a visual' if helpful.\n"
                "**2. Why Analysis (`diagnostic_question`):**\n"
                "   - Extract the part asking for 'Why', 'Explain', 'Reason', or Root Causes.\n"
                "   - **CRITICAL:** Do NOT assign 'What is the volume?' questions here. Only causal questions.\n"
                "   - Keep the text EXACT/VERBATIM. Do NOT summarize specific names/IDs.\n"
                "**3. Combined Intent:**\n"
                "   - If input is 'Show X and explain Y', put 'Show X' in `sql_question` and 'Explain Y' in `diagnostic_question`.\n\n"
                "**Few-Shot Examples:**\n"
                "- Input: 'Show me total sales for Q4.'\n"
                "  -> sql_question: 'Show me total sales for Q4 and generate a table and a visual'\n"
                "  -> diagnostic_question: null\n"
                "- Input: 'Why is profit down?'\n"
                "  -> sql_question: null\n"
                "  -> diagnostic_question: 'Why is profit down?'\n"
                "- Input: 'Get revenue for AZ and explain the dip.'\n"
                "  -> sql_question: 'Get revenue for AZ and generate a table and a visual'\n"
                "  -> diagnostic_question: 'explain the dip in revenue for AZ'\n"
                "- Input: 'SELECT * FROM SALES'\n"
                "  -> sql_question: 'SELECT * FROM SALES' (Only pass SQL if user explicitly typed it)\n"
                "  -> diagnostic_question: null"
                "YOU MUST STRICTLY FOLLOW THE ABOVE INSTRUCTIONS."
            )
        }
        
        payload = PayloadFactory.create(f"Plan this query: {query}", instructions)
        resp = invoke_cortex_agent(self.session, payload, "Planner")
        
        try:
            raw = resp.get('text', '')
            clean = raw.replace("```json", "").replace("```", "").strip()
            return PlannerDecision.model_validate_json(clean)
        except Exception:
            # Fallback assumption
            return PlannerDecision(diagnostic_query=query, reasoning="Fallback error during planning")

    def run_sql_agent(self, query: str) -> SqlResult:
        """Step 3b: Run Cortex Analyst (SQL Agent)"""
        log_checkpoint("START STEP 3b: SQL Agent", f"Input: {query}")

        instructions = {
            "system": "You are an expert Data Analyst.",
            "orchestration": "Use the analyst_tool to answer. ALWAYS generate a table (Result Set) for data requests.",
            "response": "Provide a summary. Tables/Charts are handled automatically."
        }

        tools = [{
            "tool_spec": {
                "type": "cortex_analyst_text_to_sql",
                "name": "analyst_tool"
            }
        }]

        tool_resources = {
            "analyst_tool": {
                "type": "cortex_analyst_text_to_sql",
                "semantic_view": CONFIG.cortex_analyst_object,
                "execution_environment": {"type": "warehouse", "warehouse": CONFIG.warehouse},
            }
        }

        payload = PayloadFactory.create(query, instructions, tools, tool_resources)
        resp = invoke_cortex_agent(self.session, payload, "SQL Agent")

        # Capture the standard artifacts + the newly extracted analyst delta fields
        result = SqlResult(
            answer_text=resp.get('text', ''),
            tables=resp.get('tables', []),
            charts=resp.get('charts', []),
            sql_generated=resp.get('sql_generated'),
            sql_explanation=resp.get('sql_explanation'),
            is_verified_query=resp.get('is_verified', False),
            reasoning_trace="\n".join(resp.get('debug_trace', []))
        )
        
        log_checkpoint("END STEP 3b: SQL Agent", result)
        return result

    def run_diagnostic_agent(self, query: str) -> DiagnosticResult:
        """Step 3a: Run Diagnostic Tool"""
        log_checkpoint("START STEP 3a: Diagnostic", f"Input: {query}")

        response_format = '{"summary_text": "string", "react_flow_json": {}, "clarifying_question": null}'
        instructions = {
            "system": "You are an Autonomous Root Cause Analysis Agent.",
            "orchestration": "Use Diagnostic_tool. Loop: Search -> Evaluate -> Drill.",
            "response": f"Ensure valid JSON matching: {response_format}"
        }

        tools = [{
            "tool_spec": {
                "type": "generic",
                "name": "Diagnostic_tool",
                "description": "Retrieves metric status.",
                "input_schema": {
                    "type": "object",
                    "properties": {
                        "USER_QUERY": {"type": "string"},
                        "PARENT_NODE_IDS_JSON": {"type": "string"},
                        "TREE_ID": {"type": "string"}
                    },
                    "required": ["USER_QUERY", "PARENT_NODE_IDS_JSON", "TREE_ID"]
                }
            }
        }]

        tool_resources = {
            "Diagnostic_tool": {
                "type": "procedure",
                "execution_environment": {"type": "warehouse", "warehouse": CONFIG.warehouse},
                "identifier": CONFIG.diagnostic_udf
            }
        }

        payload = PayloadFactory.create(query, instructions, tools, tool_resources)
        resp = invoke_cortex_agent(self.session, payload, "Diagnostic Agent")

        try:
            raw = resp.get('text', '{}')
            clean = raw.replace("```json", "").replace("```", "").strip()
            result = DiagnosticResult.model_validate_json(clean)
        except Exception as e:
            result = DiagnosticResult(summary_text=f"Error: {str(e)} - Raw: {raw}", react_flow_json=None)

        log_checkpoint("END STEP 3a: Diagnostic", result)
        return result

# ==========================================
# 6. MAIN EXECUTION (PARALLEL)
# ==========================================

def main(session: Session):
    manager = AgentManager(session)
    history = []
    
    # Specific input requesting both Data (SQL) and Explanation (Diagnostic)
    user_query = "show ME all the health care providers in arizona and Why is the Total Market Volume being driven by the Opioid Category , specifically Tramadol which is seeing massive New Growth, yet the Orthopedic Segment historically the core driver for this drugis contributing less than 7% of that growth?"
    
    log_checkpoint("CONTEXT", {"history": history, "current_query": user_query})
    
    # 1. Rephrase
    rephrased = manager.run_rephraser(user_query, history)
    
    # 2. Plan
    decision = manager.run_planner(rephrased)
    
    final_output = {
        "original_query": user_query,
        "processed_query": rephrased,
        "execution_plan": decision.model_dump(),
        "results": []
    }

    # 3. Parallel Execution
    if decision.clarification:
        final_output["results"].append({"type": "clarification", "message": decision.clarification})
    
    else:
        with ThreadPoolExecutor(max_workers=2) as executor:
            future_sql = None
            future_diag = None
            
            # Submit Tasks based on Planner Decision
            if decision.sql_question:
                future_sql = executor.submit(manager.run_sql_agent, decision.sql_question)
            
            if decision.diagnostic_question:
                future_diag = executor.submit(manager.run_diagnostic_agent, decision.diagnostic_question)
            
            # Collect Results
            if future_sql:
                try:
                    res = future_sql.result()
                    final_output["results"].append({
                        "type": "sql_analysis",
                        "summary": res.answer_text,
                        "tables": res.tables,
                        "charts": res.charts,
                        "metadata": {
                            "sql": res.sql_generated,
                            "explanation": res.sql_explanation,
                            "is_verified": res.is_verified_query
                        }
                    })
                except Exception as e:
                    final_output["results"].append({"type": "sql_error", "message": str(e)})

            if future_diag:
                try:
                    res = future_diag.result()
                    final_output["results"].append({
                        "type": "diagnostic_analysis",
                        "summary": res.summary_text,
                        "graph": res.react_flow_json
                    })
                except Exception as e:
                    final_output["results"].append({"type": "diagnostic_error", "message": str(e)})

    # Final Result Checkpoint
    log_checkpoint("FINAL ORCHESTRATOR OUTPUT", final_output)
    return final_output


https://www.snowflake.com/en/blog/snowflake-cortex-ai-cortex-guard-llm-safeguards/



import json
import logging
import _snowflake # Native Snowflake module for internal API calls
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import List, Dict, Any, Optional, Literal
from pydantic import BaseModel, Field
from snowflake.snowpark import Session

# ==========================================
# 1. PYDANTIC CONFIGURATION & MODELS
# ==========================================

class AgentConfig(BaseModel):
    """Configuration for the agent execution"""
    model: str = "claude-4-sonnet" # Recommended for complex orchestration
    # Update paths as per your environment
    diagnostic_udf: str = "DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.AI_POC.DIAGNOSTIC_TOOL"
    cortex_analyst_object: str = "DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.AI_POC.LATEST_MASTER_VIEW"
    warehouse: str = "DEV_IMPACT_WH"
    # Cortex Guard Configuration
    guard_name: str = "INPUT_GUARD" 

class IntentClassification(BaseModel):
    """Structured output from the Intent Classifier."""
    intent_type: str = Field(..., description="Type of intent: greeting, data_retrieval, root_cause_analysis, clarification_needed, general_question, off_topic, combined")
    data_retrieval_query: Optional[str] = Field(None, description="Natural language query for retrieving data/metrics/lists.")
    root_cause_query: Optional[str] = Field(None, description="Natural language query for causal analysis.")
    direct_response: Optional[str] = Field(None, description="Direct answer for greetings or simple questions.")
    clarification_question: Optional[str] = Field(None, description="Question to ask user when intent is unclear.")
    confidence: str = Field(..., description="Confidence level: high, medium, low")
    reasoning: str = Field(..., description="Explanation of why this classification was made")

class DiagnosticResult(BaseModel):
    """Structured output from the Diagnostic Agent"""
    summary_text: str = Field(..., description="Executive summary of findings")
    react_flow_json: Optional[Dict] = Field(None, description="The visual graph data")
    clarifying_question: Optional[str] = Field(None, description="Question to ask user if intent is unclear")

class SqlResult(BaseModel):
    """Structured output from the Cortex Analyst (SQL Agent)"""
    answer_text: str = Field(..., description="The text response from the analyst")
    tables: List[Any] = Field(default_factory=list, description="List of result sets (raw data)")
    charts: List[Dict] = Field(default_factory=list, description="List of Vega-Lite specs")
    sql_generated: Optional[str] = Field(None, description="The generated SQL query")
    sql_explanation: Optional[str] = Field(None, description="Explanation of the generated SQL")
    is_verified_query: bool = Field(False, description="Whether a verified query was used")
    reasoning_trace: Optional[str] = Field(None, description="The thinking process of the analyst")

class GuardResult(BaseModel):
    """Result from Cortex Guard evaluation"""
    is_safe: bool = Field(..., description="Whether the input passed the guard")
    violation_category: Optional[str] = Field(None, description="Category of violation if any")
    message: Optional[str] = Field(None, description="Message to user if blocked")

# Global Config Instance
CONFIG = AgentConfig()

# ==========================================
# 2. DEBUGGING / CHECKPOINT HELPER
# ==========================================

def log_checkpoint(step: str, details: Any):
    """Prints checkpoint info to stdout."""
    print(f"\n{'='*50}")
    print(f" CHECKPOINT: {step}")
    print(f"{'-'*50}")
    
    if isinstance(details, BaseModel):
        print(details.model_dump_json(indent=2))
    elif isinstance(details, (dict, list)):
        print(json.dumps(details, indent=2))
    else:
        print(str(details))
    print(f"{'='*50}\n")

# ==========================================
# 3. CORTEX GUARD WRAPPER
# ==========================================

def check_input_guard(session: Session, user_input: str) -> GuardResult:
    """
    Checks user input against Snowflake Cortex Guard.
    Implementation: Calls SNOWFLAKE.CORTEX.COMPLETE with guardrails=True options.
    """
    log_checkpoint("CORTEX GUARD CHECK", f"Input: {user_input}")
    
    try:
        # We use a lightweight check. If the model returns the standard block message, it's unsafe.
        # Note: We escape single quotes in the input to prevent SQL injection in the f-string
        safe_input = user_input.replace("'", "''")
        
        # We ask the model to simply echo the input if safe. 
        # If unsafe, Cortex Guard will intercept and replace the response.
        guard_sql = f"""
        SELECT SNOWFLAKE.CORTEX.COMPLETE(
            '{CONFIG.model}',
            [
                {{'role': 'user', 'content': '{safe_input}'}}
            ],
            {{
                'guardrails': true
            }}
        ) as response_json
        """
        
        result = session.sql(guard_sql).collect()
        
        if not result:
            return GuardResult(is_safe=True)

        # Parse the JSON response from Cortex
        response_str = result[0]['RESPONSE_JSON']
        response_data = json.loads(response_str)
        
        # Cortex Guard typically returns a specific message when content is filtered
        # Format: {"choices": [{"messages": "Response filtered by Cortex Guard"}]}
        model_output = response_data.get('choices', [{}])[0].get('messages', '')
        
        is_unsafe = "Response filtered by Cortex Guard" in model_output
        
        guard_result = GuardResult(
            is_safe=not is_unsafe,
            violation_category="unsafe_content" if is_unsafe else None,
            message="I cannot process this request because it violates our safety policy." if is_unsafe else None
        )
        
        log_checkpoint("GUARD RESULT", guard_result)
        return guard_result
        
    except Exception as e:
        log_checkpoint("GUARD ERROR", f"Error checking guard: {str(e)}")
        # Fail open - allow request to proceed if guard check fails to run
        return GuardResult(is_safe=True)

# ==========================================
# 4. CORTEX API WRAPPER
# ==========================================

def invoke_cortex_agent(session: Session, payload: Dict, agent_name: str) -> Dict:
    """Invokes the Cortex Agent API via _snowflake.send_snow_api_request."""
    AGENT_ENDPOINT_URL = "/api/v2/cortex/agent:run"
    TIMEOUT_MS = 120 * 1000  # 120 seconds
    
    headers = {
        "Content-Type": "application/json",
        "Accept": "text/event-stream"
    }

    log_checkpoint(f"INVOKING AGENT: {agent_name}", {
        "model": payload.get("models", {}).get("orchestration"),
        "tools": [t['tool_spec']['name'] for t in payload.get("tools", [])]
    })

    try:
        response_dict = _snowflake.send_snow_api_request(
            "POST",
            AGENT_ENDPOINT_URL,
            headers,
            {}, 
            payload, 
            {}, 
            TIMEOUT_MS
        )
        
        response_content = response_dict.get("content", "")
        if not response_content:
            return {"error": "Empty response from Agent API"}
            
        try:
            parsed_response = json.loads(response_content)
        except json.JSONDecodeError:
            return {"error": "Failed to decode JSON response content"}

        extracted = {
            "text": "",
            "tables": [],
            "charts": [],
            "annotations": [],
            "tool_uses": [],
            "debug_trace": [],
            "sql_generated": None,
            "sql_explanation": None,
            "is_verified": False
        }

        def process_content_list(content_items):
            for item in content_items:
                c_type = item.get("type")
                if c_type == "text":
                    extracted["text"] += item.get("text", "")
                    if item.get("annotations"):
                        extracted["annotations"].extend(item["annotations"])
                elif c_type == "table":
                    extracted["tables"].append(item.get("result_set", {}))
                elif c_type == "chart":
                    extracted["charts"].append(item.get("chart", {}))
                elif c_type == "tool_use":
                    extracted["tool_uses"].append(item)

        if isinstance(parsed_response, list):
            final_response_event = next((item for item in parsed_response if item.get('event') == 'response'), None)
            
            if final_response_event:
                data = final_response_event.get('data', {})
                process_content_list(data.get('content', []))
            
            text_parts = []
            for item in parsed_response:
                evt = item.get('event')
                data = item.get('data', {})
                
                if evt == 'response.text.delta':
                    text_parts.append(data.get('text', ''))
                elif evt == 'response.text.annotation':
                    extracted["annotations"].append(data.get('annotation'))
                elif evt == 'response.chart':
                    extracted["charts"].append(data.get('chart') or data.get('chart_spec'))
                elif evt == 'response.table':
                    extracted["tables"].append(data.get('result_set'))
                elif evt == 'response.tool_use':
                    extracted["tool_uses"].append(data)
                elif evt == 'response.thinking.delta':
                    extracted["debug_trace"].append(f"Think: {data.get('text')}")
                elif evt == 'response.tool_result.analyst.delta':
                    delta = data.get('delta', {})
                    if delta.get('sql'): extracted["sql_generated"] = delta.get('sql')
                    if delta.get('sql_explanation'): extracted["sql_explanation"] = delta.get('sql_explanation')
                    if 'verified_query_used' in delta: extracted["is_verified"] = delta.get('verified_query_used')
                    if delta.get('result_set'):
                        rs = delta.get('result_set')
                        if rs not in extracted["tables"]: extracted["tables"].append(rs)
                elif evt == 'error':
                    return {"error": f"Agent Error: {data.get('message')}"}
            
            if not extracted["text"]:
                extracted["text"] = "".join(text_parts)

        elif isinstance(parsed_response, dict):
            if 'message' in parsed_response:
                process_content_list(parsed_response['message'].get('content', []))
            elif 'choices' in parsed_response:
                process_content_list(parsed_response['choices'][0]['message'].get('content', []))

        return extracted

    except Exception as e:
        return {"error": f"API Execution Exception: {str(e)}"}

# ==========================================
# 5. PAYLOAD FACTORY
# ==========================================

class PayloadFactory:
    @staticmethod
    def create(query: str, instructions: Dict[str, str], tools: List[Dict] = None, tool_resources: Dict = None, history: List[Dict] = None) -> Dict:
        messages = history if history else []
        messages.append({"role": "user", "content": [{"type": "text", "text": query}]})

        return {
            "messages": messages,
            "tool_choice": {"type": "auto"},
            "models": {"orchestration": CONFIG.model},
            "instructions": instructions,
            "tools": tools or [],
            "tool_resources": tool_resources or {}
        }

# ==========================================
# 6. AGENT MANAGERS
# ==========================================

class AgentManager:
    def __init__(self, session: Session):
        self.session = session

    def run_rephraser(self, query: str, history: List[Dict] = None) -> str:
        """Step 1: Rephrase"""
        log_checkpoint("START STEP 1: Rephraser", f"Input: {query}")
        
        instructions = {
            "system": "You are a sophisticated Query Refinement Engine.",
            "response": "Output ONLY the final rephrased string.",
            "orchestration": """
<query_refinement_instructions>
<objective>
Transform the user's input into a standalone, context-complete query that can be understood without prior conversation history.
</objective>

<core_rules>
<rule id="1">Resolve all pronouns (it, they, that, this, those) to their specific referents</rule>
<rule id="2">Preserve ALL metrics, entity names, IDs, and numerical values EXACTLY as stated</rule>
<rule id="3">Maintain the original intent and scope - do not expand or narrow the question</rule>
<rule id="4">Keep technical terminology and domain-specific language intact</rule>
<rule id="5">Ensure the output is grammatically correct and reads naturally</rule>
</core_rules>

<transformation_examples>
<example>
<input>What about Arizona?</input>
<context>Previous discussion about sales performance in Texas</context>
<output>What is the sales performance in Arizona?</output>
</example>

<example>
<input>Why is it down?</input>
<context>Previous mention of Q4 revenue</context>
<output>Why is Q4 revenue down?</output>
</example>

<example>
<input>Show me those providers and explain the trend.</input>
<context>Healthcare providers in California with declining prescriptions</context>
<output>Show me healthcare providers in California with declining prescriptions and explain the trend.</output>
</example>
</transformation_examples>

<output_format>
Output ONLY the refined query string. Do not include explanations, metadata, or formatting.
</output_format>
</query_refinement_instructions>
"""
        }
        
        payload = PayloadFactory.create(f"Rephrase this to be standalone: {query}", instructions, history=history)
        resp = invoke_cortex_agent(self.session, payload, "Rephraser")
        
        result = resp.get('text', query).strip() or query
        log_checkpoint("END STEP 1: Rephraser", f"Output: {result}")
        return result

    def run_intent_classifier(self, query: str) -> IntentClassification:
        """Step 2: Classify Intent"""
        log_checkpoint("START STEP 2: Intent Classifier", f"Input: {query}")

        schema_hint = '''{
          "intent_type": "greeting | data_retrieval | root_cause_analysis | clarification_needed | general_question | off_topic | combined",
          "data_retrieval_query": "string or null",
          "root_cause_query": "string or null", 
          "direct_response": "string or null",
          "clarification_question": "string or null",
          "confidence": "high | medium | low",
          "reasoning": "string"
        }'''
        
        instructions = {
            "system": "You are an Expert Intent Classification System.",
            "response": f"Respond ONLY with a valid JSON object matching: {schema_hint}",
            "orchestration": """
<intent_classification_instructions>

<mission>
Your ONLY job is to identify the user's INTENT. Do NOT retrieve data, do NOT answer questions, do NOT perform analysis.
Classify the intent type and route accordingly. If you can answer directly (like greetings), provide direct_response.
</mission>

<intent_categories>

<intent name="greeting">
<description>User is greeting, saying hello, or engaging in pleasantries</description>
<indicators>hi, hello, hey, good morning, how are you, thanks, thank you, goodbye, bye</indicators>
<action>Set direct_response with a friendly greeting. No other fields needed.</action>
</intent>

<intent name="data_retrieval">
<description>User wants to see/get/retrieve DATA - numbers, lists, metrics, tables</description>
<indicators>show, list, get, display, find, what is the value, how many, count, total, give me</indicators>
<action>Extract the data request to data_retrieval_query. Keep as natural language. Add "and generate a table and a visual".</action>
</intent>

<intent name="root_cause_analysis">
<description>User wants to understand WHY, CAUSES, DRIVERS, REASONS, EXPLANATIONS</description>
<indicators>why, explain, what is driving, what is causing, what's behind, reason for, root cause, how come, what factors</indicators>
<action>Extract the causal question to root_cause_query. Keep VERBATIM - exact text from user.</action>
</intent>

<intent name="combined">
<description>User wants BOTH data AND causal analysis in one request</description>
<indicators>Contains both data keywords AND causal keywords</indicators>
<action>Split into data_retrieval_query AND root_cause_query. Keep both portions.</action>
</intent>

<intent name="clarification_needed">
<description>User's intent is unclear, vague, or ambiguous - you cannot determine what they want</description>
<indicators>Very short/vague input, unclear pronouns without context, incomplete thoughts</indicators>
<action>Set clarification_question asking user to be more specific.</action>
</intent>

<intent name="general_question">
<description>General questions about the system, capabilities, how to use features - not data or analysis requests</description>
<indicators>how do I, can you, what can you do, help me understand, how does this work</indicators>
<action>Set direct_response with helpful information about capabilities.</action>
</intent>

<intent name="off_topic">
<description>User is asking about unrelated topics not connected to data, analytics, or business questions</description>
<indicators>Questions about weather, sports, entertainment, personal topics unrelated to business/data</indicators>
<action>Set direct_response politely redirecting to business/data topics.</action>
</intent>

</intent_categories>

<CRITICAL_CLASSIFICATION_RULES>

 RULE 1: NEVER DO THE WORK - ONLY CLASSIFY
You are NOT a data analyst. You are NOT an answering agent. You ONLY identify intent type.
Do NOT retrieve data. Do NOT answer analytical questions. ONLY classify and route.

 RULE 2: CAUSAL KEYWORD DETECTION
These ALWAYS indicate root_cause_analysis intent:
- "what is driving"
- "what is causing"
- "what's driving"  
- "what's causing"
- "why is/are"
- "explain why"
- "reason for"
- "root cause"
- "what factors"
- "what's behind"
- "how come"

 RULE 3: DATA KEYWORD DETECTION  
These ALWAYS indicate data_retrieval intent:
- "show me"
- "list"
- "get"
- "display"
- "find all"
- "what is the value/total/count of"
- "how many"

 RULE 4: DIRECT RESPONSE ONLY FOR SIMPLE CASES
Use direct_response ONLY for:
- Greetings (hi, hello, thanks)
- General system questions (what can you do)
- Off-topic redirects

Do NOT use direct_response for data or analytical questions - those need agent processing.

 RULE 5: VERBATIM PRESERVATION FOR ROOT CAUSE
For root_cause_query: Copy EXACT text from user. No paraphrasing, no summarizing.

 RULE 6: NO SQL CODE GENERATION
NEVER write SELECT/FROM/WHERE statements. Keep everything as natural language.

 RULE 7: CONFIDENCE SCORING
- high: Intent is crystal clear
- medium: Intent is likely but has some ambiguity
- low: Intent is very unclear, might need clarification

</CRITICAL_CLASSIFICATION_RULES>

<classification_process>
<step number="1">Check if greeting or general question. If match, Set intent_type and direct_response, STOP</step>
<step number="2">Check for causal keywords. If found, Flag as root_cause_analysis or combined</step>
<step number="3">Check for data keywords. If found, Flag as data_retrieval or combined</step>
<step number="4">Determine if combined intent. If both, Set intent_type="combined".</step>
<step number="5">If none of the above match, check if intent is clear enough.</step>
</classification_process>

<validation_checklist>
 Step 1: Can I answer this directly? (greeting/general_question/off_topic)
 Step 2: Does it contain causal keywords? (why/driving/causing/explain/reason/factors/behind)
 Step 3: Does it contain data keywords? (show/list/get/display/what is the value/how many)
 Step 4: Does it have BOTH data and causal elements?
 Step 5: Did I preserve EXACT wording for root_cause_query?
 Step 6: Did I add "and generate a table and a visual" to data_retrieval_query?
 Step 7: Did I avoid doing the actual work?
 Step 8: Is my confidence level accurate?
</validation_checklist>
</intent_classification_instructions>
"""
        }

        payload = PayloadFactory.create(f"Classify this user input: {query}", instructions)
        resp = invoke_cortex_agent(self.session, payload, "Intent Classifier")
        
        try:
            raw = resp.get('text', '')
            clean = raw.replace("```json", "").replace("```", "").strip()
            result = IntentClassification.model_validate_json(clean)
        except Exception as e:
            # Fallback
            result = IntentClassification(
                intent_type="clarification_needed",
                clarification_question="I'm having trouble understanding your request. Could you please rephrase?",
                confidence="low",
                reasoning=f"Error parsing intent: {str(e)}"
            )
            
        log_checkpoint("END STEP 2: Intent Classifier", result)
        return result

    def run_data_agent(self, query: str) -> SqlResult:
        """Step 3a: Run Cortex Analyst (Data Retrieval Agent)"""
        log_checkpoint("START STEP 3a: Data Retrieval Agent", f"Input: {query}")
        
        instructions = {
            "system": "You are an expert Data Analyst.",
            "orchestration": """
<data_agent_instructions>
<objective>
Use the analyst_tool to answer data requests with comprehensive results including tables and visualizations.
</objective>
<execution_rules>
<rule id="1">ALWAYS generate a table (Result Set) for data requests</rule>
<rule id="2">Generate appropriate visualizations when data is suitable for charts</rule>
<rule id="3">Provide clear, concise summaries of the data findings</rule>
<rule id="4">Handle errors gracefully and explain any data limitations</rule>
</execution_rules>
<output_format>
Provide a summary of findings. Tables and charts are handled automatically by the tool.
</output_format>
</data_agent_instructions>
""",
            "response": "Provide a summary. Tables/Charts are handled automatically."
        }

        tools = [{
            "tool_spec": {
                "type": "cortex_analyst_text_to_sql",
                "name": "analyst_tool"
            }
        }]
        
        tool_resources = {
            "analyst_tool": {
                "type": "cortex_analyst_text_to_sql",
                "semantic_view": CONFIG.cortex_analyst_object,
                "execution_environment": {"type": "warehouse", "warehouse": CONFIG.warehouse},
            }
        }
        
        payload = PayloadFactory.create(query, instructions, tools, tool_resources)
        resp = invoke_cortex_agent(self.session, payload, "Data Retrieval Agent")
        
        result = SqlResult(
            answer_text=resp.get('text', ''),
            tables=resp.get('tables', []),
            charts=resp.get('charts', []),
            sql_generated=resp.get('sql_generated'),
            sql_explanation=resp.get('sql_explanation'),
            is_verified_query=resp.get('is_verified', False),
            reasoning_trace="\n".join(resp.get('debug_trace', []))
        )
        
        log_checkpoint("END STEP 3a: Data Retrieval Agent", result)
        return result

    def run_root_cause_agent(self, query: str) -> DiagnosticResult:
        """Step 3b: Run Root Cause Analysis Agent"""
        log_checkpoint("START STEP 3b: Root Cause Analysis Agent", f"Input: {query}")
        
        response_format = '{"summary_text": "string", "react_flow_json": {}, "clarifying_question": null}'
        
        instructions = {
            "system": "You are an Autonomous Root Cause Analysis Agent.",
            "orchestration": """
<root_cause_orchestration_prompt>
    <role_and_objective>
        You are an **Autonomous Root Cause Analysis Agent** designed to traverse a metric decision tree from the root node down to the leaf nodes. Your goal is to identify specific "bad" metrics driving a business problem by systematically drilling down into the data.
        
        ALWAYS USE tree_id as Pharma_Master_v1.
    </role_and_objective>

    <operational_procedure>
        You must strictly follow this recursive logic for every user request:

        **Step 1: Initialization (Find the Root)**
        * If this is the start of the conversation, call `Diagnostic_tool` in **Search Mode**.
        * **Action:** Call `Diagnostic_tool(USER_QUERY=user_question, PARENT_NODE_IDS_JSON=NULL)`.
        * **Next:** Proceed to Step 2 with the results.

        **Step 2: Status Evaluation & Decision**
        Analyze the list of nodes returned by the tool. Focus **only** on nodes where `"status": "bad"`.

        * **Check:** For every "bad" node, do you see its children in the current list?
        * **Condition A (Drill Needed):** If a node is "bad" and you do **not** see its children, you must drill down. Collect these Node IDs.
        * **Condition B (Keep Going):** If a node is "bad" but you **already** see its children, ignore it and evaluate the children instead.
        * **Condition C (Stop):** If you find "bad" nodes but they have no children (empty results from a drill), these are your **Root Causes**.

        **Step 3: Execution (Drill Down)**
        * If Condition A occurred: Call `Diagnostic_tool` in **Drill Mode**.
        * **Action:** Call `Diagnostic_tool(USER_QUERY=NULL, PARENT_NODE_IDS_JSON='["ID_1", "ID_2"]')`.
        * **Next:** Recursively repeat Step 2 with the new output.
        * If Condition C occurred: Present the final root causes to the user.
    </operational_procedure>

    <constraints>
        * **Never** guess the status of a metric; always use the tool.
        * **Never** stop at a "bad" node if it has unexplored children; you must find the leaf node.
        * Output your reasoning briefly before calling the tool.
    </constraints>
</root_cause_orchestration_prompt>
""",
            "response": """<response_structure_prompt>
    <instruction>
        You must output exactly two sections in the following order. Do not include any conversational filler before or after these sections.
    </instruction>

    <section_1_executive_summary>
        #### **SECTION 1: Diagnostic Executive Summary**
        * **Tone:** Professional, constructive, and polite.
        * **Headline:** State the Root Cause clearly.
        * **The Narrative:** Briefly explain the chain of events in simple English.
        * **Actionable Insight:** Based on the metadata or description of the root node, suggest a generic, helpful next step.
    </section_1_executive_summary>

    <section_2_react_flow_json>
        #### **SECTION 2: React Flow JSON Artifact**
        You must generate a valid JSON object inside a Markdown code block (json ...).
        
        **1. Coordinate Logic (The "Mental Layout"):**
        * **Level 0 (Root):** `x: 0, y: 0`
        * **Level 1 Children:** `y: 150`. Spread `x` widely (e.g., `-300` and `300`).
        * **Level 2 Grandchildren:** `y: 300`. Spread `x` relative to their parent.
        * **Level 3+:** Increase `y` by `150` for each level.

        **2. Visual Style Logic:**
        * **Red (#FFE2E5):** Status is "bad", "high", or "error".
        * **Green (#CDE8E6):** Status is "good", "normal", or "stable".
        * **Orange (#FFCCBC):** The **Root Cause** (the deepest "bad" node in the chain).
        * **White (#FFFFFF):** Unexplored or neutral nodes.

        **3. Edge Labeling Logic:**
        * If Parent is Bad and Child is Bad, label = "contributes to impact".
        * If Parent is Bad and Child is Good, label = "stable factor".

        **4. JSON Schema (Must Follow Exactly):**
        {
          "nodes": [
            {
              "id": "N0",
              "type": "default",
              "data": { "label": "Metric Name: Value" },
              "position": { "x": 0, "y": 0 },
              "style": { "background": "#FFE2E5", "width": 180, "color": "#333", "border": "1px solid #777", "borderRadius": "8px" }
            }
          ],
          "edges": [
            {
              "id": "e-N0-N1",
              "source": "N0",
              "target": "N1",
              "label": "driven by",
              "animated": true,
              "style": { "stroke": "#555", "strokeWidth": 2 }
            }
          ]
        }
    </section_2_react_flow_json>
    
    Resposne format -> {response_format} 
    
</response_structure_prompt>"""
        }

        tools = [{
            "tool_spec": {
                "type": "generic",
                "name": "Diagnostic_tool",
                "description": "Retrieves metric status and dimensional breakdowns for root cause analysis.",
                "input_schema": {
                    "type": "object",
                    "properties": {
                        "USER_QUERY": {"type": "string"},
                        "PARENT_NODE_IDS_JSON": {"type": "string"},
                        "TREE_ID": {"type": "string"}
                    },
                    "required": ["USER_QUERY", "PARENT_NODE_IDS_JSON", "TREE_ID"]
                }
            }
        }]
        
        tool_resources = {
            "Diagnostic_tool": {
                "type": "procedure",
                "execution_environment": {"type": "warehouse", "warehouse": CONFIG.warehouse},
                "identifier": CONFIG.diagnostic_udf
            }
        }
        
        payload = PayloadFactory.create(query, instructions, tools, tool_resources)
        resp = invoke_cortex_agent(self.session, payload, "Root Cause Analysis Agent")
        
        try:
            raw = resp.get('text', '{}')
            clean = raw.replace("```json", "").replace("```", "").strip()
            result = DiagnosticResult.model_validate_json(clean)
        except Exception as e:
            result = DiagnosticResult(summary_text=f"Error: {str(e)} - Raw: {raw}", react_flow_json=None)
            
        log_checkpoint("END STEP 3b: Root Cause Analysis Agent", result)
        return result

# ==========================================
# 7. MAIN EXECUTION
# ==========================================

def main(session: Session):
    manager = AgentManager(session)
    history = []

    # Complex Query Testing Combined Intent
    user_query = "show ME all the health care providers in arizona and Why is the Total Market Volume being driven by the Opioid Category , specifically Tramadol which is seeing massive New Growth, yet the Orthopedic Segment historically the core driver for this drugis contributing less than 7% of that growth?"
    
    log_checkpoint("INITIAL INPUT", {"history": history, "current_query": user_query})

    # 0. Cortex Guard Check
    guard_result = check_input_guard(session, user_query)
    if not guard_result.is_safe:
        return {
            "status": "blocked",
            "message": guard_result.message,
            "violation": guard_result.violation_category
        }

    # 1. Rephrase
    rephrased = manager.run_rephraser(user_query, history)
    
    # 2. Intent Classification
    intent = manager.run_intent_classifier(rephrased)

    final_output = {
        "original_query": user_query,
        "processed_query": rephrased,
        "intent_classification": intent.model_dump(),
        "results": []
    }
    
    # 3. Route based on Intent
    
    # # Simple cases: Direct response (greetings, general questions, off-topic)
    # if intent.direct_response:
    #     final_output["results"].append({
    #         "type": "direct_response",
    #         "message": intent.direct_response
    #     })
    #     log_checkpoint("FINAL OUTPUT (Direct Response)", final_output)
    #     return final_output

    # # Clarification needed
    # if intent.intent_type == "clarification_needed":
    #     final_output["results"].append({
    #         "type": "clarification",
    #         "message": intent.clarification_question
    #     })
    #     log_checkpoint("FINAL OUTPUT (Clarification)", final_output)
    #     return final_output

    # # Agent processing needed (Data + Root Cause)
    # with ThreadPoolExecutor(max_workers=2) as executor:
    #     future_data = None
    #     future_root_cause = None
        
    #     # Submit tasks based on intent
    #     if intent.data_retrieval_query:
    #         future_data = executor.submit(manager.run_data_agent, intent.data_retrieval_query)
        
    #     if intent.root_cause_query:
    #         future_root_cause = executor.submit(manager.run_root_cause_agent, intent.root_cause_query)
        
    #     # Collect results
    #     if future_data:
    #         try:
    #             res = future_data.result()
    #             final_output["results"].append({
    #                 "type": "data_analysis",
    #                 "summary": res.answer_text,
    #                 "tables": res.tables,
    #                 "charts": res.charts,
    #                 "metadata": {
    #                     "sql": res.sql_generated,
    #                     "explanation": res.sql_explanation,
    #                     "is_verified": res.is_verified_query
    #                 }
    #             })
    #         except Exception as e:
    #             final_output["results"].append({
    #                 "type": "data_error",
    #                 "message": str(e)
    #             })

    #     if future_root_cause:
    #         try:
    #             res = future_root_cause.result()
    #             final_output["results"].append({
    #                 "type": "root_cause_analysis",
    #                 "summary": res.summary_text,
    #                 "graph": res.react_flow_json
    #             })
    #         except Exception as e:
    #             final_output["results"].append({
    #                 "type": "root_cause_error",
    #                 "message": str(e)
    #             })

    # log_checkpoint("FINAL ORCHESTRATOR OUTPUT", final_output)
    # return final_output




response.tool_result.analyst.delta
An delta event streamed for the Cortex Analyst tool execution

Field

Type

Description

content_index

integer

The index in the response content array this event represents

tool_use_id

string

Unique identifier for this tool use. Can be used to associated tool results.

tool_type

string

The type of the tool (always cortex_analyst_text_to_sql for this event)

tool_name

string

The unique identifier for this tool instance

delta

CortexAnalystToolResultDelta

The content delta

Example

{
  "content_index": 0,
  "tool_use_id": "toolu_123",
  "tool_type": "cortex_analyst_text_to_sql",
  "tool_name": "my_cortex_analyst_semantic_view",
  "delta": {
    "text": "The...",
    "think": "Thinking...",
    "sql": "SELECT...",
    "sql_explanation": "This...",
    "query_id": "707787a0-a684-4ead-adb0-3c3b62b043d9",
    "verified_query_used": false,
    "result_set": {
      "statementHandle": "707787a0-a684-4ead-adb0-3c3b62b043d9",
      "resultSetMetaData": {
        "partition": 0,
        "numRows": 0,
        "format": "jsonv2",
        "rowType": [
          {
            "name": "my_column",
            "type": "VARCHAR",
            "length": 0,
            "precision": 0,
            "scale": 0,
            "nullable": false
          }
        ]
      },
      "data": [
        [
          "row1 col1",
          "row1 col2"
        ],
        [
          "row2 col1",
          "row2 col2"
        ]
      ]
    },
    "suggestions": {
      "index": 0,
      "delta": "What..."
    }
  }
}

Invalid expression [PARSE_JSON('{"intent": "market_overview"}')] in VALUES clause
    # ---------------------------------------------------------
    # ---------------------------------------------------------

        # ---------------------------------------------------------










        import json
import logging
import _snowflake # Native Snowflake module for internal API calls
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import List, Dict, Any, Optional, Literal
from pydantic import BaseModel, Field
from snowflake.snowpark import Session

# ==========================================
# 1. CONFIGURATION & MODELS
# ==========================================

class AgentConfig(BaseModel):
    """Configuration for the agent execution"""
    model: str = "claude-4-sonnet" 
    diagnostic_udf: str = "DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.AI_POC.DIAGNOSTIC_TOOL"
    cortex_analyst_object: str = "DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.AI_POC.LATEST_MASTER_VIEW"
    warehouse: str = "DEV_IMPACT_WH"
    guard_name: str = "INPUT_GUARD" 

class IntentClassification(BaseModel):
    intent_type: str = Field(..., description="greeting, data_retrieval, root_cause_analysis, clarification_needed, general_question, off_topic, combined")
    data_retrieval_query: Optional[str] = Field(None)
    root_cause_query: Optional[str] = Field(None)
    direct_response: Optional[str] = Field(None)
    clarification_question: Optional[str] = Field(None)
    confidence: str = Field(...)
    reasoning: str = Field(...)

class DiagnosticResult(BaseModel):
    summary_text: str = Field(...)
    react_flow_json: Optional[Dict] = Field(None)
    clarifying_question: Optional[str] = Field(None)

class SqlResult(BaseModel):
    answer_text: str = Field(...)
    tables: List[Any] = Field(default_factory=list)
    charts: List[Dict] = Field(default_factory=list)
    sql_generated: Optional[str] = Field(None)
    sql_explanation: Optional[str] = Field(None)
    is_verified_query: bool = Field(False)
    reasoning_trace: Optional[str] = Field(None)

class GuardResult(BaseModel):
    is_safe: bool = Field(...)
    violation_category: Optional[str] = Field(None)
    message: Optional[str] = Field(None)

CONFIG = AgentConfig()

# ==========================================
# 2. FULL PROMPT DEFINITIONS
# ==========================================

PROMPT_REPHRASER_SYSTEM = "You are a sophisticated Query Refinement Engine."

PROMPT_REPHRASER_ORCHESTRATION = """
<query_refinement_instructions>
<objective>
Transform the user's input into a standalone, context-complete query that can be understood without prior conversation history.
</objective>

<core_rules>
<rule id="1">Resolve all pronouns (it, they, that, this, those) to their specific referents</rule>
<rule id="2">Preserve ALL metrics, entity names, IDs, and numerical values EXACTLY as stated</rule>
<rule id="3">Maintain the original intent and scope - do not expand or narrow the question</rule>
<rule id="4">Keep technical terminology and domain-specific language intact</rule>
<rule id="5">Ensure the output is grammatically correct and reads naturally</rule>
</core_rules>

<transformation_examples>
<example>
<input>What about Arizona?</input>
<context>Previous discussion about sales performance in Texas</context>
<output>What is the sales performance in Arizona?</output>
</example>

<example>
<input>Why is it down?</input>
<context>Previous mention of Q4 revenue</context>
<output>Why is Q4 revenue down?</output>
</example>

<example>
<input>Show me those providers and explain the trend.</input>
<context>Healthcare providers in California with declining prescriptions</context>
<output>Show me healthcare providers in California with declining prescriptions and explain the trend.</output>
</example>
</transformation_examples>

<output_format>
Output ONLY the refined query string. Do not include explanations, metadata, or formatting.
</output_format>
</query_refinement_instructions>
"""

PROMPT_INTENT_SYSTEM = "You are an Expert Intent Classification System."

PROMPT_INTENT_ORCHESTRATION = """
<intent_classification_instructions>

<mission>
Your ONLY job is to identify the user's INTENT. Do NOT retrieve data, do NOT answer questions, do NOT perform analysis.
Classify the intent type and route accordingly. If you can answer directly (like greetings), provide direct_response.
</mission>

<intent_categories>

<intent name="greeting">
<description>User is greeting, saying hello, or engaging in pleasantries</description>
<indicators>hi, hello, hey, good morning, how are you, thanks, thank you, goodbye, bye</indicators>
<action>Set direct_response with a friendly greeting. No other fields needed.</action>
</intent>

<intent name="data_retrieval">
<description>User wants to see/get/retrieve DATA - numbers, lists, metrics, tables</description>
<indicators>show, list, get, display, find, what is the value, how many, count, total, give me</indicators>
<action>Extract the data request to data_retrieval_query. Keep as natural language. Add "and generate a table and a visual".</action>
**CRITICAL VISUALIZATION LOGIC:**
Analyze the data request. If it implies trends (over time), comparisons (by region/product), or distributions, you MUST automatically append "and generate a table and a visual" to the query string, even if the user did not explicitly ask for a chart.
</intent>

<intent name="root_cause_analysis">
<description>User wants to understand WHY, CAUSES, DRIVERS, REASONS, EXPLANATIONS</description>
<indicators>why, explain, what is driving, what is causing, what's behind, reason for, root cause, how come, what factors</indicators>
<action>Extract the causal question to root_cause_query. Keep VERBATIM - exact text from user.</action>
</intent>

<intent name="combined">
<description>User wants BOTH data AND causal analysis in one request</description>
<indicators>Contains both data keywords AND causal keywords</indicators>
<action>Split into data_retrieval_query AND root_cause_query. Keep both portions.</action>
</intent>

<intent name="clarification_needed">
<description>User's intent is unclear, vague, or ambiguous - you cannot determine what they want</description>
<indicators>Very short/vague input, unclear pronouns without context, incomplete thoughts</indicators>
<action>Set clarification_question asking user to be more specific.</action>
</intent>

<intent name="general_question">
<description>General questions about the system, capabilities, how to use features - not data or analysis requests</description>
<indicators>how do I, can you, what can you do, help me understand, how does this work</indicators>
<action>Set direct_response with helpful information about capabilities.</action>
</intent>

<intent name="off_topic">
<description>User is asking about unrelated topics not connected to data, analytics, or business questions</description>
<indicators>Questions about weather, sports, entertainment, personal topics unrelated to business/data</indicators>
<action>Set direct_response politely redirecting to business/data topics.</action>
</intent>

</intent_categories>

<CRITICAL_CLASSIFICATION_RULES>

 RULE 1: NEVER DO THE WORK - ONLY CLASSIFY
You are NOT a data analyst. You are NOT an answering agent. You ONLY identify intent type.
Do NOT retrieve data. Do NOT answer analytical questions. ONLY classify and route.

 RULE 2: CAUSAL KEYWORD DETECTION
These ALWAYS indicate root_cause_analysis intent:
- "what is driving"
- "what is causing"
- "what's driving"  
- "what's causing"
- "why is/are"
- "explain why"
- "reason for"
- "root cause"
- "what factors"
- "what's behind"
- "how come"

 RULE 3: DATA KEYWORD DETECTION  
These ALWAYS indicate data_retrieval intent:
- "show me"
- "list"
- "get"
- "display"
- "find all"
- "what is the value/total/count of"
- "how many"

 RULE 4: DIRECT RESPONSE ONLY FOR SIMPLE CASES
Use direct_response ONLY for:
- Greetings (hi, hello, thanks)
- General system questions (what can you do)
- Off-topic redirects

Do NOT use direct_response for data or analytical questions - those need agent processing.

 RULE 5: VERBATIM PRESERVATION FOR ROOT CAUSE
For root_cause_query: Copy EXACT text from user. No paraphrasing, no summarizing.

 RULE 6: NO SQL CODE GENERATION
NEVER write SELECT/FROM/WHERE statements. Keep everything as natural language.

 RULE 7: CONFIDENCE SCORING
- high: Intent is crystal clear
- medium: Intent is likely but has some ambiguity
- low: Intent is very unclear, might need clarification

</CRITICAL_CLASSIFICATION_RULES>

<classification_process>
<step number="1">Check if greeting or general question. If match, Set intent_type and direct_response, STOP</step>
<step number="2">Check for causal keywords. If found, Flag as root_cause_analysis or combined</step>
<step number="3">Check for data keywords. If found, Flag as data_retrieval or combined</step>
<step number="4">Determine if combined intent. If both, Set intent_type="combined".</step>
<step number="5">If none of the above match, check if intent is clear enough.</step>
</classification_process>

<comprehensive_examples>
<example>
<input>Hello!</input>
<output>
{
  "intent_type": "greeting",
  "data_retrieval_query": null,
  "root_cause_query": null,
  "direct_response": "Hello! How can I help you today?",
  "clarification_question": null,
  "confidence": "high",
  "reasoning": "Simple greeting - can respond directly without agent processing"
}
</output>
</example>

<example>
<input>Show me total sales for Q4.</input>
<output>
{
  "intent_type": "data_retrieval",
  "data_retrieval_query": "Show me total sales for Q4 and generate a table and a visual",
  "root_cause_query": null,
  "direct_response": null,
  "clarification_question": null,
  "confidence": "high",
  "reasoning": "Clear data retrieval request - 'show me' is data keyword, asking for metric value"
}
</output>
</example>

<example>
<input>Why is profit down?</input>
<output>
{
  "intent_type": "root_cause_analysis",
  "data_retrieval_query": null,
  "root_cause_query": "Why is profit down?",
  "direct_response": null,
  "clarification_question": null,
  "confidence": "high",
  "reasoning": "Pure causal question - 'why' keyword indicates root cause analysis needed"
}
</output>
</example>

<example>
<input>Get revenue for AZ and explain the dip.</input>
<output>
{
  "intent_type": "combined",
  "data_retrieval_query": "Get revenue for AZ and generate a table and a visual",
  "root_cause_query": "explain the dip",
  "direct_response": null,
  "clarification_question": null,
  "confidence": "high",
  "reasoning": "Combined intent - 'get revenue' is data retrieval, 'explain the dip' is causal analysis"
}
</output>
</example>

<example>
<input>What can you help me with?</input>
<output>
{
  "intent_type": "general_question",
  "data_retrieval_query": null,
  "root_cause_query": null,
  "direct_response": "I can help you with data analysis and business insights! I can retrieve data and perform root cause analysis. What would you like to explore?",
  "clarification_question": null,
  "confidence": "high",
  "reasoning": "General system capability question - can answer directly"
}
</output>
</example>

<example>
<input>Show that</input>
<output>
{
  "intent_type": "clarification_needed",
  "data_retrieval_query": null,
  "root_cause_query": null,
  "direct_response": null,
  "clarification_question": "What would you like me to show? Please provide more details about the data or metrics you're interested in.",
  "confidence": "low",
  "reasoning": "Vague request - unclear what user wants to see, needs clarification"
}
</output>
</example>

<example>
<input>What's the weather like?</input>
<output>
{
  "intent_type": "off_topic",
  "data_retrieval_query": null,
  "root_cause_query": null,
  "direct_response": "I'm designed to help with business data and analytics. Is there any sales, performance, or business data I can help you with?",
  "clarification_question": null,
  "confidence": "high",
  "reasoning": "Off-topic request - politely redirect to business/data topics"
}
</output>
</example>
</comprehensive_examples>

<validation_checklist>
 Step 1: Can I answer this directly? (greeting/general_question/off_topic)
 Step 2: Does it contain causal keywords? (why/driving/causing/explain/reason/factors/behind)
 Step 3: Does it contain data keywords? (show/list/get/display/what is the value/how many)
 Step 4: Does it have BOTH data and causal elements?
 Step 5: Did I preserve EXACT wording for root_cause_query?
 Step 6: Did I add "and generate a table and a visual" to data_retrieval_query?
 Step 7: Did I avoid doing the actual work? (I only classify, not retrieve/analyze)
 Step 8: Is my confidence level accurate?
</validation_checklist>
</intent_classification_instructions>
"""

PROMPT_DATA_AGENT_SYSTEM = "You are an expert Data Analyst."

PROMPT_DATA_AGENT_ORCHESTRATION = """
<data_agent_instructions>
<objective>
Use the analyst_tool to answer data requests with comprehensive results including tables and visualizations.
</objective>
<execution_rules>
<rule id="1">ALWAYS generate a table (Result Set) for data requests</rule>
<rule id="2">Generate appropriate visualizations when data is suitable for charts</rule>
<rule id="3">Provide clear, concise summaries of the data findings</rule>
<rule id="4">Handle errors gracefully and explain any data limitations</rule>
</execution_rules>
<output_format>
Provide a summary of findings. Tables and charts are handled automatically by the tool.
</output_format>
</data_agent_instructions>
"""

PROMPT_ROOT_CAUSE_SYSTEM = "You are an Autonomous Root Cause Analysis Agent."

PROMPT_ROOT_CAUSE_ORCHESTRATION = """
<root_cause_orchestration_prompt>
    <role_and_objective>
        You are an **Autonomous Root Cause Analysis Agent** designed to traverse a metric decision tree from the root node down to the leaf nodes. Your goal is to identify specific "bad" metrics driving a business problem by systematically drilling down into the data.
        
        ALWAYS USE tree_id as Pharma_Master_v1.
    </role_and_objective>

    <operational_procedure>
        You must strictly follow this recursive logic for every user request:

        **Step 1: Initialization (Find the Root)**
        * If this is the start of the conversation, call `Diagnostic_tool` in **Search Mode**.
        * **Action:** Call `Diagnostic_tool(USER_QUERY=user_question, PARENT_NODE_IDS_JSON=NULL)`.
        * **Next:** Proceed to Step 2 with the results.

        **Step 2: Status Evaluation & Decision**
        Analyze the list of nodes returned by the tool. Focus **only** on nodes where `"status": "bad"`.

        * **Check:** For every "bad" node, do you see its children in the current list?
        * **Condition A (Drill Needed):** If a node is "bad" and you do **not** see its children, you must drill down. Collect these Node IDs.
        * **Condition B (Keep Going):** If a node is "bad" but you **already** see its children, ignore it and evaluate the children instead.
        * **Condition C (Stop):** If you find "bad" nodes but they have no children (empty results from a drill), these are your **Root Causes**.

        **Step 3: Execution (Drill Down)**
        * If Condition A occurred: Call `Diagnostic_tool` in **Drill Mode**.
        * **Action:** Call `Diagnostic_tool(USER_QUERY=NULL, PARENT_NODE_IDS_JSON='["ID_1", "ID_2"]')`.
        * **Next:** Recursively repeat Step 2 with the new output.
        * If Condition C occurred: Present the final root causes to the user.
    </operational_procedure>

    <constraints>
        * **Never** guess the status of a metric; always use the tool.
        * **Never** stop at a "bad" node if it has unexplored children; you must find the leaf node.
        * Output your reasoning briefly before calling the tool.
    </constraints>
</root_cause_orchestration_prompt>
"""

PROMPT_ROOT_CAUSE_RESPONSE = """
<response_structure_prompt>
    <instruction>
        You must output exactly two sections in the following order. Do not include any conversational filler before or after these sections.
    </instruction>

    <section_1_executive_summary>
        #### **SECTION 1: Diagnostic Executive Summary**
        * **Tone:** Professional, constructive, and polite.
        * **Headline:** State the Root Cause clearly.
        * **The Narrative:** Briefly explain the chain of events in simple English.
        * **Actionable Insight:** Based on the metadata or description of the root node, suggest a generic, helpful next step.
    </section_1_executive_summary>

    <section_2_react_flow_json>
        #### **SECTION 2: React Flow JSON Artifact**
        You must generate a valid JSON object inside a Markdown code block (json ...).
        
        **1. Coordinate Logic (The "Mental Layout"):**
        * **Level 0 (Root):** `x: 0, y: 0`
        * **Level 1 Children:** `y: 150`. Spread `x` widely (e.g., `-300` and `300`).
        * **Level 2 Grandchildren:** `y: 300`. Spread `x` relative to their parent.
        * **Level 3+:** Increase `y` by `150` for each level.

        **2. Visual Style Logic:**
        * **Red (#FFE2E5):** Status is "bad", "high", or "error".
        * **Green (#CDE8E6):** Status is "good", "normal", or "stable".
        * **Orange (#FFCCBC):** The **Root Cause** (the deepest "bad" node in the chain).
        * **White (#FFFFFF):** Unexplored or neutral nodes.

        **3. Edge Labeling Logic:**
        * If Parent is Bad and Child is Bad, label = "contributes to impact".
        * If Parent is Bad and Child is Good, label = "stable factor".

        **4. JSON Schema (Must Follow Exactly):**
        {
          "nodes": [
            {
              "id": "N0",
              "type": "default",
              "data": { "label": "Metric Name: Value" },
              "position": { "x": 0, "y": 0 },
              "style": { "background": "#FFE2E5", "width": 180, "color": "#333", "border": "1px solid #777", "borderRadius": "8px" }
            }
          ],
          "edges": [
            {
              "id": "e-N0-N1",
              "source": "N0",
              "target": "N1",
              "label": "driven by",
              "animated": true,
              "style": { "stroke": "#555", "strokeWidth": 2 }
            }
          ]
        }
    </section_2_react_flow_json>
</response_structure_prompt>
"""

# ==========================================
# 3. HELPER FUNCTIONS
# ==========================================

def log_checkpoint(step: str, details: Any):
    """Prints checkpoint info to stdout."""
    print(f"\n{'='*50}\n CHECKPOINT: {step}\n{'-'*50}")
    if isinstance(details, BaseModel):
        print(details.model_dump_json(indent=2))
    elif isinstance(details, (dict, list)):
        print(json.dumps(details, indent=2))
    else:
        print(str(details))
    print(f"{'='*50}\n")

def check_input_guard(session: Session, user_input: str) -> GuardResult:
    """Checks user input against Snowflake Cortex Guard."""
    log_checkpoint("START: CORTEX GUARD CHECK", f"Input: {user_input}")
    try:
        safe_input = user_input.replace("'", "''")
        guard_sql = f"""
        SELECT SNOWFLAKE.CORTEX.COMPLETE(
            '{CONFIG.model}',
            [{{'role': 'user', 'content': '{safe_input}'}}],
            {{'guardrails': true}}
        ) as response_json
        """
        result = session.sql(guard_sql).collect()
        if not result:
            return GuardResult(is_safe=True, message="Safe")

        response_data = json.loads(result[0]['RESPONSE_JSON'])
        model_output = response_data.get('choices', [{}])[0].get('messages', '')
        is_unsafe = "Response filtered by Cortex Guard" in model_output
        
        guard_res = GuardResult(
            is_safe=not is_unsafe,
            violation_category="unsafe_content" if is_unsafe else None,
            # FIX: Ensure a fallback string is provided if unsafe
            message="I cannot process this request due to safety guidelines." if is_unsafe else "Safe"
        )
        return guard_res
    except Exception as e:
        log_checkpoint("ERROR: CORTEX GUARD CHECK", str(e))
        # Fail open
        return GuardResult(is_safe=True, message="Error checking guard, allowing.")

def invoke_cortex_agent(session: Session, payload: Dict, agent_name: str) -> Dict:
    """Invokes the Cortex Agent API via _snowflake.send_snow_api_request."""
    AGENT_ENDPOINT = "/api/v2/cortex/agent:run"
    
    # Log the full request payload for debugging
    log_checkpoint(f"API REQUEST: {agent_name}", payload)

    try:
        resp = _snowflake.send_snow_api_request(
            "POST", 
            AGENT_ENDPOINT, 
            {"Content-Type": "application/json", "Accept": "text/event-stream"}, 
            {}, 
            payload, 
            {}, 
            120000
        )
        
        content = resp.get("content")
        if not content:
            log_checkpoint(f"API RESPONSE ERROR: {agent_name}", "Empty content")
            return {"error": "Empty response"}
        
        # Log a snippet of the raw response
        log_checkpoint(f"API RESPONSE RAW: {agent_name}", f"Length: {len(content)}. Snippet: {str(content)[:500]}...")

        extracted = {"text": "", "tables": [], "charts": [], "sql_generated": None, "sql_explanation": None, "is_verified": False, "debug_trace": []}
        
        # Only parse if content exists
        parsed = json.loads(content)
        
        def process_event(evt, data):
            if evt == 'response.text.delta': extracted["text"] += data.get('text', '')
            elif evt == 'response.chart': extracted["charts"].append(data.get('chart') or data.get('chart_spec'))
            elif evt == 'response.table': extracted["tables"].append(data.get('result_set'))
            elif evt == 'response.thinking.delta': extracted["debug_trace"].append(data.get('text', ''))
            elif evt == 'response.tool_result.analyst.delta':
                delta = data.get('delta', {})
                if delta.get('sql'): extracted["sql_generated"] = delta.get('sql')
                if delta.get('sql_explanation'): extracted["sql_explanation"] = delta.get('sql_explanation')
                if delta.get('result_set'): extracted["tables"].append(delta.get('result_set'))

        if isinstance(parsed, list):
            for item in parsed: process_event(item.get('event'), item.get('data', {}))
        
        log_checkpoint(f"API RESPONSE EXTRACTED: {agent_name}", {"text_len": len(extracted["text"]), "tables": len(extracted["tables"])})
        return extracted

    except Exception as e:
        log_checkpoint(f"API EXCEPTION: {agent_name}", str(e))
        return {"error": str(e)}

class PayloadFactory:
    @staticmethod
    def create(query: str, instructions: Dict[str, str], tools: List[Dict] = None, resources: Dict = None, history: List[Dict] = None) -> Dict:
        messages = (history if history else []) + [{"role": "user", "content": [{"type": "text", "text": query}]}]
        return {
            "messages": messages,
            "tool_choice": {"type": "auto"},
            "models": {"orchestration": CONFIG.model},
            "instructions": instructions,
            "tools": tools or [],
            "tool_resources": resources or {}
        }

# ==========================================
# 4. AGENT MANAGER
# ==========================================

class AgentManager:
    def __init__(self, session: Session):
        self.session = session

    def run_rephraser(self, query: str, history: List[Dict] = None) -> str:
        log_checkpoint("START: REPHRASER", f"Query: {query}")
        instructions = {
            "system": PROMPT_REPHRASER_SYSTEM,
            "response": "Output ONLY the final rephrased string.",
            "orchestration": PROMPT_REPHRASER_ORCHESTRATION
        }
        payload = PayloadFactory.create(f"Rephrase standalone: {query}", instructions, history=history)
        resp = invoke_cortex_agent(self.session, payload, "Rephraser")
        result = resp.get('text', query).strip() or query
        log_checkpoint("END: REPHRASER", f"Result: {result}")
        return result

    def run_intent_classifier(self, query: str) -> IntentClassification:
        log_checkpoint("START: INTENT CLASSIFIER", f"Query: {query}")
        schema_hint = '{"intent_type": "string", "data_retrieval_query": "string", "root_cause_query": "string", "direct_response": "string", "clarification_question": "string", "confidence": "string", "reasoning": "string"}'
        instructions = {
            "system": PROMPT_INTENT_SYSTEM,
            "response": f"Respond ONLY with a valid JSON matching: {schema_hint}",
            "orchestration": PROMPT_INTENT_ORCHESTRATION
        }
        payload = PayloadFactory.create(f"Classify: {query}", instructions)
        resp = invoke_cortex_agent(self.session, payload, "Intent Classifier")
        try:
            raw = resp.get('text', '')
            # Clean possible markdown format
            clean = raw.replace("```json", "").replace("```", "").strip()
            # Parse logic: parse to dict first to ensure validity, then model validate
            parsed_dict = json.loads(clean)
            result = IntentClassification.model_validate(parsed_dict)
        except Exception as e:
            log_checkpoint("ERROR: INTENT PARSING", str(e))
            result = IntentClassification(intent_type="clarification_needed", confidence="low", reasoning=f"Parse error: {str(e)}")
            
        log_checkpoint("END: INTENT CLASSIFIER", result)
        return result

    def run_data_agent(self, query: str) -> SqlResult:
        log_checkpoint("START: DATA AGENT", f"Query: {query}")
        instructions = {
            "system": PROMPT_DATA_AGENT_SYSTEM,
            "orchestration": PROMPT_DATA_AGENT_ORCHESTRATION,
            "response": "Provide a summary. Tables/Charts are handled automatically."
        }
        tools = [{"tool_spec": {"type": "cortex_analyst_text_to_sql", "name": "analyst_tool"}}]
        resources = {"analyst_tool": {"type": "cortex_analyst_text_to_sql", "semantic_view": CONFIG.cortex_analyst_object, "execution_environment": {"type": "warehouse", "warehouse": CONFIG.warehouse}}}
        
        resp = invoke_cortex_agent(self.session, PayloadFactory.create(query, instructions, tools, resources), "Data Agent")
        result = SqlResult(
            answer_text=resp.get('text', ''),
            tables=resp.get('tables', []),
            charts=resp.get('charts', []),
            sql_generated=resp.get('sql_generated'),
            sql_explanation=resp.get('sql_explanation'),
            is_verified_query=resp.get('is_verified', False),
            reasoning_trace="\n".join(resp.get('debug_trace', []))
        )
        log_checkpoint("END: DATA AGENT", result)
        return result

    def run_root_cause_agent(self, query: str) -> DiagnosticResult:
        log_checkpoint("START: ROOT CAUSE AGENT", f"Query: {query}")
        instructions = {
            "system": PROMPT_ROOT_CAUSE_SYSTEM,
            "orchestration": PROMPT_ROOT_CAUSE_ORCHESTRATION,
            "response": PROMPT_ROOT_CAUSE_RESPONSE
        }
        tools = [{
            "tool_spec": {
                "type": "generic", 
                "name": "Diagnostic_tool", 
                "description": "Retrieves metric status.",
                "input_schema": {
                    "type": "object",
                    "properties": {
                        "USER_QUERY": {"type": "string"},
                        "PARENT_NODE_IDS_JSON": {"type": "string"},
                        "TREE_ID": {"type": "string"}
                    },
                    "required": ["USER_QUERY", "PARENT_NODE_IDS_JSON", "TREE_ID"]
                }
            }
        }]
        resources = {"Diagnostic_tool": {"type": "procedure", "execution_environment": {"type": "warehouse", "warehouse": CONFIG.warehouse}, "identifier": CONFIG.diagnostic_udf}}
        
        resp = invoke_cortex_agent(self.session, PayloadFactory.create(query, instructions, tools, resources), "Root Cause Agent")
        
        raw = resp.get('text', '')
        # Only perform manual extraction if needed
        j_start, j_end = raw.find("```json"), raw.rfind("```")
        
        if j_start != -1 and j_end != -1:
            try:
                json_str = raw[j_start+7:j_end].strip()
                parsed_json = json.loads(json_str)
                result = DiagnosticResult(summary_text=raw[:j_start].strip(), react_flow_json=parsed_json)
            except Exception as e:
                result = DiagnosticResult(summary_text=f"JSON Parse Error: {str(e)}\n{raw}", react_flow_json=None)
        else:
            result = DiagnosticResult(summary_text=raw, react_flow_json=None)

        log_checkpoint("END: ROOT CAUSE AGENT", result)
        return result
        
    def extract_response_text(self,final_output: Dict) -> str:
        """
        Parses the complex final_output dictionary to create a clean text summary 
        for storage in the Messages table.
        """
        lines = []
        
        # Check for direct responses (Greetings, etc.)
        for res in final_output.get("results", []):
            if res.get("type") == "direct_response":
                lines.append(res.get("message"))
                
            elif res.get("type") == "data_analysis":
                lines.append(" **Data Analysis:**")
                lines.append(res.get("summary"))
                if res.get("metadata", {}).get("sql"):
                    lines.append(f"\n*(Generated SQL used for analysis)*")
                    
            elif res.get("type") == "root_cause_analysis":
                lines.append(" **Root Cause Diagnosis:**")
                lines.append(res.get("summary"))
                
            elif "error" in res.get("type", ""):
                lines.append(f" Error: {res.get('message')}")
    
        # Fallback if empty
        if not lines:
            return "Processed request successfully, but no text summary was generated."
            
        return "\n\n".join(lines)

    # ==========================================
# HISTORY MANAGEMENT FUNCTIONS (UPDATED)
# ==========================================

def save_message(session: Session, conversation_id: str, sender_type: str, message_text: str, metadata: dict = None):
    """
    Saves a message to the table. Handles NoneType inputs safely.
    """
    import json
    
    try:
        # FIX: Handle None input safely
        if message_text is None:
            message_text = ""
        else:
            message_text = str(message_text) # Ensure it is a string
            
        # Escape single quotes
        safe_message = message_text.replace("'", "''")
        
        # Handle Metadata
        meta_json = json.dumps(metadata) if metadata else "{}"
        safe_meta = meta_json.replace("'", "''")
        
        created_by = "system_bot" if sender_type == "assistant" else "user_gerish"
        
        # Use SELECT for insertion (fixes the PARSE_JSON error)
        sql = f"""
        INSERT INTO {CONFIG.messages_table} 
        (CONVERSATION_ID, SENDER_TYPE, MESSAGE, METADATA, CREATED_BY, UPDATED_BY)
        SELECT 
            '{conversation_id}', 
            '{sender_type}', 
            '{safe_message}', 
            PARSE_JSON('{safe_meta}'), 
            '{created_by}', 
            '{created_by}'
        """
        session.sql(sql).collect()
        
    except Exception as e:
        print(f"Error saving message: {str(e)}")
        
def get_chat_history(session: Session, conversation_id: str) -> List[Dict]:
    """
    Retrieves history using new columns (SENDER_TYPE, MESSAGE) and maps to Cortex format.
    """
    try:
        # Fetch last 10 messages for context
        sql = f"""
        SELECT SENDER_TYPE, MESSAGE 
        FROM DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.AI_POC.MESSAGES
        WHERE CONVERSATION_ID = '{conversation_id}'
        ORDER BY CREATED_AT ASC
        LIMIT 10
        """
        rows = session.sql(sql).collect()
        
        formatted_history = []
        for row in rows:
            # Map database columns to Cortex API requirements
            # Database 'sender_type' -> Cortex 'role'
            # Database 'message' -> Cortex 'content' text
            role = row['SENDER_TYPE']
            content = row['MESSAGE']
            
            formatted_history.append({
                "role": role,
                "content": [{"type": "text", "text": content}]
            })
            
        return formatted_history
    except Exception as e:
        print(f"Error fetching history: {str(e)}")
        return []

# ==========================================
# 5. MAIN EXECUTION
# ==========================================

def main(session: Session):
    manager = AgentManager(session)
    
    # 1. SETUP SESSION
    # In a real app, pass this ID from your API/Frontend
    conversation_id = "SESSION_TEST_ARIZONA_001" 
    
    # 2. USER QUERY
    user_query = "show ME all the health care providers in arizona and Why is the Total Market Volume being driven by the Opioid Category?"
    
    # 3. GET HISTORY (for context)
    history = get_chat_history(session, conversation_id)
    log_checkpoint("MAIN: START", {"query": user_query, "history_depth": len(history)})

    # ---------------------------------------------------------
    # STEP A: SAVE USER MESSAGE
    # ---------------------------------------------------------
    save_message(
        session, 
        conversation_id, 
        "user", 
        user_query, 
        metadata={"client": "snowflake_ui", "intent_check": "pending"}
    )

    # 4. GUARDRAILS
    guard = check_input_guard(session, user_query)
    
    if not guard.is_safe:
        # FIX: Provide a default string if guard.message is somehow still None
        block_msg = guard.message if guard.message else "Request blocked by safety filters."
        
        save_message(session, conversation_id, "assistant", block_msg, {"blocked": True})
        return {"status": "blocked", "message": block_msg}
        
    # 5. REPHRASE & CLASSIFY
    rephrased = manager.run_rephraser(user_query, history)
    intent = manager.run_intent_classifier(rephrased)

    final = {
        "original": user_query, 
        "processed": rephrased, 
        "intent": intent.model_dump(), 
        "results": []
    }

    # 6. ROUTING & EXECUTION
    if intent.direct_response:
        final["results"].append({"type": "direct_response", "message": intent.direct_response})
    else:
        # Parallel Execution for Combined Intents
        with ThreadPoolExecutor(max_workers=2) as executor:
            fut_data = None
            fut_rc = None
            
            if intent.data_retrieval_query:
                fut_data = executor.submit(manager.run_data_agent, intent.data_retrieval_query)
            
            if intent.root_cause_query:
                fut_rc = executor.submit(manager.run_root_cause_agent, intent.root_cause_query)
            
            # Collect Data Results
            if fut_data:
                try:
                    res = fut_data.result()
                    final["results"].append({
                        "type": "data_analysis", 
                        "summary": res.answer_text, 
                        "tables": res.tables, 
                        "charts": res.charts,
                        "metadata": {"sql": res.sql_generated}
                    })
                except Exception as e: 
                    final["results"].append({"type": "data_error", "message": str(e)})

            # Collect Root Cause Results
            if fut_rc:
                try:
                    res = fut_rc.result()
                    final["results"].append({
                        "type": "root_cause_analysis", 
                        "summary": res.summary_text, 
                        "graph": res.react_flow_json
                    })
                except Exception as e: 
                    final["results"].append({"type": "root_cause_error", "message": str(e)})

    # ---------------------------------------------------------
    # STEP B: SAVE AGENT OUTPUT
    # ---------------------------------------------------------
    # Convert the rich JSON response into a text string for the DB
    final_text_response = manager.extract_response_text(final)
    
    # Create metadata to track performance/classification
    response_metadata = {
        "model": CONFIG.model,
        "intent": intent.intent_type,
        "confidence": intent.confidence,
        "has_sql": any(r.get("type") == "data_analysis" for r in final["results"]),
        "has_graph": any(r.get("type") == "root_cause_analysis" for r in final["results"])
    }

    save_message(
        session, 
        conversation_id, 
        "assistant", 
        final_text_response, 
        metadata=response_metadata
    )

    log_checkpoint("MAIN: COMPLETED", final)
    return final




    import json
import logging
import _snowflake  # Native Snowflake module for internal API calls
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import List, Dict, Any, Optional, Literal
from pydantic import BaseModel, Field
from snowflake.snowpark import Session

# ==========================================
# 1. CONFIGURATION & MODELS
# ==========================================

class AgentConfig(BaseModel):
    """Configuration for the agent execution"""
    model: str = "claude-4-sonnet" # Updated to a valid Snowflake Cortex model name if 4-sonnet isn't available, or keep as is
    diagnostic_udf: str = "DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.AI_POC.DIAGNOSTIC_TOOL"
    cortex_analyst_object: str = "DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.AI_POC.LATEST_MASTER_VIEW"
    warehouse: str = "DEV_IMPACT_WH"
    guard_name: str = "INPUT_GUARD"
    # Added missing field referenced in save_message
    messages_table: str = "DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.AI_POC.MESSAGES"

class IntentClassification(BaseModel):
    intent_type: str = Field(..., description="greeting, data_retrieval, root_cause_analysis, clarification_needed, general_question, off_topic, combined")
    data_retrieval_query: Optional[str] = Field(None)
    root_cause_query: Optional[str] = Field(None)
    direct_response: Optional[str] = Field(None)
    clarification_question: Optional[str] = Field(None)
    confidence: str = Field(...)
    reasoning: str = Field(...)

class DiagnosticResult(BaseModel):
    summary_text: str = Field(...)
    react_flow_json: Optional[Dict] = Field(None)
    clarifying_question: Optional[str] = Field(None)

class SqlResult(BaseModel):
    answer_text: str = Field(...)
    tables: List[Any] = Field(default_factory=list)
    charts: List[Dict] = Field(default_factory=list)
    sql_generated: Optional[str] = Field(None)
    sql_explanation: Optional[str] = Field(None)
    is_verified_query: bool = Field(False)
    reasoning_trace: Optional[str] = Field(None)

class GuardResult(BaseModel):
    is_safe: bool = Field(...)
    violation_category: Optional[str] = Field(None)
    message: Optional[str] = Field(None)

CONFIG = AgentConfig()

# ==========================================
# 2. FULL PROMPT DEFINITIONS
# ==========================================

PROMPT_REPHRASER_SYSTEM = "You are a sophisticated Query Refinement Engine."

PROMPT_REPHRASER_ORCHESTRATION = """
<query_refinement_instructions>
<objective>
Transform the user's input into a standalone, context-complete query that can be understood without prior conversation history.
</objective>

<core_rules>
<rule id="1">Resolve all pronouns (it, they, that, this, those) to their specific referents</rule>
<rule id="2">Preserve ALL metrics, entity names, IDs, and numerical values EXACTLY as stated</rule>
<rule id="3">Maintain the original intent and scope - do not expand or narrow the question</rule>
<rule id="4">Keep technical terminology and domain-specific language intact</rule>
<rule id="5">Ensure the output is grammatically correct and reads naturally</rule>
</core_rules>

<transformation_examples>
<example>
<input>What about Arizona?</input>
<context>Previous discussion about sales performance in Texas</context>
<output>What is the sales performance in Arizona?</output>
</example>

<example>
<input>Why is it down?</input>
<context>Previous mention of Q4 revenue</context>
<output>Why is Q4 revenue down?</output>
</example>

<example>
<input>Show me those providers and explain the trend.</input>
<context>Healthcare providers in California with declining prescriptions</context>
<output>Show me healthcare providers in California with declining prescriptions and explain the trend.</output>
</example>
</transformation_examples>

<output_format>
Output ONLY the refined query string. Do not include explanations, metadata, or formatting.
</output_format>
</query_refinement_instructions>
"""

PROMPT_INTENT_SYSTEM = "You are an Expert Intent Classification System."

PROMPT_INTENT_ORCHESTRATION = """
<intent_classification_instructions>

<mission>
Your ONLY job is to identify the user's INTENT. Do NOT retrieve data, do NOT answer questions, do NOT perform analysis.
Classify the intent type and route accordingly. If you can answer directly (like greetings), provide direct_response.
</mission>

<intent_categories>

<intent name="greeting">
<description>User is greeting, saying hello, or engaging in pleasantries</description>
<indicators>hi, hello, hey, good morning, how are you, thanks, thank you, goodbye, bye</indicators>
<action>Set direct_response with a friendly greeting. No other fields needed.</action>
</intent>

<intent name="data_retrieval">
<description>User wants to see/get/retrieve DATA - numbers, lists, metrics, tables</description>
<indicators>show, list, get, display, find, what is the value, how many, count, total, give me</indicators>
<action>Extract the data request to data_retrieval_query. Keep as natural language. Add "and generate a table and a visual".</action>
**CRITICAL VISUALIZATION LOGIC:**
Analyze the data request. If it implies trends (over time), comparisons (by region/product), or distributions, you MUST automatically append "and generate a table and a visual" to the query string, even if the user did not explicitly ask for a chart.
</intent>

<intent name="root_cause_analysis">
<description>User wants to understand WHY, CAUSES, DRIVERS, REASONS, EXPLANATIONS</description>
<indicators>why, explain, what is driving, what is causing, what's behind, reason for, root cause, how come, what factors</indicators>
<action>Extract the causal question to root_cause_query. Keep VERBATIM - exact text from user.</action>
</intent>

<intent name="combined">
<description>User wants BOTH data AND causal analysis in one request</description>
<indicators>Contains both data keywords AND causal keywords</indicators>
<action>Split into data_retrieval_query AND root_cause_query. Keep both portions.</action>
</intent>

<intent name="clarification_needed">
<description>User's intent is unclear, vague, or ambiguous - you cannot determine what they want</description>
<indicators>Very short/vague input, unclear pronouns without context, incomplete thoughts</indicators>
<action>Set clarification_question asking user to be more specific.</action>
</intent>

<intent name="general_question">
<description>General questions about the system, capabilities, how to use features - not data or analysis requests</description>
<indicators>how do I, can you, what can you do, help me understand, how does this work</indicators>
<action>Set direct_response with helpful information about capabilities.</action>
</intent>

<intent name="off_topic">
<description>User is asking about unrelated topics not connected to data, analytics, or business questions</description>
<indicators>Questions about weather, sports, entertainment, personal topics unrelated to business/data</indicators>
<action>Set direct_response politely redirecting to business/data topics.</action>
</intent>

</intent_categories>

<CRITICAL_CLASSIFICATION_RULES>

 RULE 1: NEVER DO THE WORK - ONLY CLASSIFY
You are NOT a data analyst. You are NOT an answering agent. You ONLY identify intent type.
Do NOT retrieve data. Do NOT answer analytical questions. ONLY classify and route.

 RULE 2: CAUSAL KEYWORD DETECTION
These ALWAYS indicate root_cause_analysis intent:
- "what is driving"
- "what is causing"
- "what's driving"  
- "what's causing"
- "why is/are"
- "explain why"
- "reason for"
- "root cause"
- "what factors"
- "what's behind"
- "how come"

 RULE 3: DATA KEYWORD DETECTION  
These ALWAYS indicate data_retrieval intent:
- "show me"
- "list"
- "get"
- "display"
- "find all"
- "what is the value/total/count of"
- "how many"

 RULE 4: DIRECT RESPONSE ONLY FOR SIMPLE CASES
Use direct_response ONLY for:
- Greetings (hi, hello, thanks)
- General system questions (what can you do)
- Off-topic redirects

Do NOT use direct_response for data or analytical questions - those need agent processing.

 RULE 5: VERBATIM PRESERVATION FOR ROOT CAUSE
For root_cause_query: Copy EXACT text from user. No paraphrasing, no summarizing.

 RULE 6: NO SQL CODE GENERATION
NEVER write SELECT/FROM/WHERE statements. Keep everything as natural language.

 RULE 7: CONFIDENCE SCORING
- high: Intent is crystal clear
- medium: Intent is likely but has some ambiguity
- low: Intent is very unclear, might need clarification

</CRITICAL_CLASSIFICATION_RULES>

<classification_process>
<step number="1">Check if greeting or general question. If match, Set intent_type and direct_response, STOP</step>
<step number="2">Check for causal keywords. If found, Flag as root_cause_analysis or combined</step>
<step number="3">Check for data keywords. If found, Flag as data_retrieval or combined</step>
<step number="4">Determine if combined intent. If both, Set intent_type="combined".</step>
<step number="5">If none of the above match, check if intent is clear enough.</step>
</classification_process>

<comprehensive_examples>
<example>
<input>Hello!</input>
<output>
{
  "intent_type": "greeting",
  "data_retrieval_query": null,
  "root_cause_query": null,
  "direct_response": "Hello! How can I help you today?",
  "clarification_question": null,
  "confidence": "high",
  "reasoning": "Simple greeting - can respond directly without agent processing"
}
</output>
</example>

<example>
<input>Show me total sales for Q4.</input>
<output>
{
  "intent_type": "data_retrieval",
  "data_retrieval_query": "Show me total sales for Q4 and generate a table and a visual",
  "root_cause_query": null,
  "direct_response": null,
  "clarification_question": null,
  "confidence": "high",
  "reasoning": "Clear data retrieval request - 'show me' is data keyword, asking for metric value"
}
</output>
</example>

<example>
<input>Why is profit down?</input>
<output>
{
  "intent_type": "root_cause_analysis",
  "data_retrieval_query": null,
  "root_cause_query": "Why is profit down?",
  "direct_response": null,
  "clarification_question": null,
  "confidence": "high",
  "reasoning": "Pure causal question - 'why' keyword indicates root cause analysis needed"
}
</output>
</example>

<example>
<input>Get revenue for AZ and explain the dip.</input>
<output>
{
  "intent_type": "combined",
  "data_retrieval_query": "Get revenue for AZ and generate a table and a visual",
  "root_cause_query": "explain the dip",
  "direct_response": null,
  "clarification_question": null,
  "confidence": "high",
  "reasoning": "Combined intent - 'get revenue' is data retrieval, 'explain the dip' is causal analysis"
}
</output>
</example>

<example>
<input>What can you help me with?</input>
<output>
{
  "intent_type": "general_question",
  "data_retrieval_query": null,
  "root_cause_query": null,
  "direct_response": "I can help you with data analysis and business insights! I can retrieve data and perform root cause analysis. What would you like to explore?",
  "clarification_question": null,
  "confidence": "high",
  "reasoning": "General system capability question - can answer directly"
}
</output>
</example>

<example>
<input>Show that</input>
<output>
{
  "intent_type": "clarification_needed",
  "data_retrieval_query": null,
  "root_cause_query": null,
  "direct_response": null,
  "clarification_question": "What would you like me to show? Please provide more details about the data or metrics you're interested in.",
  "confidence": "low",
  "reasoning": "Vague request - unclear what user wants to see, needs clarification"
}
</output>
</example>

<example>
<input>What's the weather like?</input>
<output>
{
  "intent_type": "off_topic",
  "data_retrieval_query": null,
  "root_cause_query": null,
  "direct_response": "I'm designed to help with business data and analytics. Is there any sales, performance, or business data I can help you with?",
  "clarification_question": null,
  "confidence": "high",
  "reasoning": "Off-topic request - politely redirect to business/data topics"
}
</output>
</example>
</comprehensive_examples>

<validation_checklist>
 Step 1: Can I answer this directly? (greeting/general_question/off_topic)
 Step 2: Does it contain causal keywords? (why/driving/causing/explain/reason/factors/behind)
 Step 3: Does it contain data keywords? (show/list/get/display/what is the value/how many)
 Step 4: Does it have BOTH data and causal elements?
 Step 5: Did I preserve EXACT wording for root_cause_query?
 Step 6: Did I add "and generate a table and a visual" to data_retrieval_query?
 Step 7: Did I avoid doing the actual work? (I only classify, not retrieve/analyze)
 Step 8: Is my confidence level accurate?
</validation_checklist>
</intent_classification_instructions>
"""

PROMPT_DATA_AGENT_SYSTEM = "You are an expert Data Analyst."

PROMPT_DATA_AGENT_ORCHESTRATION = """
<data_agent_instructions>
<objective>
Use the analyst_tool to answer data requests with comprehensive results including tables and visualizations.
</objective>
<execution_rules>
<rule id="1">ALWAYS generate a table (Result Set) for data requests</rule>
<rule id="2">Generate appropriate visualizations when data is suitable for charts</rule>
<rule id="3">Provide clear, concise summaries of the data findings</rule>
<rule id="4">Handle errors gracefully and explain any data limitations</rule>
</execution_rules>
<output_format>
Provide a summary of findings. Tables and charts are handled automatically by the tool. Always include sql queries and explanations in your response.
</output_format>
</data_agent_instructions>
"""

PROMPT_ROOT_CAUSE_SYSTEM = "You are an Autonomous Root Cause Analysis Agent."

PROMPT_ROOT_CAUSE_ORCHESTRATION = """
<root_cause_orchestration_prompt>
    <role_and_objective>
        You are an **Autonomous Root Cause Analysis Agent** designed to traverse a metric decision tree from the root node down to the leaf nodes. Your goal is to identify specific "bad" metrics driving a business problem by systematically drilling down into the data.
        
        ALWAYS USE tree_id as Pharma_Master_v1.
    </role_and_objective>

    <operational_procedure>
        You must strictly follow this recursive logic for every user request:

        **Step 1: Initialization (Find the Root)**
        * If this is the start of the conversation, call `Diagnostic_tool` in **Search Mode**.
        * **Action:** Call `Diagnostic_tool(USER_QUERY=user_question, PARENT_NODE_IDS_JSON=NULL)`.
        * **Next:** Proceed to Step 2 with the results.

        **Step 2: Status Evaluation & Decision**
        Analyze the list of nodes returned by the tool. Focus **only** on nodes where `"status": "bad"`.

        * **Check:** For every "bad" node, do you see its children in the current list?
        * **Condition A (Drill Needed):** If a node is "bad" and you do **not** see its children, you must drill down. Collect these Node IDs.
        * **Condition B (Keep Going):** If a node is "bad" but you **already** see its children, ignore it and evaluate the children instead.
        * **Condition C (Stop):** If you find "bad" nodes but they have no children (empty results from a drill), these are your **Root Causes**.

        **Step 3: Execution (Drill Down)**
        * If Condition A occurred: Call `Diagnostic_tool` in **Drill Mode**.
        * **Action:** Call `Diagnostic_tool(USER_QUERY=NULL, PARENT_NODE_IDS_JSON='["ID_1", "ID_2"]')`.
        * **Next:** Recursively repeat Step 2 with the new output.
        * If Condition C occurred: Present the final root causes to the user.
    </operational_procedure>

    <constraints>
        * **Never** guess the status of a metric; always use the tool.
        * **Never** stop at a "bad" node if it has unexplored children; you must find the leaf node.
        * Output your reasoning briefly before calling the tool.
    </constraints>
</root_cause_orchestration_prompt>
"""

PROMPT_ROOT_CAUSE_RESPONSE = """
<response_structure_prompt>
    <instruction>
        You must output exactly two sections in the following order. Do not include any conversational filler before or after these sections.
    </instruction>

    <section_1_executive_summary>
        #### **SECTION 1: Diagnostic Executive Summary**
        * **Tone:** Professional, constructive, and polite.
        * **Headline:** State the Root Cause clearly.
        * **The Narrative:** Briefly explain the chain of events in simple English.
        * **Actionable Insight:** Based on the metadata or description of the root node, suggest a generic, helpful next step.
    </section_1_executive_summary>

    <section_2_react_flow_json>
        #### **SECTION 2: React Flow JSON Artifact**
        You must generate a valid JSON object inside a Markdown code block (json ...).
        
        **1. Coordinate Logic (The "Mental Layout"):**
        * **Level 0 (Root):** `x: 0, y: 0`
        * **Level 1 Children:** `y: 150`. Spread `x` widely (e.g., `-300` and `300`).
        * **Level 2 Grandchildren:** `y: 300`. Spread `x` relative to their parent.
        * **Level 3+:** Increase `y` by `150` for each level.

        **2. Visual Style Logic:**
        * **Red (#FFE2E5):** Status is "bad", "high", or "error".
        * **Green (#CDE8E6):** Status is "good", "normal", or "stable".
        * **Orange (#FFCCBC):** The **Root Cause** (the deepest "bad" node in the chain).
        * **White (#FFFFFF):** Unexplored or neutral nodes.

        **3. Edge Labeling Logic:**
        * If Parent is Bad and Child is Bad, label = "contributes to impact".
        * If Parent is Bad and Child is Good, label = "stable factor".

        **4. JSON Schema (Must Follow Exactly):**
        {
          "nodes": [
            {
              "id": "N0",
              "type": "default",
              "data": { "label": "Metric Name: Value" },
              "position": { "x": 0, "y": 0 },
              "style": { "background": "#FFE2E5", "width": 180, "color": "#333", "border": "1px solid #777", "borderRadius": "8px" }
            }
          ],
          "edges": [
            {
              "id": "e-N0-N1",
              "source": "N0",
              "target": "N1",
              "label": "driven by",
              "animated": true,
              "style": { "stroke": "#555", "strokeWidth": 2 }
            }
          ]
        }
    </section_2_react_flow_json>
</response_structure_prompt>
"""

# ==========================================
# 3. HELPER FUNCTIONS
# ==========================================

def log_checkpoint(step: str, details: Any):
    """Prints checkpoint info to stdout."""
    print(f"\n{'='*50}\n CHECKPOINT: {step}\n{'-'*50}")
    if isinstance(details, BaseModel):
        print(details.model_dump_json(indent=2))
    elif isinstance(details, (dict, list)):
        print(json.dumps(details, indent=2))
    else:
        print(str(details))
    print(f"{'='*50}\n")

def check_input_guard(session: Session, user_input: str) -> GuardResult:
    """Checks user input against Snowflake Cortex Guard."""
    log_checkpoint("START: CORTEX GUARD CHECK", f"Input: {user_input}")
    try:
        safe_input = user_input.replace("'", "''")
        guard_sql = f"""
        SELECT SNOWFLAKE.CORTEX.COMPLETE(
            '{CONFIG.model}',
            [{{'role': 'user', 'content': '{safe_input}'}}],
            {{'guardrails': true}}
        ) as response_json
        """
        result = session.sql(guard_sql).collect()
        if not result:
            return GuardResult(is_safe=True, message="Safe")

        response_data = json.loads(result[0]['RESPONSE_JSON'])
        model_output = response_data.get('choices', [{}])[0].get('messages', '')
        is_unsafe = "Response filtered by Cortex Guard" in model_output
        
        guard_res = GuardResult(
            is_safe=not is_unsafe,
            violation_category="unsafe_content" if is_unsafe else None,
            message="I cannot process this request due to safety guidelines." if is_unsafe else "Safe"
        )
        return guard_res
    except Exception as e:
        log_checkpoint("ERROR: CORTEX GUARD CHECK", str(e))
        # Fail open
        return GuardResult(is_safe=True, message="Error checking guard, allowing.")

def invoke_cortex_agent(session: Session, payload: Dict, agent_name: str) -> Dict:
    """Invokes the Cortex Agent API via _snowflake.send_snow_api_request."""
    AGENT_ENDPOINT = "/api/v2/cortex/agent:run"
    
    # Log the full request payload for debugging
    log_checkpoint(f"API REQUEST: {agent_name}", payload)

    try:
        resp = _snowflake.send_snow_api_request(
            "POST", 
            AGENT_ENDPOINT, 
            {"Content-Type": "application/json", "Accept": "text/event-stream"}, 
            {}, 
            payload, 
            {}, 
            120000
        )
        
        content = resp.get("content")
        if not content:
            log_checkpoint(f"API RESPONSE ERROR: {agent_name}", "Empty content")
            return {"error": "Empty response"}
        
        # Log a snippet of the raw response
        log_checkpoint(f"API RESPONSE RAW: {agent_name}", f"Length: {len(content)}. Snippet: {str(content)[:500]}...")

        extracted = {"text": "", "tables": [], "charts": [], "sql_generated": None, "sql_explanation": None, "is_verified": False, "debug_trace": []}
        
        # Only parse if content exists
        parsed = json.loads(content)
        
        def process_event(evt, data):
            if evt == 'response.text.delta': extracted["text"] += data.get('text', '')
            elif evt == 'response.chart': extracted["charts"].append(data.get('chart') or data.get('chart_spec'))
            elif evt == 'response.table': extracted["tables"].append(data.get('result_set'))
            elif evt == 'response.thinking.delta': extracted["debug_trace"].append(data.get('text', ''))
            elif evt == 'response.tool_result.status':
                # Log the full request payload for debugging
                log_checkpoint(f"TOOL RESULT: {evt}", data)
                # delta = data.get('delta', {})
                # if delta.get('sql'): extracted["sql_generated"] = delta.get('sql')
                # if delta.get('sql_explanation'): extracted["sql_explanation"] = delta.get('sql_explanation')
                # if delta.get('result_set'): extracted["tables"].append(delta.get('result_set'))

        if isinstance(parsed, list):
            for item in parsed: process_event(item.get('event'), item.get('data', {}))
        
        log_checkpoint(f"API RESPONSE EXTRACTED: {agent_name}", {"text_len": len(extracted["text"]), "tables": len(extracted["tables"])})
        return extracted

    except Exception as e:
        log_checkpoint(f"API EXCEPTION: {agent_name}", str(e))
        return {"error": str(e)}

class PayloadFactory:
    @staticmethod
    def create(query: str, instructions: Dict[str, str], tools: List[Dict] = None, resources: Dict = None, history: List[Dict] = None) -> Dict:
        messages = (history if history else []) + [{"role": "user", "content": [{"type": "text", "text": query}]}]
        return {
            "messages": messages,
            "tool_choice": {"type": "auto"},
            "models": {"orchestration": CONFIG.model},
            "instructions": instructions,
            "tools": tools or [],
            "tool_resources": resources or {}
        }

# ==========================================
# 4. AGENT MANAGER
# ==========================================

class AgentManager:
    def __init__(self, session: Session):
        self.session = session

    def run_rephraser(self, query: str, history: List[Dict] = None) -> str:
        log_checkpoint("START: REPHRASER", f"Query: {query}")
        instructions = {
            "system": PROMPT_REPHRASER_SYSTEM,
            "response": "Output ONLY the final rephrased string.",
            "orchestration": PROMPT_REPHRASER_ORCHESTRATION
        }
        payload = PayloadFactory.create(f"Rephrase standalone: {query}", instructions, history=history)
        resp = invoke_cortex_agent(self.session, payload, "Rephraser")
        result = resp.get('text', query).strip() or query
        log_checkpoint("END: REPHRASER", f"Result: {result}")
        return result

    def run_intent_classifier(self, query: str) -> IntentClassification:
        log_checkpoint("START: INTENT CLASSIFIER", f"Query: {query}")
        schema_hint = '{"intent_type": "string", "data_retrieval_query": "string", "root_cause_query": "string", "direct_response": "string", "clarification_question": "string", "confidence": "string", "reasoning": "string"}'
        instructions = {
            "system": PROMPT_INTENT_SYSTEM,
            "response": f"Respond ONLY with a valid JSON matching: {schema_hint}",
            "orchestration": PROMPT_INTENT_ORCHESTRATION
        }
        payload = PayloadFactory.create(f"Classify: {query}", instructions)
        resp = invoke_cortex_agent(self.session, payload, "Intent Classifier")
        try:
            raw = resp.get('text', '')
            # Clean possible markdown format
            clean = raw.replace("```json", "").replace("```", "").strip()
            # Parse logic: parse to dict first to ensure validity, then model validate
            parsed_dict = json.loads(clean)
            result = IntentClassification.model_validate(parsed_dict)
        except Exception as e:
            log_checkpoint("ERROR: INTENT PARSING", str(e))
            result = IntentClassification(intent_type="clarification_needed", confidence="low", reasoning=f"Parse error: {str(e)}")
            
        log_checkpoint("END: INTENT CLASSIFIER", result)
        return result

    def run_data_agent(self, query: str) -> SqlResult:
        log_checkpoint("START: DATA AGENT", f"Query: {query}")
        instructions = {
            "system": PROMPT_DATA_AGENT_SYSTEM,
            "orchestration": PROMPT_DATA_AGENT_ORCHESTRATION,
            "response": "Provide a summary. Tables/Charts are handled automatically."
        }
        tools = [{"tool_spec": {"type": "cortex_analyst_text_to_sql", "name": "analyst_tool"}}]
        resources = {"analyst_tool": {"type": "cortex_analyst_text_to_sql", "semantic_view": CONFIG.cortex_analyst_object, "execution_environment": {"type": "warehouse", "warehouse": CONFIG.warehouse}}}
        
        resp = invoke_cortex_agent(self.session, PayloadFactory.create(query, instructions, tools, resources), "Data Agent")
        result = SqlResult(
            answer_text=resp.get('text', ''),
            tables=resp.get('tables', []),
            charts=resp.get('charts', []),
            sql_generated=resp.get('sql_generated'),
            sql_explanation=resp.get('sql_explanation'),
            is_verified_query=resp.get('is_verified', False),
            reasoning_trace="\n".join(resp.get('debug_trace', []))
        )
        log_checkpoint("END: DATA AGENT", result)
        return result

    def run_root_cause_agent(self, query: str) -> DiagnosticResult:
        log_checkpoint("START: ROOT CAUSE AGENT", f"Query: {query}")
        instructions = {
            "system": PROMPT_ROOT_CAUSE_SYSTEM,
            "orchestration": PROMPT_ROOT_CAUSE_ORCHESTRATION,
            "response": PROMPT_ROOT_CAUSE_RESPONSE
        }
        tools = [{
            "tool_spec": {
                "type": "generic", 
                "name": "Diagnostic_tool", 
                "description": "Retrieves metric status.",
                "input_schema": {
                    "type": "object",
                    "properties": {
                        "USER_QUERY": {"type": "string"},
                        "PARENT_NODE_IDS_JSON": {"type": "string"},
                        "TREE_ID": {"type": "string"}
                    },
                    "required": ["USER_QUERY", "PARENT_NODE_IDS_JSON", "TREE_ID"]
                }
            }
        }]
        resources = {"Diagnostic_tool": {"type": "procedure", "execution_environment": {"type": "warehouse", "warehouse": CONFIG.warehouse}, "identifier": CONFIG.diagnostic_udf}}
        
        resp = invoke_cortex_agent(self.session, PayloadFactory.create(query, instructions, tools, resources), "Root Cause Agent")
        
        raw = resp.get('text', '')
        # Only perform manual extraction if needed
        j_start, j_end = raw.find("```json"), raw.rfind("```")
        
        if j_start != -1 and j_end != -1:
            try:
                json_str = raw[j_start+7:j_end].strip()
                parsed_json = json.loads(json_str)
                result = DiagnosticResult(summary_text=raw[:j_start].strip(), react_flow_json=parsed_json)
            except Exception as e:
                result = DiagnosticResult(summary_text=f"JSON Parse Error: {str(e)}\n{raw}", react_flow_json=None)
        else:
            result = DiagnosticResult(summary_text=raw, react_flow_json=None)

        log_checkpoint("END: ROOT CAUSE AGENT", result)
        return result
        
    def extract_response_text(self, final_output: Dict) -> str:
        """
        Parses the complex final_output dictionary to create a clean text summary 
        for storage in the Messages table.
        """
        lines = []
        
        # Check for direct responses (Greetings, etc.)
        for res in final_output.get("results", []):
            if res.get("type") == "direct_response":
                lines.append(res.get("message"))
                
            elif res.get("type") == "data_analysis":
                lines.append(" **Data Analysis:**")
                lines.append(res.get("summary"))
                if res.get("metadata", {}).get("sql"):
                    lines.append(f"\n*(Generated SQL used for analysis)*")
                    
            elif res.get("type") == "root_cause_analysis":
                lines.append(" **Root Cause Diagnosis:**")
                lines.append(res.get("summary"))
                
            elif "error" in res.get("type", ""):
                lines.append(f" Error: {res.get('message')}")
    
        # Fallback if empty
        if not lines:
            return "Processed request successfully, but no text summary was generated."
            
        return "\n\n".join(lines)

# ==========================================
# HISTORY MANAGEMENT FUNCTIONS (UPDATED)
# ==========================================

def save_message(session: Session, conversation_id: str, sender_type: str, message_text: str, metadata: dict = None):
    """
    Saves a message to the table. Handles NoneType inputs safely.
    """
    try:
        # FIX: Handle None input safely
        if message_text is None:
            message_text = ""
        else:
            message_text = str(message_text) # Ensure it is a string
            
        # Escape single quotes
        safe_message = message_text.replace("'", "''")
        
        # Handle Metadata
        meta_json = json.dumps(metadata) if metadata else "{}"
        safe_meta = meta_json.replace("'", "''")
        
        created_by = "system_bot" if sender_type == "assistant" else "user_gerish"
        
        # Use SELECT for insertion (fixes the PARSE_JSON error)
        sql = f"""
        INSERT INTO {CONFIG.messages_table} 
        (CONVERSATION_ID, SENDER_TYPE, MESSAGE, METADATA, CREATED_BY, UPDATED_BY)
        SELECT 
            '{conversation_id}', 
            '{sender_type}', 
            '{safe_message}', 
            PARSE_JSON('{safe_meta}'), 
            '{created_by}', 
            '{created_by}'
        """
        session.sql(sql).collect()
        
    except Exception as e:
        print(f"Error saving message: {str(e)}")
        
def get_chat_history(session: Session, conversation_id: str) -> List[Dict]:
    """
    Retrieves history using new columns (SENDER_TYPE, MESSAGE) and maps to Cortex format.
    """
    try:
        # Fetch last 10 messages for context
        sql = f"""
        SELECT SENDER_TYPE, MESSAGE 
        FROM {CONFIG.messages_table}
        WHERE CONVERSATION_ID = '{conversation_id}'
        ORDER BY CREATED_AT ASC
        LIMIT 10
        """
        rows = session.sql(sql).collect()
        
        formatted_history = []
        for row in rows:
            # Map database columns to Cortex API requirements
            # Database 'sender_type' -> Cortex 'role'
            # Database 'message' -> Cortex 'content' text
            role = row['SENDER_TYPE']
            content = row['MESSAGE']
            
            formatted_history.append({
                "role": role,
                "content": [{"type": "text", "text": content}]
            })
            
        return formatted_history
    except Exception as e:
        print(f"Error fetching history: {str(e)}")
        return []

# ==========================================
# 5. MAIN EXECUTION
# ==========================================

def main(session: Session):
    manager = AgentManager(session)
    
    # 1. SETUP SESSION
    # In a real app, pass this ID from your API/Frontend
    #conversation_id = "SESSION_TEST_ARIZONA_001" 
    conversation_id="SESSION_REPHRASE_TEST_001"
    # 2. USER QUERY
    # user_query = "show ME all the health care providers in arizona and Why is the Total Market Volume being driven by the Opioid Category?"
    user_query="Why is it performing poorly there compared to last quarter?"
    # 3. GET HISTORY (for context)
    history = get_chat_history(session, conversation_id)
    log_checkpoint("MAIN: START", {"query": user_query, "history_depth": len(history)})

    # ---------------------------------------------------------
    # STEP A: SAVE USER MESSAGE
    # ---------------------------------------------------------
    save_message(
        session, 
        conversation_id, 
        "user", 
        user_query, 
        metadata={"client": "snowflake_ui", "intent_check": "pending"}
    )

    # 4. GUARDRAILS
    guard = check_input_guard(session, user_query)
    
    if not guard.is_safe:
        # FIX: Provide a default string if guard.message is somehow still None
        block_msg = guard.message if guard.message else "Request blocked by safety filters."
        
        save_message(session, conversation_id, "assistant", block_msg, {"blocked": True})
        return {"status": "blocked", "message": block_msg}
        
    # 5. REPHRASE & CLASSIFY
    rephrased = manager.run_rephraser(user_query, history)
    intent = manager.run_intent_classifier(rephrased)

    final = {
        "original": user_query, 
        "processed": rephrased, 
        "intent": intent.model_dump(), 
        "results": []
    }

    # 6. ROUTING & EXECUTION
    if intent.direct_response:
        final["results"].append({"type": "direct_response", "message": intent.direct_response})
    else:
        # Parallel Execution for Combined Intents
        with ThreadPoolExecutor(max_workers=2) as executor:
            fut_data = None
            fut_rc = None
            
            if intent.data_retrieval_query:
                fut_data = executor.submit(manager.run_data_agent, intent.data_retrieval_query)
            
            if intent.root_cause_query:
                fut_rc = executor.submit(manager.run_root_cause_agent, intent.root_cause_query)
            
            # Collect Data Results
            if fut_data:
                try:
                    res = fut_data.result()
                    final["results"].append({
                        "type": "data_analysis", 
                        "summary": res.answer_text, 
                        "tables": res.tables, 
                        "charts": res.charts,
                        "metadata": {"sql": res.sql_generated}
                    })
                except Exception as e: 
                    final["results"].append({"type": "data_error", "message": str(e)})

            # Collect Root Cause Results
            if fut_rc:
                try:
                    res = fut_rc.result()
                    final["results"].append({
                        "type": "root_cause_analysis", 
                        "summary": res.summary_text, 
                        "graph": res.react_flow_json
                    })
                except Exception as e: 
                    final["results"].append({"type": "root_cause_error", "message": str(e)})

    # ---------------------------------------------------------
    # STEP B: SAVE AGENT OUTPUT
    # ---------------------------------------------------------
    # Convert the rich JSON response into a text string for the DB
    final_text_response = manager.extract_response_text(final)
    
    # Create metadata to track performance/classification
    response_metadata = {
        "model": CONFIG.model,
        "intent": intent.intent_type,
        "confidence": intent.confidence,
        "has_sql": any(r.get("type") == "data_analysis" for r in final["results"]),
        "has_graph": any(r.get("type") == "root_cause_analysis" for r in final["results"])
    }

    save_message(
        session, 
        conversation_id, 
        "assistant", 
        final_text_response, 
        metadata=response_metadata
    )

    log_checkpoint("MAIN: COMPLETED", final)
    return final


PROMPT_REPHRASER_SYSTEM = "You are a sophisticated Query Refinement Engine."

PROMPT_REPHRASER_ORCHESTRATION = """
<query_refinement_instructions>
<objective>
Transform the user's input into a standalone, context-complete query that can be understood without prior conversation history.
</objective>

<core_rules>
<rule id="1">Resolve all pronouns (it, they, that, this, those) to their specific referents</rule>
<rule id="2">Preserve ALL metrics, entity names, IDs, and numerical values EXACTLY as stated</rule>
<rule id="3">Maintain the original intent and scope - do not expand or narrow the question</rule>
<rule id="4">Keep technical terminology and domain-specific language intact</rule>
<rule id="5">Ensure the output is grammatically correct and reads naturally</rule>
</core_rules>

<transformation_examples>
<example>
<input>What about Arizona?</input>
<context>Previous discussion about sales performance in Texas</context>
<output>What is the sales performance in Arizona?</output>
</example>

<example>
<input>Why is it down?</input>
<context>Previous mention of Q4 revenue</context>
<output>Why is Q4 revenue down?</output>
</example>

<example>
<input>Show me those providers and explain the trend.</input>
<context>Healthcare providers in California with declining prescriptions</context>
<output>Show me healthcare providers in California with declining prescriptions and explain the trend.</output>
</example>
</transformation_examples>

<output_format>
Output ONLY the refined query string. Do not include explanations, metadata, or formatting.
</output_format>
</query_refinement_instructions>
"""

PROMPT_INTENT_SYSTEM = "You are an Expert Intent Classification System."

PROMPT_INTENT_ORCHESTRATION = """
<intent_classification_instructions>

<mission>
Your ONLY job is to identify the user's INTENT. Do NOT retrieve data, do NOT answer questions, do NOT perform analysis.
Classify the intent type and route accordingly. If you can answer directly (like greetings), provide direct_response.
</mission>

<intent_categories>

<intent name="greeting">
<description>User is greeting, saying hello, or engaging in pleasantries</description>
<indicators>hi, hello, hey, good morning, how are you, thanks, thank you, goodbye, bye</indicators>
<action>Set direct_response with a friendly greeting. No other fields needed.</action>
</intent>

<intent name="data_retrieval">
<description>User wants to see/get/retrieve DATA - numbers, lists, metrics, tables</description>
<indicators>show, list, get, display, find, what is the value, how many, count, total, give me</indicators>
<action>Extract the data request to data_retrieval_query. Keep as natural language. Add "and generate a table and a visual".</action>
**CRITICAL VISUALIZATION LOGIC:**
Analyze the data request. If it implies trends (over time), comparisons (by region/product), or distributions, you MUST automatically append "and generate a table and a visual" to the query string, even if the user did not explicitly ask for a chart.
</intent>

<intent name="root_cause_analysis">
<description>User wants to understand WHY, CAUSES, DRIVERS, REASONS, EXPLANATIONS</description>
<indicators>why, explain, what is driving, what is causing, what's behind, reason for, root cause, how come, what factors</indicators>
<action>Extract the causal question to root_cause_query. Keep VERBATIM - exact text from user.</action>
</intent>

<intent name="combined">
<description>User wants BOTH data AND causal analysis in one request</description>
<indicators>Contains both data keywords AND causal keywords</indicators>
<action>Split into data_retrieval_query AND root_cause_query. Keep both portions.</action>
</intent>

<intent name="clarification_needed">
<description>User's intent is unclear, vague, or ambiguous - you cannot determine what they want</description>
<indicators>Very short/vague input, unclear pronouns without context, incomplete thoughts</indicators>
<action>Set clarification_question asking user to be more specific.</action>
</intent>

<intent name="general_question">
<description>General questions about the system, capabilities, how to use features - not data or analysis requests</description>
<indicators>how do I, can you, what can you do, help me understand, how does this work</indicators>
<action>Set direct_response with helpful information about capabilities.</action>
</intent>

<intent name="off_topic">
<description>User is asking about unrelated topics not connected to data, analytics, or business questions</description>
<indicators>Questions about weather, sports, entertainment, personal topics unrelated to business/data</indicators>
<action>Set direct_response politely redirecting to business/data topics.</action>
</intent>

</intent_categories>

<CRITICAL_CLASSIFICATION_RULES>

 RULE 1: NEVER DO THE WORK - ONLY CLASSIFY
You are NOT a data analyst. You are NOT an answering agent. You ONLY identify intent type.
Do NOT retrieve data. Do NOT answer analytical questions. ONLY classify and route.

 RULE 2: CAUSAL KEYWORD DETECTION
These ALWAYS indicate root_cause_analysis intent:
- "what is driving"
- "what is causing"
- "what's driving"  
- "what's causing"
- "why is/are"
- "explain why"
- "reason for"
- "root cause"
- "what factors"
- "what's behind"
- "how come"

 RULE 3: DATA KEYWORD DETECTION  
These ALWAYS indicate data_retrieval intent:
- "show me"
- "list"
- "get"
- "display"
- "find all"
- "what is the value/total/count of"
- "how many"

 RULE 4: DIRECT RESPONSE ONLY FOR SIMPLE CASES
Use direct_response ONLY for:
- Greetings (hi, hello, thanks)
- General system questions (what can you do)
- Off-topic redirects

Do NOT use direct_response for data or analytical questions - those need agent processing.

 RULE 5: VERBATIM PRESERVATION FOR ROOT CAUSE
For root_cause_query: Copy EXACT text from user. No paraphrasing, no summarizing.

 RULE 6: NO SQL CODE GENERATION
NEVER write SELECT/FROM/WHERE statements. Keep everything as natural language.

 RULE 7: CONFIDENCE SCORING
- high: Intent is crystal clear
- medium: Intent is likely but has some ambiguity
- low: Intent is very unclear, might need clarification

</CRITICAL_CLASSIFICATION_RULES>

<classification_process>
<step number="1">Check if greeting or general question. If match, Set intent_type and direct_response, STOP</step>
<step number="2">Check for causal keywords. If found, Flag as root_cause_analysis or combined</step>
<step number="3">Check for data keywords. If found, Flag as data_retrieval or combined</step>
<step number="4">Determine if combined intent. If both, Set intent_type="combined".</step>
<step number="5">If none of the above match, check if intent is clear enough.</step>
</classification_process>

<comprehensive_examples>
<example>
<input>Hello!</input>
<output>
{
  "intent_type": "greeting",
  "data_retrieval_query": null,
  "root_cause_query": null,
  "direct_response": "Hello! How can I help you today?",
  "clarification_question": null,
  "confidence": "high",
  "reasoning": "Simple greeting - can respond directly without agent processing"
}
</output>
</example>

<example>
<input>Show me total sales for Q4.</input>
<output>
{
  "intent_type": "data_retrieval",
  "data_retrieval_query": "Show me total sales for Q4 and generate a table and a visual",
  "root_cause_query": null,
  "direct_response": null,
  "clarification_question": null,
  "confidence": "high",
  "reasoning": "Clear data retrieval request - 'show me' is data keyword, asking for metric value"
}
</output>
</example>

<example>
<input>Why is profit down?</input>
<output>
{
  "intent_type": "root_cause_analysis",
  "data_retrieval_query": null,
  "root_cause_query": "Why is profit down?",
  "direct_response": null,
  "clarification_question": null,
  "confidence": "high",
  "reasoning": "Pure causal question - 'why' keyword indicates root cause analysis needed"
}
</output>
</example>

<example>
<input>Get revenue for AZ and explain the dip.</input>
<output>
{
  "intent_type": "combined",
  "data_retrieval_query": "Get revenue for AZ and generate a table and a visual",
  "root_cause_query": "explain the dip",
  "direct_response": null,
  "clarification_question": null,
  "confidence": "high",
  "reasoning": "Combined intent - 'get revenue' is data retrieval, 'explain the dip' is causal analysis"
}
</output>
</example>

<example>
<input>What can you help me with?</input>
<output>
{
  "intent_type": "general_question",
  "data_retrieval_query": null,
  "root_cause_query": null,
  "direct_response": "I can help you with data analysis and business insights! I can retrieve data and perform root cause analysis. What would you like to explore?",
  "clarification_question": null,
  "confidence": "high",
  "reasoning": "General system capability question - can answer directly"
}
</output>
</example>

<example>
<input>Show that</input>
<output>
{
  "intent_type": "clarification_needed",
  "data_retrieval_query": null,
  "root_cause_query": null,
  "direct_response": null,
  "clarification_question": "What would you like me to show? Please provide more details about the data or metrics you're interested in.",
  "confidence": "low",
  "reasoning": "Vague request - unclear what user wants to see, needs clarification"
}
</output>
</example>

<example>
<input>What's the weather like?</input>
<output>
{
  "intent_type": "off_topic",
  "data_retrieval_query": null,
  "root_cause_query": null,
  "direct_response": "I'm designed to help with business data and analytics. Is there any sales, performance, or business data I can help you with?",
  "clarification_question": null,
  "confidence": "high",
  "reasoning": "Off-topic request - politely redirect to business/data topics"
}
</output>
</example>
</comprehensive_examples>

<validation_checklist>
 Step 1: Can I answer this directly? (greeting/general_question/off_topic)
 Step 2: Does it contain causal keywords? (why/driving/causing/explain/reason/factors/behind)
 Step 3: Does it contain data keywords? (show/list/get/display/what is the value/how many)
 Step 4: Does it have BOTH data and causal elements?
 Step 5: Did I preserve EXACT wording for root_cause_query?
 Step 6: Did I add "and generate a table and a visual" to data_retrieval_query?
 Step 7: Did I avoid doing the actual work? (I only classify, not retrieve/analyze)
 Step 8: Is my confidence level accurate?
</validation_checklist>
</intent_classification_instructions>
"""

PROMPT_DATA_AGENT_SYSTEM = "You are an expert Data Analyst."

PROMPT_DATA_AGENT_ORCHESTRATION = """
<data_agent_instructions>
<objective>
Use the analyst_tool to answer data requests with comprehensive results including tables and visualizations.
</objective>
<execution_rules>
<rule id="1">ALWAYS generate a table (Result Set) for data requests</rule>
<rule id="2">Generate appropriate visualizations when data is suitable for charts</rule>
<rule id="3">Provide clear, concise summaries of the data findings</rule>
<rule id="4">Handle errors gracefully and explain any data limitations</rule>
</execution_rules>

<self_evaluation_instructions>
After generating the response, you must evaluate the quality of your answer and the generated SQL.
At the very end of your response, append a section formatted exactly like this:

### SELF-EVALUATION
Score: [1-10]
Reasoning: [One sentence explaining why]

Scoring Guide:
- 10: Perfect query, complete data returned, verified query used.
- 8-9: Correct query generated, reasonable data, but unverified.
- 5-7: Partial data found, or some ambiguity in the query interpretation.
- 1-4: Failed to generate SQL, empty results, or irrelevant data.
</self_evaluation_instructions>

<output_format>
Provide a summary of findings. Tables and charts are handled automatically by the tool.
</output_format>
</data_agent_instructions>
"""

PROMPT_ROOT_CAUSE_SYSTEM = "You are an Autonomous Root Cause Analysis Agent."

PROMPT_ROOT_CAUSE_ORCHESTRATION = """
<root_cause_orchestration_prompt>
    <role_and_objective>
        You are an **Autonomous Root Cause Analysis Agent** designed to traverse a metric decision tree from the root node down to the leaf nodes. Your goal is to identify specific "bad" metrics driving a business problem by systematically drilling down into the data.
        
        ALWAYS USE tree_id as Pharma_Master_v1.
    </role_and_objective>

    <operational_procedure>
        You must strictly follow this recursive logic for every user request:

        **Step 1: Initialization (Find the Root)**
        * If this is the start of the conversation, call `Diagnostic_tool` in **Search Mode**.
        * **Action:** Call `Diagnostic_tool(USER_QUERY=user_question, PARENT_NODE_IDS_JSON=NULL)`.
        * **Next:** Proceed to Step 2 with the results.

        **Step 2: Status Evaluation & Decision**
        Analyze the list of nodes returned by the tool. Focus **only** on nodes where `"status": "bad"`.

        * **Check:** For every "bad" node, do you see its children in the current list?
        * **Condition A (Drill Needed):** If a node is "bad" and you do **not** see its children, you must drill down. Collect these Node IDs.
        * **Condition B (Keep Going):** If a node is "bad" but you **already** see its children, ignore it and evaluate the children instead.
        * **Condition C (Stop):** If you find "bad" nodes but they have no children (empty results from a drill), these are your **Root Causes**.

        **Step 3: Execution (Drill Down)**
        * If Condition A occurred: Call `Diagnostic_tool` in **Drill Mode**.
        * **Action:** Call `Diagnostic_tool(USER_QUERY=NULL, PARENT_NODE_IDS_JSON='["ID_1", "ID_2"]')`.
        * **Next:** Recursively repeat Step 2 with the new output.
        * If Condition C occurred: Present the final root causes to the user.
    </operational_procedure>

    <constraints>
        * **Never** guess the status of a metric; always use the tool.
        * **Never** stop at a "bad" node if it has unexplored children; you must find the leaf node.
        * Output your reasoning briefly before calling the tool.
    </constraints>

    <self_evaluation_instructions>
    Evaluate the success of the diagnosis.
    
    ### SELF-EVALUATION
    Score: [1-10]
    Reasoning: [One sentence explaining why]

    Scoring Guide:
    - 10: Successfully identified a Leaf Node Root Cause (lowest level "bad" metric).
    - 8-9: Identified a "bad" branch but hit data limits or minor ambiguity.
    - 5-7: Found a high-level "bad" metric but could not explain the drivers (children were "good").
    - 1-4: No "bad" metrics found, or tool errors prevented analysis.
    </self_evaluation_instructions>
</root_cause_orchestration_prompt>
"""

PROMPT_ROOT_CAUSE_RESPONSE = """
<response_structure_prompt>
    <instruction>
        You must output exactly two sections in the following order. Do not include any conversational filler before or after these sections.
    </instruction>

    <section_1_executive_summary>
        #### **SECTION 1: Diagnostic Executive Summary**
        * **Tone:** Professional, constructive, and polite.
        * **Headline:** State the Root Cause clearly.
        * **The Narrative:** Briefly explain the chain of events in simple English.
        * **Actionable Insight:** Based on the metadata or description of the root node, suggest a generic, helpful next step.
        
        ### SELF-EVALUATION
        Score: [1-10]
        Reasoning: [Explanation]
    </section_1_executive_summary>

    <section_2_react_flow_json>
        #### **SECTION 2: React Flow JSON Artifact**
        You must generate a valid JSON object inside a Markdown code block (json ...).
        
        **1. Coordinate Logic (The "Mental Layout"):**
        * **Level 0 (Root):** `x: 0, y: 0`
        * **Level 1 Children:** `y: 150`. Spread `x` widely (e.g., `-300` and `300`).
        * **Level 2 Grandchildren:** `y: 300`. Spread `x` relative to their parent.
        * **Level 3+:** Increase `y` by `150` for each level.

        **2. Visual Style Logic:**
        * **Red (#FFE2E5):** Status is "bad", "high", or "error".
        * **Green (#CDE8E6):** Status is "good", "normal", or "stable".
        * **Orange (#FFCCBC):** The **Root Cause** (the deepest "bad" node in the chain).
        * **White (#FFFFFF):** Unexplored or neutral nodes.

        **3. Edge Labeling Logic:**
        * If Parent is Bad and Child is Bad, label = "contributes to impact".
        * If Parent is Bad and Child is Good, label = "stable factor".

        **4. JSON Schema (Must Follow Exactly):**
        {
          "nodes": [
            {
              "id": "N0",
              "type": "default",
              "data": { "label": "Metric Name: Value" },
              "position": { "x": 0, "y": 0 },
              "style": { "background": "#FFE2E5", "width": 180, "color": "#333", "border": "1px solid #777", "borderRadius": "8px" }
            }
          ],
          "edges": [
            {
              "id": "e-N0-N1",
              "source": "N0",
              "target": "N1",
              "label": "driven by",
              "animated": true,
              "style": { "stroke": "#555", "strokeWidth": 2 }
            }
          ]
        }
    </section_2_react_flow_json>
</response_structure_prompt>
"""
Skip to main content
Skip to editor
Skip to results
Site





Worksheets
Selection deleted
497
498
499
500
501
502
503
504
505
506
507
508
509
510
511
512
513
514
515
516
517
518
519
520
521
522
523
524
525
526
527
528
529
530
531
532
533
534
535
536
537
538
539
540
541
542
543
544
545
546
547
548
549
550
551
552
553
554
555
556
557
558
559
560
561
562
563
564
565
566
567
568
569
570
571
572
573
574
575
576
577
578
579
580
581
582
583
584
        }
    </section_2_react_flow_json>
</response_structure_prompt>
"""

# ==========================================
# 3. HELPER FUNCTIONS (API WRAPPERS)
# ==========================================

def log_checkpoint(step: str, details: Any):
    print(f"\n{'='*50}\n CHECKPOINT: {step}\n{'-'*50}")
    if isinstance(details, BaseModel):
        pprint.pprint(details.model_dump())
    elif isinstance(details, (dict, list)):
        pprint.pprint(details)
    else:
        print(str(details))
    print(f"{'='*50}\n")

def invoke_structured_output_extraction(session: Session, messages: List[Dict], pydantic_model: type[BaseModel]) -> BaseModel:
    """
    Invokes Cortex Inference using the Pydantic model to generate the JSON schema.
    Returns an instance of the Pydantic model.
    """
    ENDPOINT = "/api/v2/cortex/inference:complete"
    
    # Generate JSON Schema directly from Pydantic
    json_schema = pydantic_model.model_json_schema()
    
    # Cleanup schema (optional: remove titles to save tokens)
    if 'title' in json_schema: del json_schema['title']

    payload = {
        "model": CONFIG.model,
        "messages": messages,
        "max_tokens": 2000,
        "response_format": {
            "type": "json",
            "schema": json_schema
        }
    }

    log_checkpoint("API REQUEST (STRUCTURED)", f"Target Model: {pydantic_model.__name__}")

    try:
        resp = _snowflake.send_snow_api_request("POST", ENDPOINT, {"Content-Type": "application/json"}, {}, payload, {}, 120000)
        print(resp)
        content_str = resp.get("choices", [{}])[0].get("message", {}).get("content")
        
        if not content_str:
            raise ValueError("Empty response from Cortex")

        # Parse JSON and validate with Pydantic
        parsed_dict = json.loads(content_str)
        return pydantic_model(**parsed_dict)
        
    except Exception as e:
        print(f"Structured Extraction Error: {e}")
        # Return empty/default instance on failure to prevent crash
        return pydantic_model.construct()

def invoke_cortex_agent(session: Session, payload: Dict, agent_name: str) -> Dict:
    """Invokes 'agent:run' for tools (Analyst/Diagnostic) with 5-row limit."""
    ENDPOINT = "/api/v2/cortex/agent:run"
    print(f"--- INVOKING AGENT: {agent_name} ---")

    try:
        resp = _snowflake.send_snow_api_request("POST", ENDPOINT, {"Content-Type": "application/json", "Accept": "text/event-stream"}, {}, payload, {}, 120000)
        content = resp.get("content")
        if not content: return {"error": "Empty"}
        
        extracted = {"text": "", "tables": [], "charts": [], "sql_generated": None, "sql_explanation": None}
        try: parsed = json.loads(content)
        except: parsed = [json.loads(line) for line in content.splitlines() if line.strip()]
        
        def process_event(evt, data):
            if evt == 'response.text.delta': extracted["text"] += data.get('text', '')
            elif evt == 'response.chart': extracted["charts"].append(data.get('chart') or data.get('chart_spec'))
            elif evt == 'response.table':
                rs = data.get('result_set', [])
                extracted["tables"].append(rs[:5]) # Limit 5 rows
            elif evt == 'response.tool_result.analyst.delta':
                delta = data.get('delta', {})
                if delta.get('sql'): extracted["sql_generated"] = delta.get('sql')
                if delta.get('sql_explanation'): extracted["sql_explanation"] = delta.get('sql_explanation')
                if delta.get('result_set'): extracted["tables"].append(delta.get('result_set')[:5])
            elif evt == 'response.tool_result':
                for item in data.get('content', []):
==================================================
 CHECKPOINT: MAIN: START
--------------------------------------------------
{'query': 'show ME all the health care providers in arizona and Why is the '
          'Total Market Volume being driven by the Opioid Category?'}
==================================================
==================================================
 CHECKPOINT: START: GUARD
--------------------------------------------------
show ME all the health care providers in arizona and Why is the Total Market Volume being driven by the Opioid Category?
==================================================
==================================================
 CHECKPOINT: API REQUEST (STRUCTURED)
--------------------------------------------------
Target Model: RephraserOutput
==================================================
{'status': 500, 'content': '{\n\t"code":\t"300014",\n\t"message":\t"Cannot deserialize value of type `java.lang.String` from Array value (token `JsonToken.START_ARRAY`)\n at [Source: (org.eclipse.jetty.server.HttpInputOverHTTP); line: 1, column: 73] (through reference chain: com.snowflake.snowapi.cortexinference.model.CompleteRequest[\"messages\"]->java.util.ArrayList[0]->com.snowflake.snowapi.cortexinference.model.CompleteRequestMessagesInner[\"content\"])",\n\t"request_id":\t"0fb6c8b0-1e44-4f10-8ad4-3cccc3cf4dc5",\n\t"error_code":\t"300014"\n}', 'headers': {'\nX-Snowflake-Request-ID': '0fb6c8b0-1e44-4f10-8ad4-3cccc3cf4dc5', '\nContent-Type': 'application/json', '\nDate': 'Mon, 19 Jan 2026 14:03:49 GMT', '\nContent-Length': '497'}}
Structured Extraction Error: Empty response from Cortex

Skip to main content
Skip to editor
Skip to results
Site





Worksheets
Selection deleted
516
517
518
519
520
521
522
523
524
525
526
527
528
529
530
531
532
533
534
535
536
537
538
539
540
541
542
543
544
545
546
547
548
549
550
551
552
553
554
555
556
557
558
559
560
561
562
563
564
565
566
567
568
569
570
571
572
573
574
575
576
577
578
579
580
581
582
583
584
585
586
587
588
589
590
591
592
593
594
595
596
597
598
599
600
601
602
603
604
605
606
607
608
609
610
611
612
613
614
615
616
617
618
619
620
621
622
623
624
625
626
627
628
629
630
631
632
def invoke_structured_output_extraction(session: Session, messages: List[Dict], pydantic_model: type[BaseModel]) -> BaseModel:
    """
    Invokes Cortex Inference using the Pydantic model to generate the JSON schema.
    Returns an instance of the Pydantic model.
    """
    ENDPOINT = "/api/v2/cortex/inference:complete"
    
    # Generate JSON Schema directly from Pydantic
    json_schema = pydantic_model.model_json_schema()
    if 'title' in json_schema: del json_schema['title']

    # --- FIX: SANITIZE MESSAGES ---
    # The inference endpoint requires 'content' to be a STRING, not a LIST.
    # We must convert the [{"type": "text", "text": "..."}] format used by Agents 
    # into a simple string for the Inference API.
    sanitized_messages = []
    for msg in messages:
        content = msg.get("content")
        if isinstance(content, list):
            # Extract text from the list structure
            flat_text = " ".join([item.get("text", "") for item in content if item.get("type") == "text"])
            sanitized_messages.append({"role": msg["role"], "content": flat_text})
        else:
            # It's already a string, keep as is
            sanitized_messages.append(msg)
    # ------------------------------

    payload = {
        "model": CONFIG.model,
        "messages": sanitized_messages, # <--- Use the sanitized list
        "max_tokens": 2000,
        "response_format": {
            "type": "json",
            "schema": json_schema
        }
    }

    log_checkpoint("API REQUEST (STRUCTURED)", f"Target Model: {pydantic_model.__name__}")

    try:
        resp = _snowflake.send_snow_api_request("POST", ENDPOINT, {"Content-Type": "application/json"}, {}, payload, {}, 120000)
        
        # Check for HTTP errors in the response dict if _snowflake doesn't raise exception
        if resp.get('status') and resp.get('status') >= 400:
             print(f"API Error Response: {resp}")
             return pydantic_model.construct()

        content_str = resp.get("choices", [{}])[0].get("message", {}).get("content")
        
        if not content_str:
            print(f"Empty content from Cortex. Raw Response: {resp}")
            return pydantic_model.construct()

        # Parse JSON and validate with Pydantic
        parsed_dict = json.loads(content_str)
        return pydantic_model(**parsed_dict)
        
    except Exception as e:
        print(f"Structured Extraction Error: {e}")
        return pydantic_model.construct()

def invoke_cortex_agent(session: Session, payload: Dict, agent_name: str) -> Dict:
    """Invokes 'agent:run' for tools (Analyst/Diagnostic) with 5-row limit."""
    ENDPOINT = "/api/v2/cortex/agent:run"
    print(f"--- INVOKING AGENT: {agent_name} ---")

    try:
        resp = _snowflake.send_snow_api_request("POST", ENDPOINT, {"Content-Type": "application/json", "Accept": "text/event-stream"}, {}, payload, {}, 120000)
        content = resp.get("content")
        if not content: return {"error": "Empty"}
        
        extracted = {"text": "", "tables": [], "charts": [], "sql_generated": None, "sql_explanation": None}
        try: parsed = json.loads(content)
        except: parsed = [json.loads(line) for line in content.splitlines() if line.strip()]
        
        def process_event(evt, data):
            if evt == 'response.text.delta': extracted["text"] += data.get('text', '')
            elif evt == 'response.chart': extracted["charts"].append(data.get('chart') or data.get('chart_spec'))
            elif evt == 'response.table':
                rs = data.get('result_set', [])
                extracted["tables"].append(rs[:5]) # Limit 5 rows
            elif evt == 'response.tool_result.analyst.delta':
                delta = data.get('delta', {})
                if delta.get('sql'): extracted["sql_generated"] = delta.get('sql')
                if delta.get('sql_explanation'): extracted["sql_explanation"] = delta.get('sql_explanation')
                if delta.get('result_set'): extracted["tables"].append(delta.get('result_set')[:5])
            elif evt == 'response.tool_result':
                for item in data.get('content', []):
                    if item.get('type') == 'json':
                        json_p = item.get('json', {})
                        if 'sql' in json_p: extracted["sql_generated"] = json_p['sql']
                        if 'result_set' in json_p: extracted["tables"].append(json_p['result_set'][:5])

        if isinstance(parsed, list):
            for item in parsed: process_event(item.get('event'), item.get('data', {}))
        
        print(f"--- AGENT {agent_name} COMPLETED ---")
        return extracted
    except Exception as e: return {"error": str(e)}

def check_input_guard(session: Session, user_input: str) -> GuardResult:
    log_checkpoint("START: GUARD", user_input)
    try:
        safe_input = user_input.replace("'", "''")
        res = session.sql(f"SELECT SNOWFLAKE.CORTEX.COMPLETE('{CONFIG.model}', [{{'role': 'user', 'content': '{safe_input}'}}], {{'guardrails': true}}) as r").collect()
        if not res: return GuardResult(is_safe=True)
        is_unsafe = "Response filtered" in json.loads(res[0]['R'])['choices'][0]['messages']
        return GuardResult(is_safe=not is_unsafe, message="Blocked." if is_unsafe else None)
    except: return GuardResult(is_safe=True)

class PayloadFactory:
    @staticmethod
    def create(query: str, instructions: Dict, tools: List = None, resources: Dict = None, history: List = None) -> Dict:
        messages = (history if history else []) + [{"role": "user", "content": [{"type": "text", "text": query}]}]
        return {"messages": messages, "tool_choice": {"type": "auto"}, "models": {"orchestration": CONFIG.model}, "instructions": instructions, "tools": tools or [], "tool_resources": resources or {}}

def save_message(session: Session, conversation_id: str, sender_type: str, message_text: str, metadata: dict = None):
==================================================
 CHECKPOINT: MAIN: START
--------------------------------------------------
{'query': 'show ME all the health care providers in arizona and Why is the '
          'Total Market Volume being driven by the Opioid Category?'}
==================================================
==================================================
 CHECKPOINT: START: GUARD
--------------------------------------------------
show ME all the health care providers in arizona and Why is the Total Market Volume being driven by the Opioid Category?
==================================================
==================================================
 CHECKPOINT: API REQUEST (STRUCTURED)
--------------------------------------------------
Target Model: RephraserOutput
==================================================
Empty content from Cortex. Raw Response: {'status': 200, 'content': '[{\n\t\t"data":\t{\n\t\t\t"id":\t"25c652c6-a999-4916-b6b8-ae7b8186327b",\n\t\t\t"model":\t"claude-3-5-sonnet",\n\t\t\t"choices":\t[{\n\t\t\t\t\t"delta":\t{\n\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t"content_list":\t[{\n\t\t\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t\t\t"text":\t""\n\t\t\t\t\t\t\t}],\n\t\t\t\t\t\t"text":\t""\n\t\t\t\t\t}\n\t\t\t\t}],\n\t\t\t"usage":\t{\n\t\t\t}\n\t\t}\n\t}, {\n\t\t"data":\t{\n\t\t\t"id":\t"25c652c6-a999-4916-b6b8-ae7b8186327b",\n\t\t\t"model":\t"claude-3-5-sonnet",\n\t\t\t"choices":\t[{\n\t\t\t\t\t"delta":\t{\n\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t"content_list":\t[{\n\t\t\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t\t\t"text":\t""\n\t\t\t\t\t\t\t}],\n\t\t\t\t\t\t"text":\t""\n\t\t\t\t\t}\n\t\t\t\t}],\n\t\t\t"usage":\t{\n\t\t\t}\n\t\t}\n\t}, {\n\t\t"data":\t{\n\t\t\t"id":\t"25c652c6-a999-4916-b6b8-ae7b8186327b",\n\t\t\t"model":\t"claude-3-5-sonnet",\n\t\t\t"choices":\t[{\n\t\t\t\t\t"delta":\t{\n\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t"content":\t"{\"refi",\n\t\t\t\t\t\t"content_list":\t[{\n\t\t\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t\t\t"text":\t"{\"refi"\n\t\t\t\t\t\t\t}],\n\t\t\t\t\t\t"text":\t"{\"refi"\n\t\t\t\t\t}\n\t\t\t\t}],\n\t\t\t"usage":\t{\n\t\t\t}\n\t\t}\n\t}, {\n\t\t"data":\t{\n\t\t\t"id":\t"25c652c6-a999-4916-b6b8-ae7b8186327b",\n\t\t\t"model":\t"claude-3-5-sonnet",\n\t\t\t"choices":\t[{\n\t\t\t\t\t"delta":\t{\n\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t"content":\t"ned",\n\t\t\t\t\t\t"content_list":\t[{\n\t\t\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t\t\t"text":\t"ned"\n\t\t\t\t\t\t\t}],\n\t\t\t\t\t\t"text":\t"ned"\n\t\t\t\t\t}\n\t\t\t\t}],\n\t\t\t"usage":\t{\n\t\t\t}\n\t\t}\n\t}, {\n\t\t"data":\t{\n\t\t\t"id":\t"25c652c6-a999-4916-b6b8-ae7b8186327b",\n\t\t\t"model":\t"claude-3-5-sonnet",\n\t\t\t"choices":\t[{\n\t\t\t\t\t"delta":\t{\n\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t"content":\t"_query",\n\t\t\t\t\t\t"content_list":\t[{\n\t\t\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t\t\t"text":\t"_query"\n\t\t\t\t\t\t\t}],\n\t\t\t\t\t\t"text":\t"_query"\n\t\t\t\t\t}\n\t\t\t\t}],\n\t\t\t"usage":\t{\n\t\t\t}\n\t\t}\n\t}, {\n\t\t"data":\t{\n\t\t\t"id":\t"25c652c6-a999-4916-b6b8-ae7b8186327b",\n\t\t\t"model":\t"claude-3-5-sonnet",\n\t\t\t"choices":\t[{\n\t\t\t\t\t"delta":\t{\n\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t"content":\t"\": \"Ple",\n\t\t\t\t\t\t"content_list":\t[{\n\t\t\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t\t\t"text":\t"\": \"Ple"\n\t\t\t\t\t\t\t}],\n\t\t\t\t\t\t"text":\t"\": \"Ple"\n\t\t\t\t\t}\n\t\t\t\t}],\n\t\t\t"usage":\t{\n\t\t\t}\n\t\t}\n\t}, {\n\t\t"data":\t{\n\t\t\t"id":\t"25c652c6-a999-4916-b6b8-ae7b8186327b",\n\t\t\t"model":\t"claude-3-5-sonnet",\n\t\t\t"choices":\t[{\n\t\t\t\t\t"delta":\t{\n\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t"content":\t"ase sho",\n\t\t\t\t\t\t"content_list":\t[{\n\t\t\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t\t\t"text":\t"ase sho"\n\t\t\t\t\t\t\t}],\n\t\t\t\t\t\t"text":\t"ase sho"\n\t\t\t\t\t}\n\t\t\t\t}],\n\t\t\t"usage":\t{\n\t\t\t}\n\t\t}\n\t}, {\n\t\t"data":\t{\n\t\t\t"id":\t"25c652c6-a999-4916-b6b8-ae7b8186327b",\n\t\t\t"model":\t"claude-3-5-sonnet",\n\t\t\t"choices":\t[{\n\t\t\t\t\t"delta":\t{\n\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t"content":\t"w all h",\n\t\t\t\t\t\t"content_list":\t[{\n\t\t\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t\t\t"text":\t"w all h"\n\t\t\t\t\t\t\t}],\n\t\t\t\t\t\t"text":\t"w all h"\n\t\t\t\t\t}\n\t\t\t\t}],\n\t\t\t"usage":\t{\n\t\t\t}\n\t\t}\n\t}, {\n\t\t"data":\t{\n\t\t\t"id":\t"25c652c6-a999-4916-b6b8-ae7b8186327b",\n\t\t\t"model":\t"claude-3-5-sonnet",\n\t\t\t"choices":\t[{\n\t\t\t\t\t"delta":\t{\n\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t"content":\t"ealt",\n\t\t\t\t\t\t"content_list":\t[{\n\t\t\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t\t\t"text":\t"ealt"\n\t\t\t\t\t\t\t}],\n\t\t\t\t\t\t"text":\t"ealt"\n\t\t\t\t\t}\n\t\t\t\t}],\n\t\t\t"usage":\t{\n\t\t\t}\n\t\t}\n\t}, {\n\t\t"data":\t{\n\t\t\t"id":\t"25c652c6-a999-4916-b6b8-ae7b8186327b",\n\t\t\t"model":\t"claude-3-5-sonnet",\n\t\t\t"choices":\t[{\n\t\t\t\t\t"delta":\t{\n\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t"content":\t"hcare prov",\n\t\t\t\t\t\t"content_list":\t[{\n\t\t\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t\t\t"text":\t"hcare prov"\n\t\t\t\t\t\t\t}],\n\t\t\t\t\t\t"text":\t"hcare prov"\n\t\t\t\t\t}\n\t\t\t\t}],\n\t\t\t"usage":\t{\n\t\t\t}\n\t\t}\n\t}, {\n\t\t"data":\t{\n\t\t\t"id":\t"25c652c6-a999-4916-b6b8-ae7b8186327b",\n\t\t\t"model":\t"claude-3-5-sonnet",\n\t\t\t"choices":\t[{\n\t\t\t\t\t"delta":\t{\n\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t"content":\t"iders loc",\n\t\t\t\t\t\t"content_list":\t[{\n\t\t\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t\t\t"text":\t"iders loc"\n\t\t\t\t\t\t\t}],\n\t\t\t\t\t\t"text":\t"iders loc"\n\t\t\t\t\t}\n\t\t\t\t}],\n\t\t\t"usage":\t{\n\t\t\t}\n\t\t}\n\t}, {\n\t\t"data":\t{\n\t\t\t"id":\t"25c652c6-a999-4916-b6b8-ae7b8186327b",\n\t\t\t"model":\t"claude-3-5-sonnet",\n\t\t\t"choices":\t[{\n\t\t\t\t\t"delta":\t{\n\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t"content":\t"ated in Ar",\n\t\t\t\t\t\t"content_list":\t[{\n\t\t\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t\t\t"text":\t"ated in Ar"\n\t\t\t\t\t\t\t}],\n\t\t\t\t\t\t"text":\t"ated in Ar"\n\t\t\t\t\t}\n\t\t\t\t}],\n\t\t\t"usage":\t{\n\t\t\t}\n\t\t}\n\t}, {\n\t\t"data":\t{\n\t\t\t"id":\t"25c652c6-a999-4916-b6b8-ae7b8186327b",\n\t\t\t"model":\t"claude-3-5-sonnet",\n\t\t\t"choices":\t[{\n\t\t\t\t\t"delta":\t{\n\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t"content":\t"izona ",\n\t\t\t\t\t\t"content_list":\t[{\n\t\t\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t\t\t"text":\t"izona "\n\t\t\t\t\t\t\t}],\n\t\t\t\t\t\t"text":\t"izona "\n\t\t\t\t\t}\n\t\t\t\t}],\n\t\t\t"usage":\t{\n\t\t\t}\n\t\t}\n\t}, {\n\t\t"data":\t{\n\t\t\t"id":\t"25c652c6-a999-4916-b6b8-ae7b8186327b",\n\t\t\t"model":\t"claude-3-5-sonnet",\n\t\t\t"choices":\t[{\n\t\t\t\t\t"delta":\t{\n\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t"content":\t"an",\n\t\t\t\t\t\t"content_list":\t[{\n\t\t\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t\t\t"text":\t"an"\n\t\t\t\t\t\t\t}],\n\t\t\t\t\t\t"text":\t"an"\n\t\t\t\t\t}\n\t\t\t\t}],\n\t\t\t"usage":\t{\n\t\t\t}\n\t\t}\n\t}, {\n\t\t"data":\t{\n\t\t\t"id":\t"25c652c6-a999-4916-b6b8-ae7b8186327b",\n\t\t\t"model":\t"claude-3-5-sonnet",\n\t\t\t"choices":\t[{\n\t\t\t\t\t"delta":\t{\n\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t"content":\t"d e",\n\t\t\t\t\t\t"content_list":\t[{\n\t\t\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t\t\t"text":\t"d e"\n\t\t\t\t\t\t\t}],\n\t\t\t\t\t\t"text":\t"d e"\n\t\t\t\t\t}\n\t\t\t\t}],\n\t\t\t"usage":\t{\n\t\t\t}\n\t\t}\n\t}, {\n\t\t"data":\t{\n\t\t\t"id":\t"25c652c6-a999-4916-b6b8-ae7b8186327b",\n\t\t\t"model":\t"claude-3-5-sonnet",\n\t\t\t"choices":\t[{\n\t\t\t\t\t"delta":\t{\n\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t"content":\t"xplain why ",\n\t\t\t\t\t\t"content_list":\t[{\n\t\t\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t\t\t"text":\t"xplain why "\n\t\t\t\t\t\t\t}],\n\t\t\t\t\t\t"text":\t"xplain why "\n\t\t\t\t\t}\n\t\t\t\t}],\n\t\t\t"usage":\t{\n\t\t\t}\n\t\t}\n\t}, {\n\t\t"data":\t{\n\t\t\t"id":\t"25c652c6-a999-4916-b6b8-ae7b8186327b",\n\t\t\t"model":\t"claude-3-5-sonnet",\n\t\t\t"choices":\t[{\n\t\t\t\t\t"delta":\t{\n\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t"content":\t"the Total",\n\t\t\t\t\t\t"content_list":\t[{\n\t\t\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t\t\t"text":\t"the Total"\n\t\t\t\t\t\t\t}],\n\t\t\t\t\t\t"text":\t"the Total"\n\t\t\t\t\t}\n\t\t\t\t}],\n\t\t\t"usage":\t{\n\t\t\t}\n\t\t}\n\t}, {\n\t\t"data":\t{\n\t\t\t"id":\t"25c652c6-a999-4916-b6b8-ae7b8186327b",\n\t\t\t"model":\t"claude-3-5-sonnet",\n\t\t\t"choices":\t[{\n\t\t\t\t\t"delta":\t{\n\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t"content":\t" Marke",\n\t\t\t\t\t\t"content_list":\t[{\n\t\t\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t\t\t"text":\t" Marke"\n\t\t\t\t\t\t\t}],\n\t\t\t\t\t\t"text":\t" Marke"\n\t\t\t\t\t}\n\t\t\t\t}],\n\t\t\t"usage":\t{\n\t\t\t}\n\t\t}\n\t}, {\n\t\t"data":\t{\n\t\t\t"id":\t"25c652c6-a999-4916-b6b8-ae7b8186327b",\n\t\t\t"model":\t"claude-3-5-sonnet",\n\t\t\t"choices":\t[{\n\t\t\t\t\t"delta":\t{\n\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t"content":\t"t ",\n\t\t\t\t\t\t"content_list":\t[{\n\t\t\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t\t\t"text":\t"t "\n\t\t\t\t\t\t\t}],\n\t\t\t\t\t\t"text":\t"t "\n\t\t\t\t\t}\n\t\t\t\t}],\n\t\t\t"usage":\t{\n\t\t\t}\n\t\t}\n\t}, {\n\t\t"data":\t{\n\t\t\t"id":\t"25c652c6-a999-4916-b6b8-ae7b8186327b",\n\t\t\t"model":\t"claude-3-5-sonnet",\n\t\t\t"choices":\t[{\n\t\t\t\t\t"delta":\t{\n\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t"content":\t"Volume in Pa",\n\t\t\t\t\t\t"content_list":\t[{\n\t\t\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t\t\t"text":\t"Volume in Pa"\n\t\t\t\t\t\t\t}],\n\t\t\t\t\t\t"text":\t"Volume in Pa"\n\t\t\t\t\t}\n\t\t\t\t}],\n\t\t\t"usage":\t{\n\t\t\t}\n\t\t}\n\t}, {\n\t\t"data":\t{\n\t\t\t"id":\t"25c652c6-a999-4916-b6b8-ae7b8186327b",\n\t\t\t"model":\t"claude-3-5-sonnet",\n\t\t\t"choices":\t[{\n\t\t\t\t\t"delta":\t{\n\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t"content":\t"in ",\n\t\t\t\t\t\t"content_list":\t[{\n\t\t\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t\t\t"text":\t"in "\n\t\t\t\t\t\t\t}],\n\t\t\t\t\t\t"text":\t"in "\n\t\t\t\t\t}\n\t\t\t\t}],\n\t\t\t"usage":\t{\n\t\t\t}\n\t\t}\n\t}, {\n\t\t"data":\t{\n\t\t\t"id":\t"25c652c6-a999-4916-b6b8-ae7b8186327b",\n\t\t\t"model":\t"claude-3-5-sonnet",\n\t\t\t"choices":\t[{\n\t\t\t\t\t"delta":\t{\n\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t"content":\t"Management",\n\t\t\t\t\t\t"content_list":\t[{\n\t\t\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t\t\t"text":\t"Management"\n\t\t\t\t\t\t\t}],\n\t\t\t\t\t\t"text":\t"Management"\n\t\t\t\t\t}\n\t\t\t\t}],\n\t\t\t"usage":\t{\n\t\t\t}\n\t\t}\n\t}, {\n\t\t"data":\t{\n\t\t\t"id":\t"25c652c6-a999-4916-b6b8-ae7b8186327b",\n\t\t\t"model":\t"claude-3-5-sonnet",\n\t\t\t"choices":\t[{\n\t\t\t\t\t"delta":\t{\n\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t"content":\t" is be",\n\t\t\t\t\t\t"content_list":\t[{\n\t\t\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t\t\t"text":\t" is be"\n\t\t\t\t\t\t\t}],\n\t\t\t\t\t\t"text":\t" is be"\n\t\t\t\t\t}\n\t\t\t\t}],\n\t\t\t"usage":\t{\n\t\t\t}\n\t\t}\n\t}, {\n\t\t"data":\t{\n\t\t\t"id":\t"25c652c6-a999-4916-b6b8-ae7b8186327b",\n\t\t\t"model":\t"claude-3-5-sonnet",\n\t\t\t"choices":\t[{\n\t\t\t\t\t"delta":\t{\n\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t"content":\t"ing",\n\t\t\t\t\t\t"content_list":\t[{\n\t\t\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t\t\t"text":\t"ing"\n\t\t\t\t\t\t\t}],\n\t\t\t\t\t\t"text":\t"ing"\n\t\t\t\t\t}\n\t\t\t\t}],\n\t\t\t"usage":\t{\n\t\t\t}\n\t\t}\n\t}, {\n\t\t"data":\t{\n\t\t\t"id":\t"25c652c6-a999-4916-b6b8-ae7b8186327b",\n\t\t\t"model":\t"claude-3-5-sonnet",\n\t\t\t"choices":\t[{\n\t\t\t\t\t"delta":\t{\n\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t"content":\t" d",\n\t\t\t\t\t\t"content_list":\t[{\n\t\t\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t\t\t"text":\t" d"\n\t\t\t\t\t\t\t}],\n\t\t\t\t\t\t"text":\t" d"\n\t\t\t\t\t}\n\t\t\t\t}],\n\t\t\t"usage":\t{\n\t\t\t}\n\t\t}\n\t}, {\n\t\t"data":\t{\n\t\t\t"id":\t"25c652c6-a999-4916-b6b8-ae7b8186327b",\n\t\t\t"model":\t"claude-3-5-sonnet",\n\t\t\t"choices":\t[{\n\t\t\t\t\t"delta":\t{\n\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t"content":\t"riven by th",\n\t\t\t\t\t\t"content_list":\t[{\n\t\t\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t\t\t"text":\t"riven by th"\n\t\t\t\t\t\t\t}],\n\t\t\t\t\t\t"text":\t"riven by th"\n\t\t\t\t\t}\n\t\t\t\t}],\n\t\t\t"usage":\t{\n\t\t\t}\n\t\t}\n\t}, {\n\t\t"data":\t{\n\t\t\t"id":\t"25c652c6-a999-4916-b6b8-ae7b8186327b",\n\t\t\t"model":\t"claude-3-5-sonnet",\n\t\t\t"choices":\t[{\n\t\t\t\t\t"delta":\t{\n\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t"content":\t"e Opioid Cat",\n\t\t\t\t\t\t"content_list":\t[{\n\t\t\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t\t\t"text":\t"e Opioid Cat"\n\t\t\t\t\t\t\t}],\n\t\t\t\t\t\t"text":\t"e Opioid Cat"\n\t\t\t\t\t}\n\t\t\t\t}],\n\t\t\t"usage":\t{\n\t\t\t}\n\t\t}\n\t}, {\n\t\t"data":\t{\n\t\t\t"id":\t"25c652c6-a999-4916-b6b8-ae7b8186327b",\n\t\t\t"model":\t"claude-3-5-sonnet",\n\t\t\t"choices":\t[{\n\t\t\t\t\t"delta":\t{\n\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t"content":\t"egory.\"}",\n\t\t\t\t\t\t"content_list":\t[{\n\t\t\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t\t\t"text":\t"egory.\"}"\n\t\t\t\t\t\t\t}],\n\t\t\t\t\t\t"text":\t"egory.\"}"\n\t\t\t\t\t}\n\t\t\t\t}],\n\t\t\t"usage":\t{\n\t\t\t}\n\t\t}\n\t}, {\n\t\t"data":\t{\n\t\t\t"id":\t"25c652c6-a999-4916-b6b8-ae7b8186327b",\n\t\t\t"model":\t"claude-3-5-sonnet",\n\t\t\t"choices":\t[{\n\t\t\t\t\t"delta":\t{\n\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t"content_list":\t[{\n\t\t\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t\t\t"text":\t""\n\t\t\t\t\t\t\t}],\n\t\t\t\t\t\t"text":\t""\n\t\t\t\t\t}\n\t\t\t\t}],\n\t\t\t"usage":\t{\n\t\t\t\t"prompt_tokens":\t2190,\n\t\t\t\t"completion_tokens":\t62,\n\t\t\t\t"total_tokens":\t2252\n\t\t\t}\n\t\t}\n\t}]', 'headers': {'\nTransfer-Encoding': 'chunked', '\nDate': 'Mon, 19 Jan 2026 14:09:53 GMT', '\nContent-Type': 'text/event-stream', '\nCache-Control': 'no-cache', '\nX-Accel-Buffering': 'no', '\nX-Snowflake-Request-ID': '25c652c6-a999-4916-b6b8-ae7b8186327b'}}

Structured Extraction Error: 'list' object has no attribute 'get'
Empty model output parsed. Type: <class 'list'>

API Error Response: {'status': 400, 'content': '{\n\t"message":\t"input schema validation error: /properties/root_cause_query please specify a valid json schema object (\'type\' missing?, additionalProperties used?, invalid type array?) or a \'$ref\' value, /properties/root_cause_query additional properties are not allowed, /properties/root_cause_query unevaluated properties are not allowed, /properties/clarification_question please specify a valid json schema object (\'type\' missing?, additionalProperties used?, invalid type array?) or a \'$ref\' value, /properties/clarification_question additional properties are not allowed, /properties/clarification_question unevaluated properties are not allowed, /properties/data_retrieval_query please specify a valid json schema object (\'type\' missing?, additionalProperties used?, invalid type array?) or a \'$ref\' value, /properties/data_retrieval_query additional properties are not allowed, /properties/data_retrieval_query unevaluated properties are not allowed, /properties/direct_response please specify a valid json schema object (\'type\' missing?, additionalProperties used?, invalid type array?) or a \'$ref\' value, /properties/direct_response additional properties are not allowed, /properties/direct_response unevaluated properties are not allowed",\n\t"request_id":\t"8888e545-4c98-4fcc-8c7c-3bf4c142dae4"\n}', 'headers': {'\nContent-Length': '1299', '\nContent-Type': 'application/json;charset=utf-8', '\nX-Snowflake-Request-ID': '8888e545-4c98-4fcc-8c7c-3bf4c142dae4', '\nX-Accel-Buffering': 'no', '\nDate': 'Mon, 19 Jan 2026 14:33:52 GMT', '\nCache-Control': 'no-cache'}}
==================================================
 CHECKPOINT: API REQUEST (STRUCTURED)
--------------------------------------------------
Target Model: IntentClassification
==================================================
API Error Response: {'status': 400, 'content': '{\n\t"message":\t"input schema validation error: /properties/root_cause_query additional properties are not allowed, /properties/root_cause_query unevaluated properties are not allowed, /properties/clarification_question additional properties are not allowed, /properties/clarification_question unevaluated properties are not allowed, /properties/data_retrieval_query additional properties are not allowed, /properties/data_retrieval_query unevaluated properties are not allowed, /properties/direct_response additional properties are not allowed, /properties/direct_response unevaluated properties are not allowed",\n\t"request_id":\t"b3e4195f-9d1a-4055-97fa-3dbc75bcc038"\n}', 'headers': {'\nCache-Control': 'no-cache', '\nContent-Type': 'application/json;charset=utf-8', '\nX-Accel-Buffering': 'no', '\nContent-Length': '662', '\nX-Snowflake-Request-ID': 'b3e4195f-9d1a-4055-97fa-3dbc75bcc038', '\nDate': 'Mon, 19 Jan 2026 14:38:35 GMT'}}
Skip to main content
Skip to editor
Skip to results
Site





Worksheets
Selection deleted
516
517
518
519
520
521
522
523
524
525
526
527
528
529
530
531
532
533
534
535
536
537
538
539
540
541
542
543
544
545
546
547
548
549
550
551
552
553
554
555
556
557
558
559
560
561
562
563
564
565
566
567
568
569
570
571
572
573
574
575
576
577
578
579
580
581
582
583
584
585
586
587
588
589
590
591
592
593
594
595
596
597
598
599
600
601
602
603
604
605
606
607
608
609
610
611
612
613
614
615
616
617
618
619
620
621
622
623
624
625
626
627
628
629
630
631
632
633
634
635
636
637
638
639
640
641
642
643
644
645
646
647
648
649
650
651
652
653
654
def invoke_structured_output_extraction(session: Session, messages: List[Dict], pydantic_model: type[BaseModel]) -> BaseModel:
    """
    Invokes Cortex Inference with STRICT schema sanitization and robust response parsing.
    """
    ENDPOINT = "/api/v2/cortex/inference:complete"
    
    # --- HELPER: Strict Schema Sanitizer ---
    # Whitelists ONLY fields allowed by Cortex. Removes defaults, titles, etc.
    def strict_schema_transform(schema: Dict) -> Dict:
        new_schema = {}
        
        # 1. Allowed Keys
        if "type" in schema: new_schema["type"] = schema["type"]
        if "description" in schema: new_schema["description"] = schema["description"]
        if "enum" in schema: new_schema["enum"] = schema["enum"]
        if "required" in schema: new_schema["required"] = schema["required"]
        
        # 2. Handle Pydantic's 'anyOf' for Optional fields (Flatten to type: [str, null])
        if "anyOf" in schema:
            types = []
            for opt in schema["anyOf"]:
                if "type" in opt: types.append(opt["type"])
            if set(types) == {"string", "null"}: new_schema["type"] = ["string", "null"]
            elif set(types) == {"integer", "null"}: new_schema["type"] = ["integer", "null"]
            elif set(types) == {"number", "null"}: new_schema["type"] = ["number", "null"]
            elif set(types) == {"boolean", "null"}: new_schema["type"] = ["boolean", "null"]
            elif set(types) == {"object", "null"}: new_schema["type"] = ["object", "null"]
        
        # 3. Handle Arrays
        if "items" in schema:
            new_schema["items"] = strict_schema_transform(schema["items"])
            
        # 4. Handle Objects (Properties)
        if "properties" in schema:
            new_props = {}
            for k, v in schema["properties"].items():
                new_props[k] = strict_schema_transform(v)
            new_schema["properties"] = new_props
            
        return new_schema
    # ---------------------------------------

    # 1. Generate & Clean Schema
    raw_schema = pydantic_model.model_json_schema()
    clean_json_schema = strict_schema_transform(raw_schema)

    # 2. Sanitize Messages
    sanitized_messages = []
    for msg in messages:
        content = msg.get("content")
        if isinstance(content, list):
            flat_text = " ".join([item.get("text", "") for item in content if item.get("type") == "text"])
            sanitized_messages.append({"role": msg["role"], "content": flat_text})
        else:
            sanitized_messages.append(msg)

    payload = {
        "model": CONFIG.model,
        "messages": sanitized_messages,
        "max_tokens": 2000,
        "response_format": { "type": "json", "schema": clean_json_schema }
    }

    log_checkpoint("API REQUEST (STRUCTURED)", f"Target Model: {pydantic_model.__name__}")

    try:
        # 3. Request
        headers = { "Content-Type": "application/json", "Accept": "application/json" }
        resp = _snowflake.send_snow_api_request("POST", ENDPOINT, headers, {}, payload, {}, 120000)
        
        if resp.get('status') and resp.get('status') >= 400:
             print(f"API Error Response: {resp}")
             return pydantic_model.construct()

        content_str = resp.get("content")
        if not content_str:
            print(f"Empty content from Cortex. Raw: {resp}")
            return pydantic_model.construct()

        # 4. Parse Response Body (Handle NDJSON vs Standard JSON)
        try:
            api_body = json.loads(content_str)
        except json.JSONDecodeError:
            api_body = [json.loads(line) for line in content_str.splitlines() if line.strip()]

        model_output_str = ""

        # 5. Extraction Logic
        if isinstance(api_body, list):
            for chunk in api_body:
                data_obj = chunk.get("data", {})
                choices = data_obj.get("choices", [])
                if choices:
                    delta = choices[0].get("delta", {})
                    model_output_str += delta.get("content", "")
                        
        elif isinstance(api_body, dict):
            choices = api_body.get("choices", [{}])
            if choices:
                model_output_str = choices[0].get("message", {}).get("content", "")

        if not model_output_str:
             print(f"Empty model output parsed.")
             return pydantic_model.construct()

        # 6. Parse Inner JSON & Validate
        parsed_dict = json.loads(model_output_str)
        return pydantic_model(**parsed_dict)
        
    except Exception as e:
        print(f"Structured Extraction Error: {e}")
        return pydantic_model.construct()

def invoke_cortex_agent(session: Session, payload: Dict, agent_name: str) -> Dict:
    """Invokes 'agent:run' for tools (Analyst/Diagnostic) with 5-row limit."""
    ENDPOINT = "/api/v2/cortex/agent:run"
    print(f"--- INVOKING AGENT: {agent_name} ---")

    try:
        resp = _snowflake.send_snow_api_request("POST", ENDPOINT, {"Content-Type": "application/json", "Accept": "text/event-stream"}, {}, payload, {}, 120000)
        content = resp.get("content")
        if not content: return {"error": "Empty"}
        
        extracted = {"text": "", "tables": [], "charts": [], "sql_generated": None, "sql_explanation": None}
        try: parsed = json.loads(content)
        except: parsed = [json.loads(line) for line in content.splitlines() if line.strip()]
        
        def process_event(evt, data):
            if evt == 'response.text.delta': extracted["text"] += data.get('text', '')
            elif evt == 'response.chart': extracted["charts"].append(data.get('chart') or data.get('chart_spec'))
            elif evt == 'response.table':
                rs = data.get('result_set', [])
                extracted["tables"].append(rs[:5]) # Limit 5 rows
            elif evt == 'response.tool_result.analyst.delta':
                delta = data.get('delta', {})
                if delta.get('sql'): extracted["sql_generated"] = delta.get('sql')
                if delta.get('sql_explanation'): extracted["sql_explanation"] = delta.get('sql_explanation')
                if delta.get('result_set'): extracted["tables"].append(delta.get('result_set')[:5])
            elif evt == 'response.tool_result':
==================================================
==================================================
 CHECKPOINT: API REQUEST (STRUCTURED)
--------------------------------------------------
Target Model: IntentClassification
==================================================
--- INVOKING AGENT: Data Agent ---
--- INVOKING AGENT: Root Cause Agent ---
--- AGENT Root Cause Agent COMPLETED ---
==================================================
 CHECKPOINT: API REQUEST (STRUCTURED)
--------------------------------------------------
Target Model: RootCauseParsedOutput
==================================================
API Error Response: {'status': 400, 'content': '{\n\t"message":\t"input schema validation error: /properties/evaluation please specify a valid json schema object (\'type\' missing?, additionalProperties used?, invalid type array?) or a \'$ref\' value",\n\t"request_id":\t"2c501f0b-4ba9-472a-8d41-86af324161a0"\n}', 'headers': {'\nX-Accel-Buffering': 'no', '\nCache-Control': 'no-cache', '\nDate': 'Mon, 19 Jan 2026 14:45:30 GMT', '\nContent-Type': 'application/json;charset=utf-8', '\nContent-Length': '247', '\nX-Snowflake-Request-ID': '2c501f0b-4ba9-472a-8d41-86af324161a0'}}
==================================================
 CHECKPOINT: API REQUEST (STRUCTURED)
--------------------------------------------------
Target Model: DataAgentParsedOutput
==================================================
API Error Response: {'status': 400, 'content': '{\n\t"message":\t"input schema validation error: /properties/evaluation please specify a valid json schema object (\'type\' missing?, additionalProperties used?, invalid type array?) or a \'$ref\' value",\n\t"request_id":\t"becb5afe-f26f-4b4e-b675-90d7073eac2f"\n}', 'headers': {'\nX-Accel-Buffering': 'no', '\nContent-Length': '247', '\nContent-Type': 'application/json;charset=utf-8', '\nX-Snowflake-Request-ID': 'becb5afe-f26f-4b4e-b675-90d7073eac2f', '\nDate': 'Mon, 19 Jan 2026 14:45:48 GMT', '\nCache-Control': 'no-cache'}}
==================================================
 CHECKPOINT: MAIN: COMPLETED
--------------------------------------------------
{'intent': {'clarification_question': None,


==================================================
 CHECKPOINT: API REQUEST (STRUCTURED)
--------------------------------------------------
Target Model: RephraserOutput
==================================================
API Error Response: {'status': 500, 'content': '{\n\t"code":\t"300014",\n\t"message":\t"Cannot deserialize value of type `java.lang.String` from Array value (token `JsonToken.START_ARRAY`)\n at [Source: (org.eclipse.jetty.server.HttpInputOverHTTP); line: 1, column: 73] (through reference chain: com.snowflake.snowapi.cortexinference.model.CompleteRequest[\"messages\"]->java.util.ArrayList[0]->com.snowflake.snowapi.cortexinference.model.CompleteRequestMessagesInner[\"content\"])",\n\t"request_id":\t"c5f58b6a-9f4c-4b09-9acd-603d33ce5bc8",\n\t"error_code":\t"300014"\n}', 'headers': {'\nContent-Type': 'application/json', '\nContent-Length': '497', '\nDate': 'Mon, 19 Jan 2026 15:04:53 GMT', '\nX-Snowflake-Request-ID': 'c5f58b6a-9f4c-4b09-9acd-603d33ce5bc8'}}



==================================================
 CHECKPOINT: API REQUEST (STRUCTURED)
--------------------------------------------------
Target Model: RephraserOutput
==================================================
Structured Extraction Error: Empty response from Cortex




==================================================
 CHECKPOINT: START: GUARD
--------------------------------------------------
show ME all the health care providers in arizona and Why is the Total Market Volume being driven by the Opioid Category?
==================================================
==================================================
 CHECKPOINT: API REQUEST (STRUCTURED)
--------------------------------------------------
Target Model: RephraserOutput
==================================================
{'status': 200, 'content': '[{\n\t\t"data":\t{\n\t\t\t"id":\t"ed6e5f23-94be-4558-a38b-696f4e08ed2d",\n\t\t\t"model":\t"claude-3-5-sonnet",\n\t\t\t"choices":\t[{\n\t\t\t\t\t"delta":\t{\n\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t"content_list":\t[{\n\t\t\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t\t\t"text":\t""\n\t\t\t\t\t\t\t}],\n\t\t\t\t\t\t"text":\t""\n\t\t\t\t\t}\n\t\t\t\t}],\n\t\t\t"usage":\t{\n\t\t\t}\n\t\t}\n\t}, {\n\t\t"data":\t{\n\t\t\t"id":\t"ed6e5f23-94be-4558-a38b-696f4e08ed2d",\n\t\t\t"model":\t"claude-3-5-sonnet",\n\t\t\t"choices":\t[{\n\t\t\t\t\t"delta":\t{\n\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t"content_list":\t[{\n\t\t\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t\t\t"text":\t""\n\t\t\t\t\t\t\t}],\n\t\t\t\t\t\t"text":\t""\n\t\t\t\t\t}\n\t\t\t\t}],\n\t\t\t"usage":\t{\n\t\t\t}\n\t\t}\n\t}, {\n\t\t"data":\t{\n\t\t\t"id":\t"ed6e5f23-94be-4558-a38b-696f4e08ed2d",\n\t\t\t"model":\t"claude-3-5-sonnet",\n\t\t\t"choices":\t[{\n\t\t\t\t\t"delta":\t{\n\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t"content":\t"{\"refined",\n\t\t\t\t\t\t"content_list":\t[{\n\t\t\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t\t\t"text":\t"{\"refined"\n\t\t\t\t\t\t\t}],\n\t\t\t\t\t\t"text":\t"{\"refined"\n\t\t\t\t\t}\n\t\t\t\t}],\n\t\t\t"usage":\t{\n\t\t\t}\n\t\t}\n\t}, {\n\t\t"data":\t{\n\t\t\t"id":\t"ed6e5f23-94be-4558-a38b-696f4e08ed2d",\n\t\t\t"model":\t"claude-3-5-sonnet",\n\t\t\t"choices":\t[{\n\t\t\t\t\t"delta":\t{\n\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t"content":\t"_q",\n\t\t\t\t\t\t"content_list":\t[{\n\t\t\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t\t\t"text":\t"_q"\n\t\t\t\t\t\t\t}],\n\t\t\t\t\t\t"text":\t"_q"\n\t\t\t\t\t}\n\t\t\t\t}],\n\t\t\t"usage":\t{\n\t\t\t}\n\t\t}\n\t}, {\n\t\t"data":\t{\n\t\t\t"id":\t"ed6e5f23-94be-4558-a38b-696f4e08ed2d",\n\t\t\t"model":\t"claude-3-5-sonnet",\n\t\t\t"choices":\t[{\n\t\t\t\t\t"delta":\t{\n\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t"content":\t"uery\":",\n\t\t\t\t\t\t"content_list":\t[{\n\t\t\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t\t\t"text":\t"uery\":"\n\t\t\t\t\t\t\t}],\n\t\t\t\t\t\t"text":\t"uery\":"\n\t\t\t\t\t}\n\t\t\t\t}],\n\t\t\t"usage":\t{\n\t\t\t}\n\t\t}\n\t}, {\n\t\t"data":\t{\n\t\t\t"id":\t"ed6e5f23-94be-4558-a38b-696f4e08ed2d",\n\t\t\t"model":\t"claude-3-5-sonnet",\n\t\t\t"choices":\t[{\n\t\t\t\t\t"delta":\t{\n\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t"content":\t" \"Displa",\n\t\t\t\t\t\t"content_list":\t[{\n\t\t\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t\t\t"text":\t" \"Displa"\n\t\t\t\t\t\t\t}],\n\t\t\t\t\t\t"text":\t" \"Displa"\n\t\t\t\t\t}\n\t\t\t\t}],\n\t\t\t"usage":\t{\n\t\t\t}\n\t\t}\n\t}, {\n\t\t"data":\t{\n\t\t\t"id":\t"ed6e5f23-94be-4558-a38b-696f4e08ed2d",\n\t\t\t"model":\t"claude-3-5-sonnet",\n\t\t\t"choices":\t[{\n\t\t\t\t\t"delta":\t{\n\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t"content":\t"y all health",\n\t\t\t\t\t\t"content_list":\t[{\n\t\t\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t\t\t"text":\t"y all health"\n\t\t\t\t\t\t\t}],\n\t\t\t\t\t\t"text":\t"y all health"\n\t\t\t\t\t}\n\t\t\t\t}],\n\t\t\t"usage":\t{\n\t\t\t}\n\t\t}\n\t}, {\n\t\t"data":\t{\n\t\t\t"id":\t"ed6e5f23-94be-4558-a38b-696f4e08ed2d",\n\t\t\t"model":\t"claude-3-5-sonnet",\n\t\t\t"choices":\t[{\n\t\t\t\t\t"delta":\t{\n\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t"content":\t"care provide",\n\t\t\t\t\t\t"content_list":\t[{\n\t\t\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t\t\t"text":\t"care provide"\n\t\t\t\t\t\t\t}],\n\t\t\t\t\t\t"text":\t"care provide"\n\t\t\t\t\t}\n\t\t\t\t}],\n\t\t\t"usage":\t{\n\t\t\t}\n\t\t}\n\t}, {\n\t\t"data":\t{\n\t\t\t"id":\t"ed6e5f23-94be-4558-a38b-696f4e08ed2d",\n\t\t\t"model":\t"claude-3-5-sonnet",\n\t\t\t"choices":\t[{\n\t\t\t\t\t"delta":\t{\n\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t"content":\t"rs locat",\n\t\t\t\t\t\t"content_list":\t[{\n\t\t\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t\t\t"text":\t"rs locat"\n\t\t\t\t\t\t\t}],\n\t\t\t\t\t\t"text":\t"rs locat"\n\t\t\t\t\t}\n\t\t\t\t}],\n\t\t\t"usage":\t{\n\t\t\t}\n\t\t}\n\t}, {\n\t\t"data":\t{\n\t\t\t"id":\t"ed6e5f23-94be-4558-a38b-696f4e08ed2d",\n\t\t\t"model":\t"claude-3-5-sonnet",\n\t\t\t"choices":\t[{\n\t\t\t\t\t"delta":\t{\n\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t"content":\t"ed in Ari",\n\t\t\t\t\t\t"content_list":\t[{\n\t\t\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t\t\t"text":\t"ed in Ari"\n\t\t\t\t\t\t\t}],\n\t\t\t\t\t\t"text":\t"ed in Ari"\n\t\t\t\t\t}\n\t\t\t\t}],\n\t\t\t"usage":\t{\n\t\t\t}\n\t\t}\n\t}, {\n\t\t"data":\t{\n\t\t\t"id":\t"ed6e5f23-94be-4558-a38b-696f4e08ed2d",\n\t\t\t"model":\t"claude-3-5-sonnet",\n\t\t\t"choices":\t[{\n\t\t\t\t\t"delta":\t{\n\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t"content":\t"zona and exp",\n\t\t\t\t\t\t"content_list":\t[{\n\t\t\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t\t\t"text":\t"zona and exp"\n\t\t\t\t\t\t\t}],\n\t\t\t\t\t\t"text":\t"zona and exp"\n\t\t\t\t\t}\n\t\t\t\t}],\n\t\t\t"usage":\t{\n\t\t\t}\n\t\t}\n\t}, {\n\t\t"data":\t{\n\t\t\t"id":\t"ed6e5f23-94be-4558-a38b-696f4e08ed2d",\n\t\t\t"model":\t"claude-3-5-sonnet",\n\t\t\t"choices":\t[{\n\t\t\t\t\t"delta":\t{\n\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t"content":\t"lai",\n\t\t\t\t\t\t"content_list":\t[{\n\t\t\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t\t\t"text":\t"lai"\n\t\t\t\t\t\t\t}],\n\t\t\t\t\t\t"text":\t"lai"\n\t\t\t\t\t}\n\t\t\t\t}],\n\t\t\t"usage":\t{\n\t\t\t}\n\t\t}\n\t}, {\n\t\t"data":\t{\n\t\t\t"id":\t"ed6e5f23-94be-4558-a38b-696f4e08ed2d",\n\t\t\t"model":\t"claude-3-5-sonnet",\n\t\t\t"choices":\t[{\n\t\t\t\t\t"delta":\t{\n\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t"content":\t"n wh",\n\t\t\t\t\t\t"content_list":\t[{\n\t\t\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t\t\t"text":\t"n wh"\n\t\t\t\t\t\t\t}],\n\t\t\t\t\t\t"text":\t"n wh"\n\t\t\t\t\t}\n\t\t\t\t}],\n\t\t\t"usage":\t{\n\t\t\t}\n\t\t}\n\t}, {\n\t\t"data":\t{\n\t\t\t"id":\t"ed6e5f23-94be-4558-a38b-696f4e08ed2d",\n\t\t\t"model":\t"claude-3-5-sonnet",\n\t\t\t"choices":\t[{\n\t\t\t\t\t"delta":\t{\n\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t"content":\t"y the Total",\n\t\t\t\t\t\t"content_list":\t[{\n\t\t\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t\t\t"text":\t"y the Total"\n\t\t\t\t\t\t\t}],\n\t\t\t\t\t\t"text":\t"y the Total"\n\t\t\t\t\t}\n\t\t\t\t}],\n\t\t\t"usage":\t{\n\t\t\t}\n\t\t}\n\t}, {\n\t\t"data":\t{\n\t\t\t"id":\t"ed6e5f23-94be-4558-a38b-696f4e08ed2d",\n\t\t\t"model":\t"claude-3-5-sonnet",\n\t\t\t"choices":\t[{\n\t\t\t\t\t"delta":\t{\n\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t"content":\t" Mark",\n\t\t\t\t\t\t"content_list":\t[{\n\t\t\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t\t\t"text":\t" Mark"\n\t\t\t\t\t\t\t}],\n\t\t\t\t\t\t"text":\t" Mark"\n\t\t\t\t\t}\n\t\t\t\t}],\n\t\t\t"usage":\t{\n\t\t\t}\n\t\t}\n\t}, {\n\t\t"data":\t{\n\t\t\t"id":\t"ed6e5f23-94be-4558-a38b-696f4e08ed2d",\n\t\t\t"model":\t"claude-3-5-sonnet",\n\t\t\t"choices":\t[{\n\t\t\t\t\t"delta":\t{\n\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t"content":\t"et V",\n\t\t\t\t\t\t"content_list":\t[{\n\t\t\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t\t\t"text":\t"et V"\n\t\t\t\t\t\t\t}],\n\t\t\t\t\t\t"text":\t"et V"\n\t\t\t\t\t}\n\t\t\t\t}],\n\t\t\t"usage":\t{\n\t\t\t}\n\t\t}\n\t}, {\n\t\t"data":\t{\n\t\t\t"id":\t"ed6e5f23-94be-4558-a38b-696f4e08ed2d",\n\t\t\t"model":\t"claude-3-5-sonnet",\n\t\t\t"choices":\t[{\n\t\t\t\t\t"delta":\t{\n\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t"content":\t"olume for",\n\t\t\t\t\t\t"content_list":\t[{\n\t\t\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t\t\t"text":\t"olume for"\n\t\t\t\t\t\t\t}],\n\t\t\t\t\t\t"text":\t"olume for"\n\t\t\t\t\t}\n\t\t\t\t}],\n\t\t\t"usage":\t{\n\t\t\t}\n\t\t}\n\t}, {\n\t\t"data":\t{\n\t\t\t"id":\t"ed6e5f23-94be-4558-a38b-696f4e08ed2d",\n\t\t\t"model":\t"claude-3-5-sonnet",\n\t\t\t"choices":\t[{\n\t\t\t\t\t"delta":\t{\n\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t"content":\t" Pain ",\n\t\t\t\t\t\t"content_list":\t[{\n\t\t\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t\t\t"text":\t" Pain "\n\t\t\t\t\t\t\t}],\n\t\t\t\t\t\t"text":\t" Pain "\n\t\t\t\t\t}\n\t\t\t\t}],\n\t\t\t"usage":\t{\n\t\t\t}\n\t\t}\n\t}, {\n\t\t"data":\t{\n\t\t\t"id":\t"ed6e5f23-94be-4558-a38b-696f4e08ed2d",\n\t\t\t"model":\t"claude-3-5-sonnet",\n\t\t\t"choices":\t[{\n\t\t\t\t\t"delta":\t{\n\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t"content":\t"Manage",\n\t\t\t\t\t\t"content_list":\t[{\n\t\t\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t\t\t"text":\t"Manage"\n\t\t\t\t\t\t\t}],\n\t\t\t\t\t\t"text":\t"Manage"\n\t\t\t\t\t}\n\t\t\t\t}],\n\t\t\t"usage":\t{\n\t\t\t}\n\t\t}\n\t}, {\n\t\t"data":\t{\n\t\t\t"id":\t"ed6e5f23-94be-4558-a38b-696f4e08ed2d",\n\t\t\t"model":\t"claude-3-5-sonnet",\n\t\t\t"choices":\t[{\n\t\t\t\t\t"delta":\t{\n\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t"content":\t"ment is bei",\n\t\t\t\t\t\t"content_list":\t[{\n\t\t\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t\t\t"text":\t"ment is bei"\n\t\t\t\t\t\t\t}],\n\t\t\t\t\t\t"text":\t"ment is bei"\n\t\t\t\t\t}\n\t\t\t\t}],\n\t\t\t"usage":\t{\n\t\t\t}\n\t\t}\n\t}, {\n\t\t"data":\t{\n\t\t\t"id":\t"ed6e5f23-94be-4558-a38b-696f4e08ed2d",\n\t\t\t"model":\t"claude-3-5-sonnet",\n\t\t\t"choices":\t[{\n\t\t\t\t\t"delta":\t{\n\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t"content":\t"ng driven ",\n\t\t\t\t\t\t"content_list":\t[{\n\t\t\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t\t\t"text":\t"ng driven "\n\t\t\t\t\t\t\t}],\n\t\t\t\t\t\t"text":\t"ng driven "\n\t\t\t\t\t}\n\t\t\t\t}],\n\t\t\t"usage":\t{\n\t\t\t}\n\t\t}\n\t}, {\n\t\t"data":\t{\n\t\t\t"id":\t"ed6e5f23-94be-4558-a38b-696f4e08ed2d",\n\t\t\t"model":\t"claude-3-5-sonnet",\n\t\t\t"choices":\t[{\n\t\t\t\t\t"delta":\t{\n\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t"content":\t"by growth ",\n\t\t\t\t\t\t"content_list":\t[{\n\t\t\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t\t\t"text":\t"by growth "\n\t\t\t\t\t\t\t}],\n\t\t\t\t\t\t"text":\t"by growth "\n\t\t\t\t\t}\n\t\t\t\t}],\n\t\t\t"usage":\t{\n\t\t\t}\n\t\t}\n\t}, {\n\t\t"data":\t{\n\t\t\t"id":\t"ed6e5f23-94be-4558-a38b-696f4e08ed2d",\n\t\t\t"model":\t"claude-3-5-sonnet",\n\t\t\t"choices":\t[{\n\t\t\t\t\t"delta":\t{\n\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t"content":\t"in the",\n\t\t\t\t\t\t"content_list":\t[{\n\t\t\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t\t\t"text":\t"in the"\n\t\t\t\t\t\t\t}],\n\t\t\t\t\t\t"text":\t"in the"\n\t\t\t\t\t}\n\t\t\t\t}],\n\t\t\t"usage":\t{\n\t\t\t}\n\t\t}\n\t}, {\n\t\t"data":\t{\n\t\t\t"id":\t"ed6e5f23-94be-4558-a38b-696f4e08ed2d",\n\t\t\t"model":\t"claude-3-5-sonnet",\n\t\t\t"choices":\t[{\n\t\t\t\t\t"delta":\t{\n\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t"content":\t" Opio",\n\t\t\t\t\t\t"content_list":\t[{\n\t\t\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t\t\t"text":\t" Opio"\n\t\t\t\t\t\t\t}],\n\t\t\t\t\t\t"text":\t" Opio"\n\t\t\t\t\t}\n\t\t\t\t}],\n\t\t\t"usage":\t{\n\t\t\t}\n\t\t}\n\t}, {\n\t\t"data":\t{\n\t\t\t"id":\t"ed6e5f23-94be-4558-a38b-696f4e08ed2d",\n\t\t\t"model":\t"claude-3-5-sonnet",\n\t\t\t"choices":\t[{\n\t\t\t\t\t"delta":\t{\n\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t"content":\t"id ",\n\t\t\t\t\t\t"content_list":\t[{\n\t\t\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t\t\t"text":\t"id "\n\t\t\t\t\t\t\t}],\n\t\t\t\t\t\t"text":\t"id "\n\t\t\t\t\t}\n\t\t\t\t}],\n\t\t\t"usage":\t{\n\t\t\t}\n\t\t}\n\t}, {\n\t\t"data":\t{\n\t\t\t"id":\t"ed6e5f23-94be-4558-a38b-696f4e08ed2d",\n\t\t\t"model":\t"claude-3-5-sonnet",\n\t\t\t"choices":\t[{\n\t\t\t\t\t"delta":\t{\n\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t"content":\t"Ca",\n\t\t\t\t\t\t"content_list":\t[{\n\t\t\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t\t\t"text":\t"Ca"\n\t\t\t\t\t\t\t}],\n\t\t\t\t\t\t"text":\t"Ca"\n\t\t\t\t\t}\n\t\t\t\t}],\n\t\t\t"usage":\t{\n\t\t\t}\n\t\t}\n\t}, {\n\t\t"data":\t{\n\t\t\t"id":\t"ed6e5f23-94be-4558-a38b-696f4e08ed2d",\n\t\t\t"model":\t"claude-3-5-sonnet",\n\t\t\t"choices":\t[{\n\t\t\t\t\t"delta":\t{\n\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t"content":\t"tegory.\"}",\n\t\t\t\t\t\t"content_list":\t[{\n\t\t\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t\t\t"text":\t"tegory.\"}"\n\t\t\t\t\t\t\t}],\n\t\t\t\t\t\t"text":\t"tegory.\"}"\n\t\t\t\t\t}\n\t\t\t\t}],\n\t\t\t"usage":\t{\n\t\t\t}\n\t\t}\n\t}, {\n\t\t"data":\t{\n\t\t\t"id":\t"ed6e5f23-94be-4558-a38b-696f4e08ed2d",\n\t\t\t"model":\t"claude-3-5-sonnet",\n\t\t\t"choices":\t[{\n\t\t\t\t\t"delta":\t{\n\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t"content_list":\t[{\n\t\t\t\t\t\t\t\t"type":\t"text",\n\t\t\t\t\t\t\t\t"text":\t""\n\t\t\t\t\t\t\t}],\n\t\t\t\t\t\t"text":\t""\n\t\t\t\t\t}\n\t\t\t\t}],\n\t\t\t"usage":\t{\n\t\t\t\t"prompt_tokens":\t2190,\n\t\t\t\t"completion_tokens":\t63,\n\t\t\t\t"total_tokens":\t2253\n\t\t\t}\n\t\t}\n\t}]', 'headers': {'\nX-Accel-Buffering': 'no', '\nCache-Control': 'no-cache', '\nContent-Type': 'text/event-stream', '\nDate': 'Mon, 19 Jan 2026 15:13:28 GMT', '\nX-Snowflake-Request-ID': 'ed6e5f23-94be-4558-a38b-696f4e08ed2d', '\nTransfer-Encoding': 'chunked'}}
Structured Extraction Error: Empty response from Cortex


==================================================
==================================================
 CHECKPOINT: RAW ACCUMULATED TEXT
--------------------------------------------------
{
	"message":	"input schema validation error: /properties/data_retrieval_query please specify a valid json schema object ('type' missing?, additionalProperties used?, invalid type array?) or a '$ref' value, /properties/data_retrieval_query additional properties are not allowed, /properties/data_retrieval_query unevaluated properties are not allowed, /properties/direct_response please specify a valid json schema object ('type' missing?, additionalProperties used?, invalid type array?) or a '$ref' value, /properties/direct_response additional properties are not allowed, /properties/direct_response unevaluated properties are not allowed, /properties/root_cause_query please specify a valid json schema object ('type' missing?, additionalProperties used?, invalid type array?) or a '$ref' value, /properties/root_cause_query additional properties are not allowed, /properties/root_cause_query unevaluated properties are not allowed, /properties/clarification_question please specify a valid json schema object ('type' missing?, additionalProperties used?, invalid type array?) or a '$ref' value, /properties/clarification_question additional properties are not allowed, /properties/clarification_question unevaluated properties are not allowed",
	"request_id":	"621714fc-df25-41ae-bf02-89cfb2074399"
}
==================================================
Structured Extraction Error: 3 validation errors for IntentClassification
intent_type
  Field required [type=missing, input_value={'message': "input schema...41ae-bf02-89cfb2074399'}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.10/v/missing
confidence
  Field required [type=missing, input_value={'message': "input schema...41ae-bf02-89cfb2074399'}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.10/v/missing
reasoning
  Field required [type=missing, input_value={'message': "input schema...41ae-bf02-89cfb2074399'}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.10/v/missing


 CHECKPOINT: API REQUEST (STRUCTURED)
--------------------------------------------------
Target Model: IntentClassification
==================================================
{'status': 400, 'content': '{\n\t"message":\t"input schema validation error: /properties/root_cause_query additional properties are not allowed, /properties/root_cause_query unevaluated properties are not allowed, /properties/clarification_question additional properties are not allowed, /properties/clarification_question unevaluated properties are not allowed, /properties/data_retrieval_query additional properties are not allowed, /properties/data_retrieval_query unevaluated properties are not allowed, /properties/direct_response additional properties are not allowed, /properties/direct_response unevaluated properties are not allowed",\n\t"request_id":\t"e316d30e-841e-4f99-a1a7-569f7527e74b"\n}', 'headers': {'\nX-Snowflake-Request-ID': 'e316d30e-841e-4f99-a1a7-569f7527e74b', '\nDate': 'Mon, 19 Jan 2026 15:22:59 GMT', '\nX-Accel-Buffering': 'no', '\nContent-Length': '662', '\nContent-Type': 'application/json;charset=utf-8', '\nCache-Control': 'no-cache'}}
==================================================
 CHECKPOINT: RAW ACCUMULATED TEXT
--------------------------------------------------
==================================================
Structured Extraction Error: Accumulated text is empty. Model generation failed.
'results': [{'message': '1 validation error for SqlResult\n'
                         'charts.0\n'
                         '  Input should be a valid dictionary '
                         '[type=dict_type, input_value=\'{"title": "Total '
                         'Acute P...UTE_NRX_XPO": 1.004}]}}\', '
                         'input_type=str]\n'
                         '    For further information visit '
                         'https://errors.pydantic.dev/2.10/v/dict_type',
              'type': 'data_error'}]}

import json
import logging
import pprint
import _snowflake # Native Snowflake module for internal API calls
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import List, Dict, Any, Optional, Literal, Tuple
from pydantic import BaseModel, Field
from snowflake.snowpark import Session

# ==========================================
# 1. CONFIGURATION & MODELS
# ==========================================

class AgentConfig(BaseModel):
    """Configuration for the agent execution"""
    model: str = "claude-4-sonnet" 
    diagnostic_udf: str = "DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.AI_POC.DIAGNOSTIC_TOOL"
    cortex_analyst_object: str = "DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.AI_POC.LATEST_MASTER_VIEW"
    warehouse: str = "DEV_IMPACT_WH"
    guard_name: str = "INPUT_GUARD" 
    messages_table: str = "DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.AI_POC.MESSAGES"

# --- CORE MODELS ---

class EvaluationResult(BaseModel):
    score: int = Field(..., description="A quality score from 1-10 based on the accuracy and completeness of the answer.")
    reasoning: str = Field(..., description="A detailed explanation justifying the score.")

class IntentClassification(BaseModel):
    intent_type: str = Field(..., description="greeting, data_retrieval, root_cause_analysis, clarification_needed, general_question, off_topic, combined")
    data_retrieval_query: Optional[str] = Field(None, description="The refined query specific to data retrieval requests.")
    root_cause_query: Optional[str] = Field(None, description="The refined query specific to root cause analysis.")
    direct_response: Optional[str] = Field(None, description="A direct answer for greetings or general questions.")
    clarification_question: Optional[str] = Field(None, description="A question to ask the user if the intent is ambiguous.")
    confidence: str = Field(..., description="Confidence level: high, medium, or low.")
    reasoning: str = Field(..., description="Reasoning behind the classification.")

class RephraserOutput(BaseModel):
    refined_query: str = Field(..., description="The fully contextualized, standalone version of the user's query.")

# --- PARSING MODELS (For Extraction Step) ---

class DataAgentParsedOutput(BaseModel):
    """Schema for extracting structured data from the Data Agent's text response."""
    clean_answer_text: str = Field(..., description="The user-facing summary of the data, excluding internal evaluations.")
    clarifying_question: Optional[str] = Field(None, description="A question to ask the user if the data result was incomplete or ambiguous.")
    evaluation: EvaluationResult = Field(..., description="The self-evaluation of the response quality.")

class RootCauseParsedOutput(BaseModel):
    """Schema for extracting structured data from the Root Cause Agent's text response."""
    clean_summary_text: str = Field(..., description="The executive summary of the diagnosis.")
    react_flow_json: Optional[Dict] = Field(None, description="The React Flow JSON object representing the metric tree graph.")
    evaluation: EvaluationResult = Field(..., description="The self-evaluation of the diagnosis.")

# --- FINAL RESULT MODELS (For App/Frontend) ---

class SqlResult(BaseModel):
    answer_text: str
    clarifying_question: Optional[str] = None
    tables: List[Any] = Field(default_factory=list)
    charts: List[Dict] = Field(default_factory=list)
    sql_generated: Optional[str] = None
    sql_explanation: Optional[str] = None
    is_verified_query: bool = False
    reasoning_trace: Optional[str] = None
    evaluation: EvaluationResult

class DiagnosticResult(BaseModel):
    summary_text: str
    react_flow_json: Optional[Dict] = None
    clarifying_question: Optional[str] = None
    evaluation: EvaluationResult

class GuardResult(BaseModel):
    is_safe: bool = Field(...)
    violation_category: Optional[str] = Field(None)
    message: Optional[str] = Field(None)

CONFIG = AgentConfig()

# ==========================================
# 2. FULL PROMPT DEFINITIONS (EXACT ORIGINAL)
# ==========================================

PROMPT_REPHRASER_SYSTEM = "You are a sophisticated Query Refinement Engine."

PROMPT_REPHRASER_ORCHESTRATION = """
<query_refinement_instructions>
<objective>
Transform the user's input into a standalone, context-complete query that can be understood without prior conversation history.
</objective>

<core_rules>
<rule id="1">Resolve all pronouns (it, they, that, this, those) to their specific referents</rule>
<rule id="2">Preserve ALL metrics, entity names, IDs, and numerical values EXACTLY as stated</rule>
<rule id="3">Maintain the original intent and scope - do not expand or narrow the question</rule>
<rule id="4">Keep technical terminology and domain-specific language intact</rule>
<rule id="5">Ensure the output is grammatically correct and reads naturally</rule>
</core_rules>

<transformation_examples>
<example>
<input>What about Arizona?</input>
<context>Previous discussion about sales performance in Texas</context>
<output>What is the sales performance in Arizona?</output>
</example>

<example>
<input>Why is it down?</input>
<context>Previous mention of Q4 revenue</context>
<output>Why is Q4 revenue down?</output>
</example>

<example>
<input>Show me those providers and explain the trend.</input>
<context>Healthcare providers in California with declining prescriptions</context>
<output>Show me healthcare providers in California with declining prescriptions and explain the trend.</output>
</example>
</transformation_examples>

<output_format>
Output ONLY the refined query string. Do not include explanations, metadata, or formatting.
</output_format>
</query_refinement_instructions>
"""

PROMPT_INTENT_SYSTEM = "You are an Expert Intent Classification System."

PROMPT_INTENT_ORCHESTRATION = """
<intent_classification_instructions>

<mission>
Your ONLY job is to identify the user's INTENT. Do NOT retrieve data, do NOT answer questions, do NOT perform analysis.
Classify the intent type and route accordingly. If you can answer directly (like greetings), provide direct_response.
</mission>

<intent_categories>

<intent name="greeting">
<description>User is greeting, saying hello, or engaging in pleasantries</description>
<indicators>hi, hello, hey, good morning, how are you, thanks, thank you, goodbye, bye</indicators>
<action>Set direct_response with a friendly greeting. No other fields needed.</action>
</intent>

<intent name="data_retrieval">
<description>User wants to see/get/retrieve DATA - numbers, lists, metrics, tables</description>
<indicators>show, list, get, display, find, what is the value, how many, count, total, give me</indicators>
<action>Extract the data request to data_retrieval_query. Keep as natural language. Add "and generate a table and a visual".</action>
**CRITICAL VISUALIZATION LOGIC:**
Analyze the data request. If it implies trends (over time), comparisons (by region/product), or distributions, you MUST automatically append "and generate a table and a visual" to the query string, even if the user did not explicitly ask for a chart.
</intent>

<intent name="root_cause_analysis">
<description>User wants to understand WHY, CAUSES, DRIVERS, REASONS, EXPLANATIONS</description>
<indicators>why, explain, what is driving, what is causing, what's behind, reason for, root cause, how come, what factors</indicators>
<action>Extract the causal question to root_cause_query. Keep VERBATIM - exact text from user.</action>
</intent>

<intent name="combined">
<description>User wants BOTH data AND causal analysis in one request</description>
<indicators>Contains both data keywords AND causal keywords</indicators>
<action>Split into data_retrieval_query AND root_cause_query. Keep both portions.</action>
</intent>

<intent name="clarification_needed">
<description>User's intent is unclear, vague, or ambiguous - you cannot determine what they want</description>
<indicators>Very short/vague input, unclear pronouns without context, incomplete thoughts</indicators>
<action>Set clarification_question asking user to be more specific.</action>
</intent>

<intent name="general_question">
<description>General questions about the system, capabilities, how to use features - not data or analysis requests</description>
<indicators>how do I, can you, what can you do, help me understand, how does this work</indicators>
<action>Set direct_response with helpful information about capabilities.</action>
</intent>

<intent name="off_topic">
<description>User is asking about unrelated topics not connected to data, analytics, or business questions</description>
<indicators>Questions about weather, sports, entertainment, personal topics unrelated to business/data</indicators>
<action>Set direct_response politely redirecting to business/data topics.</action>
</intent>

</intent_categories>

<CRITICAL_CLASSIFICATION_RULES>

 RULE 1: NEVER DO THE WORK - ONLY CLASSIFY
You are NOT a data analyst. You are NOT an answering agent. You ONLY identify intent type.
Do NOT retrieve data. Do NOT answer analytical questions. ONLY classify and route.

 RULE 2: CAUSAL KEYWORD DETECTION
These ALWAYS indicate root_cause_analysis intent:
- "what is driving"
- "what is causing"
- "what's driving"  
- "what's causing"
- "why is/are"
- "explain why"
- "reason for"
- "root cause"
- "what factors"
- "what's behind"
- "how come"

 RULE 3: DATA KEYWORD DETECTION  
These ALWAYS indicate data_retrieval intent:
- "show me"
- "list"
- "get"
- "display"
- "find all"
- "what is the value/total/count of"
- "how many"

 RULE 4: DIRECT RESPONSE ONLY FOR SIMPLE CASES
Use direct_response ONLY for:
- Greetings (hi, hello, thanks)
- General system questions (what can you do)
- Off-topic redirects

Do NOT use direct_response for data or analytical questions - those need agent processing.

 RULE 5: VERBATIM PRESERVATION FOR ROOT CAUSE
For root_cause_query: Copy EXACT text from user. No paraphrasing, no summarizing.

 RULE 6: NO SQL CODE GENERATION
NEVER write SELECT/FROM/WHERE statements. Keep everything as natural language.

 RULE 7: CONFIDENCE SCORING
- high: Intent is crystal clear
- medium: Intent is likely but has some ambiguity
- low: Intent is very unclear, might need clarification

</CRITICAL_CLASSIFICATION_RULES>

<classification_process>
<step number="1">Check if greeting or general question. If match, Set intent_type and direct_response, STOP</step>
<step number="2">Check for causal keywords. If found, Flag as root_cause_analysis or combined</step>
<step number="3">Check for data keywords. If found, Flag as data_retrieval or combined</step>
<step number="4">Determine if combined intent. If both, Set intent_type="combined".</step>
<step number="5">If none of the above match, check if intent is clear enough.</step>
</classification_process>

<comprehensive_examples>
<example>
<input>Hello!</input>
<output>
{
  "intent_type": "greeting",
  "data_retrieval_query": null,
  "root_cause_query": null,
  "direct_response": "Hello! How can I help you today?",
  "clarification_question": null,
  "confidence": "high",
  "reasoning": "Simple greeting - can respond directly without agent processing"
}
</output>
</example>

<example>
<input>Show me total sales for Q4.</input>
<output>
{
  "intent_type": "data_retrieval",
  "data_retrieval_query": "Show me total sales for Q4 and generate a table and a visual",
  "root_cause_query": null,
  "direct_response": null,
  "clarification_question": null,
  "confidence": "high",
  "reasoning": "Clear data retrieval request - 'show me' is data keyword, asking for metric value"
}
</output>
</example>

<example>
<input>Why is profit down?</input>
<output>
{
  "intent_type": "root_cause_analysis",
  "data_retrieval_query": null,
  "root_cause_query": "Why is profit down?",
  "direct_response": null,
  "clarification_question": null,
  "confidence": "high",
  "reasoning": "Pure causal question - 'why' keyword indicates root cause analysis needed"
}
</output>
</example>

<example>
<input>Get revenue for AZ and explain the dip.</input>
<output>
{
  "intent_type": "combined",
  "data_retrieval_query": "Get revenue for AZ and generate a table and a visual",
  "root_cause_query": "explain the dip",
  "direct_response": null,
  "clarification_question": null,
  "confidence": "high",
  "reasoning": "Combined intent - 'get revenue' is data retrieval, 'explain the dip' is causal analysis"
}
</output>
</example>

<example>
<input>What can you help me with?</input>
<output>
{
  "intent_type": "general_question",
  "data_retrieval_query": null,
  "root_cause_query": null,
  "direct_response": "I can help you with data analysis and business insights! I can retrieve data and perform root cause analysis. What would you like to explore?",
  "clarification_question": null,
  "confidence": "high",
  "reasoning": "General system capability question - can answer directly"
}
</output>
</example>

<example>
<input>Show that</input>
<output>
{
  "intent_type": "clarification_needed",
  "data_retrieval_query": null,
  "root_cause_query": null,
  "direct_response": null,
  "clarification_question": "What would you like me to show? Please provide more details about the data or metrics you're interested in.",
  "confidence": "low",
  "reasoning": "Vague request - unclear what user wants to see, needs clarification"
}
</output>
</example>

<example>
<input>What's the weather like?</input>
<output>
{
  "intent_type": "off_topic",
  "data_retrieval_query": null,
  "root_cause_query": null,
  "direct_response": "I'm designed to help with business data and analytics. Is there any sales, performance, or business data I can help you with?",
  "clarification_question": null,
  "confidence": "high",
  "reasoning": "Off-topic request - politely redirect to business/data topics"
}
</output>
</example>
</comprehensive_examples>

<validation_checklist>
 Step 1: Can I answer this directly? (greeting/general_question/off_topic)
 Step 2: Does it contain causal keywords? (why/driving/causing/explain/reason/factors/behind)
 Step 3: Does it contain data keywords? (show/list/get/display/what is the value/how many)
 Step 4: Does it have BOTH data and causal elements?
 Step 5: Did I preserve EXACT wording for root_cause_query?
 Step 6: Did I add "and generate a table and a visual" to data_retrieval_query?
 Step 7: Did I avoid doing the actual work? (I only classify, not retrieve/analyze)
 Step 8: Is my confidence level accurate?
</validation_checklist>
</intent_classification_instructions>
"""

PROMPT_DATA_AGENT_SYSTEM = "You are an expert Data Analyst."

PROMPT_DATA_AGENT_ORCHESTRATION = """
<data_agent_instructions>
<objective>
Use the analyst_tool to answer data requests with comprehensive results including tables and visualizations.
</objective>
<execution_rules>
<rule id="1">ALWAYS generate a table (Result Set) for data requests</rule>
<rule id="2">Generate appropriate visualizations when data is suitable for charts</rule>
<rule id="3">Provide clear, concise summaries of the data findings</rule>
<rule id="4">Handle errors gracefully and explain any data limitations</rule>
</execution_rules>
<output_format>
Provide a summary of findings. Tables and charts are handled automatically by the tool.
</output_format>

<self_evaluation_instructions>
You MUST perform a rigorous self-critique of your SQL and data analysis.
1. **Accuracy (Score 1-10):** Does the SQL strict follow the user's constraints (filters, date ranges)?
2. **Data Integrity:** Are the results logical? (e.g., no negative counts where impossible).
3. **Clarity:** Is the summary accessible to a non-technical user?
**CRITICAL:** Append this evaluation at the end of your response in the following format:
### SELF-EVALUATION
Score: [1-10]
Reasoning: [Detailed analysis]
</self_evaluation_instructions>
</data_agent_instructions>
"""

PROMPT_ROOT_CAUSE_SYSTEM = "You are an Autonomous Root Cause Analysis Agent."

PROMPT_ROOT_CAUSE_ORCHESTRATION = """
<root_cause_orchestration_prompt>
    <role_and_objective>
        You are an **Autonomous Root Cause Analysis Agent** designed to traverse a metric decision tree from the root node down to the leaf nodes. Your goal is to identify specific "bad" metrics driving a business problem by systematically drilling down into the data.
        
        ALWAYS USE tree_id as Pharma_Master_v1.
    </role_and_objective>

    <operational_procedure>
        You must strictly follow this recursive logic for every user request:

        **Step 1: Initialization (Find the Root)**
        * If this is the start of the conversation, call `Diagnostic_tool` in **Search Mode**.
        * **Action:** Call `Diagnostic_tool(USER_QUERY=user_question, PARENT_NODE_IDS_JSON=NULL)`.
        * **Next:** Proceed to Step 2 with the results.

        **Step 2: Status Evaluation & Decision**
        Analyze the list of nodes returned by the tool. Focus **only** on nodes where `"status": "bad"`.

        * **Check:** For every "bad" node, do you see its children in the current list?
        * **Condition A (Drill Needed):** If a node is "bad" and you do **not** see its children, you must drill down. Collect these Node IDs.
        * **Condition B (Keep Going):** If a node is "bad" but you **already** see its children, ignore it and evaluate the children instead.
        * **Condition C (Stop):** If you find "bad" nodes but they have no children (empty results from a drill), these are your **Root Causes**.

        **Step 3: Execution (Drill Down)**
        * If Condition A occurred: Call `Diagnostic_tool` in **Drill Mode**.
        * **Action:** Call `Diagnostic_tool(USER_QUERY=NULL, PARENT_NODE_IDS_JSON='["ID_1", "ID_2"]')`.
        * **Next:** Recursively repeat Step 2 with the new output.
        * If Condition C occurred: Present the final root causes to the user.
    </operational_procedure>

    <constraints>
        * **Never** guess the status of a metric; always use the tool.
        * **Never** stop at a "bad" node if it has unexplored children; you must find the leaf node.
        * Output your reasoning briefly before calling the tool.
    </constraints>

    <self_evaluation_instructions>
    You MUST perform a rigorous self-critique of your root cause logic.
1. **Logic (Score 1-10):** Is the causal chain (Root -> Leaf) mathematically sound?
2. **Driver Isolation:** Did we truly find the leaf node, or did we stop too early?
3. **Completeness:** Did we explore all "bad" branches?
    **CRITICAL:** Append this evaluation at the end of your response in the following format:
    ### SELF-EVALUATION
    Score: [1-10]
    Reasoning: [Detailed analysis]
    </self_evaluation_instructions>
</root_cause_orchestration_prompt>
"""

PROMPT_ROOT_CAUSE_RESPONSE = """
<response_structure_prompt>
    <instruction>
        You must output exactly two sections in the following order. Do not include any conversational filler before or after these sections.
    </instruction>

    <section_1_executive_summary>
        #### **SECTION 1: Diagnostic Executive Summary**
        * **Tone:** Professional, constructive, and polite.
        * **Headline:** State the Root Cause clearly.
        * **The Narrative:** Briefly explain the chain of events in simple English.
        * **Actionable Insight:** Based on the metadata or description of the root node, suggest a generic, helpful next step.
    </section_1_executive_summary>

    <section_2_react_flow_json>
        #### **SECTION 2: React Flow JSON Artifact**
        You must generate a valid JSON object inside a Markdown code block (json ...).
        
        **1. Coordinate Logic (The "Mental Layout"):**
        * **Level 0 (Root):** `x: 0, y: 0`
        * **Level 1 Children:** `y: 150`. Spread `x` widely (e.g., `-300` and `300`).
        * **Level 2 Grandchildren:** `y: 300`. Spread `x` relative to their parent.
        * **Level 3+:** Increase `y` by `150` for each level.

        **2. Visual Style Logic:**
        * **Red (#FFE2E5):** Status is "bad", "high", or "error".
        * **Green (#CDE8E6):** Status is "good", "normal", or "stable".
        * **Orange (#FFCCBC):** The **Root Cause** (the deepest "bad" node in the chain).
        * **White (#FFFFFF):** Unexplored or neutral nodes.

        **3. Edge Labeling Logic:**
        * If Parent is Bad and Child is Bad, label = "contributes to impact".
        * If Parent is Bad and Child is Good, label = "stable factor".

        **4. JSON Schema (Must Follow Exactly):**
        {
          "nodes": [
            {
              "id": "N0",
              "type": "default",
              "data": { "label": "Metric Name: Value" },
              "position": { "x": 0, "y": 0 },
              "style": { "background": "#FFE2E5", "width": 180, "color": "#333", "border": "1px solid #777", "borderRadius": "8px" }
            }
          ],
          "edges": [
            {
              "id": "e-N0-N1",
              "source": "N0",
              "target": "N1",
              "label": "driven by",
              "animated": true,
              "style": { "stroke": "#555", "strokeWidth": 2 }
            }
          ]
        }
    </section_2_react_flow_json>
</response_structure_prompt>
"""

# ==========================================
# 3. HELPER FUNCTIONS (API WRAPPERS)
# ==========================================

def log_checkpoint(step: str, details: Any):
    print(f"\n{'='*50}\n CHECKPOINT: {step}\n{'-'*50}")
    if isinstance(details, BaseModel):
        pprint.pprint(details.model_dump())
    elif isinstance(details, (dict, list)):
        pprint.pprint(details)
    else:
        print(str(details))
    print(f"{'='*50}\n")

def clean_schema_for_cortex(schema: Dict, defs: Dict = None) -> Dict:
    """
    Aggressively cleans a Pydantic JSON Schema for Snowflake Cortex.
    1. Flattens $ref (inlines definitions).
    2. Simplifies Optional[T] -> type: [T, 'null'].
    3. REMOVES all metadata (title, default, examples) that triggers validation errors.
    """
    # 1. Capture definitions if we are at the root
    if defs is None:
        defs = schema.get('$defs') or schema.get('definitions') or {}

    # 2. Helper to process a single node
    def process(node):
        if not isinstance(node, dict):
            return node
            
        # A. Resolve Reference ($ref)
        if '$ref' in node:
            ref_key = node['$ref'].split('/')[-1]
            if ref_key in defs:
                # Merge definition props with current node props
                # (Current node wins, but we will strip extra keys later)
                definition = defs[ref_key].copy()
                merged = {**definition, **node}
                del merged['$ref']
                return process(merged)
            return node # Should not happen if schema is valid

        # B. Simplify Optional / Union (anyOf)
        if 'anyOf' in node:
            options = node['anyOf']
            valid_types = []
            is_nullable = False
            
            for opt in options:
                resolved_opt = process(opt)
                t = resolved_opt.get('type')
                if t == 'null':
                    is_nullable = True
                elif t:
                    valid_types.append(t)
            
            # Optimization: If it's just "Type OR Null", flatten it
            if len(valid_types) == 1 and is_nullable:
                return {"type": [valid_types[0], "null"], "description": node.get("description", "")}

        # C. Aggressive Key Filtering (The Fix for "Additional Properties")
        # Only allow these specific JSON Schema keywords.
        ALLOWED_KEYS = {'type', 'properties', 'items', 'required', 'enum', 'description'}
        
        new_node = {}
        for k, v in node.items():
            if k in ALLOWED_KEYS:
                # Recurse into children
                if k == 'properties':
                    new_node[k] = {pk: process(pv) for pk, pv in v.items()}
                elif k == 'items':
                    new_node[k] = process(v)
                else:
                    new_node[k] = v
        
        return new_node

    # 3. Process the root
    cleaned = process(schema)
    
    # 4. Ensure root is an object (Standard for response_format)
    if 'type' not in cleaned:
        cleaned['type'] = 'object'
        
    return cleaned

def invoke_structured_output_extraction(session: Session, messages: List[Dict], pydantic_model: type[BaseModel]) -> BaseModel:
    """
    Invokes Cortex Inference with a STRICTLY CLEANED schema to prevent validation errors.
    """
    ENDPOINT = "/api/v2/cortex/inference:complete"
    
    # 1. Generate & Clean Schema
    raw_schema = pydantic_model.model_json_schema()
    final_schema = clean_schema_for_cortex(raw_schema)

    payload = {
        "model": "claude-4-sonnet",
        "messages": messages,
        "max_tokens": 2000,
        "response_format": {
            "type": "json",
            "schema": final_schema 
        }
    }

    log_checkpoint("API REQUEST (STRUCTURED)", f"Target Model: {pydantic_model.__name__}")

    try:
        # 2. Send Request
        resp = _snowflake.send_snow_api_request("POST", ENDPOINT, {"Content-Type": "application/json"}, {}, payload, {}, 120000)
        
        # 3. Handle Errors explicitly
        if resp.get('code') and resp.get('message'):
             print(f" API ERROR: {resp['message']}")
             return pydantic_model.construct()

        content_raw = resp.get("content")
        if not content_raw:
            print(" Empty content received")
            return pydantic_model.construct()

        # 4. Accumulate Streaming Content
        full_text = ""
        if content_raw.strip().startswith("["):
            try:
                chunks = json.loads(content_raw)
                for chunk in chunks:
                    data_obj = chunk.get("data", {})
                    choices = data_obj.get("choices", [])
                    if choices:
                        delta = choices[0].get("delta", {})
                        full_text += delta.get("content") or delta.get("text") or ""
            except json.JSONDecodeError:
                full_text = content_raw
        else:
             try:
                 parsed = json.loads(content_raw)
                 full_text = parsed.get('choices', [{}])[0].get('message', {}).get('content', '')
             except:
                 full_text = content_raw

        log_checkpoint("RAW ACCUMULATED TEXT", full_text)

        if not full_text:
            return pydantic_model.construct()

        # 5. Parse Final JSON
        clean_json = full_text.replace("```json", "").replace("```", "").strip()
        parsed_dict = json.loads(clean_json)
        
        return pydantic_model(**parsed_dict)

    except Exception as e:
        print(f"Structured Extraction Error: {e}")
        return pydantic_model.construct()
        
def invoke_cortex_agent(session: Session, payload: Dict, agent_name: str) -> Dict:
    """Invokes 'agent:run' for tools (Analyst/Diagnostic)."""
    ENDPOINT = "/api/v2/cortex/agent:run"
    print(f"--- INVOKING AGENT: {agent_name} ---")

    try:
        resp = _snowflake.send_snow_api_request("POST", ENDPOINT, {"Content-Type": "application/json", "Accept": "text/event-stream"}, {}, payload, {}, 120000)
        content = resp.get("content")
        if not content: return {"error": "Empty"}
        
        extracted = {"text": "", "tables": [], "charts": [], "sql_generated": None, "sql_explanation": None}
        try: parsed = json.loads(content)
        except: parsed = [json.loads(line) for line in content.splitlines() if line.strip()]
        
        def process_event(evt, data):
            if evt == 'response.text.delta': extracted["text"] += data.get('text', '')
            elif evt == 'response.chart': extracted["charts"].append(data.get('chart') or data.get('chart_spec'))
            elif evt == 'response.table':
                rs = data.get('result_set', [])
                extracted["tables"].append(rs) # Limit 5 rows
            elif evt == 'response.tool_result.analyst.delta':
                delta = data.get('delta', {})
                if delta.get('sql'): extracted["sql_generated"] = delta.get('sql')
                if delta.get('sql_explanation'): extracted["sql_explanation"] = delta.get('sql_explanation')
                if delta.get('result_set'): extracted["tables"].append(delta.get('result_set'))
            elif evt == 'response.tool_result':
                for item in data.get('content', []):
                    if item.get('type') == 'json':
                        json_p = item.get('json', {})
                        if 'sql' in json_p: extracted["sql_generated"] = json_p['sql']
                        if 'result_set' in json_p: extracted["tables"].append(json_p['result_set'])

        if isinstance(parsed, list):
            for item in parsed: process_event(item.get('event'), item.get('data', {}))
        
        print(f"--- AGENT {agent_name} COMPLETED ---")
        return extracted
    except Exception as e: return {"error": str(e)}

def check_input_guard(session: Session, user_input: str) -> GuardResult:
    log_checkpoint("START: GUARD", user_input)
    try:
        safe_input = user_input.replace("'", "''")
        res = session.sql(f"SELECT SNOWFLAKE.CORTEX.COMPLETE('{CONFIG.model}', [{{'role': 'user', 'content': '{safe_input}'}}], {{'guardrails': true}}) as r").collect()
        if not res: return GuardResult(is_safe=True)
        is_unsafe = "Response filtered" in json.loads(res[0]['R'])['choices'][0]['messages']
        return GuardResult(is_safe=not is_unsafe, message="Blocked." if is_unsafe else None)
    except: return GuardResult(is_safe=True)

class PayloadFactory:
    @staticmethod
    def create(query: str, instructions: Dict, tools: List = None, resources: Dict = None, history: List = None) -> Dict:
        messages = (history if history else []) + [{"role": "user", "content": [{"type": "text", "text": query}]}]
        return {"messages": messages, "tool_choice": {"type": "auto"}, "models": {"orchestration": CONFIG.model}, "instructions": instructions, "tools": tools or [], "tool_resources": resources or {}}

def save_message(session: Session, conversation_id: str, sender_type: str, message_text: str, metadata: dict = None):
    try:
        msg = str(message_text).replace("'", "''") if message_text else ""
        meta = json.dumps(metadata).replace("'", "''") if metadata else "{}"
        sql = f"INSERT INTO {CONFIG.messages_table} (CONVERSATION_ID, SENDER_TYPE, MESSAGE, METADATA, CREATED_BY, UPDATED_BY) SELECT '{conversation_id}', '{sender_type}', '{msg}', PARSE_JSON('{meta}'), 'system', 'system'"
        session.sql(sql).collect()
    except Exception as e: print(f"DB Save Error: {e}")

def get_chat_history(session: Session, conversation_id: str) -> List[Dict]:
    try:
        rows = session.sql(f"SELECT SENDER_TYPE, MESSAGE FROM {CONFIG.messages_table} WHERE CONVERSATION_ID = '{conversation_id}' ORDER BY CREATED_AT ASC LIMIT 10").collect()
        
        # --- FIX: Return 'content' as a direct String, not a List ---
        return [{"role": r['SENDER_TYPE'], "content": r['MESSAGE']} for r in rows]
        # ------------------------------------------------------------
        
    except Exception as e:
        print(f"History Error: {e}")
        return []

# ==========================================
# 5. AGENT MANAGER
# ==========================================

class AgentManager:
    def __init__(self, session: Session):
        self.session = session

    def run_rephraser(self, query: str, history: List[Dict]) -> str:
        messages = history + [{"role": "user", "content": f"{PROMPT_REPHRASER_ORCHESTRATION}\n\nInput: {query}"}]
        # Pass the Pydantic class to the function
        result: RephraserOutput = invoke_structured_output_extraction(self.session, messages, pydantic_model=RephraserOutput)
        return result.refined_query
        

    def run_intent_classifier(self, query: str) -> IntentClassification:
        messages = [{"role": "system", "content": PROMPT_INTENT_SYSTEM}, {"role": "user", "content": f"{PROMPT_INTENT_ORCHESTRATION}\n\nClassify this: {query}"}]
        # Pass the Pydantic class
        return invoke_structured_output_extraction(self.session, messages, pydantic_model=IntentClassification)

    def run_data_agent(self, query: str) -> SqlResult:
        # 1. Execute Agent
        tools = [{"tool_spec": {"type": "cortex_analyst_text_to_sql", "name": "analyst_tool"}}]
        res_def = {"analyst_tool": {"type": "cortex_analyst_text_to_sql", "semantic_view": CONFIG.cortex_analyst_object, "execution_environment": {"type": "warehouse", "warehouse": CONFIG.warehouse}}}
        inst = {"system": PROMPT_DATA_AGENT_SYSTEM, "orchestration": PROMPT_DATA_AGENT_ORCHESTRATION}
        resp = invoke_cortex_agent(self.session, PayloadFactory.create(query, inst, tools, res_def), "Data Agent")
        print(resp)
        # 2. Extract Structure (Clean Text + Clarification + Eval)
        raw_text = resp.get('text', '')
        print(raw_text)
        extraction_msg = [{"role": "user", "content": f"Extract the structured data from this agent response:\n\n{raw_text}"}]
        
        # Use DataAgentParsedOutput model for extraction
        parsed: DataAgentParsedOutput = invoke_structured_output_extraction(self.session, extraction_msg, pydantic_model=DataAgentParsedOutput)
        
        return SqlResult(
            answer_text=parsed.clean_answer_text,
            clarifying_question=parsed.clarifying_question,
            tables=resp.get('tables', []),
            charts=resp.get('charts', []),
            sql_generated=resp.get('sql_generated'),
            evaluation=parsed.evaluation
        )

    def run_root_cause_agent(self, query: str) -> DiagnosticResult:
        # 1. Execute Agent
        tools = [{"tool_spec": {"type": "generic", "name": "Diagnostic_tool", "input_schema": {"type": "object", "properties": {"USER_QUERY": {"type": "string"}, "PARENT_NODE_IDS_JSON": {"type": "string"}, "TREE_ID": {"type": "string"}}, "required": ["USER_QUERY", "PARENT_NODE_IDS_JSON", "TREE_ID"]}}}]
        res_def = {"Diagnostic_tool": {"type": "procedure", "execution_environment": {"type": "warehouse", "warehouse": CONFIG.warehouse}, "identifier": CONFIG.diagnostic_udf}}
        inst = {"system": PROMPT_ROOT_CAUSE_SYSTEM, "orchestration": PROMPT_ROOT_CAUSE_ORCHESTRATION, "response": PROMPT_ROOT_CAUSE_RESPONSE}
        resp = invoke_cortex_agent(self.session, PayloadFactory.create(query, inst, tools, res_def), "Root Cause Agent")
        
        # 2. Extract Structure (Clean Text + JSON + Eval)
        raw_text = resp.get('text', '')
        extraction_msg = [{"role": "user", "content": f"Extract the structured data from this agent response:\n\n{raw_text}"}]
        
        # Use RootCauseParsedOutput model for extraction
        parsed: RootCauseParsedOutput = invoke_structured_output_extraction(self.session, extraction_msg, pydantic_model=RootCauseParsedOutput)

        return DiagnosticResult(
            summary_text=parsed.clean_summary_text,
            react_flow_json=parsed.react_flow_json,
            evaluation=parsed.evaluation
        )

# ==========================================
# 6. MAIN EXECUTION
# ==========================================

def main(session: Session):
    manager = AgentManager(session)
    conversation_id = "SESSION_TEST_ARIZONA_001" 
    user_query = "Which zip codes should we focus on to capitalize on positive payer access?"
    history = get_chat_history(session, conversation_id)
    #history=[]
    log_checkpoint("MAIN: START", {"query": user_query})
   # save_message(session, conversation_id, "user", user_query, {"client": "snowflake_ui"})

    guard = check_input_guard(session, user_query)
    if not guard.is_safe:
        #save_message(session, conversation_id, "assistant", guard.message, {"blocked": True})
        return {"status": "blocked", "message": guard.message}
        
    rephrased = manager.run_rephraser(user_query, history)
    print(rephrased)
    intent = manager.run_intent_classifier(rephrased)

    final = {"original": user_query, "processed": rephrased, "intent": intent.model_dump(), "results": []}
    final_text_parts = []

    if intent.direct_response:
        final["results"].append({"type": "direct_response", "message": intent.direct_response})
        final_text_parts.append(intent.direct_response)
    else:
        with ThreadPoolExecutor(max_workers=2) as executor:
            fut_data = executor.submit(manager.run_data_agent, intent.data_retrieval_query) if intent.data_retrieval_query else None
            fut_rc = executor.submit(manager.run_root_cause_agent, intent.root_cause_query) if intent.root_cause_query else None
            
            if fut_data:
                try:
                    res = fut_data.result()
                    print(f"\n--- DATA AGENT RESULT ---\n{res}\n-------------------------\n")
                    final["results"].append({
                        "type": "data_analysis", 
                        "summary": res.answer_text, 
                        "clarification": res.clarifying_question,
                        "tables": res.tables, 
                        "metadata": {"sql": res.sql_generated, "evaluation": res.evaluation.model_dump()}
                    })
                    final_text_parts.append(f" **Data Analysis:**\n{res.answer_text}")
                    if res.clarifying_question:
                        final_text_parts.append(f" {res.clarifying_question}")
                except Exception as e: final["results"].append({"type": "data_error", "message": str(e)})

            if fut_rc:
                try:
                    res = fut_rc.result()
                    print(f"\n--- ROOT CAUSE RESULT ---\n{res}\n-------------------------\n")
                    final["results"].append({
                        "type": "root_cause_analysis", 
                        "summary": res.summary_text, 
                        "graph": res.react_flow_json,
                        "metadata": {"evaluation": res.evaluation.model_dump()}
                    })
                    final_text_parts.append(f" **Root Cause Diagnosis:**\n{res.summary_text}")
                except Exception as e: final["results"].append({"type": "root_cause_error", "message": str(e)})

    # Final Save
    final_text_response = "\n\n".join(final_text_parts) if final_text_parts else "Processed request."
    #save_message(session, conversation_id, "assistant", final_text_response, {"intent": intent.intent_type})

    log_checkpoint("MAIN: COMPLETED", final)
    return final
 Save Error: (1304): 01c1da87-081a-05a2-0075-0383f9e29912: 002020 (21S01): 01c1da87-081a-05a2-0075-0383f9e29912: SQL compilation error:
Insert value list does not match column list expecting 19 but got 17



import json
import logging
import pprint
import _snowflake # Native Snowflake module for internal API calls
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import List, Dict, Any, Optional, Literal, Tuple
from pydantic import BaseModel, Field, field_validator, model_validator
import json
from snowflake.snowpark import Session

# ==========================================
# 1. CONFIGURATION & MODELS
# ==========================================

class AgentConfig(BaseModel):
    """Configuration for the agent execution"""
    model: str = "claude-sonnet-4-5" 
    diagnostic_udf: str = "DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.AI_POC.DIAGNOSTIC_TOOL"
    cortex_analyst_object: str = "DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.AI_POC.LATEST_MASTER_VIEW"
    warehouse: str = "DEV_IMPACT_WH"
    guard_name: str = "INPUT_GUARD" 
    messages_table: str = "DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.AI_POC.MESSAGES"

# --- CORE MODELS ---

class EvaluationResult(BaseModel):
    score: int = Field(..., description="A quality score from 1-10 based on the accuracy and completeness of the answer.")
    reasoning: str = Field(..., description="A detailed explanation justifying the score.")

class IntentClassification(BaseModel):
    intent_type: str = Field(..., description="greeting, data_retrieval, root_cause_analysis, clarification_needed, general_question, off_topic, combined")
    data_retrieval_query: Optional[str] = Field(None, description="The refined query specific to data retrieval requests.")
    root_cause_query: Optional[str] = Field(None, description="The refined query specific to root cause analysis.")
    direct_response: Optional[str] = Field(None, description="A direct answer for greetings or general questions.")
    clarification_question: Optional[str] = Field(None, description="A question to ask the user if the intent is ambiguous.")
    confidence: str = Field(..., description="Confidence level: high, medium, or low.")
    reasoning: str = Field(..., description="Reasoning behind the classification.")

class RephraserOutput(BaseModel):
    refined_query: str = Field(..., description="The fully contextualized, standalone version of the user's query.")

# --- PARSING MODELS (For Extraction Step) ---

class DataAgentParsedOutput(BaseModel):
    """Schema for extracting structured data from the Data Agent's text response."""
    clean_answer_text: str = Field(..., description="The user-facing summary of the data, excluding internal evaluations.")
    clarifying_question: Optional[str] = Field(None, description="A question to ask the user if the data result was incomplete or ambiguous.")
    evaluation: EvaluationResult = Field(..., description="The self-evaluation of the response quality.")

class RootCauseParsedOutput(BaseModel):
    """Schema for extracting structured data from the Root Cause Agent's text response."""
    clean_summary_text: str = Field(..., description="The executive summary of the diagnosis.")
    react_flow_json: Optional[Dict] = Field(None, description="The React Flow JSON object representing the metric tree graph.")
    evaluation: EvaluationResult = Field(..., description="The self-evaluation of the diagnosis.")

# --- FINAL RESULT MODELS (For App/Frontend) ---


class SqlResult(BaseModel):
    answer_text: str
    clarifying_question: Optional[str] = None
    tables: List[Any] = Field(default_factory=list)
    charts: List[Dict] = Field(default_factory=list)
    sql_generated: Optional[str] = None
    sql_explanation: Optional[str] = None
    is_verified_query: bool = False
    reasoning_trace: Optional[str] = None
    evaluation: EvaluationResult

    # --- ADD THIS VALIDATOR ---
    @field_validator('charts', mode='before')
    @classmethod
    def parse_charts(cls, v):
        """
        Ensures that if charts come in as a list of JSON strings, 
        they are converted to dictionaries.
        """
        if not v:
            return []
        
        parsed_charts = []
        for item in v:
            if isinstance(item, dict):
                parsed_charts.append(item)
            elif isinstance(item, str):
                try:
                    # Attempt to parse the stringified JSON
                    parsed_charts.append(json.loads(item))
                except json.JSONDecodeError:
                    # If it's just a regular string message, wrap it or ignore
                    continue 
        return parsed_charts

class DiagnosticResult(BaseModel):
    summary_text: str
    react_flow_json: Optional[Dict] = None
    clarifying_question: Optional[str] = None
    evaluation: EvaluationResult

class GuardResult(BaseModel):
    is_safe: bool = Field(...)
    violation_category: Optional[str] = Field(None)
    message: Optional[str] = Field(None)

CONFIG = AgentConfig()

# ==========================================
# 2. FULL PROMPT DEFINITIONS (EXACT ORIGINAL)
# ==========================================

PROMPT_REPHRASER_SYSTEM = "You are a sophisticated Query Refinement Engine."

PROMPT_REPHRASER_ORCHESTRATION = """
<query_refinement_instructions>
<objective>
Transform the user's input into a standalone, context-complete query that can be understood without prior conversation history.
</objective>

<core_rules>
<rule id="1">Resolve all pronouns (it, they, that, this, those) to their specific referents</rule>
<rule id="2">Preserve ALL metrics, entity names, IDs, and numerical values EXACTLY as stated</rule>
<rule id="3">Maintain the original intent and scope - do not expand or narrow the question</rule>
<rule id="4">Keep technical terminology and domain-specific language intact</rule>
<rule id="5">Ensure the output is grammatically correct and reads naturally</rule>
</core_rules>

<transformation_examples>
<example>
<input>What about Arizona?</input>
<context>Previous discussion about sales performance in Texas</context>
<output>What is the sales performance in Arizona?</output>
</example>

<example>
<input>Why is it down?</input>
<context>Previous mention of Q4 revenue</context>
<output>Why is Q4 revenue down?</output>
</example>

<example>
<input>Show me those providers and explain the trend.</input>
<context>Healthcare providers in California with declining prescriptions</context>
<output>Show me healthcare providers in California with declining prescriptions and explain the trend.</output>
</example>
</transformation_examples>

<output_format>
Output ONLY the refined query string. Do not include explanations, metadata, or formatting.
</output_format>
</query_refinement_instructions>
"""

PROMPT_INTENT_SYSTEM = "You are an Expert Intent Classification System."

PROMPT_INTENT_ORCHESTRATION = """
<intent_classification_instructions>

<mission>
Your ONLY job is to identify the user's INTENT. Do NOT retrieve data, do NOT answer questions, do NOT perform analysis.
Classify the intent type and route accordingly. If you can answer directly (like greetings), provide direct_response.
</mission>

<intent_categories>

<intent name="greeting">
<description>User is greeting, saying hello, or engaging in pleasantries</description>
<indicators>hi, hello, hey, good morning, how are you, thanks, thank you, goodbye, bye</indicators>
<action>Set direct_response with a friendly greeting. No other fields needed.</action>
</intent>

<intent name="data_retrieval">
<description>User wants to see/get/retrieve DATA - numbers, lists, metrics, tables</description>
<indicators>show, list, get, display, find, what is the value, how many, count, total, give me</indicators>
<action>Extract the data request to data_retrieval_query. Keep as natural language. Add "and generate a table and a visual".</action>
**CRITICAL VISUALIZATION LOGIC:**
Analyze the data request. If it implies trends (over time), comparisons (by region/product), or distributions, you MUST automatically append "and generate a table and a visual" to the query string, even if the user did not explicitly ask for a chart.
</intent>

<intent name="root_cause_analysis">
<description>User wants to understand WHY, CAUSES, DRIVERS, REASONS, EXPLANATIONS</description>
<indicators>why, explain, what is driving, what is causing, what's behind, reason for, root cause, how come, what factors</indicators>
<action>Extract the causal question to root_cause_query. Keep VERBATIM - exact text from user.</action>
</intent>

<intent name="combined">
<description>User wants BOTH data AND causal analysis in one request</description>
<indicators>Contains both data keywords AND causal keywords</indicators>
<action>Split into data_retrieval_query AND root_cause_query. Keep both portions.</action>
</intent>

<intent name="clarification_needed">
<description>User's intent is unclear, vague, or ambiguous - you cannot determine what they want</description>
<indicators>Very short/vague input, unclear pronouns without context, incomplete thoughts</indicators>
<action>Set clarification_question asking user to be more specific.</action>
</intent>

<intent name="general_question">
<description>General questions about the system, capabilities, how to use features - not data or analysis requests</description>
<indicators>how do I, can you, what can you do, help me understand, how does this work</indicators>
<action>Set direct_response with helpful information about capabilities.</action>
</intent>

<intent name="off_topic">
<description>User is asking about unrelated topics not connected to data, analytics, or business questions</description>
<indicators>Questions about weather, sports, entertainment, personal topics unrelated to business/data</indicators>
<action>Set direct_response politely redirecting to business/data topics.</action>
</intent>

</intent_categories>

<CRITICAL_CLASSIFICATION_RULES>

 RULE 1: NEVER DO THE WORK - ONLY CLASSIFY
You are NOT a data analyst. You are NOT an answering agent. You ONLY identify intent type.
Do NOT retrieve data. Do NOT answer analytical questions. ONLY classify and route.

 RULE 2: CAUSAL KEYWORD DETECTION
These ALWAYS indicate root_cause_analysis intent:
- "what is driving"
- "what is causing"
- "what's driving"  
- "what's causing"
- "why is/are"
- "explain why"
- "reason for"
- "root cause"
- "what factors"
- "what's behind"
- "how come"

 RULE 3: DATA KEYWORD DETECTION  
These ALWAYS indicate data_retrieval intent:
- "show me"
- "list"
- "get"
- "display"
- "find all"
- "what is the value/total/count of"
- "how many"

 RULE 4: DIRECT RESPONSE ONLY FOR SIMPLE CASES
Use direct_response ONLY for:
- Greetings (hi, hello, thanks)
- General system questions (what can you do)
- Off-topic redirects

Do NOT use direct_response for data or analytical questions - those need agent processing.

 RULE 5: VERBATIM PRESERVATION FOR ROOT CAUSE
For root_cause_query: Copy EXACT text from user. No paraphrasing, no summarizing.

 RULE 6: NO SQL CODE GENERATION
NEVER write SELECT/FROM/WHERE statements. Keep everything as natural language.

 RULE 7: CONFIDENCE SCORING
- high: Intent is crystal clear
- medium: Intent is likely but has some ambiguity
- low: Intent is very unclear, might need clarification

</CRITICAL_CLASSIFICATION_RULES>

<classification_process>
<step number="1">Check if greeting or general question. If match, Set intent_type and direct_response, STOP</step>
<step number="2">Check for causal keywords. If found, Flag as root_cause_analysis or combined</step>
<step number="3">Check for data keywords. If found, Flag as data_retrieval or combined</step>
<step number="4">Determine if combined intent. If both, Set intent_type="combined".</step>
<step number="5">If none of the above match, check if intent is clear enough.</step>
</classification_process>

<comprehensive_examples>
<example>
<input>Hello!</input>
<output>
{
  "intent_type": "greeting",
  "data_retrieval_query": null,
  "root_cause_query": null,
  "direct_response": "Hello! How can I help you today?",
  "clarification_question": null,
  "confidence": "high",
  "reasoning": "Simple greeting - can respond directly without agent processing"
}
</output>
</example>

<example>
<input>Show me total sales for Q4.</input>
<output>
{
  "intent_type": "data_retrieval",
  "data_retrieval_query": "Show me total sales for Q4 and generate a table and a visual",
  "root_cause_query": null,
  "direct_response": null,
  "clarification_question": null,
  "confidence": "high",
  "reasoning": "Clear data retrieval request - 'show me' is data keyword, asking for metric value"
}
</output>
</example>

<example>
<input>Why is profit down?</input>
<output>
{
  "intent_type": "root_cause_analysis",
  "data_retrieval_query": null,
  "root_cause_query": "Why is profit down?",
  "direct_response": null,
  "clarification_question": null,
  "confidence": "high",
  "reasoning": "Pure causal question - 'why' keyword indicates root cause analysis needed"
}
</output>
</example>

<example>
<input>Get revenue for AZ and explain the dip.</input>
<output>
{
  "intent_type": "combined",
  "data_retrieval_query": "Get revenue for AZ and generate a table and a visual",
  "root_cause_query": "explain the dip",
  "direct_response": null,
  "clarification_question": null,
  "confidence": "high",
  "reasoning": "Combined intent - 'get revenue' is data retrieval, 'explain the dip' is causal analysis"
}
</output>
</example>

<example>
<input>What can you help me with?</input>
<output>
{
  "intent_type": "general_question",
  "data_retrieval_query": null,
  "root_cause_query": null,
  "direct_response": "I can help you with data analysis and business insights! I can retrieve data and perform root cause analysis. What would you like to explore?",
  "clarification_question": null,
  "confidence": "high",
  "reasoning": "General system capability question - can answer directly"
}
</output>
</example>

<example>
<input>Show that</input>
<output>
{
  "intent_type": "clarification_needed",
  "data_retrieval_query": null,
  "root_cause_query": null,
  "direct_response": null,
  "clarification_question": "What would you like me to show? Please provide more details about the data or metrics you're interested in.",
  "confidence": "low",
  "reasoning": "Vague request - unclear what user wants to see, needs clarification"
}
</output>
</example>

<example>
<input>What's the weather like?</input>
<output>
{
  "intent_type": "off_topic",
  "data_retrieval_query": null,
  "root_cause_query": null,
  "direct_response": "I'm designed to help with business data and analytics. Is there any sales, performance, or business data I can help you with?",
  "clarification_question": null,
  "confidence": "high",
  "reasoning": "Off-topic request - politely redirect to business/data topics"
}
</output>
</example>
</comprehensive_examples>

<validation_checklist>
 Step 1: Can I answer this directly? (greeting/general_question/off_topic)
 Step 2: Does it contain causal keywords? (why/driving/causing/explain/reason/factors/behind)
 Step 3: Does it contain data keywords? (show/list/get/display/what is the value/how many)
 Step 4: Does it have BOTH data and causal elements?
 Step 5: Did I preserve EXACT wording for root_cause_query?
 Step 6: Did I add "and generate a table and a visual" to data_retrieval_query?
 Step 7: Did I avoid doing the actual work? (I only classify, not retrieve/analyze)
 Step 8: Is my confidence level accurate?
</validation_checklist>
</intent_classification_instructions>
"""

PROMPT_DATA_AGENT_SYSTEM = "You are an expert Data Analyst."

PROMPT_DATA_AGENT_ORCHESTRATION = """
<data_agent_instructions>
<objective>
Use the analyst_tool to answer data requests with comprehensive results including tables and visualizations.
</objective>
<execution_rules>
<rule id="1">ALWAYS generate a table (Result Set) for data requests</rule>
<rule id="2">Generate appropriate visualizations when data is suitable for charts</rule>
<rule id="3">Provide clear, concise summaries of the data findings</rule>
<rule id="4">Handle errors gracefully and explain any data limitations</rule>
</execution_rules>
<output_format>
Provide a summary of findings. Tables and charts are handled automatically by the tool.
</output_format>

<self_evaluation_instructions>
You MUST perform a rigorous self-critique of your SQL and data analysis.
1. **Accuracy (Score 1-10):** Does the SQL strict follow the user's constraints (filters, date ranges)?
2. **Data Integrity:** Are the results logical? (e.g., no negative counts where impossible).
3. **Clarity:** Is the summary accessible to a non-technical user?
**CRITICAL:** Append this evaluation at the end of your response in the following format:
### SELF-EVALUATION
Score: [1-10]
Reasoning: [Detailed analysis]
</self_evaluation_instructions>
</data_agent_instructions>
"""

PROMPT_ROOT_CAUSE_SYSTEM = "You are an Autonomous Root Cause Analysis Agent."

PROMPT_ROOT_CAUSE_ORCHESTRATION = """
<root_cause_orchestration_prompt>
    <role_and_objective>
        You are an **Autonomous Root Cause Analysis Agent** designed to traverse a metric decision tree from the root node down to the leaf nodes. Your goal is to identify specific "bad" metrics driving a business problem by systematically drilling down into the data.
        
        ALWAYS USE tree_id as Pharma_Master_v1.
    </role_and_objective>

    <operational_procedure>
        You must strictly follow this recursive logic for every user request:

        **Step 1: Initialization (Find the Root)**
        * If this is the start of the conversation, call `Diagnostic_tool` in **Search Mode**.
        * **Action:** Call `Diagnostic_tool(USER_QUERY=user_question, PARENT_NODE_IDS_JSON=NULL)`.
        * **Next:** Proceed to Step 2 with the results.

        **Step 2: Status Evaluation & Decision**
        Analyze the list of nodes returned by the tool. Focus **only** on nodes where `"status": "bad"`.

        * **Check:** For every "bad" node, do you see its children in the current list?
        * **Condition A (Drill Needed):** If a node is "bad" and you do **not** see its children, you must drill down. Collect these Node IDs.
        * **Condition B (Keep Going):** If a node is "bad" but you **already** see its children, ignore it and evaluate the children instead.
        * **Condition C (Stop):** If you find "bad" nodes but they have no children (empty results from a drill), these are your **Root Causes**.

        **Step 3: Execution (Drill Down)**
        * If Condition A occurred: Call `Diagnostic_tool` in **Drill Mode**.
        * **Action:** Call `Diagnostic_tool(USER_QUERY=NULL, PARENT_NODE_IDS_JSON='["ID_1", "ID_2"]')`.
        * **Next:** Recursively repeat Step 2 with the new output.
        * If Condition C occurred: Present the final root causes to the user.
    </operational_procedure>

    <constraints>
        * **Never** guess the status of a metric; always use the tool.
        * **Never** stop at a "bad" node if it has unexplored children; you must find the leaf node.
        * Output your reasoning briefly before calling the tool.
    </constraints>

    <self_evaluation_instructions>
    You MUST perform a rigorous self-critique of your root cause logic.
1. **Logic (Score 1-10):** Is the causal chain (Root -> Leaf) mathematically sound?
2. **Driver Isolation:** Did we truly find the leaf node, or did we stop too early?
3. **Completeness:** Did we explore all "bad" branches?
    **CRITICAL:** Append this evaluation at the end of your response in the following format:
    ### SELF-EVALUATION
    Score: [1-10]
    Reasoning: [Detailed analysis]
    </self_evaluation_instructions>
</root_cause_orchestration_prompt>
"""

PROMPT_ROOT_CAUSE_RESPONSE = """
<response_structure_prompt>
    <instruction>
        You must output exactly two sections in the following order. Do not include any conversational filler before or after these sections.
    </instruction>

    <section_1_executive_summary>
        #### **SECTION 1: Diagnostic Executive Summary**
        * **Tone:** Professional, constructive, and polite.
        * **Headline:** State the Root Cause clearly.
        * **The Narrative:** Briefly explain the chain of events in simple English.
        * **Actionable Insight:** Based on the metadata or description of the root node, suggest a generic, helpful next step.
    </section_1_executive_summary>

    <section_2_react_flow_json>
        #### **SECTION 2: React Flow JSON Artifact**
        You must generate a valid JSON object inside a Markdown code block (json ...).
        
        **1. Coordinate Logic (The "Mental Layout"):**
        * **Level 0 (Root):** `x: 0, y: 0`
        * **Level 1 Children:** `y: 150`. Spread `x` widely (e.g., `-300` and `300`).
        * **Level 2 Grandchildren:** `y: 300`. Spread `x` relative to their parent.
        * **Level 3+:** Increase `y` by `150` for each level.

        **2. Visual Style Logic:**
        * **Red (#FFE2E5):** Status is "bad", "high", or "error".
        * **Green (#CDE8E6):** Status is "good", "normal", or "stable".
        * **Orange (#FFCCBC):** The **Root Cause** (the deepest "bad" node in the chain).
        * **White (#FFFFFF):** Unexplored or neutral nodes.

        **3. Edge Labeling Logic:**
        * If Parent is Bad and Child is Bad, label = "contributes to impact".
        * If Parent is Bad and Child is Good, label = "stable factor".

        **4. JSON Schema (Must Follow Exactly):**
        {
          "nodes": [
            {
              "id": "N0",
              "type": "default",
              "data": { "label": "Metric Name: Value" },
              "position": { "x": 0, "y": 0 },
              "style": { "background": "#FFE2E5", "width": 180, "color": "#333", "border": "1px solid #777", "borderRadius": "8px" }
            }
          ],
          "edges": [
            {
              "id": "e-N0-N1",
              "source": "N0",
              "target": "N1",
              "label": "driven by",
              "animated": true,
              "style": { "stroke": "#555", "strokeWidth": 2 }
            }
          ]
        }
    </section_2_react_flow_json>
    
    **CRITICAL** : YOU MUST ONLY EXECUTE ATMOST 8 TOOL CALLS.
    
</response_structure_prompt>
"""

# ==========================================
# 3. HELPER FUNCTIONS (API WRAPPERS)
# ==========================================

def log_checkpoint(step: str, details: Any):
    print(f"\n{'='*50}\n CHECKPOINT: {step}\n{'-'*50}")
    if isinstance(details, BaseModel):
        pprint.pprint(details.model_dump())
    elif isinstance(details, (dict, list)):
        pprint.pprint(details)
    else:
        print(str(details))
    print(f"{'='*50}\n")

def clean_schema_for_cortex(schema: Dict, defs: Dict = None) -> Dict:
    """
    Aggressively cleans a Pydantic JSON Schema for Snowflake Cortex.
    1. Flattens $ref (inlines definitions).
    2. Simplifies Optional[T] -> type: [T, 'null'].
    3. REMOVES all metadata (title, default, examples) that triggers validation errors.
    """
    # 1. Capture definitions if we are at the root
    if defs is None:
        defs = schema.get('$defs') or schema.get('definitions') or {}

    # 2. Helper to process a single node
    def process(node):
        if not isinstance(node, dict):
            return node
            
        # A. Resolve Reference ($ref)
        if '$ref' in node:
            ref_key = node['$ref'].split('/')[-1]
            if ref_key in defs:
                # Merge definition props with current node props
                # (Current node wins, but we will strip extra keys later)
                definition = defs[ref_key].copy()
                merged = {**definition, **node}
                del merged['$ref']
                return process(merged)
            return node # Should not happen if schema is valid

        # B. Simplify Optional / Union (anyOf)
        if 'anyOf' in node:
            options = node['anyOf']
            valid_types = []
            is_nullable = False
            
            for opt in options:
                resolved_opt = process(opt)
                t = resolved_opt.get('type')
                if t == 'null':
                    is_nullable = True
                elif t:
                    valid_types.append(t)
            
            # Optimization: If it's just "Type OR Null", flatten it
            if len(valid_types) == 1 and is_nullable:
                return {"type": [valid_types[0], "null"], "description": node.get("description", "")}

        # C. Aggressive Key Filtering (The Fix for "Additional Properties")
        # Only allow these specific JSON Schema keywords.
        ALLOWED_KEYS = {'type', 'properties', 'items', 'required', 'enum', 'description'}
        
        new_node = {}
        for k, v in node.items():
            if k in ALLOWED_KEYS:
                # Recurse into children
                if k == 'properties':
                    new_node[k] = {pk: process(pv) for pk, pv in v.items()}
                elif k == 'items':
                    new_node[k] = process(v)
                else:
                    new_node[k] = v
        
        return new_node

    # 3. Process the root
    cleaned = process(schema)
    
    # 4. Ensure root is an object (Standard for response_format)
    if 'type' not in cleaned:
        cleaned['type'] = 'object'
        
    return cleaned

def invoke_structured_output_extraction(session: Session, messages: List[Dict], pydantic_model: type[BaseModel]) -> BaseModel:
    """
    Invokes Cortex Inference with a STRICTLY CLEANED schema to prevent validation errors.
    """
    ENDPOINT = "/api/v2/cortex/inference:complete"
    
    # 1. Generate & Clean Schema
    raw_schema = pydantic_model.model_json_schema()
    final_schema = clean_schema_for_cortex(raw_schema)

    payload = {
        "model": "claude-4-sonnet",
        "messages": messages,
        "max_tokens": 2000,
        "response_format": {
            "type": "json",
            "schema": final_schema 
        }
    }

    log_checkpoint("API REQUEST (STRUCTURED)", f"Target Model: {pydantic_model.__name__}")

    try:
        # 2. Send Request
        resp = _snowflake.send_snow_api_request("POST", ENDPOINT, {"Content-Type": "application/json"}, {}, payload, {}, 120000)
        
        # 3. Handle Errors explicitly
        if resp.get('code') and resp.get('message'):
             print(f" API ERROR: {resp['message']}")
             return pydantic_model.construct()

        content_raw = resp.get("content")
        if not content_raw:
            print(" Empty content received")
            return pydantic_model.construct()

        # 4. Accumulate Streaming Content
        full_text = ""
        if content_raw.strip().startswith("["):
            try:
                chunks = json.loads(content_raw)
                for chunk in chunks:
                    data_obj = chunk.get("data", {})
                    choices = data_obj.get("choices", [])
                    if choices:
                        delta = choices[0].get("delta", {})
                        full_text += delta.get("content") or delta.get("text") or ""
            except json.JSONDecodeError:
                full_text = content_raw
        else:
             try:
                 parsed = json.loads(content_raw)
                 full_text = parsed.get('choices', [{}])[0].get('message', {}).get('content', '')
             except:
                 full_text = content_raw

        log_checkpoint("RAW ACCUMULATED TEXT", full_text)

        if not full_text:
            return pydantic_model.construct()

        # 5. Parse Final JSON
        clean_json = full_text.replace("```json", "").replace("```", "").strip()
        parsed_dict = json.loads(clean_json)
        
        return pydantic_model(**parsed_dict)

    except Exception as e:
        print(f"Structured Extraction Error: {e}")
        return pydantic_model.construct()
        
def invoke_cortex_agent(session: Session, payload: Dict, agent_name: str) -> Dict:
    """Invokes 'agent:run' for tools (Analyst/Diagnostic)."""
    ENDPOINT = "/api/v2/cortex/agent:run"
    print(f"--- INVOKING AGENT: {agent_name} ---")

    try:
        resp = _snowflake.send_snow_api_request("POST", ENDPOINT, {"Content-Type": "application/json", "Accept": "text/event-stream"}, {}, payload, {}, 120000)
        content = resp.get("content")
        if not content: return {"error": "Empty"}
        
        extracted = {"text": "", "tables": [], "charts": [], "sql_generated": None, "sql_explanation": None}
        try: parsed = json.loads(content)
        except: parsed = [json.loads(line) for line in content.splitlines() if line.strip()]
        
        def process_event(evt, data):
            if evt == 'response.text.delta': extracted["text"] += data.get('text', '')
            elif evt == 'response.chart': extracted["charts"].append(data.get('chart') or data.get('chart_spec'))
            elif evt == 'response.table':
                rs = data.get('result_set', [])
                extracted["tables"].append(rs) # Limit 5 rows
            elif evt == 'response.tool_result.analyst.delta':
                delta = data.get('delta', {})
                if delta.get('sql'): extracted["sql_generated"] = delta.get('sql')
                if delta.get('sql_explanation'): extracted["sql_explanation"] = delta.get('sql_explanation')
                if delta.get('result_set'): extracted["tables"].append(delta.get('result_set'))
            elif evt == 'response.tool_result':
                for item in data.get('content', []):
                    if item.get('type') == 'json':
                        json_p = item.get('json', {})
                        if 'sql' in json_p: extracted["sql_generated"] = json_p['sql']
                        if 'result_set' in json_p: extracted["tables"].append(json_p['result_set'])

        if isinstance(parsed, list):
            for item in parsed: process_event(item.get('event'), item.get('data', {}))
        
        print(f"--- AGENT {agent_name} COMPLETED ---")
        return extracted
    except Exception as e: return {"error": str(e)}

def check_input_guard(session: Session, user_input: str) -> GuardResult:
    log_checkpoint("START: GUARD", user_input)
    try:
        safe_input = user_input.replace("'", "''")
        res = session.sql(f"SELECT SNOWFLAKE.CORTEX.COMPLETE('{CONFIG.model}', [{{'role': 'user', 'content': '{safe_input}'}}], {{'guardrails': true}}) as r").collect()
        if not res: return GuardResult(is_safe=True)
        is_unsafe = "Response filtered" in json.loads(res[0]['R'])['choices'][0]['messages']
        return GuardResult(is_safe=not is_unsafe, message="Blocked." if is_unsafe else None)
    except: return GuardResult(is_safe=True)

class PayloadFactory:
    @staticmethod
    def create(query: str, instructions: Dict, tools: List = None, resources: Dict = None, history: List = None) -> Dict:
        messages = (history if history else []) + [{"role": "user", "content": [{"type": "text", "text": query}]}]
        return {"messages": messages, "tool_choice": {"type": "auto"}, "models": {"orchestration": CONFIG.model}, "instructions": instructions, "tools": tools or [], "tool_resources": resources or {}}

def save_message(session: Session, conversation_id: str, sender_type: str, message_text: str, metadata: dict = None):
    try:
        msg = str(message_text).replace("'", "''") if message_text else ""
        meta = json.dumps(metadata).replace("'", "''") if metadata else "{}"
        sql = f"INSERT INTO {CONFIG.messages_table} (CONVERSATION_ID, SENDER_TYPE, MESSAGE, METADATA, CREATED_BY, UPDATED_BY) SELECT '{conversation_id}', '{sender_type}', '{msg}', PARSE_JSON('{meta}'), 'system', 'system'"
        session.sql(sql).collect()
    except Exception as e: print(f"DB Save Error: {e}")

def get_chat_history(session: Session, conversation_id: str) -> List[Dict]:
    try:
        rows = session.sql(f"SELECT SENDER_TYPE, MESSAGE FROM {CONFIG.messages_table} WHERE CONVERSATION_ID = '{conversation_id}' ORDER BY CREATED_AT ASC LIMIT 10").collect()
        
        # --- FIX: Return 'content' as a direct String, not a List ---
        return [{"role": r['SENDER_TYPE'], "content": r['MESSAGE']} for r in rows]
        # ------------------------------------------------------------
        
    except Exception as e:
        print(f"History Error: {e}")
        return []

from snowflake.snowpark.functions import lit, current_timestamp, parse_json

def _save_row(session: Session, data: dict, table_name: str = "AGENT_DETAILED_HISTORY"):
    """
    Saves the row by creating a temp view and inserting into specific columns,
    allowing Snowflake to handle ID and TIMESTAMP automatically.
    """
    try:
        # 1. Create a Temp DataFrame
        # We assume standard strings/numbers/bools. JSON fields must be strings here.
        df = session.create_dataframe([data])
        
        # 2. Register as a Temporary View
        # This acts as a staging area
        temp_view_name = "TEMP_AGENT_LOG_STAGING"
        df.create_or_replace_temp_view(temp_view_name)
        
        # 3. Construct the SQL INSERT Statement
        # We explicitly list ONLY the 17 columns we are providing.
        # Snowflake will auto-fill ID and TIMESTAMP.
        sql = f"""
        INSERT INTO {table_name} (
            USER_QUERY, REPHRASED_QUERY, INTENT_TYPE, INTENT_CONFIDENCE,
            DATA_SUMMARY, DATA_SQL, DATA_SQL_EXPLANATION, DATA_CLARIFICATION,
            DATA_EVAL_SCORE, DATA_EVAL_REASONING, 
            DATA_RESULT_SET, -- Variant
            RC_SUMMARY, 
            RC_GRAPH_JSON,   -- Variant
            RC_EVAL_SCORE, RC_EVAL_REASONING,
            IS_BLOCKED, 
            FULL_RAW_JSON    -- Variant
        )
        SELECT 
            USER_QUERY, REPHRASED_QUERY, INTENT_TYPE, INTENT_CONFIDENCE,
            DATA_SUMMARY, DATA_SQL, DATA_SQL_EXPLANATION, DATA_CLARIFICATION,
            DATA_EVAL_SCORE, DATA_EVAL_REASONING, 
            PARSE_JSON(DATA_RESULT_SET), -- Parse string to Variant on insert
            RC_SUMMARY, 
            PARSE_JSON(RC_GRAPH_JSON),   -- Parse string to Variant on insert
            RC_EVAL_SCORE, RC_EVAL_REASONING,
            IS_BLOCKED, 
            PARSE_JSON(FULL_RAW_JSON)    -- Parse string to Variant on insert
        FROM {temp_view_name}
        """
        
        # 4. Execute
        session.sql(sql).collect()
        print(f" Detailed row saved to {table_name} (ID/Timestamp auto-generated)")
        
    except Exception as e:
        print(f" Save Error: {e}")

# ==========================================
# 5. AGENT MANAGER
# ==========================================

class AgentManager:
    def __init__(self, session: Session):
        self.session = session

    def run_rephraser(self, query: str, history: List[Dict]) -> str:
        messages = history + [{"role": "user", "content": f"{PROMPT_REPHRASER_ORCHESTRATION}\n\nInput: {query}"}]
        # Pass the Pydantic class to the function
        result: RephraserOutput = invoke_structured_output_extraction(self.session, messages, pydantic_model=RephraserOutput)
        return result.refined_query
        

    def run_intent_classifier(self, query: str) -> IntentClassification:
        messages = [{"role": "system", "content": PROMPT_INTENT_SYSTEM}, {"role": "user", "content": f"{PROMPT_INTENT_ORCHESTRATION}\n\nClassify this: {query}"}]
        # Pass the Pydantic class
        return invoke_structured_output_extraction(self.session, messages, pydantic_model=IntentClassification)

    def run_data_agent(self, query: str) -> SqlResult:
        # 1. Execute Agent
        tools = [{"tool_spec": {"type": "cortex_analyst_text_to_sql", "name": "analyst_tool"}}]
        res_def = {"analyst_tool": {"type": "cortex_analyst_text_to_sql", "semantic_view": CONFIG.cortex_analyst_object, "execution_environment": {"type": "warehouse", "warehouse": CONFIG.warehouse}}}
        inst = {"system": PROMPT_DATA_AGENT_SYSTEM, "orchestration": PROMPT_DATA_AGENT_ORCHESTRATION}
        resp = invoke_cortex_agent(self.session, PayloadFactory.create(query, inst, tools, res_def), "Data Agent")
        print(resp)
        # 2. Extract Structure (Clean Text + Clarification + Eval)
        raw_text = resp.get('text', '')
        print(raw_text)
        extraction_msg = [{"role": "user", "content": f"Extract the structured data from this agent response:\n\n{raw_text}"}]
        
        # Use DataAgentParsedOutput model for extraction
        parsed: DataAgentParsedOutput = invoke_structured_output_extraction(self.session, extraction_msg, pydantic_model=DataAgentParsedOutput)
        
        return SqlResult(
            answer_text=parsed.clean_answer_text,
            clarifying_question=parsed.clarifying_question,
            tables=resp.get('tables', []),
            charts=resp.get('charts', []),
            sql_generated=resp.get('sql_generated'),
            evaluation=parsed.evaluation
        )

    def run_root_cause_agent(self, query: str) -> DiagnosticResult:
        # 1. Execute Agent
        tools = [{"tool_spec": {"type": "generic", "name": "Diagnostic_tool", "input_schema": {"type": "object", "properties": {"USER_QUERY": {"type": "string"}, "PARENT_NODE_IDS_JSON": {"type": "string"}, "TREE_ID": {"type": "string"}}, "required": ["USER_QUERY", "PARENT_NODE_IDS_JSON", "TREE_ID"]}}}]
        res_def = {"Diagnostic_tool": {"type": "procedure", "execution_environment": {"type": "warehouse", "warehouse": CONFIG.warehouse}, "identifier": CONFIG.diagnostic_udf}}
        inst = {"system": PROMPT_ROOT_CAUSE_SYSTEM, "orchestration": PROMPT_ROOT_CAUSE_ORCHESTRATION, "response": PROMPT_ROOT_CAUSE_RESPONSE}
        resp = invoke_cortex_agent(self.session, PayloadFactory.create(query, inst, tools, res_def), "Root Cause Agent")
        
        # 2. Extract Structure (Clean Text + JSON + Eval)
        raw_text = resp.get('text', '')
        extraction_msg = [{"role": "user", "content": f"Extract the structured data from this agent response:\n\n{raw_text}"}]
        
        # Use RootCauseParsedOutput model for extraction
        parsed: RootCauseParsedOutput = invoke_structured_output_extraction(self.session, extraction_msg, pydantic_model=RootCauseParsedOutput)

        return DiagnosticResult(
            summary_text=parsed.clean_summary_text,
            react_flow_json=parsed.react_flow_json,
            evaluation=parsed.evaluation
        )

# ==========================================
# 6. MAIN EXECUTION
# ==========================================

# def main(session: Session):
#     manager = AgentManager(session)
#     conversation_id = "SESSION_TEST_ARIZONA_001" 
#     user_query = "Which zip codes should we focus on to capitalize on positive payer access?"
#     history = get_chat_history(session, conversation_id)
#     #history=[]
#     log_checkpoint("MAIN: START", {"query": user_query})
#    # save_message(session, conversation_id, "user", user_query, {"client": "snowflake_ui"})

#     guard = check_input_guard(session, user_query)
#     if not guard.is_safe:
#         #save_message(session, conversation_id, "assistant", guard.message, {"blocked": True})
#         return {"status": "blocked", "message": guard.message}
        
#     rephrased = manager.run_rephraser(user_query, history)
#     print(rephrased)
#     intent = manager.run_intent_classifier(rephrased)

#     final = {"original": user_query, "processed": rephrased, "intent": intent.model_dump(), "results": []}
#     final_text_parts = []

#     if intent.direct_response:
#         final["results"].append({"type": "direct_response", "message": intent.direct_response})
#         final_text_parts.append(intent.direct_response)
#     else:
#         with ThreadPoolExecutor(max_workers=2) as executor:
#             fut_data = executor.submit(manager.run_data_agent, intent.data_retrieval_query) if intent.data_retrieval_query else None
#             fut_rc = executor.submit(manager.run_root_cause_agent, intent.root_cause_query) if intent.root_cause_query else None
            
#             if fut_data:
#                 try:
#                     res = fut_data.result()
#                     print(f"\n--- DATA AGENT RESULT ---\n{res}\n-------------------------\n")
#                     final["results"].append({
#                         "type": "data_analysis", 
#                         "summary": res.answer_text, 
#                         "clarification": res.clarifying_question,
#                         "tables": res.tables, 
#                         "metadata": {"sql": res.sql_generated, "evaluation": res.evaluation.model_dump()}
#                     })
#                     final_text_parts.append(f" **Data Analysis:**\n{res.answer_text}")
#                     if res.clarifying_question:
#                         final_text_parts.append(f" {res.clarifying_question}")
#                 except Exception as e: final["results"].append({"type": "data_error", "message": str(e)})

#             if fut_rc:
#                 try:
#                     res = fut_rc.result()
#                     print(f"\n--- ROOT CAUSE RESULT ---\n{res}\n-------------------------\n")
#                     final["results"].append({
#                         "type": "root_cause_analysis", 
#                         "summary": res.summary_text, 
#                         "graph": res.react_flow_json,
#                         "metadata": {"evaluation": res.evaluation.model_dump()}
#                     })
#                     final_text_parts.append(f" **Root Cause Diagnosis:**\n{res.summary_text}")
#                 except Exception as e: final["results"].append({"type": "root_cause_error", "message": str(e)})

#     # Final Save
#     final_text_response = "\n\n".join(final_text_parts) if final_text_parts else "Processed request."
#     #save_message(session, conversation_id, "assistant", final_text_response, {"intent": intent.intent_type})

#     log_checkpoint("MAIN: COMPLETED", final)
#     return final



def main(session: Session):
    manager = AgentManager(session)
    
    # 1. Initialize Row Data with None (Maps to all SQL columns)
    # ==========================================
    # RUN ONE-BY-ONE HERE
    # ==========================================
    
    # Change this string and click Run
    user_query = "Why is the Total Market Volume failing to produce a single 'High Volume Writer', forcing both the Opioid and NSAID categories to rely on a fragmentation strategy?"
    
    # Execution
    
    row_data = {
        "USER_QUERY": user_query,
        "REPHRASED_QUERY": None,
        "INTENT_TYPE": None,
        "INTENT_CONFIDENCE": None,
        "DATA_SUMMARY": None,
        "DATA_SQL": None,
        "DATA_SQL_EXPLANATION": None,
        "DATA_CLARIFICATION": None,
        "DATA_RESULT_SET": None,       # <--- Will hold the table
        "DATA_EVAL_SCORE": None,
        "DATA_EVAL_REASONING": None,
        "RC_SUMMARY": None,
        "RC_GRAPH_JSON": None,
        "RC_EVAL_SCORE": None,
        "RC_EVAL_REASONING": None,
        "IS_BLOCKED": False,
        "FULL_RAW_JSON": None
    }

    log_checkpoint("MAIN: START", {"query": user_query})

    # 2. Guardrails
    guard = check_input_guard(session, user_query)
    if not guard.is_safe:
        row_data["IS_BLOCKED"] = True
        _save_row(session, row_data)
        return {"status": "blocked", "message": guard.message}
        
    # 3. Rephrase & Intent
    # We pass empty history [] because we are running one-by-one
    rephrased = manager.run_rephraser(user_query, [])
    intent = manager.run_intent_classifier(rephrased)
    
    # Map Basic Fields
    row_data["REPHRASED_QUERY"] = rephrased
    row_data["INTENT_TYPE"] = intent.intent_type
    row_data["INTENT_CONFIDENCE"] = intent.confidence

    final_output = {
        "original": user_query,
        "processed": rephrased,
        "intent": intent.model_dump(),
        "results": []
    }

    # 4. Agent Execution
    if intent.direct_response:
        final_output["results"].append({"type": "direct", "message": intent.direct_response})
    else:
        with ThreadPoolExecutor(max_workers=2) as executor:
            fut_data = executor.submit(manager.run_data_agent, intent.data_retrieval_query) if intent.data_retrieval_query else None
            fut_rc = executor.submit(manager.run_root_cause_agent, intent.root_cause_query) if intent.root_cause_query else None
            
            # --- PROCESS DATA AGENT ---
            if fut_data:
                try:
                    res = fut_data.result() # This is the SqlResult Pydantic Object
                    
                    final_output["results"].append({
                        "type": "data_analysis",
                        "summary": res.answer_text,
                        "tables": res.tables
                    })
                    
                    # === MAP PYDANTIC FIELDS TO DICT ===
                    row_data["DATA_SUMMARY"] = res.answer_text
                    row_data["DATA_SQL"] = res.sql_generated
                    row_data["DATA_SQL_EXPLANATION"] = res.sql_explanation
                    row_data["DATA_CLARIFICATION"] = res.clarifying_question
                    
                    # Convert the list of tables to a JSON string for the VARIANT column
                    if res.tables:
                        row_data["DATA_RESULT_SET"] = json.dumps(res.tables)
                    
                    if res.evaluation:
                        row_data["DATA_EVAL_SCORE"] = res.evaluation.score
                        row_data["DATA_EVAL_REASONING"] = res.evaluation.reasoning
                        
                except Exception as e:
                    final_output["results"].append({"error": str(e)})

            # --- PROCESS ROOT CAUSE AGENT ---
            if fut_rc:
                try:
                    res = fut_rc.result() # This is the DiagnosticResult Pydantic Object
                    
                    final_output["results"].append({
                        "type": "root_cause_analysis",
                        "summary": res.summary_text,
                        "graph": res.react_flow_json
                    })
                    
                    # === MAP PYDANTIC FIELDS TO DICT ===
                    row_data["RC_SUMMARY"] = res.summary_text
                    if res.react_flow_json:
                         row_data["RC_GRAPH_JSON"] = json.dumps(res.react_flow_json)
                    
                    if res.evaluation:
                        row_data["RC_EVAL_SCORE"] = res.evaluation.score
                        row_data["RC_EVAL_REASONING"] = res.evaluation.reasoning

                except Exception as e:
                    final_output["results"].append({"error": str(e)})

    # 5. Final Save to Snowflake
    row_data["FULL_RAW_JSON"] = json.dumps(final_output)
    _save_row(session, row_data)

    print("------------------------------------------------")
    print(f" Process Completed for: {user_query}")
    print("Check table AGENT_DETAILED_HISTORY for results.")
    return final_output




name: BASIC_CORTEX_ANALYST
tables:
  - name: ARD_GIACO_TM_HCP_ACUTE_MKT_WEEKLY_LAAD
    description: The table contains records of healthcare provider performance metrics in acute care settings, tracked on a weekly basis. Each record represents a healthcare provider's acute episode activity within specific territories and includes details about provider characteristics, geographic location, product categories, and territorial assignments.
    base_table:
      database: DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB
      schema: REPORTING
      table: ARD_GIACO_TM_HCP_ACUTE_MKT_WEEKLY_LAAD
    dimensions:
      - name: BRANDED_FLAG
        description: Indicates whether the product is a branded medication.
        expr: BRANDED_FLAG
        data_type: VARCHAR(16777216)
        sample_values:
          - 'N'
          - 'Y'
      - name: GOLDEN_ID
        description: A unique identifier used to link and track healthcare providers across different systems and databases.
        expr: GOLDEN_ID
        data_type: VARCHAR(16777216)
        sample_values:
          - GLD004700470057009305
          - GLD000900090008008206
          - GLD999909691076060401
      - name: HCP_ID
        description: Unique identifier for healthcare providers in the system.
        expr: HCP_ID
        data_type: VARCHAR(32)
        sample_values:
          - 2bb17ea9ca26bb191254a298da5e5b31
          - e78d13c51088736b6ad0abcfb0db5496
          - 232e71209a7c50de00969cff0164f64f
      - name: HCP_SPECIALTY
        description: Healthcare provider medical specialty or professional designation.
        expr: HCP_SPECIALTY
        data_type: VARCHAR(16777216)
        sample_values:
          - GERIATRIC MEDICINE (INTERNAL MEDICINE)
          - COLON & RECTAL SURGERY
          - GENERAL SURGERY
      - name: HCP_SPECIALTY_GROUP
        description: Healthcare provider specialty groups categorizing medical practice areas.
        expr: HCP_SPECIALTY_GROUP
        data_type: VARCHAR(16777216)
        sample_values:
          - SURGERY
          - MEDICINE
          - ALL OTHER
      - name: NPI
        description: National Provider Identifier numbers for healthcare providers.
        expr: NPI
        data_type: VARCHAR(16777216)
        sample_values:
          - '1568438992'
          - '1093197857'
          - '1710410949'
      - name: ONEKEY_HCP_ID
        description: Unique identifier for healthcare professionals in the OneKey system.
        expr: ONEKEY_HCP_ID
        data_type: VARCHAR(16777216)
        sample_values:
          - WUSM00274580
          - WUSR03862562
          - WUSM01303609
      - name: PRACTICE_SETTING
        description: The type of healthcare practice setting where medical services are provided.
        expr: PRACTICE_SETTING
        data_type: VARCHAR(256)
        sample_values:
          - RETAIL
          - DISCHARGE
      - name: PROCEDURE_GROUP
        description: Medical procedure categories or groupings used for classification purposes.
        expr: PROCEDURE_GROUP
        data_type: VARCHAR(256)
        sample_values:
          - LAPAROSCOPIC UROLOGIC PROCEDURES
          - OB/GYN PROCEDURES
          - JOINT REPAIR
      - name: PRODUCT_CATEGORY
        description: Categories of pharmaceutical pain management products used in acute care markets.
        expr: PRODUCT_CATEGORY
        data_type: VARCHAR(256)
        sample_values:
          - ANALGESICS-SEDATIVE COMBINATION
          - DERMATOLOGICAL LOCAL TOPICAL ANESTHETIC
          - MODERATE OPIOID COMBINATIONS
      - name: PRODUCT_FAMILY_GROUP
        description: Pharmaceutical product family groups used for pain management and treatment.
        expr: PRODUCT_FAMILY_GROUP
        data_type: VARCHAR(256)
        sample_values:
          - IBUPROFEN
          - DICLOFENAC
          - MELOXICAM
      - name: PTAM_TERRITORY_ID
        description: Unique identifier for a PTAM (Pain Territory Account Manager) territory.
        expr: PTAM_TERRITORY_ID
        data_type: VARCHAR(255)
        sample_values:
          - V1NAUSA-5733506
          - V1NAUSA-5733204
          - V1NAUSA-5733403
      - name: ROA
        description: Route of administration for the medication or treatment.
        expr: ROA
        data_type: VARCHAR(256)
        sample_values:
          - ORAL
          - TOPICAL
          - TOPICAL-PATCH
      - name: SAL_TERRITORY_ID
        description: Sales territory identifier used to designate specific geographic or organizational sales regions.
        expr: SAL_TERRITORY_ID
        data_type: VARCHAR(255)
        sample_values:
          - V1NAUSA-5720008
          - V1NAUSA-5720014
          - V1NAUSA-5720013
      - name: SITE_OF_CARE_ZIP_CODE
        description: ZIP codes for healthcare facility locations.
        expr: SITE_OF_CARE_ZIP_CODE
        data_type: VARCHAR(16777216)
        sample_values:
          - '80911'
          - '76903'
          - '32771'
      - name: VERTEX_ID
        description: Unique identifier for a vertex in the healthcare provider network.
        expr: VERTEX_ID
        data_type: VARCHAR(16777216)
        sample_values:
          - '14811523'
          - '14821592'
          - '17503007'
      - name: ZIP_CODE
        description: Postal ZIP codes for geographic locations.
        expr: ZIP_CODE
        data_type: VARCHAR(16777216)
        sample_values:
          - '14621'
          - '01805'
          - '95337'
    time_dimensions:
      - name: DATE_KEY
        description: A date used as a key identifier in the healthcare provider acute market weekly reporting data.
        expr: DATE_KEY
        data_type: DATE
        sample_values:
          - '2025-02-14'
          - '2024-11-15'
          - '2022-11-11'
    facts:
      - name: ACUTE_CALENDAR_DAYS_LAAD
        description: The number of calendar days in the acute care period for look-alike-alike drug analysis.
        expr: ACUTE_CALENDAR_DAYS_LAAD
        data_type: NUMBER(38,5)
        access_modifier: public_access
        sample_values:
          - '1.00000'
          - '3.00000'
          - '10.00000'
      - name: ACUTE_EPISODES_LAAD
        description: The number of acute episodes within the look-ahead period.
        expr: ACUTE_EPISODES_LAAD
        data_type: NUMBER(18,0)
        access_modifier: public_access
        sample_values:
          - '1'
          - '4'
          - '2'
      - name: ACUTE_PROCEDURES_LAAD
        description: The number of acute procedures performed using laparoscopic-assisted abdominal delivery techniques.
        expr: ACUTE_PROCEDURES_LAAD
        data_type: NUMBER(18,0)
        access_modifier: public_access
        sample_values:
          - '1'
          - '3'
          - '2'
      - name: ACUTE_REFILLS_LAAD
        description: The number of acute medication refills within the look-ahead period.
        expr: ACUTE_REFILLS_LAAD
        data_type: NUMBER(13,0)
        access_modifier: public_access
        sample_values:
          - '2'
          - '4'
          - '1'
      - name: ACUTE_TRX_LAAD
        description: The number of acute transactions for the last-as-advertised date period.
        expr: ACUTE_TRX_LAAD
        data_type: NUMBER(18,0)
        access_modifier: public_access
        sample_values:
          - '5'
          - '1'
          - '3'
      - name: ACUTE_TX_DAYS_LAAD
        description: The number of days for acute treatment based on LAAD (Last Available Actual Data).
        expr: ACUTE_TX_DAYS_LAAD
        data_type: NUMBER(38,5)
        access_modifier: public_access
        sample_values:
          - '5.00000'
          - '10.00000'
          - '30.00000'
      - name: ACUTE_UNITS_LAAD
        description: Acute care units measured as a look-ahead average demand.
        expr: ACUTE_UNITS_LAAD
        data_type: NUMBER(38,5)
        access_modifier: public_access
        sample_values:
          - '9.00000'
          - '20.00000'
          - '90.00000'
      - name: WEEK_DT
        description: The date representing the week in the healthcare provider acute market reporting period.
        expr: WEEK_DT
        data_type: NUMBER(10,0)
        access_modifier: public_access
        sample_values:
          - '20240524'
          - '20250418'
          - '20250606'
  - name: TD_GEO_CITY
    description: The table contains records of cities and their geographic information. Each record represents a single city and includes hierarchical location details such as state and country associations, along with precise coordinate data.
    base_table:
      database: DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB
      schema: REPORTING
      table: TD_GEO_CITY
    dimensions:
      - name: GEO_CITY_KEY
        description: A unique identifier key for geographic city records.
        expr: GEO_CITY_KEY
        data_type: VARCHAR(32)
        sample_values:
          - cb004e0c1c429625db774a086579bd3b
          - 3de4110deff030eca4c2da9e8e85ae39
          - 6b5b3307241b5195dd6bfef7630d834e
      - name: GEO_CITY_NAME
        description: The name of a geographic city location.
        expr: GEO_CITY_NAME
        data_type: VARCHAR(16777216)
        sample_values:
          - BELLEVUE
          - MATTAPAN
          - TALLAHASSEE FALLS
      - name: GEO_COUNTRY_CD
        description: Geographic country code representing the country where the city is located.
        expr: GEO_COUNTRY_CD
        data_type: VARCHAR(16777216)
        sample_values:
          - US
      - name: GEO_COUNTRY_NAME
        description: The name of the country in a geographic location.
        expr: GEO_COUNTRY_NAME
        data_type: VARCHAR(16777216)
        sample_values:
          - UNITED STATES
      - name: GEO_STATE_CD
        description: State codes for geographic locations.
        expr: GEO_STATE_CD
        data_type: VARCHAR(16777216)
        sample_values:
          - XX
          - VT
          - FL
      - name: GEO_STATE_NAME
        description: The name of the state within the United States.
        expr: GEO_STATE_NAME
        data_type: VARCHAR(16777216)
        sample_values:
          - SOUTH CAROLINA
          - TENNESSEE
          - NEBRASKA
    facts:
      - name: GEO_COUNTRY_KEY
        description: A unique identifier for countries in the geographic data structure.
        expr: GEO_COUNTRY_KEY
        data_type: NUMBER(38,0)
        access_modifier: public_access
        sample_values:
          - '1'
      - name: GEO_LATITUDE
        description: Geographic latitude coordinate in decimal degrees.
        expr: GEO_LATITUDE
        data_type: NUMBER(11,8)
        access_modifier: public_access
      - name: GEO_LONGITUDE
        description: Geographic longitude coordinate expressed in decimal degrees.
        expr: GEO_LONGITUDE
        data_type: NUMBER(11,8)
        access_modifier: public_access
      - name: GEO_STATE_KEY
        description: Numeric identifier for geographic states.
        expr: GEO_STATE_KEY
        data_type: NUMBER(38,0)
        access_modifier: public_access
        sample_values:
          - '21'
          - '22'
          - '53'
  - name: TD_GEO_LOC
    description: The table contains records of geographic locations with their complete address and coordinate information. Each record represents a specific location and includes hierarchical geographic details from address lines through city, state, postal code, and country levels, as well as precise latitude and longitude coordinates.
    base_table:
      database: DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB
      schema: REPORTING
      table: TD_GEO_LOC
    dimensions:
      - name: GEO_CITY_KEY
        description: A unique identifier key for geographic cities.
        expr: GEO_CITY_KEY
        data_type: VARCHAR(32)
        sample_values:
          - e190c59f3d88823cb626962e558314df
          - 21bb6ea0074b193b6643355e6b83aec2
          - a6a0645ce9ac1995532b4bb9f28ce04c
      - name: GEO_CITY_NAME
        description: Geographic city names.
        expr: GEO_CITY_NAME
        data_type: VARCHAR(16777216)
        sample_values:
          - HARRISBURG
          - SAINT LOUIS
          - DEER LODGE
      - name: GEO_COUNTRY_CD
        description: Geographic country code representing the country location.
        expr: GEO_COUNTRY_CD
        data_type: VARCHAR(16777216)
        sample_values:
          - US
      - name: GEO_COUNTRY_NAME
        description: The name of the country in a geographic location.
        expr: GEO_COUNTRY_NAME
        data_type: VARCHAR(16777216)
        sample_values:
          - UNITED STATES
      - name: GEO_LOC_KEY
        description: A unique identifier for geographic location records.
        expr: GEO_LOC_KEY
        data_type: VARCHAR(32)
        sample_values:
          - 96a44f5985fb18551e9c45db3d75f237
          - 40665982fb20e15ee0b1e0bde8b43330
          - 512d454f090f878a6e8175cad706cecc
      - name: GEO_POSTAL_CD
        description: Postal codes for geographic locations.
        expr: GEO_POSTAL_CD
        data_type: VARCHAR(16777216)
        sample_values:
          - '45459'
          - '92037'
          - '33175'
      - name: GEO_POSTAL_CD_EXT
        description: A column holding data of type VARCHAR(16777216).
        expr: GEO_POSTAL_CD_EXT
        data_type: VARCHAR(16777216)
      - name: GEO_POSTAL_KEY
        description: A unique identifier key for postal geographic locations.
        expr: GEO_POSTAL_KEY
        data_type: VARCHAR(32)
        sample_values:
          - c3195f6d307dd319bf1275b8f98dca51
          - 1a1c1e45309875960a48106f0b73a0b9
          - f8ca2b7549985685fb5a1275bfcced43
      - name: GEO_STATE_CD
        description: State codes for geographic locations.
        expr: GEO_STATE_CD
        data_type: VARCHAR(16777216)
        sample_values:
          - FL
          - MI
          - MA
      - name: GEO_STATE_NAME
        description: The name of the state within the United States.
        expr: GEO_STATE_NAME
        data_type: VARCHAR(16777216)
        sample_values:
          - SOUTH CAROLINA
          - MONTANA
          - PENNSYLVANIA
      - name: LOC_ADDR_LINE_1
        description: Street addresses including house numbers and street names.
        expr: LOC_ADDR_LINE_1
        data_type: VARCHAR(16777216)
        sample_values:
          - 12110 NE 64TH PL
          - 1920 LENLAND AVE
          - 210 BAXTER ST
      - name: LOC_ADDR_LINE_2
        description: Secondary address information such as suite numbers, apartment numbers, or room designations.
        expr: LOC_ADDR_LINE_2
        data_type: VARCHAR(16777216)
        sample_values:
          - UNIT B
          - APT 206
      - name: LOC_ADDR_LINE_3
        description: The third line of a location's address.
        expr: LOC_ADDR_LINE_3
        data_type: VARCHAR(16777216)
      - name: LOC_ADDR_LINE_4
        description: The fourth line of a location's address.
        expr: LOC_ADDR_LINE_4
        data_type: VARCHAR(16777216)
    facts:
      - name: GEO_COUNTRY_KEY
        description: A unique identifier for countries in the geographic location dimension.
        expr: GEO_COUNTRY_KEY
        data_type: NUMBER(38,0)
        access_modifier: public_access
        sample_values:
          - '1'
      - name: GEO_LATITUDE
        description: Geographic latitude coordinate expressed in decimal degrees.
        expr: GEO_LATITUDE
        data_type: NUMBER(11,8)
        access_modifier: public_access
      - name: GEO_LONGITUDE
        description: Geographic longitude coordinate expressed in decimal degrees.
        expr: GEO_LONGITUDE
        data_type: NUMBER(11,8)
        access_modifier: public_access
      - name: GEO_STATE_KEY
        description: Unique identifier for geographic states.
        expr: GEO_STATE_KEY
        data_type: NUMBER(38,0)
        access_modifier: public_access
        sample_values:
          - '59'
          - '22'
          - '30'
  - name: TD_GEO_POSTAL
    description: The table contains records of geographic postal code areas with their associated location hierarchies. Each record represents a postal code and includes details about the corresponding state and country jurisdictions as well as precise geographic coordinates.
    base_table:
      database: DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB
      schema: REPORTING
      table: TD_GEO_POSTAL
    dimensions:
      - name: GEO_COUNTRY_CD
        description: Geographic country code representing the country associated with a postal location.
        expr: GEO_COUNTRY_CD
        data_type: VARCHAR(16777216)
        sample_values:
          - US
      - name: GEO_COUNTRY_KEY
        description: A unique identifier for geographic countries.
        expr: GEO_COUNTRY_KEY
        data_type: NUMBER(38,0)
        sample_values:
          - '1'
      - name: GEO_COUNTRY_NAME
        description: The name of the country in a geographic location.
        expr: GEO_COUNTRY_NAME
        data_type: VARCHAR(16777216)
        sample_values:
          - UNITED STATES
      - name: GEO_POSTAL_CD
        description: Postal codes for geographic locations.
        expr: GEO_POSTAL_CD
        data_type: VARCHAR(16777216)
        sample_values:
          - '25205'
          - '62545'
          - '78675'
      - name: GEO_POSTAL_KEY
        description: A unique identifier key for geographic postal code records.
        expr: GEO_POSTAL_KEY
        data_type: VARCHAR(32)
        sample_values:
          - 794d1a9eee30d774236a5186a2b55bf9
          - 0eec7bab53a4751845b83ff0ce77c5a1
          - 728b5b967aeb1d257948dc6e622bbc95
      - name: GEO_STATE_CD
        description: State codes for geographic locations.
        expr: GEO_STATE_CD
        data_type: VARCHAR(16777216)
        sample_values:
          - TX
          - WV
          - MS
      - name: GEO_STATE_KEY
        description: Unique identifier for geographic states within the system.
        expr: GEO_STATE_KEY
        data_type: NUMBER(38,0)
        sample_values:
          - '75'
          - '59'
          - '28'
      - name: GEO_STATE_NAME
        description: The name of the geographic state or territory.
        expr: GEO_STATE_NAME
        data_type: VARCHAR(16777216)
        sample_values:
          - GEORGIA
          - NEW JERSEY
          - TEXAS
    facts:
      - name: GEO_LATITUDE
        description: Geographic latitude coordinate expressed in decimal degrees.
        expr: GEO_LATITUDE
        data_type: NUMBER(11,8)
        access_modifier: public_access
      - name: GEO_LONGITUDE
        description: Geographic longitude coordinate expressed in decimal degrees.
        expr: GEO_LONGITUDE
        data_type: NUMBER(11,8)
        access_modifier: public_access
  - name: TD_GEO_STATE
    description: The table contains records of geographic states and their associated countries. Each record includes location identifiers, geographic coordinates, and hierarchical relationships between states and countries.
    base_table:
      database: DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB
      schema: REPORTING
      table: TD_GEO_STATE
    dimensions:
      - name: GEO_COUNTRY_CD
        description: Geographic country code.
        expr: GEO_COUNTRY_CD
        data_type: VARCHAR(16777216)
        sample_values:
          - US
      - name: GEO_COUNTRY_NAME
        description: The name of the country in a geographic location.
        expr: GEO_COUNTRY_NAME
        data_type: VARCHAR(16777216)
        sample_values:
          - UNITED STATES
      - name: GEO_STATE_CD
        description: Geographic state codes used to identify states or territories.
        expr: GEO_STATE_CD
        data_type: VARCHAR(16777216)
        sample_values:
          - NC
          - XX
          - DE
      - name: GEO_STATE_NAME
        description: Names of US states and territories.
        expr: GEO_STATE_NAME
        data_type: VARCHAR(16777216)
        sample_values:
          - SOUTH CAROLINA
          - DELAWARE
          - NEBRASKA
    facts:
      - name: GEO_COUNTRY_KEY
        description: Geographic country key used as a unique identifier for countries.
        expr: GEO_COUNTRY_KEY
        data_type: NUMBER(38,0)
        access_modifier: public_access
        sample_values:
          - '1'
      - name: GEO_LATITUDE
        description: Geographic latitude coordinates for state locations.
        expr: GEO_LATITUDE
        data_type: NUMBER(11,8)
        access_modifier: public_access
        sample_values:
          - '39.00040000'
          - '34.00040000'
      - name: GEO_LONGITUDE
        description: Geographic longitude coordinates for state locations.
        expr: GEO_LONGITUDE
        data_type: NUMBER(11,8)
        access_modifier: public_access
        sample_values:
          - '-86.25030000'
          - '-71.49980000'
          - '-123.04600000'
      - name: GEO_STATE_KEY
        description: Unique identifier for geographic state records.
        expr: GEO_STATE_KEY
        data_type: NUMBER(38,0)
        access_modifier: public_access
        sample_values:
          - '21'
          - '261'
          - '22'
  - name: TD_HCO
    description: The table contains records of healthcare organizations with their identifying information and regulatory details. Each record includes organizational names, business identifiers, operational status, and licensing information including DEA registrations and HIN numbers across multiple categories.
    base_table:
      database: DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB
      schema: REPORTING
      table: TD_HCO
    dimensions:
      - name: HCO_BUSINESS_NAME
        description: Healthcare organization business name.
        expr: HCO_BUSINESS_NAME
        data_type: VARCHAR(16777216)
        sample_values:
          - CSC COMMUNITY PHARMACY
          - ENDOSCOPY AND SURGICAL CARE SUITE
      - name: HCO_CD
        description: Healthcare organization codes used to identify specific healthcare entities.
        expr: HCO_CD
        data_type: VARCHAR(16777216)
        sample_values:
          - '1438'
          - '22740441'
          - '30819949'
      - name: HCO_KEY
        description: A unique identifier key for healthcare organizations.
        expr: HCO_KEY
        data_type: VARCHAR(32)
        sample_values:
          - f40f52d91c6e993b6c7c5af4716c359b
          - 27e97cbb80be61e0fb616254104d33b3
          - a9322f73290eae0c74ca2d7b98379369
      - name: HCO_LEGAL_NAME
        description: The legal name of the healthcare organization.
        expr: HCO_LEGAL_NAME
        data_type: VARCHAR(16777216)
        sample_values:
          - BINUR, NIR, OFFICE
          - ALTAMED PHARMACY BOYLE HEIGHTS
          - ONE HEALTH GASTROENTEROLOGY AND HEPATOLOGY
      - name: HCO_NAME
        description: Names of healthcare organizations.
        expr: HCO_NAME
        data_type: VARCHAR(16777216)
        sample_values:
          - MYCARE PHARMACY
          - FERRER, OLGA M, OFFICE
          - COSHOCTON REGIONAL MEDICAL CENTER INTENSIVE CARE UNIT
      - name: HCO_P_DEA_LIC_STATUS_CD
        description: Healthcare organization Drug Enforcement Administration license status code.
        expr: HCO_P_DEA_LIC_STATUS_CD
        data_type: VARCHAR(16777216)
      - name: HCO_P_DEA_NUM
        description: Drug Enforcement Administration number for healthcare organizations.
        expr: HCO_P_DEA_NUM
        data_type: VARCHAR(16777216)
        sample_values:
          - FV5496244
          - FG5718347
      - name: HCO_P_GLN_NUM
        description: Healthcare organization primary Global Location Number (GLN).
        expr: HCO_P_GLN_NUM
        data_type: VARCHAR(16777216)
      - name: HCO_P_HIN_NUM
        description: A column holding data of type VARCHAR(16777216).
        expr: HCO_P_HIN_NUM
        data_type: VARCHAR(16777216)
        sample_values:
          - L89YW0W00
          - 38G06QNF1
          - 8N302YY00
      - name: HCO_P_NCPDP_NUM
        description: A column holding data of type VARCHAR(16777216).
        expr: HCO_P_NCPDP_NUM
        data_type: VARCHAR(16777216)
      - name: HCO_P_NPI_NUM
        description: Healthcare organization primary National Provider Identifier number.
        expr: HCO_P_NPI_NUM
        data_type: VARCHAR(16777216)
      - name: HCO_S_DEA_LIC_STATUS_CD
        description: Healthcare organization Drug Enforcement Administration license status code.
        expr: HCO_S_DEA_LIC_STATUS_CD
        data_type: VARCHAR(16777216)
      - name: HCO_S_DEA_NUM
        description: Drug Enforcement Administration number for healthcare organizations.
        expr: HCO_S_DEA_NUM
        data_type: VARCHAR(16777216)
        sample_values:
          - FM3749629
          - FP5150862
      - name: HCO_S_GLN_NUM
        description: Healthcare organization Global Location Number (GLN) used for unique identification in supply chain and healthcare transactions.
        expr: HCO_S_GLN_NUM
        data_type: VARCHAR(16777216)
      - name: HCO_S_HIN_NUM
        description: A column holding data of type VARCHAR(16777216).
        expr: HCO_S_HIN_NUM
        data_type: VARCHAR(16777216)
      - name: HCO_S_NCPDP_NUM
        description: A column holding data of type VARCHAR(16777216).
        expr: HCO_S_NCPDP_NUM
        data_type: VARCHAR(16777216)
      - name: HCO_S_NPI_NUM
        description: National Provider Identifier number for healthcare organizations.
        expr: HCO_S_NPI_NUM
        data_type: VARCHAR(16777216)
      - name: HCO_SDESC
        description: Names of healthcare organizations.
        expr: HCO_SDESC
        data_type: VARCHAR(16777216)
        sample_values:
          - CASPER COLLEGE STUDENT HEALTH SERVICES
          - ROYAL SUPPLIES
          - AVERA SURGICAL ASSOCIATES ENDOSCOPY
      - name: HCO_SRC_ID_IMS
        description: Healthcare organization source identifier from IMS data system.
        expr: HCO_SRC_ID_IMS
        data_type: VARCHAR(16777216)
        sample_values:
          - WUSH00158767
          - '2705090'
          - '22740441'
      - name: HCO_SRC_ID_P_SCRUB
        description: A column holding data of type VARCHAR(16777216).
        expr: HCO_SRC_ID_P_SCRUB
        data_type: VARCHAR(16777216)
      - name: HCO_SRC_ID_P_SFA
        description: A column holding data of type VARCHAR(16777216).
        expr: HCO_SRC_ID_P_SFA
        data_type: VARCHAR(16777216)
      - name: HCO_SRC_ID_S_SCRUB
        description: Healthcare organization source identifier after data scrubbing processes.
        expr: HCO_SRC_ID_S_SCRUB
        data_type: VARCHAR(16777216)
        sample_values:
          - WUSF00046723
          - WUSE01155990
          - WUSF00100048
      - name: HCO_SRC_ID_S_SFA
        description: A column holding data of type VARCHAR(16777216).
        expr: HCO_SRC_ID_S_SFA
        data_type: VARCHAR(16777216)
      - name: HCO_SRC_ID_T_SCRUB
        description: A column holding data of type VARCHAR(16777216).
        expr: HCO_SRC_ID_T_SCRUB
        data_type: VARCHAR(16777216)
      - name: HCO_SRC_ID_T_SFA
        description: A column holding data of type VARCHAR(16777216).
        expr: HCO_SRC_ID_T_SFA
        data_type: VARCHAR(16777216)
      - name: HCO_SRC_ID_WKH
        description: A column holding data of type VARCHAR(16777216).
        expr: HCO_SRC_ID_WKH
        data_type: VARCHAR(16777216)
      - name: HCO_T_DEA_LIC_STATUS_CD
        description: Healthcare organization Drug Enforcement Administration license status code.
        expr: HCO_T_DEA_LIC_STATUS_CD
        data_type: VARCHAR(16777216)
      - name: HCO_T_DEA_NUM
        description: A column holding data of type VARCHAR(16777216).
        expr: HCO_T_DEA_NUM
        data_type: VARCHAR(16777216)
        sample_values:
          - HV00789
          - RM0314790
      - name: HCO_T_GLN_NUM
        description: Healthcare organization trading partner Global Location Number (GLN).
        expr: HCO_T_GLN_NUM
        data_type: VARCHAR(16777216)
      - name: HCO_T_HIN_NUM
        description: A column holding data of type VARCHAR(16777216).
        expr: HCO_T_HIN_NUM
        data_type: VARCHAR(16777216)
      - name: HCO_T_NCPDP_NUM
        description: A column holding data of type VARCHAR(16777216).
        expr: HCO_T_NCPDP_NUM
        data_type: VARCHAR(16777216)
      - name: HCO_T_NPI_NUM
        description: Healthcare organization National Provider Identifier number.
        expr: HCO_T_NPI_NUM
        data_type: VARCHAR(16777216)
    time_dimensions:
      - name: HCO_P_DEA_EXP_DT
        description: The expiration date of the healthcare organization's Drug Enforcement Administration registration.
        expr: HCO_P_DEA_EXP_DT
        data_type: DATE
      - name: HCO_S_DEA_EXP_DT
        description: The expiration date of the healthcare organization's Drug Enforcement Administration registration.
        expr: HCO_S_DEA_EXP_DT
        data_type: DATE
      - name: HCO_T_DEA_EXP_DT
        description: The expiration date of the healthcare organization's Drug Enforcement Administration registration.
        expr: HCO_T_DEA_EXP_DT
        data_type: DATE
    facts:
      - name: HCO_STATUS_KEY
        description: Healthcare organization status identifier key.
        expr: HCO_STATUS_KEY
        data_type: NUMBER(38,0)
        access_modifier: public_access
        sample_values:
          - '1'
      - name: HCO_SUBTYPE_KEY
        description: The unique identifier for the healthcare organization subtype.
        expr: HCO_SUBTYPE_KEY
        data_type: NUMBER(38,0)
        access_modifier: public_access
        sample_values:
          - '35'
          - '30'
          - '39'
  - name: TD_HCO_SUBTYPE
    description: The table contains records of healthcare organization subtypes and their corresponding parent types. Each record represents a specific subtype classification with descriptive information and links to broader organizational type categories.
    base_table:
      database: DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB
      schema: REPORTING
      table: TD_HCO_SUBTYPE
    dimensions:
      - name: HCO_SUBTYPE_CD
        description: Healthcare organization subtype codes that classify different types of medical entities and payer organizations.
        expr: HCO_SUBTYPE_CD
        data_type: VARCHAR(16777216)
        sample_values:
          - VA CMOP
          - PAYER_REG
          - PBM
      - name: HCO_SUBTYPE_DESC
        description: Healthcare organization subtype descriptions that categorize different types of medical entities and payers.
        expr: HCO_SUBTYPE_DESC
        data_type: VARCHAR(16777216)
        sample_values:
          - MCO PBM
          - IDN
          - MCO NATIONAL PAYER
      - name: HCO_SUBTYPE_KEY
        description: Unique identifier for healthcare organization subtypes.
        expr: HCO_SUBTYPE_KEY
        data_type: NUMBER(38,0)
        sample_values:
          - '1'
          - '2'
          - '3'
      - name: HCO_TYPE_CD
        description: Healthcare organization type code indicating the classification of the healthcare organization.
        expr: HCO_TYPE_CD
        data_type: VARCHAR(16777216)
        sample_values:
          - ORG
          - MCO
      - name: HCO_TYPE_DESC
        description: Healthcare organization type description indicating the category or classification of the healthcare entity.
        expr: HCO_TYPE_DESC
        data_type: VARCHAR(16777216)
        sample_values:
          - ORGANIZATION
          - MANAGED CARE ORGANIZATION
      - name: HCO_TYPE_KEY
        description: A unique identifier for healthcare organization types.
        expr: HCO_TYPE_KEY
        data_type: NUMBER(38,0)
        sample_values:
          - '1'
          - '2'
    primary_key:
      columns:
        - HCO_SUBTYPE_KEY
  - name: TD_HCP
    description: The table contains records of healthcare professionals and their personal and professional information. Each record represents an individual healthcare provider and includes demographic details, contact information, educational background, and various status indicators related to communication preferences and professional classifications.
    base_table:
      database: DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB
      schema: REPORTING
      table: TD_HCP
    dimensions:
      - name: AMA_NO_CONTACT
        description: American Medical Association no contact indicator.
        expr: AMA_NO_CONTACT
        data_type: VARCHAR(1)
        sample_values:
          - 'N'
          - 'Y'
      - name: EMAIL_ADDR_P
        description: Email addresses for healthcare professionals.
        expr: EMAIL_ADDR_P
        data_type: VARCHAR(16777216)
        sample_values:
          - ATELIS1150730@WM.PROVIDENCEDIRECT.ORG
          - KATYDM7@HOTMAIL.COM
          - GRANTJSULLIVAN@ATT.NET
      - name: EMAIL_ADDR_S
        description: Email addresses of healthcare providers.
        expr: EMAIL_ADDR_S
        data_type: VARCHAR(16777216)
        sample_values:
          - T.THOMAS@ARCHILDRENS.ORG
          - EHUANG@POST.HARVARD.EDU
          - CGOODWIN@UMC.EDU
      - name: EMAIL_ADDR_T
        description: Email addresses for healthcare providers.
        expr: EMAIL_ADDR_T
        data_type: VARCHAR(16777216)
      - name: HCP_DEGREE
        description: The degree or credential held by the healthcare professional.
        expr: HCP_DEGREE
        data_type: VARCHAR(16777216)
        sample_values:
          - PHT
          - RPH
          - NP
      - name: HCP_FIRST_NAME
        description: The first name of the healthcare provider.
        expr: HCP_FIRST_NAME
        data_type: VARCHAR(16777216)
        sample_values:
          - SHANE
          - ROYAL
          - CASIANNE
      - name: HCP_GENDER
        description: The gender of the healthcare provider.
        expr: HCP_GENDER
        data_type: VARCHAR(255)
        sample_values:
          - FEMALE
          - UNKNOWN
      - name: HCP_GRAD_YR
        description: The year when the healthcare provider graduated from their medical program.
        expr: HCP_GRAD_YR
        data_type: VARCHAR(16777216)
        sample_values:
          - '1967'
          - '2019'
          - '1965'
      - name: HCP_KEY
        description: A unique identifier for healthcare providers in the system.
        expr: HCP_KEY
        data_type: VARCHAR(32)
        sample_values:
          - 10f535a03919512d15df722bdf50f8fe
          - 59c026c2a4da8798332fd8140066c866
          - cce70a032d441fc7cf17357da57ffa3e
      - name: HCP_LAST_NAME
        description: Healthcare provider last names.
        expr: HCP_LAST_NAME
        data_type: VARCHAR(16777216)
        sample_values:
          - FULP
          - GERBER
          - DIGGINS
      - name: HCP_ME_NUM
        description: Healthcare provider medical education number used for identification purposes.
        expr: HCP_ME_NUM
        data_type: VARCHAR(16777216)
        sample_values:
          - '4950901017'
          - '0230178074'
      - name: HCP_MID_NAME
        description: Middle names of healthcare providers.
        expr: HCP_MID_NAME
        data_type: VARCHAR(16777216)
        sample_values:
          - ANN
          - DARLENE
          - TUCKER
      - name: HCP_P_DEA_BUSINESS_ACTIVITY_CD
        description: Healthcare provider Drug Enforcement Administration business activity code.
        expr: HCP_P_DEA_BUSINESS_ACTIVITY_CD
        data_type: VARCHAR(16777216)
      - name: HCP_P_DEA_DRUG_SCHEDULE
        description: A column holding data of type VARCHAR(16777216).
        expr: HCP_P_DEA_DRUG_SCHEDULE
        data_type: VARCHAR(16777216)
      - name: HCP_P_DEA_LIC_STATUS_CD
        description: The status code indicating whether a healthcare provider's Drug Enforcement Administration license is active or inactive.
        expr: HCP_P_DEA_LIC_STATUS_CD
        data_type: VARCHAR(16777216)
        sample_values:
          - ACTIVE
      - name: HCP_P_DEA_NUM
        description: Drug Enforcement Administration number assigned to healthcare providers for prescribing controlled substances.
        expr: HCP_P_DEA_NUM
        data_type: VARCHAR(16777216)
        sample_values:
          - AB7255272
          - BB3188833
      - name: HCP_P_DEA_STATE_OF_LICENSURE
        description: The state where the healthcare provider's Drug Enforcement Administration license is issued.
        expr: HCP_P_DEA_STATE_OF_LICENSURE
        data_type: VARCHAR(16777216)
        sample_values:
          - TX
          - MA
          - LA
      - name: HCP_P_HIN
        description: A column holding data of type VARCHAR(16777216).
        expr: HCP_P_HIN
        data_type: VARCHAR(16777216)
      - name: HCP_P_MA_ID
        description: A column holding data of type VARCHAR(16777216).
        expr: HCP_P_MA_ID
        data_type: VARCHAR(16777216)
        sample_values:
          - '216513'
          - '166691'
          - '169135'
      - name: HCP_P_NPI_NUM
        description: National Provider Identifier (NPI) numbers for healthcare providers.
        expr: HCP_P_NPI_NUM
        data_type: VARCHAR(16777216)
        sample_values:
          - '1134821382'
          - '1235525957'
          - '1558956375'
      - name: HCP_P_STATE_LIC_NUM
        description: Healthcare provider state license numbers.
        expr: HCP_P_STATE_LIC_NUM
        data_type: VARCHAR(16777216)
        sample_values:
          - PA2022-0048
          - '107955'
          - '238052'
      - name: HCP_P_STATE_LIC_STATE_CD
        description: State code where the healthcare provider holds their professional license.
        expr: HCP_P_STATE_LIC_STATE_CD
        data_type: VARCHAR(16777216)
        sample_values:
          - AR
          - NV
          - TX
      - name: HCP_P_STATE_LIC_STATUS
        description: The status of a healthcare provider's professional state license.
        expr: HCP_P_STATE_LIC_STATUS
        data_type: VARCHAR(16777216)
        sample_values:
          - INACTIVE
          - ACTIVE
      - name: HCP_PDRP_OPTOUT_IND
        description: Healthcare provider Patient Data Request Program opt-out indicator.
        expr: HCP_PDRP_OPTOUT_IND
        data_type: VARCHAR(16777216)
        sample_values:
          - 'Y'
          - 'N'
      - name: HCP_PHONE_HOME_P
        description: Healthcare provider's home phone number.
        expr: HCP_PHONE_HOME_P
        data_type: VARCHAR(16777216)
      - name: HCP_PHONE_MOBILE_P
        description: Mobile phone number for the healthcare provider.
        expr: HCP_PHONE_MOBILE_P
        data_type: VARCHAR(16777216)
      - name: HCP_PHONE_WORK_P
        description: Work phone numbers for healthcare providers.
        expr: HCP_PHONE_WORK_P
        data_type: VARCHAR(16777216)
        sample_values:
          - '3604862900'
          - '2183486888'
          - '9155323937'
      - name: HCP_S_DEA_BUSINESS_ACTIVITY_CD
        description: Drug Enforcement Administration business activity code for healthcare providers.
        expr: HCP_S_DEA_BUSINESS_ACTIVITY_CD
        data_type: VARCHAR(16777216)
      - name: HCP_S_DEA_DRUG_SCHEDULE
        description: A column holding data of type VARCHAR(16777216).
        expr: HCP_S_DEA_DRUG_SCHEDULE
        data_type: VARCHAR(16777216)
      - name: HCP_S_DEA_LIC_STATUS_CD
        description: Healthcare provider Drug Enforcement Administration license status code.
        expr: HCP_S_DEA_LIC_STATUS_CD
        data_type: VARCHAR(16777216)
        sample_values:
          - ACTIVE
      - name: HCP_S_DEA_NUM
        description: Drug Enforcement Administration number assigned to healthcare providers for prescribing controlled substances.
        expr: HCP_S_DEA_NUM
        data_type: VARCHAR(16777216)
        sample_values:
          - FG6124919
          - FF8289161
      - name: HCP_S_DEA_STATE_OF_LICENSURE
        description: The state where the healthcare provider's Drug Enforcement Administration license was issued.
        expr: HCP_S_DEA_STATE_OF_LICENSURE
        data_type: VARCHAR(16777216)
        sample_values:
          - VA
          - NE
      - name: HCP_S_HIN
        description: A column holding data of type VARCHAR(16777216).
        expr: HCP_S_HIN
        data_type: VARCHAR(16777216)
      - name: HCP_S_MA_ID
        description: Healthcare provider master agreement identifier.
        expr: HCP_S_MA_ID
        data_type: VARCHAR(16777216)
        sample_values:
          - '381767'
          - '808700'
          - '469231'
      - name: HCP_S_NPI_NUM
        description: National Provider Identifier number for healthcare providers.
        expr: HCP_S_NPI_NUM
        data_type: VARCHAR(16777216)
        sample_values:
          - '1003443490'
          - '1396321816'
          - '1295437895'
      - name: HCP_S_STATE_LIC_NUM
        description: State license numbers for healthcare providers.
        expr: HCP_S_STATE_LIC_NUM
        data_type: VARCHAR(16777216)
        sample_values:
          - RN528086L
          - 053978-23
          - '22566'
      - name: HCP_S_STATE_LIC_STATE_CD
        description: State code where the healthcare provider holds their professional license.
        expr: HCP_S_STATE_LIC_STATE_CD
        data_type: VARCHAR(16777216)
        sample_values:
          - CT
          - WI
      - name: HCP_S_STATE_LIC_STATUS
        description: The status of a healthcare provider's state license.
        expr: HCP_S_STATE_LIC_STATUS
        data_type: VARCHAR(16777216)
        sample_values:
          - PROBATION
          - ACTIVE
      - name: HCP_SRC_ID_10_IMS2
        description: Healthcare provider source identifier from IMS database system.
        expr: HCP_SRC_ID_10_IMS2
        data_type: VARCHAR(16777216)
        sample_values:
          - '7692967'
          - '24968143'
          - '8098879'
      - name: HCP_SRC_ID_3_SCRUB
        description: Healthcare provider source identifier from the third data source after data scrubbing processes.
        expr: HCP_SRC_ID_3_SCRUB
        data_type: VARCHAR(16777216)
        sample_values:
          - WUSM01621661
          - WUSR06017841
          - WUSP00548392
      - name: HCP_SRC_ID_4_SFA
        description: A column holding data of type VARCHAR(16777216).
        expr: HCP_SRC_ID_4_SFA
        data_type: VARCHAR(16777216)
      - name: HCP_SRC_ID_5_SFA
        description: A column holding data of type VARCHAR(16777216).
        expr: HCP_SRC_ID_5_SFA
        data_type: VARCHAR(16777216)
      - name: HCP_SRC_ID_CF_SPDI
        description: A column holding data of type VARCHAR(16777216).
        expr: HCP_SRC_ID_CF_SPDI
        data_type: VARCHAR(16777216)
      - name: HCP_SRC_ID_IMS
        description: Healthcare provider source identifier from IMS data system.
        expr: HCP_SRC_ID_IMS
        data_type: VARCHAR(16777216)
        sample_values:
          - '7182700'
          - '1292510'
          - '2851684'
      - name: HCP_SRC_ID_OH_TDDD
        description: A column holding data of type VARCHAR(16777216).
        expr: HCP_SRC_ID_OH_TDDD
        data_type: VARCHAR(16777216)
        sample_values:
          - '020363900'
          - '021366000'
      - name: HCP_SRC_ID_P_CLIENT
        description: A column holding data of type VARCHAR(16777216).
        expr: HCP_SRC_ID_P_CLIENT
        data_type: VARCHAR(16777216)
      - name: HCP_SRC_ID_P_COPROMO
        description: A column holding data of type VARCHAR(16777216).
        expr: HCP_SRC_ID_P_COPROMO
        data_type: VARCHAR(16777216)
      - name: HCP_SRC_ID_P_SCRUB
        description: Healthcare provider source identifier after data scrubbing processes.
        expr: HCP_SRC_ID_P_SCRUB
        data_type: VARCHAR(16777216)
        sample_values:
          - '13322122'
          - '15733078'
      - name: HCP_SRC_ID_P_SFA
        description: A column holding data of type VARCHAR(16777216).
        expr: HCP_SRC_ID_P_SFA
        data_type: VARCHAR(16777216)
      - name: HCP_SRC_ID_P_SP
        description: A column holding data of type VARCHAR(16777216).
        expr: HCP_SRC_ID_P_SP
        data_type: VARCHAR(16777216)
      - name: HCP_SRC_ID_S_CLIENT
        description: A column holding data of type VARCHAR(16777216).
        expr: HCP_SRC_ID_S_CLIENT
        data_type: VARCHAR(16777216)
      - name: HCP_SRC_ID_S_COPROMO
        description: A column holding data of type VARCHAR(16777216).
        expr: HCP_SRC_ID_S_COPROMO
        data_type: VARCHAR(16777216)
      - name: HCP_SRC_ID_S_SCRUB
        description: Healthcare provider source identifier after data scrubbing processes.
        expr: HCP_SRC_ID_S_SCRUB
        data_type: VARCHAR(16777216)
        sample_values:
          - WUSM05200310
          - WUSM04669326
          - WUSM00017540
      - name: HCP_SRC_ID_S_SFA
        description: A column holding data of type VARCHAR(16777216).
        expr: HCP_SRC_ID_S_SFA
        data_type: VARCHAR(16777216)
      - name: HCP_SRC_ID_S_SP
        description: A column holding data of type VARCHAR(16777216).
        expr: HCP_SRC_ID_S_SP
        data_type: VARCHAR(16777216)
      - name: HCP_SRC_ID_SHA
        description: A column holding data of type VARCHAR(16777216).
        expr: HCP_SRC_ID_SHA
        data_type: VARCHAR(16777216)
      - name: HCP_SRC_ID_T_COPROMO
        description: A column holding data of type VARCHAR(16777216).
        expr: HCP_SRC_ID_T_COPROMO
        data_type: VARCHAR(16777216)
      - name: HCP_SRC_ID_T_SFA
        description: A column holding data of type VARCHAR(16777216).
        expr: HCP_SRC_ID_T_SFA
        data_type: VARCHAR(16777216)
      - name: HCP_SRC_ID_T_SP
        description: A column holding data of type VARCHAR(16777216).
        expr: HCP_SRC_ID_T_SP
        data_type: VARCHAR(16777216)
      - name: HCP_SUFFIX
        description: Healthcare provider name suffix such as senior or junior designations.
        expr: HCP_SUFFIX
        data_type: VARCHAR(16777216)
        sample_values:
          - JR
          - II
          - SR
      - name: HCP_T_DEA_BUSINESS_ACTIVITY_CD
        description: Drug Enforcement Administration business activity code for healthcare providers.
        expr: HCP_T_DEA_BUSINESS_ACTIVITY_CD
        data_type: VARCHAR(16777216)
      - name: HCP_T_DEA_DRUG_SCHEDULE
        description: A column holding data of type VARCHAR(16777216).
        expr: HCP_T_DEA_DRUG_SCHEDULE
        data_type: VARCHAR(16777216)
      - name: HCP_T_DEA_LIC_STATUS_CD
        description: Healthcare provider Drug Enforcement Administration license status code.
        expr: HCP_T_DEA_LIC_STATUS_CD
        data_type: VARCHAR(16777216)
        sample_values:
          - ACTIVE
      - name: HCP_T_DEA_NUM
        description: Drug Enforcement Administration number for healthcare providers.
        expr: HCP_T_DEA_NUM
        data_type: VARCHAR(16777216)
        sample_values:
          - FK9444655
          - FB3199975
      - name: HCP_T_DEA_STATE_OF_LICENSURE
        description: The state where the healthcare provider's Drug Enforcement Administration license was issued.
        expr: HCP_T_DEA_STATE_OF_LICENSURE
        data_type: VARCHAR(16777216)
        sample_values:
          - SD
          - TN
      - name: HCP_T_HIN
        description: A column holding data of type VARCHAR(16777216).
        expr: HCP_T_HIN
        data_type: VARCHAR(16777216)
      - name: HCP_T_MA_ID
        description: A column holding data of type VARCHAR(16777216).
        expr: HCP_T_MA_ID
        data_type: VARCHAR(16777216)
        sample_values:
          - '634359'
          - '526408'
      - name: HCP_T_NPI_NUM
        description: National Provider Identifier number for healthcare providers.
        expr: HCP_T_NPI_NUM
        data_type: VARCHAR(16777216)
      - name: HCP_T_STATE_LIC_NUM
        description: Healthcare provider state license numbers.
        expr: HCP_T_STATE_LIC_NUM
        data_type: VARCHAR(16777216)
        sample_values:
          - '0810007329'
          - '23410'
      - name: HCP_T_STATE_LIC_STATE_CD
        description: The state code where the healthcare provider holds their license.
        expr: HCP_T_STATE_LIC_STATE_CD
        data_type: VARCHAR(16777216)
        sample_values:
          - MD
          - FL
      - name: HCP_T_STATE_LIC_STATUS
        description: The status of a healthcare provider's state license.
        expr: HCP_T_STATE_LIC_STATUS
        data_type: VARCHAR(16777216)
        sample_values:
          - INACTIVE
          - ACTIVE
      - name: HCP_TITLE
        description: Healthcare provider professional title or designation.
        expr: HCP_TITLE
        data_type: VARCHAR(16777216)
      - name: KOL_IND
        description: Key opinion leader indicator flag.
        expr: KOL_IND
        data_type: VARCHAR(16777216)
      - name: NO_SEE_IND
        description: A column holding data of type VARCHAR(16777216).
        expr: NO_SEE_IND
        data_type: VARCHAR(16777216)
      - name: SAMPLEABILITY_IND
        description: An indicator of whether the healthcare provider can be sampled.
        expr: SAMPLEABILITY_IND
        data_type: VARCHAR(16777216)
    time_dimensions:
      - name: HCP_BIRTH_DT
        description: Healthcare provider birth dates.
        expr: HCP_BIRTH_DT
        data_type: DATE
        sample_values:
          - '1968-01-01'
          - '1971-01-01'
          - '1978-01-01'
      - name: HCP_P_DEA_EXP_DT
        description: The expiration date of the healthcare provider's Drug Enforcement Administration registration.
        expr: HCP_P_DEA_EXP_DT
        data_type: DATE
        sample_values:
          - '2028-01-31'
          - '2028-05-31'
          - '2027-02-28'
      - name: HCP_P_STATE_LIC_EXP_DT
        description: The expiration date of the healthcare provider's state license.
        expr: HCP_P_STATE_LIC_EXP_DT
        data_type: DATE
        sample_values:
          - '2027-08-31'
          - '2028-08-31'
          - '2025-11-30'
      - name: HCP_P_STATE_LIC_ISSUE_DT
        description: The date when the healthcare provider's state license was issued.
        expr: HCP_P_STATE_LIC_ISSUE_DT
        data_type: DATE
        sample_values:
          - '2022-07-01'
          - '2020-02-13'
          - '2024-06-23'
      - name: HCP_PDRP_OPTOUT_DT
        description: The date when a healthcare provider opted out of the Prescription Drug Reporting Program.
        expr: HCP_PDRP_OPTOUT_DT
        data_type: DATE
        sample_values:
          - '2008-12-04'
          - '2008-11-27'
      - name: HCP_S_DEA_EXP_DT
        description: The expiration date of the healthcare provider's Drug Enforcement Administration registration.
        expr: HCP_S_DEA_EXP_DT
        data_type: DATE
        sample_values:
          - '2026-07-31'
          - '2026-12-31'
          - '2026-03-31'
      - name: HCP_S_STATE_LIC_EXP_DT
        description: The expiration date of the healthcare provider's state license.
        expr: HCP_S_STATE_LIC_EXP_DT
        data_type: DATE
        sample_values:
          - '2026-04-05'
          - '2026-02-04'
          - '2027-03-01'
      - name: HCP_S_STATE_LIC_ISSUE_DT
        description: The date when the healthcare provider's state license was issued.
        expr: HCP_S_STATE_LIC_ISSUE_DT
        data_type: DATE
        sample_values:
          - '2019-04-23'
          - '2021-05-14'
      - name: HCP_T_DEA_EXP_DT
        description: The expiration date of the healthcare provider's Drug Enforcement Administration registration.
        expr: HCP_T_DEA_EXP_DT
        data_type: DATE
        sample_values:
          - '2028-04-30'
          - '2026-08-31'
          - '2027-10-31'
      - name: HCP_T_STATE_LIC_EXP_DT
        description: The expiration date of the healthcare provider's state license.
        expr: HCP_T_STATE_LIC_EXP_DT
        data_type: DATE
        sample_values:
          - '2026-10-31'
          - '2025-12-31'
          - '2026-09-30'
      - name: HCP_T_STATE_LIC_ISSUE_DT
        description: The date when the healthcare provider's state license was issued.
        expr: HCP_T_STATE_LIC_ISSUE_DT
        data_type: DATE
        sample_values:
          - '2002-05-08'
          - '2022-02-18'
      - name: SAMPLEABILITY_DT
        description: The date when sampleability status was determined or last updated.
        expr: SAMPLEABILITY_DT
        data_type: DATE
    facts:
      - name: HCP_STATUS_KEY
        description: Healthcare provider status identifier used as a foreign key reference.
        expr: HCP_STATUS_KEY
        data_type: NUMBER(38,0)
        access_modifier: public_access
        sample_values:
          - '1'
      - name: HCP_SUBTYPE_KEY
        description: Healthcare provider subtype identifier key.
        expr: HCP_SUBTYPE_KEY
        data_type: NUMBER(38,0)
        access_modifier: public_access
        sample_values:
          - '9'
          - '10'
          - '13'
    primary_key:
      columns:
        - HCP_KEY
  - name: TD_PROD_BRAND
    description: The table contains records of product brand and categorization information used for sales performance reporting. Each record represents a product hierarchy structure that includes market segments, category groupings, individual categories, family groupings, and product families with their corresponding identifiers and descriptions.
    base_table:
      database: DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB
      schema: REPORTING
      table: TD_PROD_BRAND
    dimensions:
      - name: PROD_BRAND_CD
        description: Product brand codes for pharmaceutical and medical products.
        expr: PROD_BRAND_CD
        data_type: VARCHAR(256)
        sample_values:
          - ANOLOR 300
          - CHILDRENS Q-PAP
          - TENCON
      - name: PROD_BRAND_DESC
        description: Brand names of pharmaceutical pain management products along with their associated market categories.
        expr: PROD_BRAND_DESC
        data_type: VARCHAR(256)
        sample_values:
          - BUFFERED ASPIRIN EXTRA S BRAND (VERTEX ACUTE MARKET)
          - LIDOPRIL XR BRAND (ACUTE HEOR MARKET)
          - RA ORASOL BRAND (VERTEX ACUTE MARKET)
      - name: PROD_BRAND_KEY
        description: A unique identifier key for product brands.
        expr: PROD_BRAND_KEY
        data_type: VARCHAR(32)
        sample_values:
          - a96f921f9adcf6357022ae1d77e0036e
          - 77238a2664c2da30f3763020cc9f64a1
          - a3013ea55958b130a8be56287a23ac84
      - name: PROD_BRAND_SDESC
        description: Product brand short description or name.
        expr: PROD_BRAND_SDESC
        data_type: VARCHAR(256)
        sample_values:
          - RECTASMOOTHE
          - LIDOVIX L
          - NUVAKAAN-II
      - name: PROD_BRAND_UCD
        description: Brand names of pharmaceutical and over-the-counter medical products.
        expr: PROD_BRAND_UCD
        data_type: VARCHAR(256)
        sample_values:
          - CAPSAICIN TOPICAL PAIN P
          - PAIN-EZE PLUS
          - PRILO PATCH II
      - name: PROD_CAT_CD
        description: Pharmaceutical product category codes indicating the therapeutic classification of medical products.
        expr: PROD_CAT_CD
        data_type: VARCHAR(256)
        sample_values:
          - DERMATOLOGICAL TOPICAL ANESTHETIC COMBINATIONS
          - LIDOCAINE - ANESTHETIC
          - AMIDES
      - name: PROD_CAT_DESC
        description: Product category descriptions for pharmaceutical pain management treatments.
        expr: PROD_CAT_DESC
        data_type: VARCHAR(256)
        sample_values:
          - ANALGESICS-SEDATIVE COMBINATION CATEGORY (ANY PAIN MARKET)
          - LIDOCAINE - ANESTHETIC CATEGORY (VERTEX ACUTE MARKET)
          - DENTAL LOCAL ANESTHETIC CATEGORY (ANY PAIN MARKET)
      - name: PROD_CAT_KEY
        description: A unique identifier key for product categories.
        expr: PROD_CAT_KEY
        data_type: VARCHAR(32)
        sample_values:
          - 12bc423a463b94db26c110a7b5f35c2b
          - 51d89477c08fab581269b5cd07cc9249
          - 6cdf4a9156745f9ceab6a9d55493f62f
      - name: PROD_CAT_SDESC
        description: Product category short descriptions for pharmaceutical and medical products.
        expr: PROD_CAT_SDESC
        data_type: VARCHAR(256)
        sample_values:
          - RHEUMATOID ARTHRITIS
          - DERMATOLOGICAL TOPICAL ANESTHETIC
          - SSRI
      - name: PROD_CATGRP_CD
        description: Product category group codes representing different pharmaceutical and medical product classifications.
        expr: PROD_CATGRP_CD
        data_type: VARCHAR(256)
        sample_values:
          - OSTEOARTHRITIS
          - ANESTHETIC
          - DENTALS
      - name: PROD_CATGRP_DESC
        description: Product category group descriptions for pharmaceutical products in acute care markets.
        expr: PROD_CATGRP_DESC
        data_type: VARCHAR(256)
        sample_values:
          - OTHER CATEGORY GROUP (ANY PAIN MARKET)
          - DERMATOLOGICAL CATEGORY GROUP (VERTEX ACUTE MARKET)
          - NON-NARCOTIC ANALGESIC CATEGORY GROUP (VERTEX ACUTE MARKET)
      - name: PROD_CATGRP_KEY
        description: A unique identifier key for product category groups.
        expr: PROD_CATGRP_KEY
        data_type: VARCHAR(32)
        sample_values:
          - ae4d74c1255ef3b525bf3ee4914ed273
          - a9946aba572bb08c111e94c3c36c84f7
          - d8cad3b14468ba5121e210028e133b00
      - name: PROD_CATGRP_SDESC
        description: Product category group short description indicating the therapeutic classification or type of pharmaceutical product.
        expr: PROD_CATGRP_SDESC
        data_type: VARCHAR(256)
        sample_values:
          - ANESTHETIC
          - DENTALS
          - NON-NARCOTIC ANALGESIC
      - name: PROD_FAM_CD
        description: Product family codes used to categorize and group related products.
        expr: PROD_FAM_CD
        data_type: VARCHAR(256)
        sample_values:
          - HYCOGESIC
          - PAMPRIN
          - ENDOLOR
      - name: PROD_FAM_DESC
        description: Product family descriptions for pain relief medications and treatments.
        expr: PROD_FAM_DESC
        data_type: VARCHAR(256)
        sample_values:
          - EFFEXOR XR FAMILY (ACUTE HEOR MARKET)
          - ENDOLOR FAMILY (ANY PAIN MARKET)
          - DYNAMIC FAMILY (ANY PAIN MARKET)
      - name: PROD_FAM_KEY
        description: A unique identifier key for product families.
        expr: PROD_FAM_KEY
        data_type: VARCHAR(32)
        sample_values:
          - 10738f1513e6f471c10da189c7b6db7c
          - 5e208a4effc1cd0786bed71851c6964f
          - 1ab075c96c0468e9796a665631ad472e
      - name: PROD_FAM_SDESC
        description: Pharmaceutical product family short descriptions or names.
        expr: PROD_FAM_SDESC
        data_type: VARCHAR(256)
        sample_values:
          - CHLORASEPTIC SR THRT
          - CHILDRENS Q-PAP
          - SYNOFLEX
      - name: PROD_FAMGRP_CD
        description: Active pharmaceutical ingredients or drug compounds used in pain management products.
        expr: PROD_FAMGRP_CD
        data_type: VARCHAR(256)
        sample_values:
          - CAPSAICIN-MENTHOL - DERMATOLOGICAL TOPICAL ANESTHETIC COMBINATIONS
          - HYDROCODONE
          - BENZOCAINE-ZINC CHLORIDE
      - name: PROD_FAMGRP_DESC
        description: Pharmaceutical product family group descriptions indicating drug types and their associated pain market categories.
        expr: PROD_FAMGRP_DESC
        data_type: VARCHAR(256)
        sample_values:
          - CAPSAICIN FAMILY GROUP (ANY PAIN MARKET)
          - BENZOCAINE-ZINC CHLORIDE FAMILY GROUP (ANY PAIN MARKET)
          - OXYCODONE COMBINATIONS FAMILY GROUP (ACUTE HEOR MARKET)
      - name: PROD_FAMGRP_KEY
        description: A unique identifier key for product family groups represented as a hash value.
        expr: PROD_FAMGRP_KEY
        data_type: VARCHAR(32)
        sample_values:
          - e86d9067df720cbe38d87f1d1e6ba4bb
          - 2d8609830dfd91355e0f57b69a124265
          - 2c25349bf27be50f2527bb0084f0f4d2
      - name: PROD_FAMGRP_SDESC
        description: Pharmaceutical product family group short descriptions indicating the active ingredient or drug category.
        expr: PROD_FAMGRP_SDESC
        data_type: VARCHAR(256)
        sample_values:
          - DESIPRAMINE
          - BENZOCAINE - DERMATOLOGICAL TOPICAL ANESTHETIC COMBINATIONS
          - LIDOCAINE - DERMATOLOGICAL TOPICAL ANESTHETIC COMBINATIONS
      - name: PROD_MKT_CD
        description: Product marketing code identifying the specific marketing category or segment for the product brand.
        expr: PROD_MKT_CD
        data_type: VARCHAR(256)
        sample_values:
          - ACUTE HEOR
          - ANY PAIN
          - VERTEX ACUTE
      - name: PROD_MKT_DESC
        description: Product market description indicating the specific market segment or category for the product.
        expr: PROD_MKT_DESC
        data_type: VARCHAR(256)
        sample_values:
          - VERTEX ACUTE MARKET
          - ACUTE HEOR MARKET
          - ANY PAIN MARKET
      - name: PROD_MKT_KEY
        description: A unique marketing key identifier for products.
        expr: PROD_MKT_KEY
        data_type: VARCHAR(32)
        sample_values:
          - da0dacac9831661226335a3eb0b04274
          - 89cf3596760b4a79df67736f2272a1b7
          - c8c606d1c69b2144eea5bbe3157289b6
      - name: PROD_MKT_SDESC
        description: Product marketing short description for pharmaceutical pain management brands.
        expr: PROD_MKT_SDESC
        data_type: VARCHAR(256)
        sample_values:
          - ACUTE HEOR
          - ANY PAIN
          - VERTEX ACUTE
    primary_key:
      columns:
        - PROD_BRAND_KEY
  - name: TM_ARD_HCP_ACUTE_MKT_WEEKLY_XPO
    description: The table contains records of healthcare provider prescription activity in acute care settings, tracked on a weekly basis. Each record represents prescription exposure data for a specific healthcare provider and includes provider identifiers, specialty information, territorial assignments, and prescription metrics for acute care treatments.
    base_table:
      database: DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB
      schema: REPORTING
      table: TM_ARD_HCP_ACUTE_MKT_WEEKLY_XPO
    dimensions:
      - name: BRANDED_FLAG
        description: A flag indicating whether the product is branded or not.
        expr: BRANDED_FLAG
        data_type: VARCHAR(16777216)
        sample_values:
          - 'N'
          - 'Y'
      - name: GOLDEN_ID
        description: A unique identifier used to link and track healthcare providers across different systems and databases.
        expr: GOLDEN_ID
        data_type: VARCHAR(16777216)
        sample_values:
          - GLD000600060001002101
          - GLD999900180020002401
          - GLD021402140287037101
      - name: HCP_ID
        description: Unique identifier for healthcare providers.
        expr: HCP_ID
        data_type: VARCHAR(32)
        sample_values:
          - b53fb88ce1b284c55206728afb2a9da6
          - e32c570ee80606057196f62cf5b6e502
          - 132c4377c0b6eee2172aefb7d046b30e
      - name: HCP_SPECIALTY
        description: Medical specialty or practice area of the healthcare provider.
        expr: HCP_SPECIALTY
        data_type: VARCHAR(16777216)
        sample_values:
          - ADULT RECONSTRUCTIVE ORTHOPEDICS
          - EMERGENCY MEDICINE
          - DENTIST
      - name: HCP_SPECIALTY_GROUP
        description: Healthcare provider specialty groups categorizing medical professionals by their area of practice.
        expr: HCP_SPECIALTY_GROUP
        data_type: VARCHAR(16777216)
        sample_values:
          - MEDICINE
          - PHYSICIAN EXTENDERS
          - ORTHOPEDICS AND SPORTS MEDICINE
      - name: NPI
        description: National Provider Identifier numbers for healthcare providers.
        expr: NPI
        data_type: VARCHAR(16777216)
        sample_values:
          - '1194281006'
          - '1659465573'
          - '1396203352'
      - name: ONEKEY_HCP_ID
        description: Unique identifier for healthcare providers in the OneKey system.
        expr: ONEKEY_HCP_ID
        data_type: VARCHAR(16777216)
        sample_values:
          - WUSD00201756
          - WUSM00530772
          - WUSM00311233
      - name: PRODUCT_CATEGORY
        description: Categories of pharmaceutical products used for pain management and treatment.
        expr: PRODUCT_CATEGORY
        data_type: VARCHAR(256)
        sample_values:
          - NSAID
          - STRONG OPIOID AGONIST
          - ANTICONVULSANTS MISC.
      - name: PRODUCT_FAMILY_GROUP
        description: Pharmaceutical product family groups categorizing related medications and therapeutic compounds.
        expr: PRODUCT_FAMILY_GROUP
        data_type: VARCHAR(256)
        sample_values:
          - LIDOCAINE - DERMATOLOGICAL LOCAL TOPICAL ANESTHETIC
          - MELOXICAM
          - HYDROCODONE COMBINATIONS
      - name: PTAM_TERRITORY_ID
        description: Unique identifier for a PTAM (Pain Territory Account Manager) territory.
        expr: PTAM_TERRITORY_ID
        data_type: VARCHAR(255)
        sample_values:
          - V1NAUSA-5733101
          - V1NAUSA-5733602
          - V1NAUSA-5733604
      - name: ROA
        description: Route of administration for pharmaceutical products.
        expr: ROA
        data_type: VARCHAR(256)
        sample_values:
          - ORAL
          - TOPICAL
          - TOPICAL-PATCH
      - name: SAL_TERRITORY_ID
        description: Sales territory identifier used to designate specific geographic or organizational sales regions.
        expr: SAL_TERRITORY_ID
        data_type: VARCHAR(255)
        sample_values:
          - V1NAUSA-5720008
          - V1NAUSA-5720014
      - name: SITE_OF_CARE_ZIP_CODE
        description: ZIP codes for healthcare facility locations.
        expr: SITE_OF_CARE_ZIP_CODE
        data_type: VARCHAR(16777216)
        sample_values:
          - '73118'
          - '43228'
          - '37027'
      - name: VERTEX_ID
        description: Unique identifier for a vertex in the healthcare provider network.
        expr: VERTEX_ID
        data_type: VARCHAR(16777216)
        sample_values:
          - '15670811'
          - '14499271'
      - name: ZIP_CODE
        description: Postal ZIP codes for geographic locations.
        expr: ZIP_CODE
        data_type: VARCHAR(16777216)
        sample_values:
          - '20850'
          - '33912'
          - '90262'
    time_dimensions:
      - name: DATE_KEY
        description: The date associated with each record in the healthcare provider acute market weekly exposure data.
        expr: DATE_KEY
        data_type: DATE
        sample_values:
          - '2024-05-17'
          - '2024-12-06'
          - '2025-02-07'
    facts:
      - name: ACUTE_NRX_XPO
        description: Acute new prescription exposure index for healthcare providers in the market.
        expr: ACUTE_NRX_XPO
        data_type: NUMBER(38,10)
        access_modifier: public_access
        sample_values:
          - '2.0320000000'
          - '0.9650000000'
          - '1.0420000000'
      - name: ACUTE_TRX_XPO
        description: Acute transaction exposure metric for healthcare providers in the market.
        expr: ACUTE_TRX_XPO
        data_type: NUMBER(38,10)
        access_modifier: public_access
        sample_values:
          - '1.6080000000'
          - '1.0300000000'
          - '0.9630000000'
      - name: ACUTE_TX_DAYS_XPO
        description: The number of days of acute treatment exposure.
        expr: ACUTE_TX_DAYS_XPO
        data_type: NUMBER(38,10)
        access_modifier: public_access
        sample_values:
          - '4.2033678514'
          - '3.2592136056'
          - '24.4437444312'
      - name: ACUTE_UNITS_XPO
        description: Acute care units exposure metric.
        expr: ACUTE_UNITS_XPO
        data_type: NUMBER(38,10)
        access_modifier: public_access
        sample_values:
          - '61.1900000000'
          - '160.0900000000'
          - '30.0000000000'
      - name: WEEK_DT
        description: The date representing a specific week in the healthcare provider acute market reporting period.
        expr: WEEK_DT
        data_type: NUMBER(10,0)
        access_modifier: public_access
        sample_values:
          - '20251024'
          - '20241220'
          - '20250321'
relationships:
  - name: LAAD_WEEKLY_TO_HCP
    left_table: ARD_GIACO_TM_HCP_ACUTE_MKT_WEEKLY_LAAD
    right_table: TD_HCP
    relationship_columns:
      - left_column: HCP_ID
        right_column: HCP_KEY
    relationship_type: many_to_one
    join_type: left_outer
  - name: HCO_TO_SUBTYPE
    left_table: TD_HCO
    right_table: TD_HCO_SUBTYPE
    relationship_columns:
      - left_column: HCO_SUBTYPE_KEY
        right_column: HCO_SUBTYPE_KEY
    relationship_type: many_to_one
    join_type: left_outer
  - name: XPO_WEEKLY_TO_HCP
    left_table: TM_ARD_HCP_ACUTE_MKT_WEEKLY_XPO
    right_table: TD_HCP
    relationship_columns:
      - left_column: HCP_ID
        right_column: HCP_KEY
    relationship_type: many_to_one
    join_type: left_outer


create or replace semantic view DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.REPORTING.BASIC_CORTEX_ANALYST
	tables (
		DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.REPORTING.ARD_GIACO_TM_HCP_ACUTE_MKT_WEEKLY_LAAD comment='The table contains records of healthcare provider performance metrics in acute care settings, tracked on a weekly basis. Each record represents a healthcare provider''s acute episode activity within specific territories and includes details about provider characteristics, geographic location, product categories, and territorial assignments.',
		DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.REPORTING.TD_GEO_CITY comment='The table contains records of cities and their geographic information. Each record represents a single city and includes hierarchical location details such as state and country associations, along with precise coordinate data.',
		DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.REPORTING.TD_GEO_LOC comment='The table contains records of geographic locations with their complete address and coordinate information. Each record represents a specific location and includes hierarchical geographic details from address lines through city, state, postal code, and country levels, as well as precise latitude and longitude coordinates.',
		DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.REPORTING.TD_GEO_POSTAL comment='The table contains records of geographic postal code areas with their associated location hierarchies. Each record represents a postal code and includes details about the corresponding state and country jurisdictions as well as precise geographic coordinates.',
		DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.REPORTING.TD_GEO_STATE comment='The table contains records of geographic states and their associated countries. Each record includes location identifiers, geographic coordinates, and hierarchical relationships between states and countries.',
		DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.REPORTING.TD_HCO comment='The table contains records of healthcare organizations with their identifying information and regulatory details. Each record includes organizational names, business identifiers, operational status, and licensing information including DEA registrations and HIN numbers across multiple categories.',
		DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.REPORTING.TD_HCO_SUBTYPE primary key (HCO_SUBTYPE_KEY) comment='The table contains records of healthcare organization subtypes and their corresponding parent types. Each record represents a specific subtype classification with descriptive information and links to broader organizational type categories.',
		DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.REPORTING.TD_HCP primary key (HCP_KEY) comment='The table contains records of healthcare professionals and their personal and professional information. Each record represents an individual healthcare provider and includes demographic details, contact information, educational background, and various status indicators related to communication preferences and professional classifications.',
		DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.REPORTING.TD_PROD_BRAND primary key (PROD_BRAND_KEY) comment='The table contains records of product brand and categorization information used for sales performance reporting. Each record represents a product hierarchy structure that includes market segments, category groupings, individual categories, family groupings, and product families with their corresponding identifiers and descriptions.',
		DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.REPORTING.TM_ARD_HCP_ACUTE_MKT_WEEKLY_XPO comment='The table contains records of healthcare provider prescription activity in acute care settings, tracked on a weekly basis. Each record represents prescription exposure data for a specific healthcare provider and includes provider identifiers, specialty information, territorial assignments, and prescription metrics for acute care treatments.'
	)
	relationships (
		LAAD_WEEKLY_TO_HCP as ARD_GIACO_TM_HCP_ACUTE_MKT_WEEKLY_LAAD(HCP_ID) references TD_HCP(HCP_KEY),
		HCO_TO_SUBTYPE as TD_HCO(HCO_SUBTYPE_KEY) references TD_HCO_SUBTYPE(HCO_SUBTYPE_KEY),
		XPO_WEEKLY_TO_HCP as TM_ARD_HCP_ACUTE_MKT_WEEKLY_XPO(HCP_ID) references TD_HCP(HCP_KEY)
	)
	facts (
		ARD_GIACO_TM_HCP_ACUTE_MKT_WEEKLY_LAAD.ACUTE_CALENDAR_DAYS_LAAD as ACUTE_CALENDAR_DAYS_LAAD comment='The number of calendar days in the acute care period for look-alike-alike drug analysis.',
		ARD_GIACO_TM_HCP_ACUTE_MKT_WEEKLY_LAAD.ACUTE_EPISODES_LAAD as ACUTE_EPISODES_LAAD comment='The number of acute episodes within the look-ahead period.',
		ARD_GIACO_TM_HCP_ACUTE_MKT_WEEKLY_LAAD.ACUTE_PROCEDURES_LAAD as ACUTE_PROCEDURES_LAAD comment='The number of acute procedures performed using laparoscopic-assisted abdominal delivery techniques.',
		ARD_GIACO_TM_HCP_ACUTE_MKT_WEEKLY_LAAD.ACUTE_REFILLS_LAAD as ACUTE_REFILLS_LAAD comment='The number of acute medication refills within the look-ahead period.',
		ARD_GIACO_TM_HCP_ACUTE_MKT_WEEKLY_LAAD.ACUTE_TRX_LAAD as ACUTE_TRX_LAAD comment='The number of acute transactions for the last-as-advertised date period.',
		ARD_GIACO_TM_HCP_ACUTE_MKT_WEEKLY_LAAD.ACUTE_TX_DAYS_LAAD as ACUTE_TX_DAYS_LAAD comment='The number of days for acute treatment based on LAAD (Last Available Actual Data).',
		ARD_GIACO_TM_HCP_ACUTE_MKT_WEEKLY_LAAD.ACUTE_UNITS_LAAD as ACUTE_UNITS_LAAD comment='Acute care units measured as a look-ahead average demand.',
		ARD_GIACO_TM_HCP_ACUTE_MKT_WEEKLY_LAAD.WEEK_DT as WEEK_DT comment='The date representing the week in the healthcare provider acute market reporting period.',
		TD_GEO_CITY.GEO_COUNTRY_KEY as GEO_COUNTRY_KEY comment='A unique identifier for countries in the geographic data structure.',
		TD_GEO_CITY.GEO_LATITUDE as GEO_LATITUDE comment='Geographic latitude coordinate in decimal degrees.',
		TD_GEO_CITY.GEO_LONGITUDE as GEO_LONGITUDE comment='Geographic longitude coordinate expressed in decimal degrees.',
		TD_GEO_CITY.GEO_STATE_KEY as GEO_STATE_KEY comment='Numeric identifier for geographic states.',
		TD_GEO_LOC.GEO_COUNTRY_KEY as GEO_COUNTRY_KEY comment='A unique identifier for countries in the geographic location dimension.',
		TD_GEO_LOC.GEO_LATITUDE as GEO_LATITUDE comment='Geographic latitude coordinate expressed in decimal degrees.',
		TD_GEO_LOC.GEO_LONGITUDE as GEO_LONGITUDE comment='Geographic longitude coordinate expressed in decimal degrees.',
		TD_GEO_LOC.GEO_STATE_KEY as GEO_STATE_KEY comment='Unique identifier for geographic states.',
		TD_GEO_POSTAL.GEO_LATITUDE as GEO_LATITUDE comment='Geographic latitude coordinate expressed in decimal degrees.',
		TD_GEO_POSTAL.GEO_LONGITUDE as GEO_LONGITUDE comment='Geographic longitude coordinate expressed in decimal degrees.',
		TD_GEO_STATE.GEO_COUNTRY_KEY as GEO_COUNTRY_KEY comment='Geographic country key used as a unique identifier for countries.',
		TD_GEO_STATE.GEO_LATITUDE as GEO_LATITUDE comment='Geographic latitude coordinates for state locations.',
		TD_GEO_STATE.GEO_LONGITUDE as GEO_LONGITUDE comment='Geographic longitude coordinates for state locations.',
		TD_GEO_STATE.GEO_STATE_KEY as GEO_STATE_KEY comment='Unique identifier for geographic state records.',
		TD_HCO.HCO_STATUS_KEY as HCO_STATUS_KEY comment='Healthcare organization status identifier key.',
		TD_HCO.HCO_SUBTYPE_KEY as HCO_SUBTYPE_KEY comment='The unique identifier for the healthcare organization subtype.',
		TD_HCP.HCP_STATUS_KEY as HCP_STATUS_KEY comment='Healthcare provider status identifier used as a foreign key reference.',
		TD_HCP.HCP_SUBTYPE_KEY as HCP_SUBTYPE_KEY comment='Healthcare provider subtype identifier key.',
		TM_ARD_HCP_ACUTE_MKT_WEEKLY_XPO.ACUTE_NRX_XPO as ACUTE_NRX_XPO comment='Acute new prescription exposure index for healthcare providers in the market.',
		TM_ARD_HCP_ACUTE_MKT_WEEKLY_XPO.ACUTE_TRX_XPO as ACUTE_TRX_XPO comment='Acute transaction exposure metric for healthcare providers in the market.',
		TM_ARD_HCP_ACUTE_MKT_WEEKLY_XPO.ACUTE_TX_DAYS_XPO as ACUTE_TX_DAYS_XPO comment='The number of days of acute treatment exposure.',
		TM_ARD_HCP_ACUTE_MKT_WEEKLY_XPO.ACUTE_UNITS_XPO as ACUTE_UNITS_XPO comment='Acute care units exposure metric.',
		TM_ARD_HCP_ACUTE_MKT_WEEKLY_XPO.WEEK_DT as WEEK_DT comment='The date representing a specific week in the healthcare provider acute market reporting period.'
	)
	dimensions (
		ARD_GIACO_TM_HCP_ACUTE_MKT_WEEKLY_LAAD.BRANDED_FLAG as BRANDED_FLAG comment='Indicates whether the product is a branded medication.',
		ARD_GIACO_TM_HCP_ACUTE_MKT_WEEKLY_LAAD.GOLDEN_ID as GOLDEN_ID comment='A unique identifier used to link and track healthcare providers across different systems and databases.',
		ARD_GIACO_TM_HCP_ACUTE_MKT_WEEKLY_LAAD.HCP_ID as HCP_ID comment='Unique identifier for healthcare providers in the system.',
		ARD_GIACO_TM_HCP_ACUTE_MKT_WEEKLY_LAAD.HCP_SPECIALTY as HCP_SPECIALTY comment='Healthcare provider medical specialty or professional designation.',
		ARD_GIACO_TM_HCP_ACUTE_MKT_WEEKLY_LAAD.HCP_SPECIALTY_GROUP as HCP_SPECIALTY_GROUP comment='Healthcare provider specialty groups categorizing medical practice areas.',
		ARD_GIACO_TM_HCP_ACUTE_MKT_WEEKLY_LAAD.NPI as NPI comment='National Provider Identifier numbers for healthcare providers.',
		ARD_GIACO_TM_HCP_ACUTE_MKT_WEEKLY_LAAD.ONEKEY_HCP_ID as ONEKEY_HCP_ID comment='Unique identifier for healthcare professionals in the OneKey system.',
		ARD_GIACO_TM_HCP_ACUTE_MKT_WEEKLY_LAAD.PRACTICE_SETTING as PRACTICE_SETTING comment='The type of healthcare practice setting where medical services are provided.',
		ARD_GIACO_TM_HCP_ACUTE_MKT_WEEKLY_LAAD.PROCEDURE_GROUP as PROCEDURE_GROUP comment='Medical procedure categories or groupings used for classification purposes.',
		ARD_GIACO_TM_HCP_ACUTE_MKT_WEEKLY_LAAD.PRODUCT_CATEGORY as PRODUCT_CATEGORY comment='Categories of pharmaceutical pain management products used in acute care markets.',
		ARD_GIACO_TM_HCP_ACUTE_MKT_WEEKLY_LAAD.PRODUCT_FAMILY_GROUP as PRODUCT_FAMILY_GROUP comment='Pharmaceutical product family groups used for pain management and treatment.',
		ARD_GIACO_TM_HCP_ACUTE_MKT_WEEKLY_LAAD.PTAM_TERRITORY_ID as PTAM_TERRITORY_ID comment='Unique identifier for a PTAM (Pain Territory Account Manager) territory.',
		ARD_GIACO_TM_HCP_ACUTE_MKT_WEEKLY_LAAD.ROA as ROA comment='Route of administration for the medication or treatment.',
		ARD_GIACO_TM_HCP_ACUTE_MKT_WEEKLY_LAAD.SAL_TERRITORY_ID as SAL_TERRITORY_ID comment='Sales territory identifier used to designate specific geographic or organizational sales regions.',
		ARD_GIACO_TM_HCP_ACUTE_MKT_WEEKLY_LAAD.SITE_OF_CARE_ZIP_CODE as SITE_OF_CARE_ZIP_CODE comment='ZIP codes for healthcare facility locations.',
		ARD_GIACO_TM_HCP_ACUTE_MKT_WEEKLY_LAAD.VERTEX_ID as VERTEX_ID comment='Unique identifier for a vertex in the healthcare provider network.',
		ARD_GIACO_TM_HCP_ACUTE_MKT_WEEKLY_LAAD.ZIP_CODE as ZIP_CODE comment='Postal ZIP codes for geographic locations.',
		ARD_GIACO_TM_HCP_ACUTE_MKT_WEEKLY_LAAD.DATE_KEY as DATE_KEY comment='A date used as a key identifier in the healthcare provider acute market weekly reporting data.',
		TD_GEO_CITY.GEO_CITY_KEY as GEO_CITY_KEY comment='A unique identifier key for geographic city records.',
		TD_GEO_CITY.GEO_CITY_NAME as GEO_CITY_NAME comment='The name of a geographic city location.',
		TD_GEO_CITY.GEO_COUNTRY_CD as GEO_COUNTRY_CD comment='Geographic country code representing the country where the city is located.',
		TD_GEO_CITY.GEO_COUNTRY_NAME as GEO_COUNTRY_NAME comment='The name of the country in a geographic location.',
		TD_GEO_CITY.GEO_STATE_CD as GEO_STATE_CD comment='State codes for geographic locations.',
		TD_GEO_CITY.GEO_STATE_NAME as GEO_STATE_NAME comment='The name of the state within the United States.',
		TD_GEO_LOC.GEO_CITY_KEY as GEO_CITY_KEY comment='A unique identifier key for geographic cities.',
		TD_GEO_LOC.GEO_CITY_NAME as GEO_CITY_NAME comment='Geographic city names.',
		TD_GEO_LOC.GEO_COUNTRY_CD as GEO_COUNTRY_CD comment='Geographic country code representing the country location.',
		TD_GEO_LOC.GEO_COUNTRY_NAME as GEO_COUNTRY_NAME comment='The name of the country in a geographic location.',
		TD_GEO_LOC.GEO_LOC_KEY as GEO_LOC_KEY comment='A unique identifier for geographic location records.',
		TD_GEO_LOC.GEO_POSTAL_CD as GEO_POSTAL_CD comment='Postal codes for geographic locations.',
		TD_GEO_LOC.GEO_POSTAL_CD_EXT as GEO_POSTAL_CD_EXT comment='A column holding data of type VARCHAR(16777216).',
		TD_GEO_LOC.GEO_POSTAL_KEY as GEO_POSTAL_KEY comment='A unique identifier key for postal geographic locations.',
		TD_GEO_LOC.GEO_STATE_CD as GEO_STATE_CD comment='State codes for geographic locations.',
		TD_GEO_LOC.GEO_STATE_NAME as GEO_STATE_NAME comment='The name of the state within the United States.',
		TD_GEO_LOC.LOC_ADDR_LINE_1 as LOC_ADDR_LINE_1 comment='Street addresses including house numbers and street names.',
		TD_GEO_LOC.LOC_ADDR_LINE_2 as LOC_ADDR_LINE_2 comment='Secondary address information such as suite numbers, apartment numbers, or room designations.',
		TD_GEO_LOC.LOC_ADDR_LINE_3 as LOC_ADDR_LINE_3 comment='The third line of a location''s address.',
		TD_GEO_LOC.LOC_ADDR_LINE_4 as LOC_ADDR_LINE_4 comment='The fourth line of a location''s address.',
		TD_GEO_POSTAL.GEO_COUNTRY_CD as GEO_COUNTRY_CD comment='Geographic country code representing the country associated with a postal location.',
		TD_GEO_POSTAL.GEO_COUNTRY_KEY as GEO_COUNTRY_KEY comment='A unique identifier for geographic countries.',
		TD_GEO_POSTAL.GEO_COUNTRY_NAME as GEO_COUNTRY_NAME comment='The name of the country in a geographic location.',
		TD_GEO_POSTAL.GEO_POSTAL_CD as GEO_POSTAL_CD comment='Postal codes for geographic locations.',
		TD_GEO_POSTAL.GEO_POSTAL_KEY as GEO_POSTAL_KEY comment='A unique identifier key for geographic postal code records.',
		TD_GEO_POSTAL.GEO_STATE_CD as GEO_STATE_CD comment='State codes for geographic locations.',
		TD_GEO_POSTAL.GEO_STATE_KEY as GEO_STATE_KEY comment='Unique identifier for geographic states within the system.',
		TD_GEO_POSTAL.GEO_STATE_NAME as GEO_STATE_NAME comment='The name of the geographic state or territory.',
		TD_GEO_STATE.GEO_COUNTRY_CD as GEO_COUNTRY_CD comment='Geographic country code.',
		TD_GEO_STATE.GEO_COUNTRY_NAME as GEO_COUNTRY_NAME comment='The name of the country in a geographic location.',
		TD_GEO_STATE.GEO_STATE_CD as GEO_STATE_CD comment='Geographic state codes used to identify states or territories.',
		TD_GEO_STATE.GEO_STATE_NAME as GEO_STATE_NAME comment='Names of US states and territories.',
		TD_HCO.HCO_BUSINESS_NAME as HCO_BUSINESS_NAME comment='Healthcare organization business name.',
		TD_HCO.HCO_CD as HCO_CD comment='Healthcare organization codes used to identify specific healthcare entities.',
		TD_HCO.HCO_KEY as HCO_KEY comment='A unique identifier key for healthcare organizations.',
		TD_HCO.HCO_LEGAL_NAME as HCO_LEGAL_NAME comment='The legal name of the healthcare organization.',
		TD_HCO.HCO_NAME as HCO_NAME comment='Names of healthcare organizations.',
		TD_HCO.HCO_P_DEA_LIC_STATUS_CD as HCO_P_DEA_LIC_STATUS_CD comment='Healthcare organization Drug Enforcement Administration license status code.',
		TD_HCO.HCO_P_DEA_NUM as HCO_P_DEA_NUM comment='Drug Enforcement Administration number for healthcare organizations.',
		TD_HCO.HCO_P_GLN_NUM as HCO_P_GLN_NUM comment='Healthcare organization primary Global Location Number (GLN).',
		TD_HCO.HCO_P_HIN_NUM as HCO_P_HIN_NUM comment='A column holding data of type VARCHAR(16777216).',
		TD_HCO.HCO_P_NCPDP_NUM as HCO_P_NCPDP_NUM comment='A column holding data of type VARCHAR(16777216).',
		TD_HCO.HCO_P_NPI_NUM as HCO_P_NPI_NUM comment='Healthcare organization primary National Provider Identifier number.',
		TD_HCO.HCO_S_DEA_LIC_STATUS_CD as HCO_S_DEA_LIC_STATUS_CD comment='Healthcare organization Drug Enforcement Administration license status code.',
		TD_HCO.HCO_S_DEA_NUM as HCO_S_DEA_NUM comment='Drug Enforcement Administration number for healthcare organizations.',
		TD_HCO.HCO_S_GLN_NUM as HCO_S_GLN_NUM comment='Healthcare organization Global Location Number (GLN) used for unique identification in supply chain and healthcare transactions.',
		TD_HCO.HCO_S_HIN_NUM as HCO_S_HIN_NUM comment='A column holding data of type VARCHAR(16777216).',
		TD_HCO.HCO_S_NCPDP_NUM as HCO_S_NCPDP_NUM comment='A column holding data of type VARCHAR(16777216).',
		TD_HCO.HCO_S_NPI_NUM as HCO_S_NPI_NUM comment='National Provider Identifier number for healthcare organizations.',
		TD_HCO.HCO_SDESC as HCO_SDESC comment='Names of healthcare organizations.',
		TD_HCO.HCO_SRC_ID_IMS as HCO_SRC_ID_IMS comment='Healthcare organization source identifier from IMS data system.',
		TD_HCO.HCO_SRC_ID_P_SCRUB as HCO_SRC_ID_P_SCRUB comment='A column holding data of type VARCHAR(16777216).',
		TD_HCO.HCO_SRC_ID_P_SFA as HCO_SRC_ID_P_SFA comment='A column holding data of type VARCHAR(16777216).',
		TD_HCO.HCO_SRC_ID_S_SCRUB as HCO_SRC_ID_S_SCRUB comment='Healthcare organization source identifier after data scrubbing processes.',
		TD_HCO.HCO_SRC_ID_S_SFA as HCO_SRC_ID_S_SFA comment='A column holding data of type VARCHAR(16777216).',
		TD_HCO.HCO_SRC_ID_T_SCRUB as HCO_SRC_ID_T_SCRUB comment='A column holding data of type VARCHAR(16777216).',
		TD_HCO.HCO_SRC_ID_T_SFA as HCO_SRC_ID_T_SFA comment='A column holding data of type VARCHAR(16777216).',
		TD_HCO.HCO_SRC_ID_WKH as HCO_SRC_ID_WKH comment='A column holding data of type VARCHAR(16777216).',
		TD_HCO.HCO_T_DEA_LIC_STATUS_CD as HCO_T_DEA_LIC_STATUS_CD comment='Healthcare organization Drug Enforcement Administration license status code.',
		TD_HCO.HCO_T_DEA_NUM as HCO_T_DEA_NUM comment='A column holding data of type VARCHAR(16777216).',
		TD_HCO.HCO_T_GLN_NUM as HCO_T_GLN_NUM comment='Healthcare organization trading partner Global Location Number (GLN).',
		TD_HCO.HCO_T_HIN_NUM as HCO_T_HIN_NUM comment='A column holding data of type VARCHAR(16777216).',
		TD_HCO.HCO_T_NCPDP_NUM as HCO_T_NCPDP_NUM comment='A column holding data of type VARCHAR(16777216).',
		TD_HCO.HCO_T_NPI_NUM as HCO_T_NPI_NUM comment='Healthcare organization National Provider Identifier number.',
		TD_HCO.HCO_P_DEA_EXP_DT as HCO_P_DEA_EXP_DT comment='The expiration date of the healthcare organization''s Drug Enforcement Administration registration.',
		TD_HCO.HCO_S_DEA_EXP_DT as HCO_S_DEA_EXP_DT comment='The expiration date of the healthcare organization''s Drug Enforcement Administration registration.',
		TD_HCO.HCO_T_DEA_EXP_DT as HCO_T_DEA_EXP_DT comment='The expiration date of the healthcare organization''s Drug Enforcement Administration registration.',
		TD_HCO_SUBTYPE.HCO_SUBTYPE_CD as HCO_SUBTYPE_CD comment='Healthcare organization subtype codes that classify different types of medical entities and payer organizations.',
		TD_HCO_SUBTYPE.HCO_SUBTYPE_DESC as HCO_SUBTYPE_DESC comment='Healthcare organization subtype descriptions that categorize different types of medical entities and payers.',
		TD_HCO_SUBTYPE.HCO_SUBTYPE_KEY as HCO_SUBTYPE_KEY comment='Unique identifier for healthcare organization subtypes.',
		TD_HCO_SUBTYPE.HCO_TYPE_CD as HCO_TYPE_CD comment='Healthcare organization type code indicating the classification of the healthcare organization.',
		TD_HCO_SUBTYPE.HCO_TYPE_DESC as HCO_TYPE_DESC comment='Healthcare organization type description indicating the category or classification of the healthcare entity.',
		TD_HCO_SUBTYPE.HCO_TYPE_KEY as HCO_TYPE_KEY comment='A unique identifier for healthcare organization types.',
		TD_HCP.AMA_NO_CONTACT as AMA_NO_CONTACT comment='American Medical Association no contact indicator.',
		TD_HCP.EMAIL_ADDR_P as EMAIL_ADDR_P comment='Email addresses for healthcare professionals.',
		TD_HCP.EMAIL_ADDR_S as EMAIL_ADDR_S comment='Email addresses of healthcare providers.',
		TD_HCP.EMAIL_ADDR_T as EMAIL_ADDR_T comment='Email addresses for healthcare providers.',
		TD_HCP.HCP_DEGREE as HCP_DEGREE comment='The degree or credential held by the healthcare professional.',
		TD_HCP.HCP_FIRST_NAME as HCP_FIRST_NAME comment='The first name of the healthcare provider.',
		TD_HCP.HCP_GENDER as HCP_GENDER comment='The gender of the healthcare provider.',
		TD_HCP.HCP_GRAD_YR as HCP_GRAD_YR comment='The year when the healthcare provider graduated from their medical program.',
		TD_HCP.HCP_KEY as HCP_KEY comment='A unique identifier for healthcare providers in the system.',
		TD_HCP.HCP_LAST_NAME as HCP_LAST_NAME comment='Healthcare provider last names.',
		TD_HCP.HCP_ME_NUM as HCP_ME_NUM comment='Healthcare provider medical education number used for identification purposes.',
		TD_HCP.HCP_MID_NAME as HCP_MID_NAME comment='Middle names of healthcare providers.',
		TD_HCP.HCP_P_DEA_BUSINESS_ACTIVITY_CD as HCP_P_DEA_BUSINESS_ACTIVITY_CD comment='Healthcare provider Drug Enforcement Administration business activity code.',
		TD_HCP.HCP_P_DEA_DRUG_SCHEDULE as HCP_P_DEA_DRUG_SCHEDULE comment='A column holding data of type VARCHAR(16777216).',
		TD_HCP.HCP_P_DEA_LIC_STATUS_CD as HCP_P_DEA_LIC_STATUS_CD comment='The status code indicating whether a healthcare provider''s Drug Enforcement Administration license is active or inactive.',
		TD_HCP.HCP_P_DEA_NUM as HCP_P_DEA_NUM comment='Drug Enforcement Administration number assigned to healthcare providers for prescribing controlled substances.',
		TD_HCP.HCP_P_DEA_STATE_OF_LICENSURE as HCP_P_DEA_STATE_OF_LICENSURE comment='The state where the healthcare provider''s Drug Enforcement Administration license is issued.',
		TD_HCP.HCP_P_HIN as HCP_P_HIN comment='A column holding data of type VARCHAR(16777216).',
		TD_HCP.HCP_P_MA_ID as HCP_P_MA_ID comment='A column holding data of type VARCHAR(16777216).',
		TD_HCP.HCP_P_NPI_NUM as HCP_P_NPI_NUM comment='National Provider Identifier (NPI) numbers for healthcare providers.',
		TD_HCP.HCP_P_STATE_LIC_NUM as HCP_P_STATE_LIC_NUM comment='Healthcare provider state license numbers.',
		TD_HCP.HCP_P_STATE_LIC_STATE_CD as HCP_P_STATE_LIC_STATE_CD comment='State code where the healthcare provider holds their professional license.',
		TD_HCP.HCP_P_STATE_LIC_STATUS as HCP_P_STATE_LIC_STATUS comment='The status of a healthcare provider''s professional state license.',
		TD_HCP.HCP_PDRP_OPTOUT_IND as HCP_PDRP_OPTOUT_IND comment='Healthcare provider Patient Data Request Program opt-out indicator.',
		TD_HCP.HCP_PHONE_HOME_P as HCP_PHONE_HOME_P comment='Healthcare provider''s home phone number.',
		TD_HCP.HCP_PHONE_MOBILE_P as HCP_PHONE_MOBILE_P comment='Mobile phone number for the healthcare provider.',
		TD_HCP.HCP_PHONE_WORK_P as HCP_PHONE_WORK_P comment='Work phone numbers for healthcare providers.',
		TD_HCP.HCP_S_DEA_BUSINESS_ACTIVITY_CD as HCP_S_DEA_BUSINESS_ACTIVITY_CD comment='Drug Enforcement Administration business activity code for healthcare providers.',
		TD_HCP.HCP_S_DEA_DRUG_SCHEDULE as HCP_S_DEA_DRUG_SCHEDULE comment='A column holding data of type VARCHAR(16777216).',
		TD_HCP.HCP_S_DEA_LIC_STATUS_CD as HCP_S_DEA_LIC_STATUS_CD comment='Healthcare provider Drug Enforcement Administration license status code.',
		TD_HCP.HCP_S_DEA_NUM as HCP_S_DEA_NUM comment='Drug Enforcement Administration number assigned to healthcare providers for prescribing controlled substances.',
		TD_HCP.HCP_S_DEA_STATE_OF_LICENSURE as HCP_S_DEA_STATE_OF_LICENSURE comment='The state where the healthcare provider''s Drug Enforcement Administration license was issued.',
		TD_HCP.HCP_S_HIN as HCP_S_HIN comment='A column holding data of type VARCHAR(16777216).',
		TD_HCP.HCP_S_MA_ID as HCP_S_MA_ID comment='Healthcare provider master agreement identifier.',
		TD_HCP.HCP_S_NPI_NUM as HCP_S_NPI_NUM comment='National Provider Identifier number for healthcare providers.',
		TD_HCP.HCP_S_STATE_LIC_NUM as HCP_S_STATE_LIC_NUM comment='State license numbers for healthcare providers.',
		TD_HCP.HCP_S_STATE_LIC_STATE_CD as HCP_S_STATE_LIC_STATE_CD comment='State code where the healthcare provider holds their professional license.',
		TD_HCP.HCP_S_STATE_LIC_STATUS as HCP_S_STATE_LIC_STATUS comment='The status of a healthcare provider''s state license.',
		TD_HCP.HCP_SRC_ID_10_IMS2 as HCP_SRC_ID_10_IMS2 comment='Healthcare provider source identifier from IMS database system.',
		TD_HCP.HCP_SRC_ID_3_SCRUB as HCP_SRC_ID_3_SCRUB comment='Healthcare provider source identifier from the third data source after data scrubbing processes.',
		TD_HCP.HCP_SRC_ID_4_SFA as HCP_SRC_ID_4_SFA comment='A column holding data of type VARCHAR(16777216).',
		TD_HCP.HCP_SRC_ID_5_SFA as HCP_SRC_ID_5_SFA comment='A column holding data of type VARCHAR(16777216).',
		TD_HCP.HCP_SRC_ID_CF_SPDI as HCP_SRC_ID_CF_SPDI comment='A column holding data of type VARCHAR(16777216).',
		TD_HCP.HCP_SRC_ID_IMS as HCP_SRC_ID_IMS comment='Healthcare provider source identifier from IMS data system.',
		TD_HCP.HCP_SRC_ID_OH_TDDD as HCP_SRC_ID_OH_TDDD comment='A column holding data of type VARCHAR(16777216).',
		TD_HCP.HCP_SRC_ID_P_CLIENT as HCP_SRC_ID_P_CLIENT comment='A column holding data of type VARCHAR(16777216).',
		TD_HCP.HCP_SRC_ID_P_COPROMO as HCP_SRC_ID_P_COPROMO comment='A column holding data of type VARCHAR(16777216).',
		TD_HCP.HCP_SRC_ID_P_SCRUB as HCP_SRC_ID_P_SCRUB comment='Healthcare provider source identifier after data scrubbing processes.',
		TD_HCP.HCP_SRC_ID_P_SFA as HCP_SRC_ID_P_SFA comment='A column holding data of type VARCHAR(16777216).',
		TD_HCP.HCP_SRC_ID_P_SP as HCP_SRC_ID_P_SP comment='A column holding data of type VARCHAR(16777216).',
		TD_HCP.HCP_SRC_ID_S_CLIENT as HCP_SRC_ID_S_CLIENT comment='A column holding data of type VARCHAR(16777216).',
		TD_HCP.HCP_SRC_ID_S_COPROMO as HCP_SRC_ID_S_COPROMO comment='A column holding data of type VARCHAR(16777216).',
		TD_HCP.HCP_SRC_ID_S_SCRUB as HCP_SRC_ID_S_SCRUB comment='Healthcare provider source identifier after data scrubbing processes.',
		TD_HCP.HCP_SRC_ID_S_SFA as HCP_SRC_ID_S_SFA comment='A column holding data of type VARCHAR(16777216).',
		TD_HCP.HCP_SRC_ID_S_SP as HCP_SRC_ID_S_SP comment='A column holding data of type VARCHAR(16777216).',
		TD_HCP.HCP_SRC_ID_SHA as HCP_SRC_ID_SHA comment='A column holding data of type VARCHAR(16777216).',
		TD_HCP.HCP_SRC_ID_T_COPROMO as HCP_SRC_ID_T_COPROMO comment='A column holding data of type VARCHAR(16777216).',
		TD_HCP.HCP_SRC_ID_T_SFA as HCP_SRC_ID_T_SFA comment='A column holding data of type VARCHAR(16777216).',
		TD_HCP.HCP_SRC_ID_T_SP as HCP_SRC_ID_T_SP comment='A column holding data of type VARCHAR(16777216).',
		TD_HCP.HCP_SUFFIX as HCP_SUFFIX comment='Healthcare provider name suffix such as senior or junior designations.',
		TD_HCP.HCP_T_DEA_BUSINESS_ACTIVITY_CD as HCP_T_DEA_BUSINESS_ACTIVITY_CD comment='Drug Enforcement Administration business activity code for healthcare providers.',
		TD_HCP.HCP_T_DEA_DRUG_SCHEDULE as HCP_T_DEA_DRUG_SCHEDULE comment='A column holding data of type VARCHAR(16777216).',
		TD_HCP.HCP_T_DEA_LIC_STATUS_CD as HCP_T_DEA_LIC_STATUS_CD comment='Healthcare provider Drug Enforcement Administration license status code.',
		TD_HCP.HCP_T_DEA_NUM as HCP_T_DEA_NUM comment='Drug Enforcement Administration number for healthcare providers.',
		TD_HCP.HCP_T_DEA_STATE_OF_LICENSURE as HCP_T_DEA_STATE_OF_LICENSURE comment='The state where the healthcare provider''s Drug Enforcement Administration license was issued.',
		TD_HCP.HCP_T_HIN as HCP_T_HIN comment='A column holding data of type VARCHAR(16777216).',
		TD_HCP.HCP_T_MA_ID as HCP_T_MA_ID comment='A column holding data of type VARCHAR(16777216).',
		TD_HCP.HCP_T_NPI_NUM as HCP_T_NPI_NUM comment='National Provider Identifier number for healthcare providers.',
		TD_HCP.HCP_T_STATE_LIC_NUM as HCP_T_STATE_LIC_NUM comment='Healthcare provider state license numbers.',
		TD_HCP.HCP_T_STATE_LIC_STATE_CD as HCP_T_STATE_LIC_STATE_CD comment='The state code where the healthcare provider holds their license.',
		TD_HCP.HCP_T_STATE_LIC_STATUS as HCP_T_STATE_LIC_STATUS comment='The status of a healthcare provider''s state license.',
		TD_HCP.HCP_TITLE as HCP_TITLE comment='Healthcare provider professional title or designation.',
		TD_HCP.KOL_IND as KOL_IND comment='Key opinion leader indicator flag.',
		TD_HCP.NO_SEE_IND as NO_SEE_IND comment='A column holding data of type VARCHAR(16777216).',
		TD_HCP.SAMPLEABILITY_IND as SAMPLEABILITY_IND comment='An indicator of whether the healthcare provider can be sampled.',
		TD_HCP.HCP_BIRTH_DT as HCP_BIRTH_DT comment='Healthcare provider birth dates.',
		TD_HCP.HCP_P_DEA_EXP_DT as HCP_P_DEA_EXP_DT comment='The expiration date of the healthcare provider''s Drug Enforcement Administration registration.',
		TD_HCP.HCP_P_STATE_LIC_EXP_DT as HCP_P_STATE_LIC_EXP_DT comment='The expiration date of the healthcare provider''s state license.',
		TD_HCP.HCP_P_STATE_LIC_ISSUE_DT as HCP_P_STATE_LIC_ISSUE_DT comment='The date when the healthcare provider''s state license was issued.',
		TD_HCP.HCP_PDRP_OPTOUT_DT as HCP_PDRP_OPTOUT_DT comment='The date when a healthcare provider opted out of the Prescription Drug Reporting Program.',
		TD_HCP.HCP_S_DEA_EXP_DT as HCP_S_DEA_EXP_DT comment='The expiration date of the healthcare provider''s Drug Enforcement Administration registration.',
		TD_HCP.HCP_S_STATE_LIC_EXP_DT as HCP_S_STATE_LIC_EXP_DT comment='The expiration date of the healthcare provider''s state license.',
		TD_HCP.HCP_S_STATE_LIC_ISSUE_DT as HCP_S_STATE_LIC_ISSUE_DT comment='The date when the healthcare provider''s state license was issued.',
		TD_HCP.HCP_T_DEA_EXP_DT as HCP_T_DEA_EXP_DT comment='The expiration date of the healthcare provider''s Drug Enforcement Administration registration.',
		TD_HCP.HCP_T_STATE_LIC_EXP_DT as HCP_T_STATE_LIC_EXP_DT comment='The expiration date of the healthcare provider''s state license.',
		TD_HCP.HCP_T_STATE_LIC_ISSUE_DT as HCP_T_STATE_LIC_ISSUE_DT comment='The date when the healthcare provider''s state license was issued.',
		TD_HCP.SAMPLEABILITY_DT as SAMPLEABILITY_DT comment='The date when sampleability status was determined or last updated.',
		TD_PROD_BRAND.PROD_BRAND_CD as PROD_BRAND_CD comment='Product brand codes for pharmaceutical and medical products.',
		TD_PROD_BRAND.PROD_BRAND_DESC as PROD_BRAND_DESC comment='Brand names of pharmaceutical pain management products along with their associated market categories.',
		TD_PROD_BRAND.PROD_BRAND_KEY as PROD_BRAND_KEY comment='A unique identifier key for product brands.',
		TD_PROD_BRAND.PROD_BRAND_SDESC as PROD_BRAND_SDESC comment='Product brand short description or name.',
		TD_PROD_BRAND.PROD_BRAND_UCD as PROD_BRAND_UCD comment='Brand names of pharmaceutical and over-the-counter medical products.',
		TD_PROD_BRAND.PROD_CAT_CD as PROD_CAT_CD comment='Pharmaceutical product category codes indicating the therapeutic classification of medical products.',
		TD_PROD_BRAND.PROD_CAT_DESC as PROD_CAT_DESC comment='Product category descriptions for pharmaceutical pain management treatments.',
		TD_PROD_BRAND.PROD_CAT_KEY as PROD_CAT_KEY comment='A unique identifier key for product categories.',
		TD_PROD_BRAND.PROD_CAT_SDESC as PROD_CAT_SDESC comment='Product category short descriptions for pharmaceutical and medical products.',
		TD_PROD_BRAND.PROD_CATGRP_CD as PROD_CATGRP_CD comment='Product category group codes representing different pharmaceutical and medical product classifications.',
		TD_PROD_BRAND.PROD_CATGRP_DESC as PROD_CATGRP_DESC comment='Product category group descriptions for pharmaceutical products in acute care markets.',
		TD_PROD_BRAND.PROD_CATGRP_KEY as PROD_CATGRP_KEY comment='A unique identifier key for product category groups.',
		TD_PROD_BRAND.PROD_CATGRP_SDESC as PROD_CATGRP_SDESC comment='Product category group short description indicating the therapeutic classification or type of pharmaceutical product.',
		TD_PROD_BRAND.PROD_FAM_CD as PROD_FAM_CD comment='Product family codes used to categorize and group related products.',
		TD_PROD_BRAND.PROD_FAM_DESC as PROD_FAM_DESC comment='Product family descriptions for pain relief medications and treatments.',
		TD_PROD_BRAND.PROD_FAM_KEY as PROD_FAM_KEY comment='A unique identifier key for product families.',
		TD_PROD_BRAND.PROD_FAM_SDESC as PROD_FAM_SDESC comment='Pharmaceutical product family short descriptions or names.',
		TD_PROD_BRAND.PROD_FAMGRP_CD as PROD_FAMGRP_CD comment='Active pharmaceutical ingredients or drug compounds used in pain management products.',
		TD_PROD_BRAND.PROD_FAMGRP_DESC as PROD_FAMGRP_DESC comment='Pharmaceutical product family group descriptions indicating drug types and their associated pain market categories.',
		TD_PROD_BRAND.PROD_FAMGRP_KEY as PROD_FAMGRP_KEY comment='A unique identifier key for product family groups represented as a hash value.',
		TD_PROD_BRAND.PROD_FAMGRP_SDESC as PROD_FAMGRP_SDESC comment='Pharmaceutical product family group short descriptions indicating the active ingredient or drug category.',
		TD_PROD_BRAND.PROD_MKT_CD as PROD_MKT_CD comment='Product marketing code identifying the specific marketing category or segment for the product brand.',
		TD_PROD_BRAND.PROD_MKT_DESC as PROD_MKT_DESC comment='Product market description indicating the specific market segment or category for the product.',
		TD_PROD_BRAND.PROD_MKT_KEY as PROD_MKT_KEY comment='A unique marketing key identifier for products.',
		TD_PROD_BRAND.PROD_MKT_SDESC as PROD_MKT_SDESC comment='Product marketing short description for pharmaceutical pain management brands.',
		TM_ARD_HCP_ACUTE_MKT_WEEKLY_XPO.BRANDED_FLAG as BRANDED_FLAG comment='A flag indicating whether the product is branded or not.',
		TM_ARD_HCP_ACUTE_MKT_WEEKLY_XPO.GOLDEN_ID as GOLDEN_ID comment='A unique identifier used to link and track healthcare providers across different systems and databases.',
		TM_ARD_HCP_ACUTE_MKT_WEEKLY_XPO.HCP_ID as HCP_ID comment='Unique identifier for healthcare providers.',
		TM_ARD_HCP_ACUTE_MKT_WEEKLY_XPO.HCP_SPECIALTY as HCP_SPECIALTY comment='Medical specialty or practice area of the healthcare provider.',
		TM_ARD_HCP_ACUTE_MKT_WEEKLY_XPO.HCP_SPECIALTY_GROUP as HCP_SPECIALTY_GROUP comment='Healthcare provider specialty groups categorizing medical professionals by their area of practice.',
		TM_ARD_HCP_ACUTE_MKT_WEEKLY_XPO.NPI as NPI comment='National Provider Identifier numbers for healthcare providers.',
		TM_ARD_HCP_ACUTE_MKT_WEEKLY_XPO.ONEKEY_HCP_ID as ONEKEY_HCP_ID comment='Unique identifier for healthcare providers in the OneKey system.',
		TM_ARD_HCP_ACUTE_MKT_WEEKLY_XPO.PRODUCT_CATEGORY as PRODUCT_CATEGORY comment='Categories of pharmaceutical products used for pain management and treatment.',
		TM_ARD_HCP_ACUTE_MKT_WEEKLY_XPO.PRODUCT_FAMILY_GROUP as PRODUCT_FAMILY_GROUP comment='Pharmaceutical product family groups categorizing related medications and therapeutic compounds.',
		TM_ARD_HCP_ACUTE_MKT_WEEKLY_XPO.PTAM_TERRITORY_ID as PTAM_TERRITORY_ID comment='Unique identifier for a PTAM (Pain Territory Account Manager) territory.',
		TM_ARD_HCP_ACUTE_MKT_WEEKLY_XPO.ROA as ROA comment='Route of administration for pharmaceutical products.',
		TM_ARD_HCP_ACUTE_MKT_WEEKLY_XPO.SAL_TERRITORY_ID as SAL_TERRITORY_ID comment='Sales territory identifier used to designate specific geographic or organizational sales regions.',
		TM_ARD_HCP_ACUTE_MKT_WEEKLY_XPO.SITE_OF_CARE_ZIP_CODE as SITE_OF_CARE_ZIP_CODE comment='ZIP codes for healthcare facility locations.',
		TM_ARD_HCP_ACUTE_MKT_WEEKLY_XPO.VERTEX_ID as VERTEX_ID comment='Unique identifier for a vertex in the healthcare provider network.',
		TM_ARD_HCP_ACUTE_MKT_WEEKLY_XPO.ZIP_CODE as ZIP_CODE comment='Postal ZIP codes for geographic locations.',
		TM_ARD_HCP_ACUTE_MKT_WEEKLY_XPO.DATE_KEY as DATE_KEY comment='The date associated with each record in the healthcare provider acute market weekly exposure data.'
	)
	with extension (CA='{"tables":[{"name":"ARD_GIACO_TM_HCP_ACUTE_MKT_WEEKLY_LAAD","dimensions":[{"name":"BRANDED_FLAG","sample_values":["N","Y"]},{"name":"GOLDEN_ID","sample_values":["GLD004700470057009305","GLD000900090008008206","GLD999909691076060401"]},{"name":"HCP_ID","sample_values":["2bb17ea9ca26bb191254a298da5e5b31","e78d13c51088736b6ad0abcfb0db5496","232e71209a7c50de00969cff0164f64f"]},{"name":"HCP_SPECIALTY","sample_values":["GERIATRIC MEDICINE (INTERNAL MEDICINE)","COLON & RECTAL SURGERY","GENERAL SURGERY"]},{"name":"HCP_SPECIALTY_GROUP","sample_values":["SURGERY","MEDICINE","ALL OTHER"]},{"name":"NPI","sample_values":["1568438992","1093197857","1710410949"]},{"name":"ONEKEY_HCP_ID","sample_values":["WUSM00274580","WUSR03862562","WUSM01303609"]},{"name":"PRACTICE_SETTING","sample_values":["RETAIL","DISCHARGE"]},{"name":"PROCEDURE_GROUP","sample_values":["LAPAROSCOPIC UROLOGIC PROCEDURES","OB/GYN PROCEDURES","JOINT REPAIR"]},{"name":"PRODUCT_CATEGORY","sample_values":["ANALGESICS-SEDATIVE COMBINATION","DERMATOLOGICAL LOCAL TOPICAL ANESTHETIC","MODERATE OPIOID COMBINATIONS"]},{"name":"PRODUCT_FAMILY_GROUP","sample_values":["IBUPROFEN","DICLOFENAC","MELOXICAM"]},{"name":"PTAM_TERRITORY_ID","sample_values":["V1NAUSA-5733506","V1NAUSA-5733204","V1NAUSA-5733403"]},{"name":"ROA","sample_values":["ORAL","TOPICAL","TOPICAL-PATCH"]},{"name":"SAL_TERRITORY_ID","sample_values":["V1NAUSA-5720008","V1NAUSA-5720014","V1NAUSA-5720013"]},{"name":"SITE_OF_CARE_ZIP_CODE","sample_values":["80911","76903","32771"]},{"name":"VERTEX_ID","sample_values":["14811523","14821592","17503007"]},{"name":"ZIP_CODE","sample_values":["14621","01805","95337"]}],"facts":[{"name":"ACUTE_CALENDAR_DAYS_LAAD","sample_values":["1.00000","3.00000","10.00000"]},{"name":"ACUTE_EPISODES_LAAD","sample_values":["1","4","2"]},{"name":"ACUTE_PROCEDURES_LAAD","sample_values":["1","3","2"]},{"name":"ACUTE_REFILLS_LAAD","sample_values":["2","4","1"]},{"name":"ACUTE_TRX_LAAD","sample_values":["5","1","3"]},{"name":"ACUTE_TX_DAYS_LAAD","sample_values":["5.00000","10.00000","30.00000"]},{"name":"ACUTE_UNITS_LAAD","sample_values":["9.00000","20.00000","90.00000"]},{"name":"WEEK_DT","sample_values":["20240524","20250418","20250606"]}],"time_dimensions":[{"name":"DATE_KEY","sample_values":["2025-02-14","2024-11-15","2022-11-11"]}]},{"name":"TD_GEO_CITY","dimensions":[{"name":"GEO_CITY_KEY","sample_values":["cb004e0c1c429625db774a086579bd3b","3de4110deff030eca4c2da9e8e85ae39","6b5b3307241b5195dd6bfef7630d834e"]},{"name":"GEO_CITY_NAME","sample_values":["BELLEVUE","MATTAPAN","TALLAHASSEE FALLS"]},{"name":"GEO_COUNTRY_CD","sample_values":["US"]},{"name":"GEO_COUNTRY_NAME","sample_values":["UNITED STATES"]},{"name":"GEO_STATE_CD","sample_values":["XX","VT","FL"]},{"name":"GEO_STATE_NAME","sample_values":["SOUTH CAROLINA","TENNESSEE","NEBRASKA"]}],"facts":[{"name":"GEO_COUNTRY_KEY","sample_values":["1"]},{"name":"GEO_LATITUDE"},{"name":"GEO_LONGITUDE"},{"name":"GEO_STATE_KEY","sample_values":["21","22","53"]}]},{"name":"TD_GEO_LOC","dimensions":[{"name":"GEO_CITY_KEY","sample_values":["e190c59f3d88823cb626962e558314df","21bb6ea0074b193b6643355e6b83aec2","a6a0645ce9ac1995532b4bb9f28ce04c"]},{"name":"GEO_CITY_NAME","sample_values":["HARRISBURG","SAINT LOUIS","DEER LODGE"]},{"name":"GEO_COUNTRY_CD","sample_values":["US"]},{"name":"GEO_COUNTRY_NAME","sample_values":["UNITED STATES"]},{"name":"GEO_LOC_KEY","sample_values":["96a44f5985fb18551e9c45db3d75f237","40665982fb20e15ee0b1e0bde8b43330","512d454f090f878a6e8175cad706cecc"]},{"name":"GEO_POSTAL_CD","sample_values":["45459","92037","33175"]},{"name":"GEO_POSTAL_CD_EXT"},{"name":"GEO_POSTAL_KEY","sample_values":["c3195f6d307dd319bf1275b8f98dca51","1a1c1e45309875960a48106f0b73a0b9","f8ca2b7549985685fb5a1275bfcced43"]},{"name":"GEO_STATE_CD","sample_values":["FL","MI","MA"]},{"name":"GEO_STATE_NAME","sample_values":["SOUTH CAROLINA","MONTANA","PENNSYLVANIA"]},{"name":"LOC_ADDR_LINE_1","sample_values":["12110 NE 64TH PL","1920 LENLAND AVE","210 BAXTER ST"]},{"name":"LOC_ADDR_LINE_2","sample_values":["UNIT B","APT 206"]},{"name":"LOC_ADDR_LINE_3"},{"name":"LOC_ADDR_LINE_4"}],"facts":[{"name":"GEO_COUNTRY_KEY","sample_values":["1"]},{"name":"GEO_LATITUDE"},{"name":"GEO_LONGITUDE"},{"name":"GEO_STATE_KEY","sample_values":["59","22","30"]}]},{"name":"TD_GEO_POSTAL","dimensions":[{"name":"GEO_COUNTRY_CD","sample_values":["US"]},{"name":"GEO_COUNTRY_KEY","sample_values":["1"]},{"name":"GEO_COUNTRY_NAME","sample_values":["UNITED STATES"]},{"name":"GEO_POSTAL_CD","sample_values":["25205","62545","78675"]},{"name":"GEO_POSTAL_KEY","sample_values":["794d1a9eee30d774236a5186a2b55bf9","0eec7bab53a4751845b83ff0ce77c5a1","728b5b967aeb1d257948dc6e622bbc95"]},{"name":"GEO_STATE_CD","sample_values":["TX","WV","MS"]},{"name":"GEO_STATE_KEY","sample_values":["75","59","28"]},{"name":"GEO_STATE_NAME","sample_values":["GEORGIA","NEW JERSEY","TEXAS"]}],"facts":[{"name":"GEO_LATITUDE"},{"name":"GEO_LONGITUDE"}]},{"name":"TD_GEO_STATE","dimensions":[{"name":"GEO_COUNTRY_CD","sample_values":["US"]},{"name":"GEO_COUNTRY_NAME","sample_values":["UNITED STATES"]},{"name":"GEO_STATE_CD","sample_values":["NC","XX","DE"]},{"name":"GEO_STATE_NAME","sample_values":["SOUTH CAROLINA","DELAWARE","NEBRASKA"]}],"facts":[{"name":"GEO_COUNTRY_KEY","sample_values":["1"]},{"name":"GEO_LATITUDE","sample_values":["39.00040000","34.00040000"]},{"name":"GEO_LONGITUDE","sample_values":["-86.25030000","-71.49980000","-123.04600000"]},{"name":"GEO_STATE_KEY","sample_values":["21","261","22"]}]},{"name":"TD_HCO","dimensions":[{"name":"HCO_BUSINESS_NAME","sample_values":["CSC COMMUNITY PHARMACY","ENDOSCOPY AND SURGICAL CARE SUITE"]},{"name":"HCO_CD","sample_values":["1438","22740441","30819949"]},{"name":"HCO_KEY","sample_values":["f40f52d91c6e993b6c7c5af4716c359b","27e97cbb80be61e0fb616254104d33b3","a9322f73290eae0c74ca2d7b98379369"]},{"name":"HCO_LEGAL_NAME","sample_values":["BINUR, NIR, OFFICE","ALTAMED PHARMACY BOYLE HEIGHTS","ONE HEALTH GASTROENTEROLOGY AND HEPATOLOGY"]},{"name":"HCO_NAME","sample_values":["MYCARE PHARMACY","FERRER, OLGA M, OFFICE","COSHOCTON REGIONAL MEDICAL CENTER INTENSIVE CARE UNIT"]},{"name":"HCO_P_DEA_LIC_STATUS_CD"},{"name":"HCO_P_DEA_NUM","sample_values":["FV5496244","FG5718347"]},{"name":"HCO_P_GLN_NUM"},{"name":"HCO_P_HIN_NUM","sample_values":["L89YW0W00","38G06QNF1","8N302YY00"]},{"name":"HCO_P_NCPDP_NUM"},{"name":"HCO_P_NPI_NUM"},{"name":"HCO_S_DEA_LIC_STATUS_CD"},{"name":"HCO_S_DEA_NUM","sample_values":["FM3749629","FP5150862"]},{"name":"HCO_S_GLN_NUM"},{"name":"HCO_S_HIN_NUM"},{"name":"HCO_S_NCPDP_NUM"},{"name":"HCO_S_NPI_NUM"},{"name":"HCO_SDESC","sample_values":["CASPER COLLEGE STUDENT HEALTH SERVICES","ROYAL SUPPLIES","AVERA SURGICAL ASSOCIATES ENDOSCOPY"]},{"name":"HCO_SRC_ID_IMS","sample_values":["WUSH00158767","2705090","22740441"]},{"name":"HCO_SRC_ID_P_SCRUB"},{"name":"HCO_SRC_ID_P_SFA"},{"name":"HCO_SRC_ID_S_SCRUB","sample_values":["WUSF00046723","WUSE01155990","WUSF00100048"]},{"name":"HCO_SRC_ID_S_SFA"},{"name":"HCO_SRC_ID_T_SCRUB"},{"name":"HCO_SRC_ID_T_SFA"},{"name":"HCO_SRC_ID_WKH"},{"name":"HCO_T_DEA_LIC_STATUS_CD"},{"name":"HCO_T_DEA_NUM","sample_values":["HV00789","RM0314790"]},{"name":"HCO_T_GLN_NUM"},{"name":"HCO_T_HIN_NUM"},{"name":"HCO_T_NCPDP_NUM"},{"name":"HCO_T_NPI_NUM"}],"facts":[{"name":"HCO_STATUS_KEY","sample_values":["1"]},{"name":"HCO_SUBTYPE_KEY","sample_values":["35","30","39"]}],"time_dimensions":[{"name":"HCO_P_DEA_EXP_DT"},{"name":"HCO_S_DEA_EXP_DT"},{"name":"HCO_T_DEA_EXP_DT"}]},{"name":"TD_HCO_SUBTYPE","dimensions":[{"name":"HCO_SUBTYPE_CD","sample_values":["VA CMOP","PAYER_REG","PBM"]},{"name":"HCO_SUBTYPE_DESC","sample_values":["MCO PBM","IDN","MCO NATIONAL PAYER"]},{"name":"HCO_SUBTYPE_KEY","sample_values":["1","2","3"]},{"name":"HCO_TYPE_CD","sample_values":["ORG","MCO"]},{"name":"HCO_TYPE_DESC","sample_values":["ORGANIZATION","MANAGED CARE ORGANIZATION"]},{"name":"HCO_TYPE_KEY","sample_values":["1","2"]}]},{"name":"TD_HCP","dimensions":[{"name":"AMA_NO_CONTACT","sample_values":["N","Y"]},{"name":"EMAIL_ADDR_P","sample_values":["ATELIS1150730@WM.PROVIDENCEDIRECT.ORG","KATYDM7@HOTMAIL.COM","GRANTJSULLIVAN@ATT.NET"]},{"name":"EMAIL_ADDR_S","sample_values":["T.THOMAS@ARCHILDRENS.ORG","EHUANG@POST.HARVARD.EDU","CGOODWIN@UMC.EDU"]},{"name":"EMAIL_ADDR_T"},{"name":"HCP_DEGREE","sample_values":["PHT","RPH","NP"]},{"name":"HCP_FIRST_NAME","sample_values":["SHANE","ROYAL","CASIANNE"]},{"name":"HCP_GENDER","sample_values":["FEMALE","UNKNOWN"]},{"name":"HCP_GRAD_YR","sample_values":["1967","2019","1965"]},{"name":"HCP_KEY","sample_values":["10f535a03919512d15df722bdf50f8fe","59c026c2a4da8798332fd8140066c866","cce70a032d441fc7cf17357da57ffa3e"]},{"name":"HCP_LAST_NAME","sample_values":["FULP","GERBER","DIGGINS"]},{"name":"HCP_ME_NUM","sample_values":["4950901017","0230178074"]},{"name":"HCP_MID_NAME","sample_values":["ANN","DARLENE","TUCKER"]},{"name":"HCP_P_DEA_BUSINESS_ACTIVITY_CD"},{"name":"HCP_P_DEA_DRUG_SCHEDULE"},{"name":"HCP_P_DEA_LIC_STATUS_CD","sample_values":["ACTIVE"]},{"name":"HCP_P_DEA_NUM","sample_values":["AB7255272","BB3188833"]},{"name":"HCP_P_DEA_STATE_OF_LICENSURE","sample_values":["TX","MA","LA"]},{"name":"HCP_P_HIN"},{"name":"HCP_P_MA_ID","sample_values":["216513","166691","169135"]},{"name":"HCP_P_NPI_NUM","sample_values":["1134821382","1235525957","1558956375"]},{"name":"HCP_P_STATE_LIC_NUM","sample_values":["PA2022-0048","107955","238052"]},{"name":"HCP_P_STATE_LIC_STATE_CD","sample_values":["AR","NV","TX"]},{"name":"HCP_P_STATE_LIC_STATUS","sample_values":["INACTIVE","ACTIVE"]},{"name":"HCP_PDRP_OPTOUT_IND","sample_values":["Y","N"]},{"name":"HCP_PHONE_HOME_P"},{"name":"HCP_PHONE_MOBILE_P"},{"name":"HCP_PHONE_WORK_P","sample_values":["3604862900","2183486888","9155323937"]},{"name":"HCP_S_DEA_BUSINESS_ACTIVITY_CD"},{"name":"HCP_S_DEA_DRUG_SCHEDULE"},{"name":"HCP_S_DEA_LIC_STATUS_CD","sample_values":["ACTIVE"]},{"name":"HCP_S_DEA_NUM","sample_values":["FG6124919","FF8289161"]},{"name":"HCP_S_DEA_STATE_OF_LICENSURE","sample_values":["VA","NE"]},{"name":"HCP_S_HIN"},{"name":"HCP_S_MA_ID","sample_values":["381767","808700","469231"]},{"name":"HCP_S_NPI_NUM","sample_values":["1003443490","1396321816","1295437895"]},{"name":"HCP_S_STATE_LIC_NUM","sample_values":["RN528086L","053978-23","22566"]},{"name":"HCP_S_STATE_LIC_STATE_CD","sample_values":["CT","WI"]},{"name":"HCP_S_STATE_LIC_STATUS","sample_values":["PROBATION","ACTIVE"]},{"name":"HCP_SRC_ID_10_IMS2","sample_values":["7692967","24968143","8098879"]},{"name":"HCP_SRC_ID_3_SCRUB","sample_values":["WUSM01621661","WUSR06017841","WUSP00548392"]},{"name":"HCP_SRC_ID_4_SFA"},{"name":"HCP_SRC_ID_5_SFA"},{"name":"HCP_SRC_ID_CF_SPDI"},{"name":"HCP_SRC_ID_IMS","sample_values":["7182700","1292510","2851684"]},{"name":"HCP_SRC_ID_OH_TDDD","sample_values":["020363900","021366000"]},{"name":"HCP_SRC_ID_P_CLIENT"},{"name":"HCP_SRC_ID_P_COPROMO"},{"name":"HCP_SRC_ID_P_SCRUB","sample_values":["13322122","15733078"]},{"name":"HCP_SRC_ID_P_SFA"},{"name":"HCP_SRC_ID_P_SP"},{"name":"HCP_SRC_ID_S_CLIENT"},{"name":"HCP_SRC_ID_S_COPROMO"},{"name":"HCP_SRC_ID_S_SCRUB","sample_values":["WUSM05200310","WUSM04669326","WUSM00017540"]},{"name":"HCP_SRC_ID_S_SFA"},{"name":"HCP_SRC_ID_S_SP"},{"name":"HCP_SRC_ID_SHA"},{"name":"HCP_SRC_ID_T_COPROMO"},{"name":"HCP_SRC_ID_T_SFA"},{"name":"HCP_SRC_ID_T_SP"},{"name":"HCP_SUFFIX","sample_values":["JR","II","SR"]},{"name":"HCP_T_DEA_BUSINESS_ACTIVITY_CD"},{"name":"HCP_T_DEA_DRUG_SCHEDULE"},{"name":"HCP_T_DEA_LIC_STATUS_CD","sample_values":["ACTIVE"]},{"name":"HCP_T_DEA_NUM","sample_values":["FK9444655","FB3199975"]},{"name":"HCP_T_DEA_STATE_OF_LICENSURE","sample_values":["SD","TN"]},{"name":"HCP_T_HIN"},{"name":"HCP_T_MA_ID","sample_values":["634359","526408"]},{"name":"HCP_T_NPI_NUM"},{"name":"HCP_T_STATE_LIC_NUM","sample_values":["0810007329","23410"]},{"name":"HCP_T_STATE_LIC_STATE_CD","sample_values":["MD","FL"]},{"name":"HCP_T_STATE_LIC_STATUS","sample_values":["INACTIVE","ACTIVE"]},{"name":"HCP_TITLE"},{"name":"KOL_IND"},{"name":"NO_SEE_IND"},{"name":"SAMPLEABILITY_IND"}],"facts":[{"name":"HCP_STATUS_KEY","sample_values":["1"]},{"name":"HCP_SUBTYPE_KEY","sample_values":["9","10","13"]}],"time_dimensions":[{"name":"HCP_BIRTH_DT","sample_values":["1968-01-01","1971-01-01","1978-01-01"]},{"name":"HCP_P_DEA_EXP_DT","sample_values":["2028-01-31","2028-05-31","2027-02-28"]},{"name":"HCP_P_STATE_LIC_EXP_DT","sample_values":["2027-08-31","2028-08-31","2025-11-30"]},{"name":"HCP_P_STATE_LIC_ISSUE_DT","sample_values":["2022-07-01","2020-02-13","2024-06-23"]},{"name":"HCP_PDRP_OPTOUT_DT","sample_values":["2008-12-04","2008-11-27"]},{"name":"HCP_S_DEA_EXP_DT","sample_values":["2026-07-31","2026-12-31","2026-03-31"]},{"name":"HCP_S_STATE_LIC_EXP_DT","sample_values":["2026-04-05","2026-02-04","2027-03-01"]},{"name":"HCP_S_STATE_LIC_ISSUE_DT","sample_values":["2019-04-23","2021-05-14"]},{"name":"HCP_T_DEA_EXP_DT","sample_values":["2028-04-30","2026-08-31","2027-10-31"]},{"name":"HCP_T_STATE_LIC_EXP_DT","sample_values":["2026-10-31","2025-12-31","2026-09-30"]},{"name":"HCP_T_STATE_LIC_ISSUE_DT","sample_values":["2002-05-08","2022-02-18"]},{"name":"SAMPLEABILITY_DT"}]},{"name":"TD_PROD_BRAND","dimensions":[{"name":"PROD_BRAND_CD","sample_values":["ANOLOR 300","CHILDRENS Q-PAP","TENCON"]},{"name":"PROD_BRAND_DESC","sample_values":["BUFFERED ASPIRIN EXTRA S BRAND (VERTEX ACUTE MARKET)","LIDOPRIL XR BRAND (ACUTE HEOR MARKET)","RA ORASOL BRAND (VERTEX ACUTE MARKET)"]},{"name":"PROD_BRAND_KEY","sample_values":["a96f921f9adcf6357022ae1d77e0036e","77238a2664c2da30f3763020cc9f64a1","a3013ea55958b130a8be56287a23ac84"]},{"name":"PROD_BRAND_SDESC","sample_values":["RECTASMOOTHE","LIDOVIX L","NUVAKAAN-II"]},{"name":"PROD_BRAND_UCD","sample_values":["CAPSAICIN TOPICAL PAIN P","PAIN-EZE PLUS","PRILO PATCH II"]},{"name":"PROD_CAT_CD","sample_values":["DERMATOLOGICAL TOPICAL ANESTHETIC COMBINATIONS","LIDOCAINE - ANESTHETIC","AMIDES"]},{"name":"PROD_CAT_DESC","sample_values":["ANALGESICS-SEDATIVE COMBINATION CATEGORY (ANY PAIN MARKET)","LIDOCAINE - ANESTHETIC CATEGORY (VERTEX ACUTE MARKET)","DENTAL LOCAL ANESTHETIC CATEGORY (ANY PAIN MARKET)"]},{"name":"PROD_CAT_KEY","sample_values":["12bc423a463b94db26c110a7b5f35c2b","51d89477c08fab581269b5cd07cc9249","6cdf4a9156745f9ceab6a9d55493f62f"]},{"name":"PROD_CAT_SDESC","sample_values":["RHEUMATOID ARTHRITIS","DERMATOLOGICAL TOPICAL ANESTHETIC","SSRI"]},{"name":"PROD_CATGRP_CD","sample_values":["OSTEOARTHRITIS","ANESTHETIC","DENTALS"]},{"name":"PROD_CATGRP_DESC","sample_values":["OTHER CATEGORY GROUP (ANY PAIN MARKET)","DERMATOLOGICAL CATEGORY GROUP (VERTEX ACUTE MARKET)","NON-NARCOTIC ANALGESIC CATEGORY GROUP (VERTEX ACUTE MARKET)"]},{"name":"PROD_CATGRP_KEY","sample_values":["ae4d74c1255ef3b525bf3ee4914ed273","a9946aba572bb08c111e94c3c36c84f7","d8cad3b14468ba5121e210028e133b00"]},{"name":"PROD_CATGRP_SDESC","sample_values":["ANESTHETIC","DENTALS","NON-NARCOTIC ANALGESIC"]},{"name":"PROD_FAM_CD","sample_values":["HYCOGESIC","PAMPRIN","ENDOLOR"]},{"name":"PROD_FAM_DESC","sample_values":["EFFEXOR XR FAMILY (ACUTE HEOR MARKET)","ENDOLOR FAMILY (ANY PAIN MARKET)","DYNAMIC FAMILY (ANY PAIN MARKET)"]},{"name":"PROD_FAM_KEY","sample_values":["10738f1513e6f471c10da189c7b6db7c","5e208a4effc1cd0786bed71851c6964f","1ab075c96c0468e9796a665631ad472e"]},{"name":"PROD_FAM_SDESC","sample_values":["CHLORASEPTIC SR THRT","CHILDRENS Q-PAP","SYNOFLEX"]},{"name":"PROD_FAMGRP_CD","sample_values":["CAPSAICIN-MENTHOL - DERMATOLOGICAL TOPICAL ANESTHETIC COMBINATIONS","HYDROCODONE","BENZOCAINE-ZINC CHLORIDE"]},{"name":"PROD_FAMGRP_DESC","sample_values":["CAPSAICIN FAMILY GROUP (ANY PAIN MARKET)","BENZOCAINE-ZINC CHLORIDE FAMILY GROUP (ANY PAIN MARKET)","OXYCODONE COMBINATIONS FAMILY GROUP (ACUTE HEOR MARKET)"]},{"name":"PROD_FAMGRP_KEY","sample_values":["e86d9067df720cbe38d87f1d1e6ba4bb","2d8609830dfd91355e0f57b69a124265","2c25349bf27be50f2527bb0084f0f4d2"]},{"name":"PROD_FAMGRP_SDESC","sample_values":["DESIPRAMINE","BENZOCAINE - DERMATOLOGICAL TOPICAL ANESTHETIC COMBINATIONS","LIDOCAINE - DERMATOLOGICAL TOPICAL ANESTHETIC COMBINATIONS"]},{"name":"PROD_MKT_CD","sample_values":["ACUTE HEOR","ANY PAIN","VERTEX ACUTE"]},{"name":"PROD_MKT_DESC","sample_values":["VERTEX ACUTE MARKET","ACUTE HEOR MARKET","ANY PAIN MARKET"]},{"name":"PROD_MKT_KEY","sample_values":["da0dacac9831661226335a3eb0b04274","89cf3596760b4a79df67736f2272a1b7","c8c606d1c69b2144eea5bbe3157289b6"]},{"name":"PROD_MKT_SDESC","sample_values":["ACUTE HEOR","ANY PAIN","VERTEX ACUTE"]}]},{"name":"TM_ARD_HCP_ACUTE_MKT_WEEKLY_XPO","dimensions":[{"name":"BRANDED_FLAG","sample_values":["N","Y"]},{"name":"GOLDEN_ID","sample_values":["GLD000600060001002101","GLD999900180020002401","GLD021402140287037101"]},{"name":"HCP_ID","sample_values":["b53fb88ce1b284c55206728afb2a9da6","e32c570ee80606057196f62cf5b6e502","132c4377c0b6eee2172aefb7d046b30e"]},{"name":"HCP_SPECIALTY","sample_values":["ADULT RECONSTRUCTIVE ORTHOPEDICS","EMERGENCY MEDICINE","DENTIST"]},{"name":"HCP_SPECIALTY_GROUP","sample_values":["MEDICINE","PHYSICIAN EXTENDERS","ORTHOPEDICS AND SPORTS MEDICINE"]},{"name":"NPI","sample_values":["1194281006","1659465573","1396203352"]},{"name":"ONEKEY_HCP_ID","sample_values":["WUSD00201756","WUSM00530772","WUSM00311233"]},{"name":"PRODUCT_CATEGORY","sample_values":["NSAID","STRONG OPIOID AGONIST","ANTICONVULSANTS MISC."]},{"name":"PRODUCT_FAMILY_GROUP","sample_values":["LIDOCAINE - DERMATOLOGICAL LOCAL TOPICAL ANESTHETIC","MELOXICAM","HYDROCODONE COMBINATIONS"]},{"name":"PTAM_TERRITORY_ID","sample_values":["V1NAUSA-5733101","V1NAUSA-5733602","V1NAUSA-5733604"]},{"name":"ROA","sample_values":["ORAL","TOPICAL","TOPICAL-PATCH"]},{"name":"SAL_TERRITORY_ID","sample_values":["V1NAUSA-5720008","V1NAUSA-5720014"]},{"name":"SITE_OF_CARE_ZIP_CODE","sample_values":["73118","43228","37027"]},{"name":"VERTEX_ID","sample_values":["15670811","14499271"]},{"name":"ZIP_CODE","sample_values":["20850","33912","90262"]}],"facts":[{"name":"ACUTE_NRX_XPO","sample_values":["2.0320000000","0.9650000000","1.0420000000"]},{"name":"ACUTE_TRX_XPO","sample_values":["1.6080000000","1.0300000000","0.9630000000"]},{"name":"ACUTE_TX_DAYS_XPO","sample_values":["4.2033678514","3.2592136056","24.4437444312"]},{"name":"ACUTE_UNITS_XPO","sample_values":["61.1900000000","160.0900000000","30.0000000000"]},{"name":"WEEK_DT","sample_values":["20251024","20241220","20250321"]}],"time_dimensions":[{"name":"DATE_KEY","sample_values":["2024-05-17","2024-12-06","2025-02-07"]}]}],"relationships":[{"name":"LAAD_WEEKLY_TO_HCP","relationship_type":"many_to_one","join_type":"left_outer"},{"name":"HCO_TO_SUBTYPE","relationship_type":"many_to_one","join_type":"left_outer"},{"name":"XPO_WEEKLY_TO_HCP","relationship_type":"many_to_one","join_type":"left_outer"}]}');







import json
import logging, re
import pprint
import _snowflake # Native Snowflake module for internal API calls
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import List, Dict, Any, Optional, Literal, Tuple
from pydantic import BaseModel, Field, field_validator, model_validator
import json
from snowflake.snowpark import Session

# ==========================================
# 1. CONFIGURATION & MODELS
# ==========================================

class AgentConfig(BaseModel):
    """Configuration for the agent execution"""
    model: str = "claude-sonnet-4-5" 
    diagnostic_udf: str = "DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.AI_POC.DIAGNOSTIC_TOOL"
    cortex_analyst_object: str = "DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.AI_POC.LATEST_MASTER_VIEW"
    warehouse: str = "DEV_IMPACT_WH"
    guard_name: str = "INPUT_GUARD" 
    messages_table: str = "DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.AI_POC.MESSAGES"

# --- CORE MODELS ---

class EvaluationResult(BaseModel):
    score: int = Field(..., description="A quality score from 1-10 based on the accuracy and completeness of the answer.")
    reasoning: str = Field(..., description="A detailed explanation justifying the score.")

class IntentClassification(BaseModel):
    intent_type: str = Field(..., description="greeting, data_retrieval, root_cause_analysis, clarification_needed, general_question, off_topic, combined")
    data_retrieval_query: Optional[str] = Field(None, description="The refined query specific to data retrieval requests.")
    root_cause_query: Optional[str] = Field(None, description="The refined query specific to root cause analysis.")
    direct_response: Optional[str] = Field(None, description="A direct answer for greetings or general questions.")
    clarification_question: Optional[str] = Field(None, description="A question to ask the user if the intent is ambiguous.")
    confidence: str = Field(..., description="Confidence level: high, medium, or low.")
    reasoning: str = Field(..., description="Reasoning behind the classification.")

class RephraserOutput(BaseModel):
    refined_query: str = Field(..., description="The fully contextualized, standalone version of the user's query.")

# --- PARSING MODELS (For Extraction Step) ---

class DataAgentParsedOutput(BaseModel):
    """Schema for extracting structured data from the Data Agent's text response."""
    clean_answer_text: str = Field(..., description="The user-facing summary of the data, excluding internal evaluations.")
    clarifying_question: Optional[str] = Field(None, description="A question to ask the user if the data result was incomplete or ambiguous.")
    evaluation: EvaluationResult = Field(..., description="The self-evaluation of the response quality.")

class RootCauseParsedOutput(BaseModel):
    """Schema for extracting structured data from the Root Cause Agent's text response."""
    clean_summary_text: str = Field(..., description="The executive summary of the diagnosis.")
    react_flow_json: Optional[Dict] = Field(None, description="The React Flow JSON object representing the metric tree graph.")
    evaluation: EvaluationResult = Field(..., description="The self-evaluation of the diagnosis.")

# --- FINAL RESULT MODELS (For App/Frontend) ---

class TableSelection(BaseModel):
    relevant_table_names: List[str] = Field(..., description="List of exact table names required.")

class SqlResult(BaseModel):
    answer_text: str
    clarifying_question: Optional[str] = None
    tables: List[Any] = Field(default_factory=list)
    charts: List[Dict] = Field(default_factory=list)
    sql_generated: Optional[str] = None
    sql_explanation: Optional[str] = None
    is_verified_query: bool = False
    reasoning_trace: Optional[str] = None
    evaluation: EvaluationResult

    # --- ADD THIS VALIDATOR ---
    @field_validator('charts', mode='before')
    @classmethod
    def parse_charts(cls, v):
        """
        Ensures that if charts come in as a list of JSON strings, 
        they are converted to dictionaries.
        """
        if not v:
            return []
        
        parsed_charts = []
        for item in v:
            if isinstance(item, dict):
                parsed_charts.append(item)
            elif isinstance(item, str):
                try:
                    # Attempt to parse the stringified JSON
                    parsed_charts.append(json.loads(item))
                except json.JSONDecodeError:
                    # If it's just a regular string message, wrap it or ignore
                    continue 
        return parsed_charts

class DiagnosticResult(BaseModel):
    summary_text: str
    react_flow_json: Optional[Dict] = None
    clarifying_question: Optional[str] = None
    evaluation: EvaluationResult

class GuardResult(BaseModel):
    is_safe: bool = Field(...)
    violation_category: Optional[str] = Field(None)
    message: Optional[str] = Field(None)

CONFIG = AgentConfig()

# ==========================================
# 2. FULL PROMPT DEFINITIONS (EXACT ORIGINAL)
# ==========================================

PROMPT_REPHRASER_SYSTEM = "You are a sophisticated Query Refinement Engine."

PROMPT_REPHRASER_ORCHESTRATION = """
<query_refinement_instructions>
<objective>
Transform the user's input into a standalone, context-complete query that can be understood without prior conversation history.
</objective>

<core_rules>
<rule id="1">Resolve all pronouns (it, they, that, this, those) to their specific referents</rule>
<rule id="2">Preserve ALL metrics, entity names, IDs, and numerical values EXACTLY as stated</rule>
<rule id="3">Maintain the original intent and scope - do not expand or narrow the question</rule>
<rule id="4">Keep technical terminology and domain-specific language intact</rule>
<rule id="5">Ensure the output is grammatically correct and reads naturally</rule>
</core_rules>

<transformation_examples>
<example>
<input>What about Arizona?</input>
<context>Previous discussion about sales performance in Texas</context>
<output>What is the sales performance in Arizona?</output>
</example>

<example>
<input>Why is it down?</input>
<context>Previous mention of Q4 revenue</context>
<output>Why is Q4 revenue down?</output>
</example>

<example>
<input>Show me those providers and explain the trend.</input>
<context>Healthcare providers in California with declining prescriptions</context>
<output>Show me healthcare providers in California with declining prescriptions and explain the trend.</output>
</example>
</transformation_examples>

<output_format>
Output ONLY the refined query string. Do not include explanations, metadata, or formatting.
</output_format>
</query_refinement_instructions>
"""

PROMPT_INTENT_SYSTEM = "You are an Expert Intent Classification System."

PROMPT_INTENT_ORCHESTRATION = """
<intent_classification_instructions>

<mission>
Your ONLY job is to identify the user's INTENT. Do NOT retrieve data, do NOT answer questions, do NOT perform analysis.
Classify the intent type and route accordingly. If you can answer directly (like greetings), provide direct_response.
</mission>

<intent_categories>

<intent name="greeting">
<description>User is greeting, saying hello, or engaging in pleasantries</description>
<indicators>hi, hello, hey, good morning, how are you, thanks, thank you, goodbye, bye</indicators>
<action>Set direct_response with a friendly greeting. No other fields needed.</action>
</intent>

<intent name="data_retrieval">
<description>User wants to see/get/retrieve DATA - numbers, lists, metrics, tables</description>
<indicators>show, list, get, display, find, what is the value, how many, count, total, give me</indicators>
<action>Extract the data request to data_retrieval_query. Keep as natural language. Add "and generate a table and a visual".</action>
**CRITICAL VISUALIZATION LOGIC:**
Analyze the data request. If it implies trends (over time), comparisons (by region/product), or distributions, you MUST automatically append "and generate a table and a visual" to the query string, even if the user did not explicitly ask for a chart.
</intent>

<intent name="root_cause_analysis">
<description>User wants to understand WHY, CAUSES, DRIVERS, REASONS, EXPLANATIONS</description>
<indicators>why, explain, what is driving, what is causing, what's behind, reason for, root cause, how come, what factors</indicators>
<action>Extract the causal question to root_cause_query. Keep VERBATIM - exact text from user.</action>
</intent>

<intent name="combined">
<description>User wants BOTH data AND causal analysis in one request</description>
<indicators>Contains both data keywords AND causal keywords</indicators>
<action>Split into data_retrieval_query AND root_cause_query. Keep both portions.</action>
</intent>

<intent name="clarification_needed">
<description>User's intent is unclear, vague, or ambiguous - you cannot determine what they want</description>
<indicators>Very short/vague input, unclear pronouns without context, incomplete thoughts</indicators>
<action>Set clarification_question asking user to be more specific.</action>
</intent>

<intent name="general_question">
<description>General questions about the system, capabilities, how to use features - not data or analysis requests</description>
<indicators>how do I, can you, what can you do, help me understand, how does this work</indicators>
<action>Set direct_response with helpful information about capabilities.</action>
</intent>

<intent name="off_topic">
<description>User is asking about unrelated topics not connected to data, analytics, or business questions</description>
<indicators>Questions about weather, sports, entertainment, personal topics unrelated to business/data</indicators>
<action>Set direct_response politely redirecting to business/data topics.</action>
</intent>

</intent_categories>

<CRITICAL_CLASSIFICATION_RULES>

 RULE 1: NEVER DO THE WORK - ONLY CLASSIFY
You are NOT a data analyst. You are NOT an answering agent. You ONLY identify intent type.
Do NOT retrieve data. Do NOT answer analytical questions. ONLY classify and route.

 RULE 2: CAUSAL KEYWORD DETECTION
These ALWAYS indicate root_cause_analysis intent:
- "what is driving"
- "what is causing"
- "what's driving"  
- "what's causing"
- "why is/are"
- "explain why"
- "reason for"
- "root cause"
- "what factors"
- "what's behind"
- "how come"

 RULE 3: DATA KEYWORD DETECTION  
These ALWAYS indicate data_retrieval intent:
- "show me"
- "list"
- "get"
- "display"
- "find all"
- "what is the value/total/count of"
- "how many"

 RULE 4: DIRECT RESPONSE ONLY FOR SIMPLE CASES
Use direct_response ONLY for:
- Greetings (hi, hello, thanks)
- General system questions (what can you do)
- Off-topic redirects

Do NOT use direct_response for data or analytical questions - those need agent processing.

 RULE 5: VERBATIM PRESERVATION FOR ROOT CAUSE
For root_cause_query: Copy EXACT text from user. No paraphrasing, no summarizing.

 RULE 6: NO SQL CODE GENERATION
NEVER write SELECT/FROM/WHERE statements. Keep everything as natural language.

 RULE 7: CONFIDENCE SCORING
- high: Intent is crystal clear
- medium: Intent is likely but has some ambiguity
- low: Intent is very unclear, might need clarification

</CRITICAL_CLASSIFICATION_RULES>

<classification_process>
<step number="1">Check if greeting or general question. If match, Set intent_type and direct_response, STOP</step>
<step number="2">Check for causal keywords. If found, Flag as root_cause_analysis or combined</step>
<step number="3">Check for data keywords. If found, Flag as data_retrieval or combined</step>
<step number="4">Determine if combined intent. If both, Set intent_type="combined".</step>
<step number="5">If none of the above match, check if intent is clear enough.</step>
</classification_process>

<comprehensive_examples>
<example>
<input>Hello!</input>
<output>
{
  "intent_type": "greeting",
  "data_retrieval_query": null,
  "root_cause_query": null,
  "direct_response": "Hello! How can I help you today?",
  "clarification_question": null,
  "confidence": "high",
  "reasoning": "Simple greeting - can respond directly without agent processing"
}
</output>
</example>

<example>
<input>Show me total sales for Q4.</input>
<output>
{
  "intent_type": "data_retrieval",
  "data_retrieval_query": "Show me total sales for Q4 and generate a table and a visual",
  "root_cause_query": null,
  "direct_response": null,
  "clarification_question": null,
  "confidence": "high",
  "reasoning": "Clear data retrieval request - 'show me' is data keyword, asking for metric value"
}
</output>
</example>

<example>
<input>Why is profit down?</input>
<output>
{
  "intent_type": "root_cause_analysis",
  "data_retrieval_query": null,
  "root_cause_query": "Why is profit down?",
  "direct_response": null,
  "clarification_question": null,
  "confidence": "high",
  "reasoning": "Pure causal question - 'why' keyword indicates root cause analysis needed"
}
</output>
</example>

<example>
<input>Get revenue for AZ and explain the dip.</input>
<output>
{
  "intent_type": "combined",
  "data_retrieval_query": "Get revenue for AZ and generate a table and a visual",
  "root_cause_query": "explain the dip",
  "direct_response": null,
  "clarification_question": null,
  "confidence": "high",
  "reasoning": "Combined intent - 'get revenue' is data retrieval, 'explain the dip' is causal analysis"
}
</output>
</example>

<example>
<input>What can you help me with?</input>
<output>
{
  "intent_type": "general_question",
  "data_retrieval_query": null,
  "root_cause_query": null,
  "direct_response": "I can help you with data analysis and business insights! I can retrieve data and perform root cause analysis. What would you like to explore?",
  "clarification_question": null,
  "confidence": "high",
  "reasoning": "General system capability question - can answer directly"
}
</output>
</example>

<example>
<input>Show that</input>
<output>
{
  "intent_type": "clarification_needed",
  "data_retrieval_query": null,
  "root_cause_query": null,
  "direct_response": null,
  "clarification_question": "What would you like me to show? Please provide more details about the data or metrics you're interested in.",
  "confidence": "low",
  "reasoning": "Vague request - unclear what user wants to see, needs clarification"
}
</output>
</example>

<example>
<input>What's the weather like?</input>
<output>
{
  "intent_type": "off_topic",
  "data_retrieval_query": null,
  "root_cause_query": null,
  "direct_response": "I'm designed to help with business data and analytics. Is there any sales, performance, or business data I can help you with?",
  "clarification_question": null,
  "confidence": "high",
  "reasoning": "Off-topic request - politely redirect to business/data topics"
}
</output>
</example>
</comprehensive_examples>

<validation_checklist>
 Step 1: Can I answer this directly? (greeting/general_question/off_topic)
 Step 2: Does it contain causal keywords? (why/driving/causing/explain/reason/factors/behind)
 Step 3: Does it contain data keywords? (show/list/get/display/what is the value/how many)
 Step 4: Does it have BOTH data and causal elements?
 Step 5: Did I preserve EXACT wording for root_cause_query?
 Step 6: Did I add "and generate a table and a visual" to data_retrieval_query?
 Step 7: Did I avoid doing the actual work? (I only classify, not retrieve/analyze)
 Step 8: Is my confidence level accurate?
</validation_checklist>
</intent_classification_instructions>
"""

PROMPT_DATA_AGENT_SYSTEM = "You are an expert Data Analyst."

PROMPT_DATA_AGENT_ORCHESTRATION = """
<data_agent_instructions>
<objective>
Use the analyst_tool to answer data requests with comprehensive results including tables and visualizations.
</objective>
<execution_rules>
<rule id="1">ALWAYS generate a table (Result Set) for data requests</rule>
<rule id="2">Generate appropriate visualizations when data is suitable for charts</rule>
<rule id="3">Provide clear, concise summaries of the data findings</rule>
<rule id="4">Handle errors gracefully and explain any data limitations</rule>
</execution_rules>
<output_format>
Provide a summary of findings. Tables and charts are handled automatically by the tool.
</output_format>

<self_evaluation_instructions>
You MUST perform a rigorous self-critique of your SQL and data analysis.
1. **Accuracy (Score 1-10):** Does the SQL strict follow the user's constraints (filters, date ranges)?
2. **Data Integrity:** Are the results logical? (e.g., no negative counts where impossible).
3. **Clarity:** Is the summary accessible to a non-technical user?
**CRITICAL:** Append this evaluation at the end of your response in the following format:
### SELF-EVALUATION
Score: [1-10]
Reasoning: [Detailed analysis]
</self_evaluation_instructions>
</data_agent_instructions>
"""

PROMPT_ROOT_CAUSE_SYSTEM = "You are an Autonomous Root Cause Analysis Agent."

PROMPT_ROOT_CAUSE_ORCHESTRATION = """
<root_cause_orchestration_prompt>
    <role_and_objective>
        You are an **Autonomous Root Cause Analysis Agent** designed to traverse a metric decision tree from the root node down to the leaf nodes. Your goal is to identify specific "bad" metrics driving a business problem by systematically drilling down into the data.
        
        ALWAYS USE tree_id as Pharma_Master_v1.
    </role_and_objective>

    <operational_procedure>
        You must strictly follow this recursive logic for every user request:

        **Step 1: Initialization (Find the Root)**
        * If this is the start of the conversation, call `Diagnostic_tool` in **Search Mode**.
        * **Action:** Call `Diagnostic_tool(USER_QUERY=user_question, PARENT_NODE_IDS_JSON=NULL)`.
        * **Next:** Proceed to Step 2 with the results.

        **Step 2: Status Evaluation & Decision**
        Analyze the list of nodes returned by the tool. Focus **only** on nodes where `"status": "bad"`.

        * **Check:** For every "bad" node, do you see its children in the current list?
        * **Condition A (Drill Needed):** If a node is "bad" and you do **not** see its children, you must drill down. Collect these Node IDs.
        * **Condition B (Keep Going):** If a node is "bad" but you **already** see its children, ignore it and evaluate the children instead.
        * **Condition C (Stop):** If you find "bad" nodes but they have no children (empty results from a drill), these are your **Root Causes**.

        **Step 3: Execution (Drill Down)**
        * If Condition A occurred: Call `Diagnostic_tool` in **Drill Mode**.
        * **Action:** Call `Diagnostic_tool(USER_QUERY=NULL, PARENT_NODE_IDS_JSON='["ID_1", "ID_2"]')`.
        * **Next:** Recursively repeat Step 2 with the new output.
        * If Condition C occurred: Present the final root causes to the user.
    </operational_procedure>

    <constraints>
        * **Never** guess the status of a metric; always use the tool.
        * **Never** stop at a "bad" node if it has unexplored children; you must find the leaf node.
        * Output your reasoning briefly before calling the tool.
    </constraints>

    <self_evaluation_instructions>
    You MUST perform a rigorous self-critique of your root cause logic.
1. **Logic (Score 1-10):** Is the causal chain (Root -> Leaf) mathematically sound?
2. **Driver Isolation:** Did we truly find the leaf node, or did we stop too early?
3. **Completeness:** Did we explore all "bad" branches?
    **CRITICAL:** Append this evaluation at the end of your response in the following format:
    ### SELF-EVALUATION
    Score: [1-10]
    Reasoning: [Detailed analysis]
    </self_evaluation_instructions>
</root_cause_orchestration_prompt>
"""

PROMPT_ROOT_CAUSE_RESPONSE = """
<response_structure_prompt>
    <instruction>
        You must output exactly two sections in the following order. Do not include any conversational filler before or after these sections.
    </instruction>

    <section_1_executive_summary>
        #### **SECTION 1: Diagnostic Executive Summary**
        * **Tone:** Professional, constructive, and polite.
        * **Headline:** State the Root Cause clearly.
        * **The Narrative:** Briefly explain the chain of events in simple English.
        * **Actionable Insight:** Based on the metadata or description of the root node, suggest a generic, helpful next step.
    </section_1_executive_summary>

    <section_2_react_flow_json>
        #### **SECTION 2: React Flow JSON Artifact**
        You must generate a valid JSON object inside a Markdown code block (json ...).
        
        **1. Coordinate Logic (The "Mental Layout"):**
        * **Level 0 (Root):** `x: 0, y: 0`
        * **Level 1 Children:** `y: 150`. Spread `x` widely (e.g., `-300` and `300`).
        * **Level 2 Grandchildren:** `y: 300`. Spread `x` relative to their parent.
        * **Level 3+:** Increase `y` by `150` for each level.

        **2. Visual Style Logic:**
        * **Red (#FFE2E5):** Status is "bad", "high", or "error".
        * **Green (#CDE8E6):** Status is "good", "normal", or "stable".
        * **Orange (#FFCCBC):** The **Root Cause** (the deepest "bad" node in the chain).
        * **White (#FFFFFF):** Unexplored or neutral nodes.

        **3. Edge Labeling Logic:**
        * If Parent is Bad and Child is Bad, label = "contributes to impact".
        * If Parent is Bad and Child is Good, label = "stable factor".

        **4. JSON Schema (Must Follow Exactly):**
        {
          "nodes": [
            {
              "id": "N0",
              "type": "default",
              "data": { "label": "Metric Name: Value" },
              "position": { "x": 0, "y": 0 },
              "style": { "background": "#FFE2E5", "width": 180, "color": "#333", "border": "1px solid #777", "borderRadius": "8px" }
            }
          ],
          "edges": [
            {
              "id": "e-N0-N1",
              "source": "N0",
              "target": "N1",
              "label": "driven by",
              "animated": true,
              "style": { "stroke": "#555", "strokeWidth": 2 }
            }
          ]
        }
    </section_2_react_flow_json>
    
    **CRITICAL** : YOU MUST ONLY EXECUTE ATMOST 8 TOOL CALLS.
    
</response_structure_prompt>
"""

# ==========================================
# 3. HELPER FUNCTIONS (API WRAPPERS)
# ==========================================

def log_checkpoint(step: str, details: Any):
    print(f"\n{'='*50}\n CHECKPOINT: {step}\n{'-'*50}")
    if isinstance(details, BaseModel):
        pprint.pprint(details.model_dump())
    elif isinstance(details, (dict, list)):
        pprint.pprint(details)
    else:
        print(str(details))
    print(f"{'='*50}\n")

def clean_schema_for_cortex(schema: Dict, defs: Dict = None) -> Dict:
    """
    Aggressively cleans a Pydantic JSON Schema for Snowflake Cortex.
    1. Flattens $ref (inlines definitions).
    2. Simplifies Optional[T] -> type: [T, 'null'].
    3. REMOVES all metadata (title, default, examples) that triggers validation errors.
    """
    # 1. Capture definitions if we are at the root
    if defs is None:
        defs = schema.get('$defs') or schema.get('definitions') or {}

    # 2. Helper to process a single node
    def process(node):
        if not isinstance(node, dict):
            return node
            
        # A. Resolve Reference ($ref)
        if '$ref' in node:
            ref_key = node['$ref'].split('/')[-1]
            if ref_key in defs:
                # Merge definition props with current node props
                # (Current node wins, but we will strip extra keys later)
                definition = defs[ref_key].copy()
                merged = {**definition, **node}
                del merged['$ref']
                return process(merged)
            return node # Should not happen if schema is valid

        # B. Simplify Optional / Union (anyOf)
        if 'anyOf' in node:
            options = node['anyOf']
            valid_types = []
            is_nullable = False
            
            for opt in options:
                resolved_opt = process(opt)
                t = resolved_opt.get('type')
                if t == 'null':
                    is_nullable = True
                elif t:
                    valid_types.append(t)
            
            # Optimization: If it's just "Type OR Null", flatten it
            if len(valid_types) == 1 and is_nullable:
                return {"type": [valid_types[0], "null"], "description": node.get("description", "")}

        # C. Aggressive Key Filtering (The Fix for "Additional Properties")
        # Only allow these specific JSON Schema keywords.
        ALLOWED_KEYS = {'type', 'properties', 'items', 'required', 'enum', 'description'}
        
        new_node = {}
        for k, v in node.items():
            if k in ALLOWED_KEYS:
                # Recurse into children
                if k == 'properties':
                    new_node[k] = {pk: process(pv) for pk, pv in v.items()}
                elif k == 'items':
                    new_node[k] = process(v)
                else:
                    new_node[k] = v
        
        return new_node

    # 3. Process the root
    cleaned = process(schema)
    
    # 4. Ensure root is an object (Standard for response_format)
    if 'type' not in cleaned:
        cleaned['type'] = 'object'
        
    return cleaned

def invoke_structured_output_extraction(session: Session, messages: List[Dict], pydantic_model: type[BaseModel]) -> BaseModel:
    """
    Invokes Cortex Inference with a STRICTLY CLEANED schema to prevent validation errors.
    """
    ENDPOINT = "/api/v2/cortex/inference:complete"
    
    # 1. Generate & Clean Schema
    raw_schema = pydantic_model.model_json_schema()
    final_schema = clean_schema_for_cortex(raw_schema)

    payload = {
        "model": "claude-4-sonnet",
        "messages": messages,
        "max_tokens": 2000,
        "response_format": {
            "type": "json",
            "schema": final_schema 
        }
    }

    log_checkpoint("API REQUEST (STRUCTURED)", f"Target Model: {pydantic_model.__name__}")

    try:
        # 2. Send Request
        resp = _snowflake.send_snow_api_request("POST", ENDPOINT, {"Content-Type": "application/json"}, {}, payload, {}, 120000)
        
        # 3. Handle Errors explicitly
        if resp.get('code') and resp.get('message'):
             print(f" API ERROR: {resp['message']}")
             return pydantic_model.construct()

        content_raw = resp.get("content")
        if not content_raw:
            print(" Empty content received")
            return pydantic_model.construct()

        # 4. Accumulate Streaming Content
        full_text = ""
        if content_raw.strip().startswith("["):
            try:
                chunks = json.loads(content_raw)
                for chunk in chunks:
                    data_obj = chunk.get("data", {})
                    choices = data_obj.get("choices", [])
                    if choices:
                        delta = choices[0].get("delta", {})
                        full_text += delta.get("content") or delta.get("text") or ""
            except json.JSONDecodeError:
                full_text = content_raw
        else:
             try:
                 parsed = json.loads(content_raw)
                 full_text = parsed.get('choices', [{}])[0].get('message', {}).get('content', '')
             except:
                 full_text = content_raw

        log_checkpoint("RAW ACCUMULATED TEXT", full_text)

        if not full_text:
            return pydantic_model.construct()

        # 5. Parse Final JSON
        clean_json = full_text.replace("```json", "").replace("```", "").strip()
        parsed_dict = json.loads(clean_json)
        
        return pydantic_model(**parsed_dict)

    except Exception as e:
        print(f"Structured Extraction Error: {e}")
        return pydantic_model.construct()
        
def invoke_cortex_agent(session: Session, payload: Dict, agent_name: str) -> Dict:
    """Invokes 'agent:run' for tools (Analyst/Diagnostic)."""
    ENDPOINT = "/api/v2/cortex/agent:run"
    print(f"--- INVOKING AGENT: {agent_name} ---")

    try:
        resp = _snowflake.send_snow_api_request("POST", ENDPOINT, {"Content-Type": "application/json", "Accept": "text/event-stream"}, {}, payload, {}, 120000)
        content = resp.get("content")
        if not content: return {"error": "Empty"}
        
        extracted = {"text": "", "tables": [], "charts": [], "sql_generated": None, "sql_explanation": None}
        try: parsed = json.loads(content)
        except: parsed = [json.loads(line) for line in content.splitlines() if line.strip()]
        
        def process_event(evt, data):
            if evt == 'response.text.delta': extracted["text"] += data.get('text', '')
            elif evt == 'response.chart': extracted["charts"].append(data.get('chart') or data.get('chart_spec'))
            elif evt == 'response.table':
                rs = data.get('result_set', [])
                extracted["tables"].append(rs) # Limit 5 rows
            elif evt == 'response.tool_result.analyst.delta':
                delta = data.get('delta', {})
                if delta.get('sql'): extracted["sql_generated"] = delta.get('sql')
                if delta.get('sql_explanation'): extracted["sql_explanation"] = delta.get('sql_explanation')
                if delta.get('result_set'): extracted["tables"].append(delta.get('result_set'))
            elif evt == 'response.tool_result':
                for item in data.get('content', []):
                    if item.get('type') == 'json':
                        json_p = item.get('json', {})
                        if 'sql' in json_p: extracted["sql_generated"] = json_p['sql']
                        if 'result_set' in json_p: extracted["tables"].append(json_p['result_set'])

        if isinstance(parsed, list):
            for item in parsed: process_event(item.get('event'), item.get('data', {}))
        
        print(f"--- AGENT {agent_name} COMPLETED ---")
        return extracted
    except Exception as e: return {"error": str(e)}

def check_input_guard(session: Session, user_input: str) -> GuardResult:
    log_checkpoint("START: GUARD", user_input)
    try:
        safe_input = user_input.replace("'", "''")
        res = session.sql(f"SELECT SNOWFLAKE.CORTEX.COMPLETE('{CONFIG.model}', [{{'role': 'user', 'content': '{safe_input}'}}], {{'guardrails': true}}) as r").collect()
        if not res: return GuardResult(is_safe=True)
        is_unsafe = "Response filtered" in json.loads(res[0]['R'])['choices'][0]['messages']
        return GuardResult(is_safe=not is_unsafe, message="Blocked." if is_unsafe else None)
    except: return GuardResult(is_safe=True)

class PayloadFactory:
    @staticmethod
    def create(query: str, instructions: Dict, tools: List = None, resources: Dict = None, history: List = None) -> Dict:
        messages = (history if history else []) + [{"role": "user", "content": [{"type": "text", "text": query}]}]
        return {"messages": messages, "tool_choice": {"type": "auto"}, "models": {"orchestration": CONFIG.model}, "instructions": instructions, "tools": tools or [], "tool_resources": resources or {}}

def save_message(session: Session, conversation_id: str, sender_type: str, message_text: str, metadata: dict = None):
    try:
        msg = str(message_text).replace("'", "''") if message_text else ""
        meta = json.dumps(metadata).replace("'", "''") if metadata else "{}"
        sql = f"INSERT INTO {CONFIG.messages_table} (CONVERSATION_ID, SENDER_TYPE, MESSAGE, METADATA, CREATED_BY, UPDATED_BY) SELECT '{conversation_id}', '{sender_type}', '{msg}', PARSE_JSON('{meta}'), 'system', 'system'"
        session.sql(sql).collect()
    except Exception as e: print(f"DB Save Error: {e}")

def get_chat_history(session: Session, conversation_id: str) -> List[Dict]:
    try:
        rows = session.sql(f"SELECT SENDER_TYPE, MESSAGE FROM {CONFIG.messages_table} WHERE CONVERSATION_ID = '{conversation_id}' ORDER BY CREATED_AT ASC LIMIT 10").collect()
        
        # --- FIX: Return 'content' as a direct String, not a List ---
        return [{"role": r['SENDER_TYPE'], "content": r['MESSAGE']} for r in rows]
        # ------------------------------------------------------------
        
    except Exception as e:
        print(f"History Error: {e}")
        return []

from snowflake.snowpark.functions import lit, current_timestamp, parse_json

def _save_row(session: Session, data: dict, table_name: str = "AGENT_DETAILED_HISTORY"):
    """
    Saves the row by creating a temp view and inserting into specific columns,
    allowing Snowflake to handle ID and TIMESTAMP automatically.
    """
    try:
        # 1. Create a Temp DataFrame
        # We assume standard strings/numbers/bools. JSON fields must be strings here.
        df = session.create_dataframe([data])
        
        # 2. Register as a Temporary View
        # This acts as a staging area
        temp_view_name = "TEMP_AGENT_LOG_STAGING"
        df.create_or_replace_temp_view(temp_view_name)
        
        # 3. Construct the SQL INSERT Statement
        # We explicitly list ONLY the 17 columns we are providing.
        # Snowflake will auto-fill ID and TIMESTAMP.
        sql = f"""
        INSERT INTO {table_name} (
            USER_QUERY, REPHRASED_QUERY, INTENT_TYPE, INTENT_CONFIDENCE,
            DATA_SUMMARY, DATA_SQL, DATA_SQL_EXPLANATION, DATA_CLARIFICATION,
            DATA_EVAL_SCORE, DATA_EVAL_REASONING, 
            DATA_RESULT_SET, -- Variant
            RC_SUMMARY, 
            RC_GRAPH_JSON,   -- Variant
            RC_EVAL_SCORE, RC_EVAL_REASONING,
            IS_BLOCKED, 
            FULL_RAW_JSON    -- Variant
        )
        SELECT 
            USER_QUERY, REPHRASED_QUERY, INTENT_TYPE, INTENT_CONFIDENCE,
            DATA_SUMMARY, DATA_SQL, DATA_SQL_EXPLANATION, DATA_CLARIFICATION,
            DATA_EVAL_SCORE, DATA_EVAL_REASONING, 
            PARSE_JSON(DATA_RESULT_SET), -- Parse string to Variant on insert
            RC_SUMMARY, 
            PARSE_JSON(RC_GRAPH_JSON),   -- Parse string to Variant on insert
            RC_EVAL_SCORE, RC_EVAL_REASONING,
            IS_BLOCKED, 
            PARSE_JSON(FULL_RAW_JSON)    -- Parse string to Variant on insert
        FROM {temp_view_name}
        """
        
        # 4. Execute
        session.sql(sql).collect()
        print(f" Detailed row saved to {table_name} (ID/Timestamp auto-generated)")
        
    except Exception as e:
        print(f" Save Error: {e}")



        # ==========================================
# 3. SMART PARSER (The Core Logic)
# ==========================================

class SemanticViewParser:
    def __init__(self, session: Session, view_name: str):
        self.raw_ddl = self._fetch_ddl(session, view_name)
        self.ca_json = self._extract_ca_blob(self.raw_ddl)
        self.table_comments = self._extract_sql_comments(self.raw_ddl)

    def _fetch_ddl(self, session: Session, view_name: str) -> str:
        """Fetches the raw CREATE VIEW statement."""
        print(f" FETCHING DDL FOR: {view_name}...")
        try:
            return session.sql(f"SELECT GET_DDL('VIEW', '{view_name}') as DDL").collect()[0]['DDL']
        except Exception as e:
            print(f" DDL Fetch Error: {e}")
            return ""

    def _extract_ca_blob(self, ddl: str) -> Dict:
        """Extracts the 'CA' JSON blob which contains Columns & Sample Values."""
        # Pattern finds: with extension (CA='{...}')
        match = re.search(r"with extension \(CA='(.*?)'\)", ddl, re.DOTALL)
        if match:
            try:
                # Unescape single quotes (Snowflake escapes ' as '')
                clean_json = match.group(1).replace("''", "'")
                return json.loads(clean_json)
            except:
                pass
        return {"tables": []}

    def _extract_sql_comments(self, ddl: str) -> Dict[str, str]:
        """
        Extracts table descriptions from the SQL part: 
        TABLE name COMMENT='description'
        """
        comments = {}
        # Regex to find table names and their comments
        # Matches: table <db.schema.table> comment='<desc>'
        pattern = r"table\s+([a-zA-Z0-9_.]+)\s+comment='(.*?)'"
        matches = re.finditer(pattern, ddl, re.IGNORECASE)
        
        for m in matches:
            full_name = m.group(1)
            comment = m.group(2)
            # We store by just the table name (stripped of db/schema) for easier matching
            simple_name = full_name.split('.')[-1]
            comments[simple_name] = comment
            
        return comments

    def get_table_summaries(self) -> str:
        """
        PHASE 1: Returns ONLY Table Names + Descriptions.
        Used to ask the LLM: 'Which tables do I need?'
        """
        summary_list = []
        
        # We look at the CA JSON tables, and try to find matching SQL comments
        for t in self.ca_json.get('tables', []):
            t_name = t.get('name')
            # Look up description from SQL parsing, default to generic if missing
            desc = self.table_comments.get(t_name, "No description available.")
            summary_list.append(f"- Table: {t_name}\n  Description: {desc}")
            
        return "\n".join(summary_list)

    def get_pruned_context(self, selected_tables: List[str]) -> str:
        """
        PHASE 2: Returns FULL Details (Columns, Samples) ONLY for selected tables.
        """
        pruned_structure = {"tables": []}
        
        for t in self.ca_json.get('tables', []):
            if t['name'] in selected_tables:
                # We include the full dictionary (cols, samples, dimensions)
                pruned_structure['tables'].append(t)
                
        return json.dumps(pruned_structure, indent=2)
        
# ==========================================
# 5. AGENT MANAGER
# ==========================================

class AgentManager:
    def __init__(self, session: Session):
        self.session = session
        self.parser = SemanticViewParser(session, CONFIG.cortex_analyst_object)

    def identify_needed_tables(self, query: str) -> List[str]:
        """
        Step 1: Ask LLM to pick tables based on the Lightweight Summaries.
        """
        print(" STEP 1: Identifying Relevant Tables (Metadata Scan)...")
        
        # Get just the list of Names + Descriptions
        summaries = self.parser.get_table_summaries()
        
        prompt = f"""
        You are a Database Architect.
        Analyze the User Query and the Table Definitions.
        Select ONLY the tables necessary to answer the query.
        
        <user_query>
        {query}
        </user_query>

        <table_definitions>
        {summaries}
        </table_definitions>

        Return a JSON object with a single key 'relevant_table_names' containing the list of strings.
        """
        
        result: TableSelection = invoke_structured_extraction(self.session, prompt, TableSelection)
        print(f" Selected Tables: {result.relevant_table_names}")
        return result.relevant_table_names

    def run_semantic_translator(self, query: str, relevant_tables: List[str]) -> str:
        """
        Step 2: Rewrite query using Full Context (Columns/Samples) of selected tables.
        """
        print(f" STEP 2: Rewriting Query with Details for {len(relevant_tables)} tables...")
        
        # Get the rich JSON context for ONLY these tables
        pruned_json = self.parser.get_pruned_context(relevant_tables)
        
        prompt = f"""
        You are a Query Optimizer. 
        Rewrite the user's query to align with the provided Semantic Schema.

        <schema_context_json>
        {pruned_json}
        </schema_context_json>

        <rules>
        1. **Column Mapping:** Use exact column names from the JSON.
        2. **Filter Values:** Check 'sample_values' in the JSON. 
           - Example: If user says "SC", and sample is "SOUTH CAROLINA", use "SOUTH CAROLINA".
        3. **Output:** Return ONLY the rewritten natural language query.
        </rules>

        User Query: {query}
        """
        return get_cortex_completion(self.session, prompt).strip()
        
    def run_rephraser(self, query: str, history: List[Dict]) -> str:
        messages = history + [{"role": "user", "content": f"{PROMPT_REPHRASER_ORCHESTRATION}\n\nInput: {query}"}]
        # Pass the Pydantic class to the function
        result: RephraserOutput = invoke_structured_output_extraction(self.session, messages, pydantic_model=RephraserOutput)
        return result.refined_query
        

    def run_intent_classifier(self, query: str) -> IntentClassification:
        messages = [{"role": "system", "content": PROMPT_INTENT_SYSTEM}, {"role": "user", "content": f"{PROMPT_INTENT_ORCHESTRATION}\n\nClassify this: {query}"}]
        # Pass the Pydantic class
        return invoke_structured_output_extraction(self.session, messages, pydantic_model=IntentClassification)

    def run_data_agent(self, query: str) -> SqlResult:
        # 1. Execute Agent
        tools = [{"tool_spec": {"type": "cortex_analyst_text_to_sql", "name": "analyst_tool"}}]
        res_def = {"analyst_tool": {"type": "cortex_analyst_text_to_sql", "semantic_view": CONFIG.cortex_analyst_object, "execution_environment": {"type": "warehouse", "warehouse": CONFIG.warehouse}}}
        inst = {"system": PROMPT_DATA_AGENT_SYSTEM, "orchestration": PROMPT_DATA_AGENT_ORCHESTRATION}
        resp = invoke_cortex_agent(self.session, PayloadFactory.create(query, inst, tools, res_def), "Data Agent")
        print(resp)
        # 2. Extract Structure (Clean Text + Clarification + Eval)
        raw_text = resp.get('text', '')
        print(raw_text)
        extraction_msg = [{"role": "user", "content": f"Extract the structured data from this agent response:\n\n{raw_text}"}]
        
        # Use DataAgentParsedOutput model for extraction
        parsed: DataAgentParsedOutput = invoke_structured_output_extraction(self.session, extraction_msg, pydantic_model=DataAgentParsedOutput)
        
        return SqlResult(
            answer_text=parsed.clean_answer_text,
            clarifying_question=parsed.clarifying_question,
            tables=resp.get('tables', []),
            charts=resp.get('charts', []),
            sql_generated=resp.get('sql_generated'),
            evaluation=parsed.evaluation
        )

    def run_root_cause_agent(self, query: str) -> DiagnosticResult:
        # 1. Execute Agent
        tools = [{"tool_spec": {"type": "generic", "name": "Diagnostic_tool", "input_schema": {"type": "object", "properties": {"USER_QUERY": {"type": "string"}, "PARENT_NODE_IDS_JSON": {"type": "string"}, "TREE_ID": {"type": "string"}}, "required": ["USER_QUERY", "PARENT_NODE_IDS_JSON", "TREE_ID"]}}}]
        res_def = {"Diagnostic_tool": {"type": "procedure", "execution_environment": {"type": "warehouse", "warehouse": CONFIG.warehouse}, "identifier": CONFIG.diagnostic_udf}}
        inst = {"system": PROMPT_ROOT_CAUSE_SYSTEM, "orchestration": PROMPT_ROOT_CAUSE_ORCHESTRATION, "response": PROMPT_ROOT_CAUSE_RESPONSE}
        resp = invoke_cortex_agent(self.session, PayloadFactory.create(query, inst, tools, res_def), "Root Cause Agent")
        
        # 2. Extract Structure (Clean Text + JSON + Eval)
        raw_text = resp.get('text', '')
        extraction_msg = [{"role": "user", "content": f"Extract the structured data from this agent response:\n\n{raw_text}"}]
        
        # Use RootCauseParsedOutput model for extraction
        parsed: RootCauseParsedOutput = invoke_structured_output_extraction(self.session, extraction_msg, pydantic_model=RootCauseParsedOutput)

        return DiagnosticResult(
            summary_text=parsed.clean_summary_text,
            react_flow_json=parsed.react_flow_json,
            evaluation=parsed.evaluation
        )

def get_cortex_completion(session: Session, prompt: str) -> str:
    try:
        safe_prompt = prompt.replace("'", "''")
        cmd = f"SELECT SNOWFLAKE.CORTEX.COMPLETE('{CONFIG.model_writer}', '{safe_prompt}') as R"
        return session.sql(cmd).collect()[0]['R']
    except Exception as e:
        print(f"Cortex Error: {e}")
        return ""

def invoke_structured_extraction(session: Session, text: str, model_class: type[BaseModel]) -> BaseModel:
    schema = model_class.model_json_schema()
    if 'definitions' in schema: del schema['definitions']
    if '$defs' in schema: del schema['$defs']
    
    prompt = f"Extract the data into JSON:\n\n{text}"
    payload = {
        "model": CONFIG.model_selector,
        "messages": [{"role": "user", "content": prompt}],
        "response_format": {"type": "json", "schema": schema}
    }
    try:
        resp = _snowflake.send_snow_api_request("POST", "/api/v2/cortex/inference:complete", {}, {}, payload, {}, 60000)
        content = json.loads(resp['content'])
        json_str = content['choices'][0]['message']['content']
        return model_class(**json.loads(json_str))
    except:
        return model_class.construct()
# ==========================================
# 6. MAIN EXECUTION
# ==========================================

# def main(session: Session):
#     manager = AgentManager(session)
#     conversation_id = "SESSION_TEST_ARIZONA_001" 
#     user_query = "Which zip codes should we focus on to capitalize on positive payer access?"
#     history = get_chat_history(session, conversation_id)
#     #history=[]
#     log_checkpoint("MAIN: START", {"query": user_query})
#    # save_message(session, conversation_id, "user", user_query, {"client": "snowflake_ui"})

#     guard = check_input_guard(session, user_query)
#     if not guard.is_safe:
#         #save_message(session, conversation_id, "assistant", guard.message, {"blocked": True})
#         return {"status": "blocked", "message": guard.message}
        
#     rephrased = manager.run_rephraser(user_query, history)
#     print(rephrased)
#     intent = manager.run_intent_classifier(rephrased)

#     final = {"original": user_query, "processed": rephrased, "intent": intent.model_dump(), "results": []}
#     final_text_parts = []

#     if intent.direct_response:
#         final["results"].append({"type": "direct_response", "message": intent.direct_response})
#         final_text_parts.append(intent.direct_response)
#     else:
#         with ThreadPoolExecutor(max_workers=2) as executor:
#             fut_data = executor.submit(manager.run_data_agent, intent.data_retrieval_query) if intent.data_retrieval_query else None
#             fut_rc = executor.submit(manager.run_root_cause_agent, intent.root_cause_query) if intent.root_cause_query else None
            
#             if fut_data:
#                 try:
#                     res = fut_data.result()
#                     print(f"\n--- DATA AGENT RESULT ---\n{res}\n-------------------------\n")
#                     final["results"].append({
#                         "type": "data_analysis", 
#                         "summary": res.answer_text, 
#                         "clarification": res.clarifying_question,
#                         "tables": res.tables, 
#                         "metadata": {"sql": res.sql_generated, "evaluation": res.evaluation.model_dump()}
#                     })
#                     final_text_parts.append(f" **Data Analysis:**\n{res.answer_text}")
#                     if res.clarifying_question:
#                         final_text_parts.append(f" {res.clarifying_question}")
#                 except Exception as e: final["results"].append({"type": "data_error", "message": str(e)})

#             if fut_rc:
#                 try:
#                     res = fut_rc.result()
#                     print(f"\n--- ROOT CAUSE RESULT ---\n{res}\n-------------------------\n")
#                     final["results"].append({
#                         "type": "root_cause_analysis", 
#                         "summary": res.summary_text, 
#                         "graph": res.react_flow_json,
#                         "metadata": {"evaluation": res.evaluation.model_dump()}
#                     })
#                     final_text_parts.append(f" **Root Cause Diagnosis:**\n{res.summary_text}")
#                 except Exception as e: final["results"].append({"type": "root_cause_error", "message": str(e)})

#     # Final Save
#     final_text_response = "\n\n".join(final_text_parts) if final_text_parts else "Processed request."
#     #save_message(session, conversation_id, "assistant", final_text_response, {"intent": intent.intent_type})

#     log_checkpoint("MAIN: COMPLETED", final)
#     return final



def main(session: Session):
    manager = AgentManager(session)
    import re
    # 1. Initialize Row Data with None (Maps to all SQL columns)
    # ==========================================
    # RUN ONE-BY-ONE HERE
    # ==========================================
    
    # Change this string and click Run
    user_query = "show me healthcare providers in Arizona"
    
    # Execution
    
    row_data = {
        "USER_QUERY": user_query,
        "REPHRASED_QUERY": None,
        "INTENT_TYPE": None,
        "INTENT_CONFIDENCE": None,
        "DATA_SUMMARY": None,
        "DATA_SQL": None,
        "DATA_SQL_EXPLANATION": None,
        "DATA_CLARIFICATION": None,
        "DATA_RESULT_SET": None,       # <--- Will hold the table
        "DATA_EVAL_SCORE": None,
        "DATA_EVAL_REASONING": None,
        "RC_SUMMARY": None,
        "RC_GRAPH_JSON": None,
        "RC_EVAL_SCORE": None,
        "RC_EVAL_REASONING": None,
        "IS_BLOCKED": False,
        "FULL_RAW_JSON": None
    }

    log_checkpoint("MAIN: START", {"query": user_query})

    # 2. Guardrails
    guard = check_input_guard(session, user_query)
    if not guard.is_safe:
        row_data["IS_BLOCKED"] = True
        _save_row(session, row_data)
        return {"status": "blocked", "message": guard.message}
        
    # 3. Rephrase & Intent
    # We pass empty history [] because we are running one-by-one
    rephrased = manager.run_rephraser(user_query, [])
    intent = manager.run_intent_classifier(rephrased)
    
    # Map Basic Fields
    row_data["REPHRASED_QUERY"] = rephrased
    row_data["INTENT_TYPE"] = intent.intent_type
    row_data["INTENT_CONFIDENCE"] = intent.confidence

    final_output = {
        "original": user_query,
        "processed": rephrased,
        "intent": intent.model_dump(),
        "results": []
    }

    # 4. Agent Execution
    if intent.direct_response:
        final_output["results"].append({"type": "direct", "message": intent.direct_response})

    # A. Get Needed Tables (Using Names + Descriptions)
    needed_tables = manager.identify_needed_tables(user_query)
    print(needed_tables)   
    if not needed_tables:
            print(" No tables identified.")
            # return result.model_dump()
            
        # B. Rewrite Query (Using Columns + Samples for those tables)
    optimized_query = manager.run_semantic_translator(user_query, needed_tables)
    print(f"\n OPTIMIZED QUERY: {optimized_query}")
    # else:
    #     with ThreadPoolExecutor(max_workers=2) as executor:
    #         fut_data = executor.submit(manager.run_data_agent, intent.data_retrieval_query) if intent.data_retrieval_query else None
    #         fut_rc = executor.submit(manager.run_root_cause_agent, intent.root_cause_query) if intent.root_cause_query else None
            
    #         # --- PROCESS DATA AGENT ---
    #         if fut_data:
    #             try:
    #                 res = fut_data.result() # This is the SqlResult Pydantic Object
                    
    #                 final_output["results"].append({
    #                     "type": "data_analysis",
    #                     "summary": res.answer_text,
    #                     "tables": res.tables
    #                 })
                    
    #                 # === MAP PYDANTIC FIELDS TO DICT ===
    #                 row_data["DATA_SUMMARY"] = res.answer_text
    #                 row_data["DATA_SQL"] = res.sql_generated
    #                 row_data["DATA_SQL_EXPLANATION"] = res.sql_explanation
    #                 row_data["DATA_CLARIFICATION"] = res.clarifying_question
                    
    #                 # Convert the list of tables to a JSON string for the VARIANT column
    #                 if res.tables:
    #                     row_data["DATA_RESULT_SET"] = json.dumps(res.tables)
                    
    #                 if res.evaluation:
    #                     row_data["DATA_EVAL_SCORE"] = res.evaluation.score
    #                     row_data["DATA_EVAL_REASONING"] = res.evaluation.reasoning
                        
    #             except Exception as e:
    #                 final_output["results"].append({"error": str(e)})

    #         # --- PROCESS ROOT CAUSE AGENT ---
    #         if fut_rc:
    #             try:
    #                 res = fut_rc.result() # This is the DiagnosticResult Pydantic Object
                    
    #                 final_output["results"].append({
    #                     "type": "root_cause_analysis",
    #                     "summary": res.summary_text,
    #                     "graph": res.react_flow_json
    #                 })
                    
    #                 # === MAP PYDANTIC FIELDS TO DICT ===
    #                 row_data["RC_SUMMARY"] = res.summary_text
    #                 if res.react_flow_json:
    #                      row_data["RC_GRAPH_JSON"] = json.dumps(res.react_flow_json)
                    
    #                 if res.evaluation:
    #                     row_data["RC_EVAL_SCORE"] = res.evaluation.score
    #                     row_data["RC_EVAL_REASONING"] = res.evaluation.reasoning

    #             except Exception as e:
    #                 final_output["results"].append({"error": str(e)})

    # # 5. Final Save to Snowflake
    # row_data["FULL_RAW_JSON"] = json.dumps(final_output)
    # _save_row(session, row_data)

    # print("------------------------------------------------")
    # print(f" Process Completed for: {user_query}")
    # print("Check table AGENT_DETAILED_HISTORY for results.")
    # return final_output


Skip to main content
Skip to editor
Skip to results
Site





Worksheets
Selection deleted
374
375
376
377
378
379
380
381
382
383
384
385
386
387
388
389
390
391
392
393
394
395
396
397
398
399
400
401
402
403
404
405
406
407
408
409
410
411
412
413
414
415
416
417
418
419
420
421
422
423
424
425
426
427
428
429
430
431
432
433
434
435
436
437
438
439
440
441
    </section_2_react_flow_json>
    
    **CRITICAL** : YOU MUST ONLY EXECUTE ATMOST 8 TOOL CALLS.
    
</response_structure_prompt>
"""

# ==========================================
# 3. SEMANTIC CONTEXT PARSER (SMART LOGIC)
# ==========================================

class SemanticViewParser:
    """
    Parses the GET_DDL output of the Semantic View to extract:
    1. SQL Comments (Table Descriptions)
    2. CA JSON Blob (Column definitions & Sample Values)
    """
    def __init__(self, session: Session, view_name: str):
        self.raw_ddl = self._fetch_ddl(session, view_name)
        self.ca_json = self._extract_ca_blob(self.raw_ddl)
        self.table_comments = self._extract_sql_comments(self.raw_ddl)

    def _fetch_ddl(self, session: Session, view_name: str) -> str:
        """Fetches the raw CREATE VIEW statement."""
        print(f" FETCHING DDL FOR: {view_name}...")
        try:
            return session.sql(f"SELECT GET_DDL('VIEW', '{view_name}') as DDL").collect()
        except Exception as e:
            print(f" DDL Fetch Error: {e}")
            return ""

    def _extract_ca_blob(self, ddl: str) -> Dict:
        """Extracts the 'CA' JSON blob which contains Columns & Sample Values."""
        # Pattern finds: with extension (CA='{...}')
        match = re.search(r"with extension \(CA='(.*?)'\)", ddl, re.DOTALL)
        if match:
            try:
                # Unescape single quotes (Snowflake escapes ' as '')
                clean_json = match.group(1).replace("''", "'")
                return json.loads(clean_json)
            except: pass
        return {"tables": []}

    def _extract_sql_comments(self, ddl: str) -> Dict[str, str]:
        """Extracts table descriptions from the SQL part."""
        comments = {}
        # Regex to find table names and their comments
        pattern = r"table\s+([a-zA-Z0-9_.]+)\s+comment='(.*?)'"
        matches = re.finditer(pattern, ddl, re.IGNORECASE)
        for m in matches:
            full_name = m.group(1)
            comment = m.group(2)
            # Store by simple name
            simple_name = full_name.split('.')[-1]
            comments[simple_name] = comment
        return comments

    def get_table_summaries(self) -> str:
        """
        PHASE 1: Returns ONLY Table Names + Descriptions.
        Used for the Table Selection Step.
        """
        summary_list = []
        for t in self.ca_json.get('tables', []):
            t_name = t.get('name')
            desc = self.table_comments.get(t_name, "No description available.")
            summary_list.append(f"- Table: {t_name}\n  Description: {desc}")
        return "\n".join(summary_list)
 FETCHING DDL FOR: DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.REPORTING.BASIC_CORTEX_ANALYST...
 DDL Fetch Error: (1304): 01c1e098-081a-12d3-0075-0383fa88121a: 002030 (42601): 01c1e098-081a-12d3-0075-0383fa88121a: SQL compilation error:
Invalid object type: '{0}'
==================================================
 CHECKPOINT: MAIN: START
--------------------------------------------------
{'query': 'show me healthcare providers in Arizona'}
==================================================
==================================================
 CHECKPOINT: START: GUARD
--------------------------------------------------
show me healthcare providers in Arizona
==================================================
Extraction Error: main_module.RephraserOutput() argument after ** must be a mapping, not list
Databases
Worksheets
Data products
Search objects
7 more Databases
Pinned (1)



JSON Parse Error: 1 validation error for RephraserOutput
refined_query
  Field required [type=missing, input_value={'data': {'id': 'e17fbc0b...t': ''}}], 'usage': {}}}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.10/v/missing


{'description': "Schema for extracting structured data from the Data Agent's text response.", 'properties': {'clean_answer_text': {'description': 'The user-facing summary of the data, excluding internal evaluations.', 'type': 'string'}, 'clarifying_question': {'type': ['string', 'null'], 'description': 'A question to ask the user if the data result was incomplete or ambiguous.'}, 'evaluation': {'description': 'The self-evaluation of the response quality.'}}, 'required': ['clean_answer_text', 'evaluation'], 'type': 'object'}
==================================================
 CHECKPOINT: API REQUEST (STRUCTURED)
--------------------------------------------------
Target Model: DataAgentParsedOutput
==================================================
{
	"message":	"input schema validation error: /properties/evaluation please specify a valid json schema object ('type' missing?, additionalProperties used?, invalid type array?) or a '$ref' value",
	"request_id":	"3276ba80-661c-4776-8ac6-d5636e9ba1e7"
}
==================================================
 CHECKPOINT: RAW ACCUMULATED TEXT
--------------------------------------------------
==================================================
==================================================
 CHECKPOINT: API REQUEST (STRUCTURED)
--------------------------------------------------
Target Model: IntentClassification
==================================================
{
	"message":	"input schema validation error: /properties/root_cause_query additional properties are not allowed, /properties/root_cause_query unevaluated properties are not allowed, /properties/clarification_question additional properties are not allowed, /properties/clarification_question unevaluated properties are not allowed, /properties/data_retrieval_query additional properties are not allowed, /properties/data_retrieval_query unevaluated properties are not allowed, /properties/direct_response additional properties are not allowed, /properties/direct_response unevaluated properties are not allowed",
	"request_id":	"bd69e7bb-1529-4d5b-a13a-07ea7dcde6c4"
}
==================================================
 CHECKPOINT: RAW ACCUMULATED TEXT
--------------------------------------------------
==================================================


show me health care prescribers in arizona
==================================================
{
	"message":	"input schema validation error: root level type should be object, got null",
	"request_id":	"661bb3d2-c1bd-43bb-9baa-cb87bdc19dce"
}



def invoke_cortex_agent(session: Session, payload: Dict, agent_name: str) -> Dict:
    """Invokes 'agent:run' for tools (Analyst/Diagnostic)."""
    ENDPOINT = "/api/v2/cortex/agent:run"
    print(f"--- INVOKING AGENT: {agent_name} ---")

    try:
        resp = _snowflake.send_snow_api_request("POST", ENDPOINT, {"Content-Type": "application/json", "Accept": "text/event-stream"}, {}, payload, {}, 120000)
        content = resp.get("content")
        print(content)
        if not content: return {"error": "Empty"}
        
        extracted = {"text": "", "tables": [], "charts": [], "sql_generated": None, "sql_explanation": None}
        try: parsed = json.loads(content)
        except: parsed = [json.loads(line) for line in content.splitlines() if line.strip()]
        
        def process_event(evt, data):
            if evt == 'response.text.delta': extracted["text"] += data.get('text', '')
            elif evt == 'response.chart': extracted["charts"].append(data.get('chart') or data.get('chart_spec'))
            elif evt == 'response.table':
                rs = data.get('result_set', [])
                extracted["tables"].append(rs) # Limit 5 rows
            elif evt == 'response.tool_result.analyst.delta':
                delta = data.get('delta', {})
                if delta.get('sql'): extracted["sql_generated"] = delta.get('sql')
                if delta.get('sql_explanation'): extracted["sql_explanation"] = delta.get('sql_explanation')
                if delta.get('result_set'): extracted["tables"].append(delta.get('result_set'))
            elif evt == 'response.tool_result':
                for item in data.get('content', []):
                    if item.get('type') == 'json':
                        json_p = item.get('json', {})
                        if 'sql' in json_p: extracted["sql_generated"] = json_p['sql']
                        if 'result_set' in json_p: extracted["tables"].append(json_p['result_set'])

        if isinstance(parsed, list):
            for item in parsed: process_event(item.get('event'), item.get('data', {}))
        
        print(f"--- AGENT {agent_name} COMPLETED ---")
        return extracted
    except Exception as e: return {"error": str(e)}


# ==========================================
# 2. FULL PROMPT DEFINITIONS (EXACT ORIGINAL)
# ==========================================

PROMPT_REPHRASER_SYSTEM = "You are a sophisticated Query Refinement Engine."

PROMPT_REPHRASER_ORCHESTRATION = """
<query_refinement_instructions>
<objective>
Transform the user's input into a standalone, context-complete query that can be understood without prior conversation history.
</objective>

<core_rules>
<rule id="1">Resolve all pronouns (it, they, that, this, those) to their specific referents</rule>
<rule id="2">Preserve ALL metrics, entity names, IDs, and numerical values EXACTLY as stated</rule>
<rule id="3">Maintain the original intent and scope - do not expand or narrow the question</rule>
<rule id="4">Keep technical terminology and domain-specific language intact</rule>
<rule id="5">Ensure the output is grammatically correct and reads naturally</rule>
</core_rules>

<transformation_examples>
<example>
<input>What about Arizona?</input>
<context>Previous discussion about sales performance in Texas</context>
<output>What is the sales performance in Arizona?</output>
</example>

<example>
<input>Why is it down?</input>
<context>Previous mention of Q4 revenue</context>
<output>Why is Q4 revenue down?</output>
</example>

<example>
<input>Show me those providers and explain the trend.</input>
<context>Healthcare providers in California with declining prescriptions</context>
<output>Show me healthcare providers in California with declining prescriptions and explain the trend.</output>
</example>
</transformation_examples>

<output_format>
Output ONLY the refined query string. Do not include explanations, metadata, or formatting.
</output_format>
</query_refinement_instructions>
"""

PROMPT_INTENT_SYSTEM = "You are an Expert Intent Classification System."

PROMPT_INTENT_ORCHESTRATION = """
<intent_classification_instructions>

<mission>
Your ONLY job is to identify the user's INTENT. Do NOT retrieve data, do NOT answer questions, do NOT perform analysis.
Classify the intent type and route accordingly. If you can answer directly (like greetings), provide direct_response.
</mission>

<intent_categories>

<intent name="greeting">
<description>User is greeting, saying hello, or engaging in pleasantries</description>
<indicators>hi, hello, hey, good morning, how are you, thanks, thank you, goodbye, bye</indicators>
<action>Set direct_response with a friendly greeting. No other fields needed.</action>
</intent>

<intent name="data_retrieval">
<description>User wants to see/get/retrieve DATA - numbers, lists, metrics, tables</description>
<indicators>show, list, get, display, find, what is the value, how many, count, total, give me</indicators>
<action>Extract the data request to data_retrieval_query. Keep as natural language. Add "and generate a table and a visual".</action>
**CRITICAL VISUALIZATION LOGIC:**
Analyze the data request. If it implies trends (over time), comparisons (by region/product), or distributions, you MUST automatically append "and generate a table and a visual" to the query string, even if the user did not explicitly ask for a chart.
</intent>

<intent name="root_cause_analysis">
<description>User wants to understand WHY, CAUSES, DRIVERS, REASONS, EXPLANATIONS</description>
<indicators>why, explain, what is driving, what is causing, what's behind, reason for, root cause, how come, what factors</indicators>
<action>Extract the causal question to root_cause_query. Keep VERBATIM - exact text from user.</action>
</intent>

<intent name="combined">
<description>User wants BOTH data AND causal analysis in one request</description>
<indicators>Contains both data keywords AND causal keywords</indicators>
<action>Split into data_retrieval_query AND root_cause_query. Keep both portions.</action>
</intent>

<intent name="clarification_needed">
<description>User's intent is unclear, vague, or ambiguous - you cannot determine what they want</description>
<indicators>Very short/vague input, unclear pronouns without context, incomplete thoughts</indicators>
<action>Set clarification_question asking user to be more specific.</action>
</intent>

<intent name="general_question">
<description>General questions about the system, capabilities, how to use features - not data or analysis requests</description>
<indicators>how do I, can you, what can you do, help me understand, how does this work</indicators>
<action>Set direct_response with helpful information about capabilities.</action>
</intent>

<intent name="off_topic">
<description>User is asking about unrelated topics not connected to data, analytics, or business questions</description>
<indicators>Questions about weather, sports, entertainment, personal topics unrelated to business/data</indicators>
<action>Set direct_response politely redirecting to business/data topics.</action>
</intent>

</intent_categories>

<CRITICAL_CLASSIFICATION_RULES>

 RULE 1: NEVER DO THE WORK - ONLY CLASSIFY
You are NOT a data analyst. You are NOT an answering agent. You ONLY identify intent type.
Do NOT retrieve data. Do NOT answer analytical questions. ONLY classify and route.

 RULE 2: CAUSAL KEYWORD DETECTION
These ALWAYS indicate root_cause_analysis intent:
- "what is driving"
- "what is causing"
- "what's driving"  
- "what's causing"
- "why is/are"
- "explain why"
- "reason for"
- "root cause"
- "what factors"
- "what's behind"
- "how come"

 RULE 3: DATA KEYWORD DETECTION  
These ALWAYS indicate data_retrieval intent:
- "show me"
- "list"
- "get"
- "display"
- "find all"
- "what is the value/total/count of"
- "how many"

 RULE 4: DIRECT RESPONSE ONLY FOR SIMPLE CASES
Use direct_response ONLY for:
- Greetings (hi, hello, thanks)
- General system questions (what can you do)
- Off-topic redirects

Do NOT use direct_response for data or analytical questions - those need agent processing.

 RULE 5: VERBATIM PRESERVATION FOR ROOT CAUSE
For root_cause_query: Copy EXACT text from user. No paraphrasing, no summarizing.

 RULE 6: NO SQL CODE GENERATION
NEVER write SELECT/FROM/WHERE statements. Keep everything as natural language.

 RULE 7: CONFIDENCE SCORING
- high: Intent is crystal clear
- medium: Intent is likely but has some ambiguity
- low: Intent is very unclear, might need clarification

</CRITICAL_CLASSIFICATION_RULES>

<classification_process>
<step number="1">Check if greeting or general question. If match, Set intent_type and direct_response, STOP</step>
<step number="2">Check for causal keywords. If found, Flag as root_cause_analysis or combined</step>
<step number="3">Check for data keywords. If found, Flag as data_retrieval or combined</step>
<step number="4">Determine if combined intent. If both, Set intent_type="combined".</step>
<step number="5">If none of the above match, check if intent is clear enough.</step>
</classification_process>

<comprehensive_examples>
<example>
<input>Hello!</input>
<output>
{
  "intent_type": "greeting",
  "data_retrieval_query": null,
  "root_cause_query": null,
  "direct_response": "Hello! How can I help you today?",
  "clarification_question": null,
  "confidence": "high",
  "reasoning": "Simple greeting - can respond directly without agent processing"
}
</output>
</example>

<example>
<input>Show me total sales for Q4.</input>
<output>
{
  "intent_type": "data_retrieval",
  "data_retrieval_query": "Show me total sales for Q4 and generate a table and a visual",
  "root_cause_query": null,
  "direct_response": null,
  "clarification_question": null,
  "confidence": "high",
  "reasoning": "Clear data retrieval request - 'show me' is data keyword, asking for metric value"
}
</output>
</example>

<example>
<input>Why is profit down?</input>
<output>
{
  "intent_type": "root_cause_analysis",
  "data_retrieval_query": null,
  "root_cause_query": "Why is profit down?",
  "direct_response": null,
  "clarification_question": null,
  "confidence": "high",
  "reasoning": "Pure causal question - 'why' keyword indicates root cause analysis needed"
}
</output>
</example>

<example>
<input>Get revenue for AZ and explain the dip.</input>
<output>
{
  "intent_type": "combined",
  "data_retrieval_query": "Get revenue for AZ and generate a table and a visual",
  "root_cause_query": "explain the dip",
  "direct_response": null,
  "clarification_question": null,
  "confidence": "high",
  "reasoning": "Combined intent - 'get revenue' is data retrieval, 'explain the dip' is causal analysis"
}
</output>
</example>

<example>
<input>What can you help me with?</input>
<output>
{
  "intent_type": "general_question",
  "data_retrieval_query": null,
  "root_cause_query": null,
  "direct_response": "I can help you with data analysis and business insights! I can retrieve data and perform root cause analysis. What would you like to explore?",
  "clarification_question": null,
  "confidence": "high",
  "reasoning": "General system capability question - can answer directly"
}
</output>
</example>

<example>
<input>Show that</input>
<output>
{
  "intent_type": "clarification_needed",
  "data_retrieval_query": null,
  "root_cause_query": null,
  "direct_response": null,
  "clarification_question": "What would you like me to show? Please provide more details about the data or metrics you're interested in.",
  "confidence": "low",
  "reasoning": "Vague request - unclear what user wants to see, needs clarification"
}
</output>
</example>

<example>
<input>What's the weather like?</input>
<output>
{
  "intent_type": "off_topic",
  "data_retrieval_query": null,
  "root_cause_query": null,
  "direct_response": "I'm designed to help with business data and analytics. Is there any sales, performance, or business data I can help you with?",
  "clarification_question": null,
  "confidence": "high",
  "reasoning": "Off-topic request - politely redirect to business/data topics"
}
</output>
</example>
</comprehensive_examples>

<validation_checklist>
 Step 1: Can I answer this directly? (greeting/general_question/off_topic)
 Step 2: Does it contain causal keywords? (why/driving/causing/explain/reason/factors/behind)
 Step 3: Does it contain data keywords? (show/list/get/display/what is the value/how many)
 Step 4: Does it have BOTH data and causal elements?
 Step 5: Did I preserve EXACT wording for root_cause_query?
 Step 6: Did I add "and generate a table and a visual" to data_retrieval_query?
 Step 7: Did I avoid doing the actual work? (I only classify, not retrieve/analyze)
 Step 8: Is my confidence level accurate?
</validation_checklist>
</intent_classification_instructions>
"""

PROMPT_DATA_AGENT_SYSTEM = "You are an expert Data Analyst."

PROMPT_DATA_AGENT_ORCHESTRATION = """
<data_agent_instructions>
<objective>
Use the analyst_tool to answer data requests with comprehensive results including tables and visualizations.
</objective>
<execution_rules>
<rule id="1">ALWAYS generate a table (Result Set) for data requests</rule>
<rule id="2">Generate appropriate visualizations when data is suitable for charts</rule>
<rule id="3">Provide clear, concise summaries of the data findings</rule>
<rule id="4">Handle errors gracefully and explain any data limitations</rule>
</execution_rules>
<output_format>
Provide a summary of findings. Tables and charts are handled automatically by the tool.
</output_format>

<self_evaluation_instructions>
You MUST perform a rigorous self-critique of your SQL and data analysis.
1. **Accuracy (Score 1-10):** Does the SQL strict follow the user's constraints (filters, date ranges)?
2. **Data Integrity:** Are the results logical? (e.g., no negative counts where impossible).
3. **Clarity:** Is the summary accessible to a non-technical user?
**CRITICAL:** Append this evaluation at the end of your response in the following format:
### SELF-EVALUATION
Score: [1-10]
Reasoning: [Detailed analysis]
</self_evaluation_instructions>
</data_agent_instructions>
"""

PROMPT_ROOT_CAUSE_SYSTEM = "You are an Autonomous Root Cause Analysis Agent."

PROMPT_ROOT_CAUSE_ORCHESTRATION = """
<root_cause_orchestration_prompt>
    <role_and_objective>
        You are an **Autonomous Root Cause Analysis Agent** designed to traverse a metric decision tree from the root node down to the leaf nodes. Your goal is to identify specific "bad" metrics driving a business problem by systematically drilling down into the data.
        
        ALWAYS USE tree_id as Pharma_Master_v1.
    </role_and_objective>

    <operational_procedure>
        You must strictly follow this recursive logic for every user request:

        **Step 1: Initialization (Find the Root)**
        * If this is the start of the conversation, call `Diagnostic_tool` in **Search Mode**.
        * **Action:** Call `Diagnostic_tool(USER_QUERY=user_question, PARENT_NODE_IDS_JSON=NULL)`.
        * **Next:** Proceed to Step 2 with the results.

        **Step 2: Status Evaluation & Decision**
        Analyze the list of nodes returned by the tool. Focus **only** on nodes where `"status": "bad"`.

        * **Check:** For every "bad" node, do you see its children in the current list?
        * **Condition A (Drill Needed):** If a node is "bad" and you do **not** see its children, you must drill down. Collect these Node IDs.
        * **Condition B (Keep Going):** If a node is "bad" but you **already** see its children, ignore it and evaluate the children instead.
        * **Condition C (Stop):** If you find "bad" nodes but they have no children (empty results from a drill), these are your **Root Causes**.

        **Step 3: Execution (Drill Down)**
        * If Condition A occurred: Call `Diagnostic_tool` in **Drill Mode**.
        * **Action:** Call `Diagnostic_tool(USER_QUERY=NULL, PARENT_NODE_IDS_JSON='["ID_1", "ID_2"]')`.
        * **Next:** Recursively repeat Step 2 with the new output.
        * If Condition C occurred: Present the final root causes to the user.
    </operational_procedure>

    <constraints>
        * **Never** guess the status of a metric; always use the tool.
        * **Never** stop at a "bad" node if it has unexplored children; you must find the leaf node.
        * Output your reasoning briefly before calling the tool.
    </constraints>

    <self_evaluation_instructions>
    You MUST perform a rigorous self-critique of your root cause logic.
1. **Logic (Score 1-10):** Is the causal chain (Root -> Leaf) mathematically sound?
2. **Driver Isolation:** Did we truly find the leaf node, or did we stop too early?
3. **Completeness:** Did we explore all "bad" branches?
    **CRITICAL:** Append this evaluation at the end of your response in the following format:
    ### SELF-EVALUATION
    Score: [1-10]
    Reasoning: [Detailed analysis]
    </self_evaluation_instructions>
</root_cause_orchestration_prompt>
"""

PROMPT_ROOT_CAUSE_RESPONSE = """
<response_structure_prompt>
    <instruction>
        You must output exactly two sections in the following order. Do not include any conversational filler before or after these sections.
    </instruction>

    <section_1_executive_summary>
        #### **SECTION 1: Diagnostic Executive Summary**
        * **Tone:** Professional, constructive, and polite.
        * **Headline:** State the Root Cause clearly.
        * **The Narrative:** Briefly explain the chain of events in simple English.
        * **Actionable Insight:** Based on the metadata or description of the root node, suggest a generic, helpful next step.
    </section_1_executive_summary>

    <section_2_react_flow_json>
        #### **SECTION 2: React Flow JSON Artifact**
        You must generate a valid JSON object inside a Markdown code block (json ...).
        
        **1. Coordinate Logic (The "Mental Layout"):**
        * **Level 0 (Root):** `x: 0, y: 0`
        * **Level 1 Children:** `y: 150`. Spread `x` widely (e.g., `-300` and `300`).
        * **Level 2 Grandchildren:** `y: 300`. Spread `x` relative to their parent.
        * **Level 3+:** Increase `y` by `150` for each level.

        **2. Visual Style Logic:**
        * **Red (#FFE2E5):** Status is "bad", "high", or "error".
        * **Green (#CDE8E6):** Status is "good", "normal", or "stable".
        * **Orange (#FFCCBC):** The **Root Cause** (the deepest "bad" node in the chain).
        * **White (#FFFFFF):** Unexplored or neutral nodes.

        **3. Edge Labeling Logic:**
        * If Parent is Bad and Child is Bad, label = "contributes to impact".
        * If Parent is Bad and Child is Good, label = "stable factor".

        **4. JSON Schema (Must Follow Exactly):**
        {
          "nodes": [
            {
              "id": "N0",
              "type": "default",
              "data": { "label": "Metric Name: Value" },
              "position": { "x": 0, "y": 0 },
              "style": { "background": "#FFE2E5", "width": 180, "color": "#333", "border": "1px solid #777", "borderRadius": "8px" }
            }
          ],
          "edges": [
            {
              "id": "e-N0-N1",
              "source": "N0",
              "target": "N1",
              "label": "driven by",
              "animated": true,
              "style": { "stroke": "#555", "strokeWidth": 2 }
            }
          ]
        }
    </section_2_react_flow_json>
    
    **CRITICAL** : YOU MUST ONLY EXECUTE ATMOST 8 TOOL CALLS.
    
</response_structure_prompt>
"""
==================================================
==================================================
 CHECKPOINT: START: GUARD
--------------------------------------------------
Why has the Orthopedic segment ceased to be the primary growth driver for our Tramadol brand, effectively handing the market over to generalists?
==================================================
--- INVOKING AGENT: Rephraser Agent ---
--- AGENT Rephraser Agent COMPLETED ---
Rephrased: What factors have caused the Orthopedic segment to decline as the primary growth driver for Tramadol brand, resulting in market share shift to generalist physicians?
--- INVOKING AGENT: Intent Agent ---
--- AGENT Intent Agent COMPLETED ---
Intent: root_cause_analysis
--- INVOKING AGENT: Root Cause Agent ---
--- AGENT Root Cause Agent COMPLETED ---
 Extraction/Validation Error: 2 validation errors for RootCauseParsedOutput
clean_summary_text
  Field required [type=missing, input_value={'nodes': [{'id': 'K5', '...0', 'strokeWidth': 2}}]}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.8/v/missing
evaluation
  Field required [type=missing, input_value={'nodes': [{'id': 'K5', '...0', 'strokeWidth': 2}}]}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.8/v/missing
Databases
Worksheets
Data products
Search objects
7 more Databases
Pinned (1)


==================================================
==================================================
 CHECKPOINT: START: GUARD
--------------------------------------------------
show me healthcare providers in Arizona
==================================================
--- INVOKING AGENT: Rephraser Agent ---
--- AGENT Rephraser Agent COMPLETED ---
--- INVOKING AGENT: Intent Agent ---
--- AGENT Intent Agent COMPLETED ---
 Starting Data Agent Flows (Standard & Optimized)...
--- INVOKING AGENT: Data Agent ---
 IDENTIFYING RELEVANT TABLES...
Optimization failed: 1 validation error for TableSelection
relevant_table_names
  Field required [type=missing, input_value={}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.8/v/missing
--- AGENT Data Agent COMPLETED ---



{
    "graph": {
        "nodes": [
            { "id": "K1", "metric": "Total Market Volume (TRX)" },
            { "id": "K2", "metric": "Total New Starts (NRX)" },
            { "id": "K3", "metric": "Opioid Category Volume" },
            { "id": "K4", "metric": "NSAID Category Volume" },
            { "id": "K5", "metric": "Tramadol Brand Volume" },
            { "id": "K6", "metric": "Diclofenac Brand Volume" },
            { "id": "K7", "metric": "Tramadol New Growth (NRX)" },
            { "id": "K8", "metric": "Tramadol Retention (Refills)" },
            { "id": "K9", "metric": "Diclofenac New Growth (NRX)" },
            { "id": "K10", "metric": "Orthopedic Tramadol Starts" },
            { "id": "K11", "metric": "PCP Tramadol Starts" },
            { "id": "K12", "metric": "OPIOD Market Volume" },
            { "id": "K13", "metric": "NSAID Market Volume" },
            { "id": "K14", "metric": "High Volume Writers (>10)" }
        ],
        "edges": [
            { "source": "K3", "target": "K1" }, 
            { "source": "K4", "target": "K1" }, 
            { "source": "K5", "target": "K3" }, 
            { "source": "K6", "target": "K4" }, 
            { "source": "K7", "target": "K5" }, 
            { "source": "K8", "target": "K5" }, 
            { "source": "K9", "target": "K6" }, 
            { "source": "K10", "target": "K7" }, 
            { "source": "K11", "target": "K7" }
        ]
    }
}



create or replace TABLE DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.AI_POC.DECISION_TREE_STORE_NEW (
	TREE_ID VARCHAR(50) NOT NULL,
	GRAPH_JSON VARIANT,
	CREATED_AT TIMESTAMP_NTZ(9) DEFAULT CURRENT_TIMESTAMP(),
	primary key (TREE_ID)
);



INSERT INTO KPI_KNOWLEDGE_BASE_NEW (KPI_ID, METRIC_NAME, DESCRIPTION, SQL_QUERY, FEW_SHOT_EXAMPLES, KPI_EMBEDDING)

-- LEVEL 1: Market & Totals
SELECT 'K1', 'Total Market Volume (TRX)', 'Total volume of all acute prescriptions across the entire market.', 
'SELECT SUM(ACUTE_TRX_XPO) FROM MASTER_DB_SAMPLE_DATA', 
PARSE_JSON('[]'), SNOWFLAKE.CORTEX.EMBED_TEXT_768('snowflake-arctic-embed-m', 'Total Market Volume TRX all sales')

UNION ALL
SELECT 'K2', 'Total New Starts (NRX)', 'Total volume of new-to-therapy prescriptions, indicating market growth.', 
'SELECT SUM(ACUTE_NRX_XPO) FROM MASTER_DB_SAMPLE_DATA', 
PARSE_JSON('[]'), SNOWFLAKE.CORTEX.EMBED_TEXT_768('snowflake-arctic-embed-m', 'Total New Starts NRX growth')

-- LEVEL 2: Categories
UNION ALL
SELECT 'K3', 'Opioid Category Volume', 'Total prescriptions for the Opioid drug class (e.g., Tramadol).', 
'SELECT SUM(ACUTE_TRX_XPO) FROM MASTER_DB_SAMPLE_DATA WHERE PRODUCT_CATEGORY = ''OPIOID''', 
PARSE_JSON('[]'), SNOWFLAKE.CORTEX.EMBED_TEXT_768('snowflake-arctic-embed-m', 'Opioid Category Volume pain meds')

UNION ALL
SELECT 'K4', 'NSAID Category Volume', 'Total prescriptions for the NSAID drug class (e.g., Diclofenac).', 
'SELECT SUM(ACUTE_TRX_XPO) FROM MASTER_DB_SAMPLE_DATA WHERE PRODUCT_CATEGORY = ''NSAID''', 
PARSE_JSON('[]'), SNOWFLAKE.CORTEX.EMBED_TEXT_768('snowflake-arctic-embed-m', 'NSAID Category Volume anti inflammatory')

-- LEVEL 3: Products
UNION ALL
SELECT 'K5', 'Tramadol Brand Volume', 'Total prescriptions specifically for the Tramadol product family.', 
'SELECT SUM(ACUTE_TRX_XPO) FROM MASTER_DB_SAMPLE_DATA WHERE PRODUCT_FAMILY_GROUP = ''TRAMADOL''', 
PARSE_JSON('[]'), SNOWFLAKE.CORTEX.EMBED_TEXT_768('snowflake-arctic-embed-m', 'Tramadol Brand Volume product specific')

UNION ALL
SELECT 'K6', 'Diclofenac Brand Volume', 'Total prescriptions specifically for the Diclofenac product family.', 
'SELECT SUM(ACUTE_TRX_XPO) FROM MASTER_DB_SAMPLE_DATA WHERE PRODUCT_FAMILY_GROUP = ''DICLOFENAC''', 
PARSE_JSON('[]'), SNOWFLAKE.CORTEX.EMBED_TEXT_768('snowflake-arctic-embed-m', 'Diclofenac Brand Volume product specific')

-- LEVEL 4: Product Performance Metrics (New vs Refill)
UNION ALL
SELECT 'K7', 'Tramadol New Growth (NRX)', 'New patient prescriptions for Tramadol. Key indicator of sales force effectiveness.', 
'SELECT SUM(ACUTE_NRX_XPO) FROM MASTER_DB_SAMPLE_DATA WHERE PRODUCT_FAMILY_GROUP = ''TRAMADOL''', 
PARSE_JSON('[]'), SNOWFLAKE.CORTEX.EMBED_TEXT_768('snowflake-arctic-embed-m', 'Tramadol New Growth NRX new patients')

UNION ALL
SELECT 'K8', 'Tramadol Retention (Refills)', 'Volume of Tramadol refills (TRX minus NRX), indicating patient retention.', 
'SELECT SUM(ACUTE_TRX_XPO) - SUM(ACUTE_NRX_XPO) FROM MASTER_DB_SAMPLE_DATA WHERE PRODUCT_FAMILY_GROUP = ''TRAMADOL''', 
PARSE_JSON('[]'), SNOWFLAKE.CORTEX.EMBED_TEXT_768('snowflake-arctic-embed-m', 'Tramadol Retention Refills loyal patients')

UNION ALL
SELECT 'K9', 'Diclofenac New Growth (NRX)', 'New patient prescriptions for Diclofenac.', 
'SELECT SUM(ACUTE_NRX_XPO) FROM MASTER_DB_SAMPLE_DATA WHERE PRODUCT_FAMILY_GROUP = ''DICLOFENAC''', 
PARSE_JSON('[]'), SNOWFLAKE.CORTEX.EMBED_TEXT_768('snowflake-arctic-embed-m', 'Diclofenac New Growth NRX')

-- LEVEL 5: Specialist & Geography Segments
UNION ALL
SELECT 'K10', 'Orthopedic Tramadol Starts', 'New Tramadol prescriptions written specifically by Orthopedic Surgeons.', 
'SELECT SUM(ACUTE_NRX_XPO) FROM MASTER_DB_SAMPLE_DATA WHERE PRODUCT_FAMILY_GROUP = ''TRAMADOL'' AND PRIMARY_SPECIALTY_METRIC LIKE ''%Orthopedic%''', 
PARSE_JSON('[]'), SNOWFLAKE.CORTEX.EMBED_TEXT_768('snowflake-arctic-embed-m', 'Orthopedic Tramadol Starts surgeon new rx')

UNION ALL
SELECT 'K11', 'PCP Tramadol Starts', 'New Tramadol prescriptions written by Primary Care/Internal Medicine.', 
'SELECT SUM(ACUTE_NRX_XPO) FROM MASTER_DB_SAMPLE_DATA WHERE PRODUCT_FAMILY_GROUP = ''TRAMADOL'' AND PRIMARY_SPECIALTY_METRIC IN (''Other PCP Specialties'', ''Internal Medicine'')', 
PARSE_JSON('[]'), SNOWFLAKE.CORTEX.EMBED_TEXT_768('snowflake-arctic-embed-m', 'PCP Tramadol Starts primary care')

UNION ALL
SELECT 'K12', 'NC Market Volume', 'Total prescription volume in North Carolina, a key territory.', 
'SELECT SUM(ACUTE_TRX_XPO) FROM MASTER_DB_SAMPLE_DATA WHERE HCP_STATE = ''NC''', 
PARSE_JSON('[]'), SNOWFLAKE.CORTEX.EMBED_TEXT_768('snowflake-arctic-embed-m', 'NC Market Volume north carolina state')

UNION ALL
SELECT 'K13', 'AR Market Volume', 'Total prescription volume in Arkansas.', 
'SELECT SUM(ACUTE_TRX_XPO) FROM MASTER_DB_SAMPLE_DATA WHERE HCP_STATE = ''AR''', 
PARSE_JSON('[]'), SNOWFLAKE.CORTEX.EMBED_TEXT_768('snowflake-arctic-embed-m', 'AR Market Volume arkansas state')

UNION ALL
SELECT 'K14', 'High Volume Writers (>10)', 'Prescriptions coming from HCPs with more than 10 total scripts.', 
'SELECT SUM(ACUTE_TRX_XPO) FROM MASTER_DB_SAMPLE_DATA WHERE ACUTE_TRX_XPO > 10', 
PARSE_JSON('[]'), SNOWFLAKE.CORTEX.EMBED_TEXT_768('snowflake-arctic-embed-m', 'High Volume Writers top prescribers')

UNION ALL
SELECT 'K15', 'NP/PA Segment Contribution', 'Volume generated by Nurse Practitioners and Physician Assistants.', 
'SELECT SUM(ACUTE_TRX_XPO) FROM MASTER_DB_SAMPLE_DATA WHERE PRIMARY_SPECIALTY_METRIC = ''NP/PA''', 
PARSE_JSON('[]'), SNOWFLAKE.CORTEX.EMBED_TEXT_768('snowflake-arctic-embed-m', 'NP PA Segment Contribution nurse practitioner');


INSERT INTO DECISION_TREE_STORE_NEW (TREE_ID, GRAPH_JSON) 
SELECT 'Pharma_Master_v1', PARSE_JSON($$
{
    "graph": {
        "nodes": [
            { "id": "K1", "metric": "Total Market Volume (TRX)" },
            { "id": "K2", "metric": "Total New Starts (NRX)" },
            { "id": "K3", "metric": "Opioid Category Volume" },
            { "id": "K4", "metric": "NSAID Category Volume" },
            { "id": "K5", "metric": "Tramadol Brand Volume" },
            { "id": "K6", "metric": "Diclofenac Brand Volume" },
            { "id": "K7", "metric": "Tramadol New Growth (NRX)" },
            { "id": "K8", "metric": "Tramadol Retention (Refills)" },
            { "id": "K9", "metric": "Diclofenac New Growth (NRX)" },
            { "id": "K10", "metric": "Orthopedic Tramadol Starts" },
            { "id": "K11", "metric": "PCP Tramadol Starts" },
            { "id": "K12", "metric": "NC Market Volume" },
            { "id": "K13", "metric": "AR Market Volume" },
            { "id": "K14", "metric": "High Volume Writers (>10)" },
            { "id": "K15", "metric": "NP/PA Segment Contribution" }
        ],
        "edges": [
            { "source": "K3", "target": "K1" }, 
            { "source": "K4", "target": "K1" }, 
            { "source": "K5", "target": "K3" }, 
            { "source": "K6", "target": "K4" }, 
            { "source": "K7", "target": "K5" }, 
            { "source": "K8", "target": "K5" }, 
            { "source": "K9", "target": "K6" }, 
            { "source": "K10", "target": "K7" }, 
            { "source": "K11", "target": "K7" }, 
            { "source": "K15", "target": "K4" }
        ]
    }
}
$$);



























import json
import logging
import pprint
import re
import _snowflake # Native Snowflake module for internal API calls
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import List, Dict, Any, Optional, Literal, Tuple
from pydantic import BaseModel, Field, field_validator
from snowflake.snowpark import Session
from snowflake.snowpark.functions import lit, parse_json
from collections import defaultdict

# ==========================================
# 1. CONFIGURATION
# ==========================================

class AgentConfig(BaseModel):
    """Configuration for the agent execution"""
    # LLM Models
    model: str = "claude-sonnet-4-5"            
    
    # Snowflake Objects
    cortex_analyst_object_master: str = "DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.AI_POC.MASTERTABLE_V1"
    cortex_analyst_object_ards: str = "DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.REPORTING.BASIC_CORTEX_ANALYST"
    warehouse: str = "DEV_PAIN_SALES_PERFORMANCE_B_WH"
    messages_table: str = "DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.AI_POC.MESSAGES"
    diagnostic_udf: str = "DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.AI_POC.DIAGNOSTIC_TOOL"
    
    enable_semantic_parsing: bool = True

CONFIG = AgentConfig()

# ==========================================
# 2. PYDANTIC MODELS (Structure Only)
# ==========================================

class EvaluationResult(BaseModel):
    score: int = Field(..., description="Score 1-10.")
    reasoning: str = Field(..., description="Justification.")

class IntentClassification(BaseModel):
    intent_type: str = Field(..., description="greeting, data_retrieval, root_cause_analysis, clarification_needed, general_question, off_topic, combined")
    data_retrieval_query: Optional[str] = None
    root_cause_query: Optional[str] = None
    direct_response: Optional[str] = None
    clarification_question: Optional[str] = None
    confidence: str = Field(..., description="high, medium, low")
    reasoning: str = Field(..., description="Reasoning")

class RephraserOutput(BaseModel):
    refined_query: str = Field(..., description="The fully contextualized query.")

class TableSelection(BaseModel):
    relevant_table_names: List[str] = Field(..., description="List of table names.")

class GuardResult(BaseModel):
    is_safe: bool = Field(...)
    message: Optional[str] = Field(None)

class DataAgentParsedOutput(BaseModel):
    clean_answer_text: str = Field(...)
    clarifying_question: Optional[str] = None
    evaluation: EvaluationResult = Field(...)

class RootCauseParsedOutput(BaseModel):
    clean_summary_text: str = Field(...)
    react_flow_json: Optional[Dict] = None
    evaluation: EvaluationResult = Field(...)

class SqlResult(BaseModel):
    answer_text: str
    clarifying_question: Optional[str] = None
    tables: List[Any] = Field(default_factory=list)
    charts: List[Dict] = Field(default_factory=list)
    sql_generated: Optional[str] = None
    sql_explanation: Optional[str] = None
    is_verified_query: bool = False
    evaluation: EvaluationResult
    is_retry: bool = False

    @field_validator('charts', mode='before')
    @classmethod
    def parse_charts(cls, v):
        if not v: return []
        parsed = []
        for item in v:
            if isinstance(item, dict): parsed.append(item)
            elif isinstance(item, str):
                try: parsed.append(json.loads(item))
                except: continue 
        return parsed

class DiagnosticResult(BaseModel):
    summary_text: str
    react_flow_json: Optional[Dict] = None
    evaluation: EvaluationResult

# ==========================================
# 3. PROMPTS (Separated Logic & Response)
# ==========================================

# --- REPHRASER ---
PROMPT_REPHRASER_SYSTEM = "You are a sophisticated Query Refinement Engine."

PROMPT_REPHRASER_ORCHESTRATION = """
<query_refinement_instructions>
<objective>
Transform the user's input into a standalone, context-complete query that can be understood without prior conversation history.
</objective>

<core_rules>
<rule id="1">Resolve all pronouns (it, they, that, this, those) to their specific referents</rule>
<rule id="2">Preserve ALL metrics, entity names, IDs, and numerical values EXACTLY as stated</rule>
<rule id="3">Maintain the original intent and scope - do not expand or narrow the question</rule>
<rule id="4">Keep technical terminology and domain-specific language intact</rule>
<rule id="5">Ensure the output is grammatically correct and reads naturally</rule>
</core_rules>

<transformation_examples>
<example>
<input>What about Arizona?</input>
<context>Previous discussion about sales performance in Texas</context>
<output>What is the sales performance in Arizona?</output>
</example>

<example>
<input>Why is it down?</input>
<context>Previous mention of Q4 revenue</context>
<output>Why is Q4 revenue down?</output>
</example>
</transformation_examples>
</query_refinement_instructions>
"""

PROMPT_REPHRASER_RESPONSE = """
<output_format>
At the VERY END of your text response, YOU MUST output a JSON block STRICTLY in below format: 
Example: { "refined_query": "What is the sales performance in Arizona?" }
Do not include any other text or markdown outside the JSON object.
</output_format>
"""

# --- INTENT ---
PROMPT_INTENT_SYSTEM = "You are an Expert Intent Classification System."

PROMPT_INTENT_ORCHESTRATION = """
<intent_classification_instructions>

<mission>
Your ONLY job is to identify the user's INTENT. Do NOT retrieve data, do NOT answer questions, do NOT perform analysis.
Classify the intent type and route accordingly. If you can answer directly (like greetings), provide direct_response.
</mission>

<intent_categories>

<intent name="greeting">
<description>User is greeting, saying hello, or engaging in pleasantries</description>
<indicators>hi, hello, hey, good morning, how are you, thanks, thank you, goodbye, bye</indicators>
<action>Set direct_response with a friendly greeting. No other fields needed.</action>
</intent>

<intent name="data_retrieval">
<description>User wants to see/get/retrieve DATA - numbers, lists, metrics, tables</description>
<indicators>show, list, get, display, find, what is the value, how many, count, total, give me</indicators>
<action>Extract the data request to data_retrieval_query. Keep as natural language. Add "and generate a table and a visual".</action>
**CRITICAL VISUALIZATION LOGIC:**
Analyze the data request. If it implies trends (over time), comparisons (by region/product), or distributions, you MUST automatically append "and generate a table and a visual" to the query string, even if the user did not explicitly ask for a chart.
</intent>

<intent name="root_cause_analysis">
<description>User wants to understand WHY, CAUSES, DRIVERS, REASONS, EXPLANATIONS</description>
<indicators>why, explain, what is driving, what is causing, what's behind, reason for, root cause, how come, what factors</indicators>
<action>Extract the causal question to root_cause_query. Keep VERBATIM - exact text from user.</action>
</intent>

<intent name="combined">
<description>User wants BOTH data AND causal analysis in one request</description>
<indicators>Contains both data keywords AND causal keywords</indicators>
<action>Split into data_retrieval_query AND root_cause_query. Keep both portions.</action>
</intent>

<intent name="clarification_needed">
<description>User's intent is unclear, vague, or ambiguous - you cannot determine what they want</description>
<indicators>Very short/vague input, unclear pronouns without context, incomplete thoughts</indicators>
<action>Set clarification_question asking user to be more specific.</action>
</intent>

<intent name="general_question">
<description>General questions about the system, capabilities, how to use features - not data or analysis requests</description>
<indicators>how do I, can you, what can you do, help me understand, how does this work</indicators>
<action>Set direct_response with helpful information about capabilities.</action>
</intent>

<intent name="off_topic">
<description>User is asking about unrelated topics not connected to data, analytics, or business questions</description>
<indicators>Questions about weather, sports, entertainment, personal topics unrelated to business/data</indicators>
<action>Set direct_response politely redirecting to business/data topics.</action>
</intent>

</intent_categories>

<CRITICAL_CLASSIFICATION_RULES>

 RULE 1: NEVER DO THE WORK - ONLY CLASSIFY
You are NOT a data analyst. You are NOT an answering agent. You ONLY identify intent type.
Do NOT retrieve data. Do NOT answer analytical questions. ONLY classify and route.

 RULE 2: CAUSAL KEYWORD DETECTION
These ALWAYS indicate root_cause_analysis intent:
- "what is driving"
- "what is causing"
- "what's driving"  
- "what's causing"
- "why is/are"
- "explain why"
- "reason for"
- "root cause"
- "what factors"
- "what's behind"
- "how come"

 RULE 3: DATA KEYWORD DETECTION  
These ALWAYS indicate data_retrieval intent:
- "show me"
- "list"
- "get"
- "display"
- "find all"
- "what is the value/total/count of"
- "how many"

 RULE 4: DIRECT RESPONSE ONLY FOR SIMPLE CASES
Use direct_response ONLY for:
- Greetings (hi, hello, thanks)
- General system questions (what can you do)
- Off-topic redirects

Do NOT use direct_response for data or analytical questions - those need agent processing.

 RULE 5: VERBATIM PRESERVATION FOR ROOT CAUSE
For root_cause_query: Copy EXACT text from user. No paraphrasing, no summarizing.

 RULE 6: NO SQL CODE GENERATION
NEVER write SELECT/FROM/WHERE statements. Keep everything as natural language.

 RULE 7: CONFIDENCE SCORING
- high: Intent is crystal clear
- medium: Intent is likely but has some ambiguity
- low: Intent is very unclear, might need clarification

</CRITICAL_CLASSIFICATION_RULES>
</intent_classification_instructions>
"""

PROMPT_INTENT_RESPONSE = """
<output_format>
At the VERY END of your text response, YOU MUST output a JSON block STRICTLY in below format:
{
  "intent_type": "data_retrieval",
  "data_retrieval_query": "Show me sales...",
  "root_cause_query": null,
  "direct_response": null,
  "clarification_question": null,
  "confidence": "high",
  "reasoning": "User used 'show me' keyword"
}
</output_format>
"""

# --- DATA AGENT ---
PROMPT_DATA_AGENT_SYSTEM = "You are an expert Data Analyst."

PROMPT_DATA_AGENT_ORCHESTRATION = """
<data_agent_instructions>
<objective>
Use the analyst_tool to answer data requests with comprehensive results including tables and visualizations.
</objective>
<execution_rules>
<rule id="1">ALWAYS generate a table (Result Set) for data requests</rule>
<rule id="2">Generate appropriate visualizations when data is suitable for charts</rule>
<rule id="3">Provide clear, concise summaries of the data findings</rule>
<rule id="4">Handle errors gracefully and explain any data limitations</rule>
</execution_rules>

<self_evaluation_instructions>
You MUST perform a rigorous self-critique of your SQL and data analysis.
1. **Accuracy (Score 1-10):** Does the SQL strict follow the user's constraints (filters, date ranges)?
2. **Data Integrity:** Are the results logical? (e.g., no negative counts where impossible).
3. **Clarity:** Is the summary accessible to a non-technical user?
</self_evaluation_instructions>
</data_agent_instructions>
"""

PROMPT_DATA_AGENT_RESPONSE = """
<output_format>
At the VERY END of your text response, YOU MUST output a JSON block STRICTLY in below format:
```json
{
  "clean_answer_text": "Summary of findings...",
  "clarifying_question": null,
  "evaluation": {
    "score": 8,
    "reasoning": "Data matches request."
  }
}
```
</output_format>
"""

# --- ROOT CAUSE ---
PROMPT_ROOT_CAUSE_SYSTEM = "You are an Autonomous Root Cause Analysis Agent."

PROMPT_ROOT_CAUSE_ORCHESTRATION = """
<root_cause_orchestration_prompt>
    <role_and_objective>
        You are an **Autonomous Root Cause Analysis Agent** designed to traverse a metric decision tree from the root node down to the leaf nodes. Your goal is to identify specific "bad" metrics driving a business problem by systematically drilling down into the data.
        
        ALWAYS USE tree_id as Pharma_Master_v1.
    </role_and_objective>

    <operational_procedure>
        You must strictly follow this recursive logic for every user request:

        **Step 1: Initialization (Find the Root)**
        * If this is the start of the conversation, call `Diagnostic_tool` in **Search Mode**.
        * **Action:** Call `Diagnostic_tool(USER_QUERY=user_question, PARENT_NODE_IDS_JSON=NULL)`.
        * **Next:** Proceed to Step 2 with the results.

        **Step 2: Status Evaluation & Decision**
        Analyze the list of nodes returned by the tool. Focus **only** on nodes where `"status": "bad"`.

        * **Check:** For every "bad" node, do you see its children in the current list?
        * **Condition A (Drill Needed):** If a node is "bad" and you do **not** see its children, you must drill down. Collect these Node IDs.
        * **Condition B (Keep Going):** If a node is "bad" but you **already** see its children, ignore it and evaluate the children instead.
        * **Condition C (Stop):** If you find "bad" nodes but they have no children (empty results from a drill), these are your **Root Causes**.

        **Step 3: Execution (Drill Down)**
        * If Condition A occurred: Call `Diagnostic_tool` in **Drill Mode**.
        * **Action:** Call `Diagnostic_tool(USER_QUERY=NULL, PARENT_NODE_IDS_JSON='["ID_1", "ID_2"]')`.
        * **Next:** Recursively repeat Step 2 with the new output.
        * If Condition C occurred: Present the final root causes to the user.
    </operational_procedure>

    <constraints>
        * **Never** guess the status of a metric; always use the tool.
        * **Never** stop at a "bad" node if it has unexplored children; you must find the leaf node.
        * Output your reasoning briefly before calling the tool.
    </constraints>

    <self_evaluation_instructions>
    You MUST perform a rigorous self-critique of your root cause logic.
    1. **Logic (Score 1-10):** Is the causal chain (Root -> Leaf) mathematically sound?
    2. **Driver Isolation:** Did we truly find the leaf node, or did we stop too early?
    3. **Completeness:** Did we explore all "bad" branches?
    **CRITICAL:** Append this evaluation at the end of your response in the following format:
    ### SELF-EVALUATION
    Score: [1-10]
    Reasoning: [Detailed analysis]
    </self_evaluation_instructions>
</root_cause_orchestration_prompt>
"""

PROMPT_ROOT_CAUSE_RESPONSE = """
<response_structure_prompt>
    <instruction>
        You must output exactly two sections in the following order. Do not include any conversational filler before or after these sections.
    </instruction>

    <section_1_executive_summary>
        #### **SECTION 1: Diagnostic Executive Summary**
        * **Tone:** Professional, constructive, and polite.
        * **Headline:** State the Root Cause clearly.
        * **The Narrative:** Briefly explain the chain of events in simple English.
        * **Actionable Insight:** Based on the metadata or description of the root node, suggest a generic, helpful next step.
    </section_1_executive_summary>

    <section_2_react_flow_json>
        #### **SECTION 2: React Flow JSON Artifact**
        You must generate a valid JSON object inside a Markdown code block (json ...).
        
        **4. JSON Schema (Must Follow Exactly):**
        {
          "nodes": [
            {
              "id": "N0",
              "type": "default",
              "data": { "label": "Metric Name: Value" },
              "position": { "x": 0, "y": 0 },
              "style": { "background": "#FFE2E5", "width": 180, "color": "#333", "border": "1px solid #777", "borderRadius": "8px" }
            }
          ],
          "edges": [
            {
              "id": "e-N0-N1",
              "source": "N0",
              "target": "N1",
              "label": "driven by",
              "animated": true,
              "style": { "stroke": "#555", "strokeWidth": 2 }
            }
          ]
        }
    </section_2_react_flow_json>
    
    <section_3_final_json>
        CRITICAL: Provide the final JSON block for the parser here as defined in the system prompt evaluation section.
    </section_3_final_json>
    
    **CRITICAL** : YOU MUST ONLY EXECUTE ATMOST 8 TOOL CALLS.
    
    <output_format>
    At the VERY END of your text response, YOU MUST output a JSON block STRICTLY in below format:
    ```json
    {
      "clean_summary_text": "Executive summary...",
      "react_flow_json": { "nodes": [], "edges": [] },
      "evaluation": { "score": 9, "reasoning": "Found root cause." }
    }
    ```
    </output_format>
</response_structure_prompt>
"""

# --- TABLE SELECTION ---
PROMPT_TABLE_SELECTION = """
<instruction>
You are an expert Database Architect and Schema Analyzer.
Your goal is to identify the subset of tables from the provided list that are strictly relevant to answering the user's query.

<rules>
1. **Analyze the Query**: Carefully understand the business entities, metrics, and dimensions requested.
2. **Review Summaries**: Check the Table Name and Description for each table provided.
3. **Strict Selection**: Select ONLY tables that contain the data needed. Do NOT include tables "just in case".
4. **Keyword Matching**: 
   - If the query mentions "sales" or "revenue", look for Fact tables with those metrics.
   - If the query mentions "location", "city", or "state", look for Geography Dimension tables.
   - If the query mentions "products", look for Product Dimension tables.
5. **Empty Return**: If no tables seem relevant, return an empty list.
</rules>

<output_format>
Output ONLY a valid JSON object with the following structure. Do not output markdown code blocks.
{
  "relevant_table_names": ["Table_A", "Table_B"]
}
</output_format>
</instruction>
"""

# --- SEMANTIC TRANSLATOR ---
PROMPT_SEMANTIC_TRANSLATOR = """
<instruction>
You are a Semantic Query Optimizer and SQL Expert.
Your goal is to rewrite the User's Natural Language Query so that it aligns perfectly with the provided Database Schema Context.

<rules>
1. **Vocabulary Mapping:** Replace generic business terms in the user query with the EXACT column names found in the Schema Context.
   - Example: If user says "revenue" and context has "TOTAL_SALES_AMT", use "TOTAL_SALES_AMT".
   - Example: If user says "doctors" and context has "HCP_ID", use "HCP_ID".
2. **Filter Alignment:** Check 'sample_values' in the context.
   - Example: If user says "in NY", and sample values for 'STATE_CD' are 'New York', rewrite to "STATE_CD is 'New York'".
3. **Disambiguation:** If a term matches multiple columns, use the column descriptions to pick the most relevant one.
4. **Preservation:** Do not change the user's core intent (e.g., ranking, aggregation, filtering). Just swap the terminology.
5. **Output**: Return ONLY the rewritten natural language query string. Do not output SQL. Do not output JSON.
</rules>
</instruction>
"""

# ==========================================
# 4. HELPER FUNCTIONS
# ==========================================

def log_checkpoint(step: str, details: Any):
    print(f"\n{'='*50}\n CHECKPOINT: {step}\n{'-'*50}")
    if isinstance(details, BaseModel): pprint.pprint(details.model_dump())
    elif isinstance(details, (dict, list)): pprint.pprint(details)
    else: print(str(details))
    print(f"{'='*50}\n")

def invoke_cortex_agent(session: Session, payload: Dict, agent_name: str) -> Dict:
    """Invokes 'agent:run' for tools (Analyst/Diagnostic/Generic)."""
    ENDPOINT = "/api/v2/cortex/agent:run"
    print(f"--- INVOKING AGENT: {agent_name} ---")

    try:
        resp = _snowflake.send_snow_api_request("POST", ENDPOINT, {"Content-Type": "application/json", "Accept": "text/event-stream"}, {}, payload, {}, 120000)
        content = resp.get("content")
        # print(content) # Debugging raw stream
        if not content: return {"error": "Empty"}
        
        extracted = {"text": "", "tables": [], "charts": [], "sql_generated": None, "sql_explanation": None}
        try: parsed = json.loads(content)
        except: parsed = [json.loads(line) for line in content.splitlines() if line.strip()]
        
        def process_event(evt, data):
            if evt == 'response.text.delta': 
                extracted["text"] += data.get('text', '')
            elif evt == 'response.chart': 
                extracted["charts"].append(data.get('chart') or data.get('chart_spec'))
            elif evt == 'response.table':
                rs = data.get('result_set', [])
                extracted["tables"].append(rs) 
            elif evt == 'response.tool_result.analyst.delta':
                delta = data.get('delta', {})
                if delta.get('sql'): extracted["sql_generated"] = delta.get('sql')
                if delta.get('sql_explanation'): extracted["sql_explanation"] = delta.get('sql_explanation')
                if delta.get('result_set'): extracted["tables"].append(delta.get('result_set'))
            elif evt == 'response.tool_result':
                for item in data.get('content', []):
                    if item.get('type') == 'json':
                        json_p = item.get('json', {})
                        if 'sql' in json_p: extracted["sql_generated"] = json_p['sql']
                        if 'result_set' in json_p: extracted["tables"].append(json_p['result_set'])

        if isinstance(parsed, list):
            for item in parsed: process_event(item.get('event'), item.get('data', {}))
        
        print(f"--- AGENT {agent_name} COMPLETED ---")
        return extracted
    except Exception as e: return {"error": str(e)}

def extract_pydantic_from_text(text: str, model_class: type[BaseModel]) -> BaseModel:
    """
    Robustly finds JSON in text (Markdown blocks or raw) and parses it.
    Returns a default model instance on failure instead of raising exceptions.
    """
    if not text:
        return model_class() # Return default model

    def try_parse(json_str):
        try:
            return json.loads(json_str)
        except json.JSONDecodeError:
            try: return json.loads(json_str, strict=False)
            except: return None

    # Strategy 1: Find JSON code block ```json ... ```
    match = re.search(r'```json\s*(\{.*?\})\s*```', text, re.DOTALL)
    if match:
        data = try_parse(match.group(1))
        if data: return model_class(**data)

    # Strategy 2: Find raw outermost braces { ... }
    start = text.find('{')
    end = text.rfind('}')
    if start != -1 and end != -1 and end > start:
        candidate = text[start:end+1]
        data = try_parse(candidate)
        if data: return model_class(**data)
    
    # Special Handling: Rephraser might output raw text
    if model_class == RephraserOutput:
        print(f" JSON Parse Failed for Rephraser. Using raw text.")
        return RephraserOutput(refined_query=text.strip())

    print(f" JSON Parse Failed for {model_class.__name__}.")
    return model_class()

def check_input_guard(session: Session, user_input: str) -> GuardResult:
    log_checkpoint("START: GUARD", user_input)
    try:
        safe_input = user_input.replace("'", "''")
        res = session.sql(f"SELECT SNOWFLAKE.CORTEX.COMPLETE('{CONFIG.model}', [{{'role': 'user', 'content': '{safe_input}'}}], {{'guardrails': true}}) as r").collect()
        if not res: return GuardResult(is_safe=True)
        is_unsafe = "Response filtered" in json.loads(res[0]['R'])['choices'][0]['messages']
        print(is_unsafe)
        return GuardResult(is_safe=not is_unsafe, message="Blocked." if is_unsafe else None)
    except: return GuardResult(is_safe=True)

class PayloadFactory:
    @staticmethod
    def create(query: str, instructions: Any, tools: List = None, resources: Dict = None, history: List = None) -> Dict:
        messages = (history if history else []) + [{"role": "user", "content": [{"type": "text", "text": query}]}]
        inst_payload = instructions if isinstance(instructions, dict) else {"system": instructions}
        return {
            "messages": messages,
            "models": {"orchestration": CONFIG.model},
            "instructions": inst_payload,
            "tools": tools or [],
            "tool_resources": resources or {}
        }

def _save_row(session: Session, data: dict, table_name: str = "AGENT_DETAILED_HISTORY"):
    try:
        df = session.create_dataframe([data])
        df.create_or_replace_temp_view("TEMP_AGENT_LOG_STAGING")
        sql = f"""
        INSERT INTO {table_name} (
            USER_QUERY, REPHRASED_QUERY, INTENT_TYPE, INTENT_CONFIDENCE,
            DATA_SUMMARY, DATA_SQL, DATA_SQL_EXPLANATION, DATA_CLARIFICATION,
            DATA_EVAL_SCORE, DATA_EVAL_REASONING, 
            DATA_RESULT_SET, RC_SUMMARY, RC_GRAPH_JSON,
            RC_EVAL_SCORE, RC_EVAL_REASONING, IS_BLOCKED, FULL_RAW_JSON
        )
        SELECT 
            USER_QUERY, REPHRASED_QUERY, INTENT_TYPE, INTENT_CONFIDENCE,
            DATA_SUMMARY, DATA_SQL, DATA_SQL_EXPLANATION, DATA_CLARIFICATION,
            DATA_EVAL_SCORE, DATA_EVAL_REASONING, 
            PARSE_JSON(DATA_RESULT_SET), RC_SUMMARY, PARSE_JSON(RC_GRAPH_JSON),
            RC_EVAL_SCORE, RC_EVAL_REASONING, IS_BLOCKED, PARSE_JSON(FULL_RAW_JSON)
        FROM TEMP_AGENT_LOG_STAGING
        """
        session.sql(sql).collect()
        print(f" Row saved to {table_name}")
    except Exception as e: print(f" Save Error: {e}")

def get_cortex_completion(session: Session, prompt: str) -> str:
    try:
        safe_prompt = prompt.replace("'", "''")
        cmd = f"SELECT SNOWFLAKE.CORTEX.COMPLETE('{CONFIG.model}', '{safe_prompt}') as R"
        return session.sql(cmd).collect()[0]['R']
    except Exception as e: return ""

# ==========================================
# 5. SEMANTIC VIEW PARSER
# ==========================================

class SemanticViewParser:
    def __init__(self, session: Session, view_name: str):
        self.ca_json = {"tables": [], "relationships": []}
        self.table_comments = {} 
        self.column_metadata = defaultdict(lambda: defaultdict(dict)) 
        self.rel_metadata = defaultdict(dict) 
        if CONFIG.enable_semantic_parsing:
            self._fetch_and_parse(session, view_name)

    def _fetch_and_parse(self, session: Session, view_name: str):
        print(f" DESCRIBING SEMANTIC VIEW: {view_name}...")
        try:
            rows = session.sql(f"DESCRIBE SEMANTIC VIEW {view_name}").collect()
            data = [row.as_dict() for row in rows]
            
            ca_row = next((r for r in data if r.get('object_kind') == 'EXTENSION' and r.get('object_name') == 'CA'), None)
            if ca_row:
                try: self.ca_json = json.loads(ca_row['property_value'])
                except: pass

            for r in data:
                kind = r.get('object_kind')
                name = r.get('object_name')
                prop = r.get('property')
                val = r.get('property_value')
                
                if kind == 'TABLE' and prop == 'COMMENT':
                    self.table_comments[name.split('.')[-1]] = val
                elif kind in ['DIMENSION', 'FACT', 'COLUMN']:
                    t_name = r.get('parent_entity', '').split('.')[-1]
                    if t_name:
                        if prop == 'COMMENT': self.column_metadata[t_name][name]['description'] = val
                        elif prop == 'DATA_TYPE': self.column_metadata[t_name][name]['data_type'] = val
                elif kind == 'RELATIONSHIP':
                    if prop == 'TABLE': self.rel_metadata[name]['source_table'] = val.split('.')[-1]
                    elif prop == 'REF_TABLE': self.rel_metadata[name]['target_table'] = val.split('.')[-1]
                    elif prop == 'FOREIGN_KEY': self.rel_metadata[name]['keys'] = val

            print(f" Metadata Loaded: {len(self.ca_json.get('tables', []))} tables enriched.")
        except Exception as e:
            print(f" Metadata Parse Failed: {e}")

    def get_table_summaries(self) -> str:
        summary_list = []
        for t in self.ca_json.get('tables', []):
            t_name = t.get('name')
            desc = self.table_comments.get(t_name, "No description.")
            summary_list.append(f"- Table: {t_name}\n  Description: {desc}")
        return "\n".join(summary_list) if summary_list else ""

    def get_pruned_context(self, selected_tables: List[str]) -> str:
        pruned = {"tables": [], "relationships": []}
        for t in self.ca_json.get('tables', []):
            t_name = t['name']
            if t_name in selected_tables:
                table_copy = t.copy()
                table_copy['description'] = self.table_comments.get(t_name, "")
                for category in ['dimensions', 'facts', 'time_dimensions']:
                    if category in table_copy:
                        enriched_cols = []
                        for col in table_copy[category]:
                            col_copy = col.copy()
                            meta = self.column_metadata[t_name].get(col['name'], {})
                            if 'description' in meta: col_copy['description'] = meta['description']
                            if 'data_type' in meta: col_copy['data_type'] = meta['data_type']
                            enriched_cols.append(col_copy)
                        table_copy[category] = enriched_cols
                pruned['tables'].append(table_copy)
        
        if 'relationships' in self.ca_json:
            for rel in self.ca_json['relationships']:
                r_name = rel.get('name')
                source = self.rel_metadata.get(r_name, {}).get('source_table')
                if source in selected_tables:
                    pruned['relationships'].append(rel)
        return json.dumps(pruned, indent=2)

# ==========================================
# 6. AGENT MANAGER
# ==========================================

class AgentManager:
    def __init__(self, session: Session):
        self.session = session
        self.parser = SemanticViewParser(session, CONFIG.cortex_analyst_object_ards)

    def identify_needed_tables(self, query: str) -> List[str]:
        print(" IDENTIFYING RELEVANT TABLES...")
        if not self.parser.ca_json.get('tables'): return []
        summaries = self.parser.get_table_summaries()
        prompt = f"{PROMPT_TABLE_SELECTION}\n\nUser Query: {query}\n\nTable Summaries:\n{summaries}"
        res_text = get_cortex_completion(self.session, prompt)
        print(res_text)
        result = extract_pydantic_from_text(res_text, TableSelection)
        print(f" Selected: {result.relevant_table_names}")
        return result.relevant_table_names

    def run_semantic_translator(self, query: str, relevant_tables: List[str]) -> str:
        print(f" REWRITING QUERY...")
        pruned_json = self.parser.get_pruned_context(relevant_tables)
        print(pruned_json)
        prompt = f"{PROMPT_SEMANTIC_TRANSLATOR}\n\nSchema Context:\n{pruned_json}\n\nUser Query: {query}"
        return get_cortex_completion(self.session, prompt).strip()

    def run_rephraser(self, query: str, history: List[Dict]) -> RephraserOutput:
        inst = {
            "system": PROMPT_REPHRASER_SYSTEM,
            "orchestration": PROMPT_REPHRASER_ORCHESTRATION,
            "response": PROMPT_REPHRASER_RESPONSE
        }
        payload = PayloadFactory.create(query, inst, history=history)
        resp = invoke_cortex_agent(self.session, payload, "Rephraser Agent")
        return extract_pydantic_from_text(resp.get("text", ""), RephraserOutput)

    def run_intent_classifier(self, query: str) -> IntentClassification:
        inst = {
            "system": PROMPT_INTENT_SYSTEM, 
            "orchestration": PROMPT_INTENT_ORCHESTRATION,
            "response": PROMPT_INTENT_RESPONSE
        }
        payload = PayloadFactory.create(query, inst)
        resp = invoke_cortex_agent(self.session, payload, "Intent Agent")
        return extract_pydantic_from_text(resp.get("text", ""), IntentClassification)

    def run_data_agent(self, query: str, is_optimized: bool = False) -> SqlResult:
        # Select the correct Cortex Analyst object based on optimization flag
        target_view = CONFIG.cortex_analyst_object_ards if is_optimized else CONFIG.cortex_analyst_object_master
        
        tools = [{"tool_spec": {"type": "cortex_analyst_text_to_sql", "name": "analyst_tool"}}]
        res_def = {
            "analyst_tool": {
                "type": "cortex_analyst_text_to_sql",
                "semantic_view": target_view,
                "execution_environment": {"type": "warehouse", "warehouse": CONFIG.warehouse}
            }
        }
        inst = {
            "system": PROMPT_DATA_AGENT_SYSTEM, 
            "orchestration": PROMPT_DATA_AGENT_ORCHESTRATION,
            "response": PROMPT_DATA_AGENT_RESPONSE
        }
        payload = PayloadFactory.create(query, inst, tools, res_def)
        resp = invoke_cortex_agent(self.session, payload, "Data Agent" + (" (Optimized)" if is_optimized else ""))
        print(resp)
        raw_text = resp.get('text', '')
        parsed = extract_pydantic_from_text(raw_text, DataAgentParsedOutput)
        
        return SqlResult(
            answer_text=parsed.clean_answer_text,
            clarifying_question=parsed.clarifying_question,
            tables=resp.get('tables', []),
            sql_generated=resp.get('sql_generated'),
            sql_explanation=resp.get('sql_explanation'),
            evaluation=parsed.evaluation
        )

    def run_root_cause_agent(self, query: str) -> DiagnosticResult:
        tools = [{"tool_spec": {"type": "generic", "name": "Diagnostic_tool", "input_schema": {"type": "object", "properties": {"USER_QUERY": {"type": "string"}, "PARENT_NODE_IDS_JSON": {"type": "string"}, "TREE_ID": {"type": "string"}}, "required": ["USER_QUERY", "PARENT_NODE_IDS_JSON", "TREE_ID"]}}}]
        res_def = {"Diagnostic_tool": {"type": "procedure", "execution_environment": {"type": "warehouse", "warehouse": CONFIG.warehouse}, "identifier": CONFIG.diagnostic_udf}}
        
        inst = {
            "system": PROMPT_ROOT_CAUSE_SYSTEM, 
            "orchestration": PROMPT_ROOT_CAUSE_ORCHESTRATION,
            "response": PROMPT_ROOT_CAUSE_RESPONSE
        }
        payload = PayloadFactory.create(query, inst, tools, res_def)
        resp = invoke_cortex_agent(self.session, payload, "Root Cause Agent")
        
        raw_text = resp.get('text', '')
        parsed = extract_pydantic_from_text(raw_text, RootCauseParsedOutput)

        return DiagnosticResult(
            summary_text=parsed.clean_summary_text,
            react_flow_json=parsed.react_flow_json,
            evaluation=parsed.evaluation
        )

    def run_data_flow_orchestrator(self, query: str) -> SqlResult:
        """Handles standard execution vs optimized self-healing execution via parallelism."""
        
        # Helper to run optimization sequence
        def run_optimization_sequence():
            try:
                needed_tables = self.identify_needed_tables(query)
                if needed_tables:
                    optimized_q = self.run_semantic_translator(query, needed_tables)
                    print(f" Optimized Query: {optimized_q}")
                    return self.run_data_agent(optimized_q, is_optimized=True)
            except Exception as e:
                print(f"Optimization failed: {e}")
            return SqlResult(answer_text="Optimization Failed", evaluation=EvaluationResult(score=0))

        # Helper to run standard sequence
        def run_standard_sequence():
            return self.run_data_agent(query, is_optimized=False)

        # Execute Parallel
        print(" Starting Data Agent Flows (Standard & Optimized)...")
        with ThreadPoolExecutor(max_workers=2) as executor:
            future_std = executor.submit(run_standard_sequence)
            future_opt = executor.submit(run_optimization_sequence)
            res_std = future_std.result()
            res_opt = future_opt.result()

        # Decision Logic (Score & Fallback)
        final_res = res_std
        print(f" Standard Score: {res_std.evaluation.score} | Optimized Score: {res_opt.evaluation.score}")
        
        # If standard is high quality, keep it
        if res_std.evaluation.score >= 8:
            pass
            
        # If BOTH are low OR scores are equal (and >0), combine insights
        elif (res_std.evaluation.score < 8 and res_opt.evaluation.score < 8) or \
             (res_std.evaluation.score == res_opt.evaluation.score and res_std.evaluation.score > 0):
             
             print(" Scores Low/Equal. Combining Summaries.")
             base = res_opt if res_opt.evaluation.score > 0 else res_std
             
             combined_text = (
                 f"**Standard Analysis:**\n{res_std.answer_text}\n\n"
                 f"**Deep Context Analysis:**\n{res_opt.answer_text}"
             )
             
             final_res = SqlResult(
                 answer_text=combined_text,
                 tables=base.tables,
                 charts=base.charts,
                 sql_generated=base.sql_generated, 
                 sql_explanation=base.sql_explanation,
                 evaluation=base.evaluation,
                 is_retry=True
             )

        # If Optimized is strictly better, use it
        elif res_opt.evaluation.score > res_std.evaluation.score:
            print(f" Switched to Optimized Result (Score: {res_opt.evaluation.score})")
            final_res = res_opt
            final_res.is_retry = True
            
        return final_res

# ==========================================
# 7. MAIN EXECUTION (PARALLEL LOGIC)
# ==========================================

def main(session: Session):
    manager = AgentManager(session)
    user_query = "Show me the top 10 healthcare providers by acute transaction exposure, including their specialty and location."
    
    row_data = {
        "USER_QUERY": user_query, "REPHRASED_QUERY": None, "INTENT_TYPE": None, "INTENT_CONFIDENCE": None,
        "DATA_SUMMARY": None, "DATA_SQL": None, "DATA_SQL_EXPLANATION": None, "DATA_CLARIFICATION": None,
        "DATA_RESULT_SET": None, "DATA_EVAL_SCORE": None, "DATA_EVAL_REASONING": None,
        "RC_SUMMARY": None, "RC_GRAPH_JSON": None, "RC_EVAL_SCORE": None, "RC_EVAL_REASONING": None,
        "IS_BLOCKED": False, "FULL_RAW_JSON": None
    }
    
    log_checkpoint("MAIN: START", {"query": user_query})

    guard = check_input_guard(session, user_query)
    if not guard.is_safe:
        row_data["IS_BLOCKED"] = True
        _save_row(session, row_data)
        return {"status": "blocked", "message": guard.message}

    rephrased = manager.run_rephraser(user_query, [])
    intent = manager.run_intent_classifier(rephrased.refined_query or user_query)
    
    row_data["REPHRASED_QUERY"] = rephrased.refined_query
    row_data["INTENT_TYPE"] = intent.intent_type
    row_data["INTENT_CONFIDENCE"] = intent.confidence

    final_output = {"original": user_query, "processed": rephrased.refined_query, "intent": intent.model_dump(), "results": []}

    if intent.direct_response:
        final_output["results"].append({"type": "direct", "message": intent.direct_response})
    else:
        futures = {}
        # Launch Data and Root Cause Flows in PARALLEL if intent allows
        with ThreadPoolExecutor(max_workers=2) as executor:
            
            # 1. Data Agent Flow (Standard vs Optimized inside orchestrator)
            if intent.intent_type in ["data_retrieval", "combined"] and intent.data_retrieval_query:
                q = intent.data_retrieval_query
                futures["data"] = executor.submit(manager.run_data_flow_orchestrator, q)
            
            # 2. Root Cause Flow
            if intent.intent_type in ["root_cause_analysis", "combined"] and intent.root_cause_query:
                q = intent.root_cause_query or rephrased.refined_query
                futures["rc"] = executor.submit(manager.run_root_cause_agent, q)

        # Collect Results
        if "data" in futures:
            res = futures["data"].result()
            final_output["results"].append({"type": "data_analysis", "summary": res.answer_text, "tables": res.tables})
            row_data["DATA_SUMMARY"] = res.answer_text
            row_data["DATA_SQL"] = res.sql_generated
            row_data["DATA_SQL_EXPLANATION"] = res.sql_explanation
            if res.tables: row_data["DATA_RESULT_SET"] = json.dumps(res.tables)
            row_data["DATA_EVAL_SCORE"] = res.evaluation.score
            row_data["DATA_EVAL_REASONING"] = res.evaluation.reasoning

        if "rc" in futures:
            res_rc = futures["rc"].result()
            final_output["results"].append({"type": "root_cause", "summary": res_rc.summary_text, "graph": res_rc.react_flow_json})
            row_data["RC_SUMMARY"] = res_rc.summary_text
            if res_rc.react_flow_json: row_data["RC_GRAPH_JSON"] = json.dumps(res_rc.react_flow_json)
            row_data["RC_EVAL_SCORE"] = res_rc.evaluation.score
            row_data["RC_EVAL_REASONING"] = res_rc.evaluation.reasoning

    row_data["FULL_RAW_JSON"] = json.dumps(final_output)
    _save_row(session, row_data)
    print(" Process Completed")
    return final_output



--- INVOKING AGENT: Rephraser Agent ---
--- INVOKING AGENT: Intent Agent ---
 Starting Data Agent Flows (Standard & Optimized)...
--- INVOKING AGENT: Data Agent ---
 IDENTIFYING RELEVANT TABLES...
 DESCRIBING SEMANTIC VIEW: DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.AI_POC.MASTERTABLE_V1...
 Metadata Loaded from DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.AI_POC.MASTERTABLE_V1
 Selected: ['MASTER_TABLE_V1']
 REWRITING QUERY...
 Optimized Query: Top 10 HCO_NAME in Arizona ranked by size, quality ratings, or market presence
--- INVOKING AGENT: Data Agent (Optimized) ---
 Standard Score: 0 | Optimized Score: 0
 Scores Low/Equal. Combining Summaries.
 Save Message Failed: (1304): 01c20280-081a-368c-0075-0383fdb1d8da: 000904 (42000): 01c20280-081a-368c-0075-0383fdb1d8da: SQL compilation error: error line 1 at position 71
invalid identifier 'SESSION_ID'
 Audit Log Error: (1304): 01c20280-081a-368c-0075-0383fdb1d8f2: 002020 (21S01): 01c20280-081a-368c-0075-0383fdb1d8f2: SQL compilation error:
Insert value list does not match column list expecting 19 but got 9
 Process Completed



 Standard Score: 0 | Optimized Score: 9
 Switched to Optimized Result (Score: 9)
/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/pydantic/main.py:364: UserWarning: Pydantic serializer warnings:
  Expected `dict[any, any]` but got `str` - serialized value may not be as expected
  Expected `dict[any, any]` but got `str` - serialized value may not be as expected
  return self.__pydantic_serializer__.to_python(
 Audit Log Error: (1304): 01c202c1-081a-386d-0075-0383fdb88492: 002023 (22000): 01c202c1-081a-386d-0075-0383fdb88492: SQL compilation error:
Expression type does not match column data type, expecting VARIANT but got VARCHAR(134217728) for column FULL_RAW_JSON
 Process Completed



create or replace TABLE DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.AI_POC.MESSAGES (
	ID VARCHAR(16777216) DEFAULT UUID_STRING(),
	CONVERSATION_ID VARCHAR(16777216) NOT NULL,
	SOURCE_MSG_ID VARCHAR(16777216),
	MESSAGE VARCHAR(16777216) NOT NULL,
	SENDER_TYPE VARCHAR(16777216) NOT NULL,
	METADATA VARIANT,
	FEEDBACK_REACTION VARCHAR(16777216),
	CREATED_BY VARCHAR(16777216),
	UPDATED_BY VARCHAR(16777216),
	CREATED_AT TIMESTAMP_LTZ(9) DEFAULT CURRENT_TIMESTAMP(),
	UPDATED_AT TIMESTAMP_LTZ(9) DEFAULT CURRENT_TIMESTAMP()
);


  total_acute_trx_laad DESC NULLS LAST
LIMIT 10
 -- Generated by Cortex Analyst (request_id: fdecde98-305b-4296-b7d3-a8ef3e680e95)
;", "is_blocked": false, "tool_artifacts": [{"type": "data_analysis", "summary": "The top 10 HCP_IDs ranked by ACUTE_TRX_LAAD over the last 12 months are displayed in the horizontal bar chart. The leading healthcare provider (HCP_ID: 9d2874e648c48c41632a3fc164312154) has 83,397 total acute transactions, significantly higher than the second-ranked provider at 8,674. The remaining providers range from approximately 4,600 to 6,500 total acute transactions.", "tables": [{"data": [["9d2874e648c48c41632a3fc164312154", "83397", "2025-01-31", "2025-10-03", "36547", "36"], ["426309c0bc85c6be8c65f5187f4cdb18", "8674", "2025-01-31", "2025-10-03", "3883", "36"], ["07ab7d8e415c68a6c2d059355ed73e40", "6463", "2025-01-31", "2025-10-03", "2632", "36"], ["c0a44a68867ddebaec6f9880a2a2ef86", "6199", "2025-01-31", "2025-10-03", "3027", "36"], ["a253e32cfed3c7ff87e3c601a239f2eb", "5641", "2025-01-31", "2025-10-03", "2282", "36"], ["6bb64dc65baa5bec6d7296e182a311cd", "5102", "2025-01-31", "2025-10-03", "1153", "36"], ["377d582b8f1147bce1207d064e8fcea7", "4965", "2025-01-31", "2025-10-03", "2259", "36"], ["9d8e38c37799e25b19085f735e472609", "4639", "2025-01-31", "2025-10-03", "258", "36"], ["45b1c3472aa95dbbafaf594e5b8c3e28", "4600", "2025-01-31", "2025-10-03", "2690", "36"], ["9802c4d4a790ef2df205802da6cf5a65", "4592", "2025-01-31", "2025-10-03", "2456", "36"]], "resultSetMetaData": {"format": "jsonv2", "numRows": 10, "partition": 0, "partitionInfo": [{"rowCount": 10, "uncompressedSize": 840}], "rowType": [{"length": 32, "name": "HCP_ID", "nullable": false, "precision": 0, "scale": 0, "type": "text"}, {"length": 0, "name": "TOTAL_ACUTE_TRX_LAAD", "nullable": true, "precision": 30, "scale": 0, "type": "fixed"}, {"length": 0, "name": "MIN_DATE", "nullable": true, "precision": 0, "scale": 0, "type": "date"}, {"length": 0, "name": "MAX_DATE", "nullable": true, "precision": 0, "scale": 0, "type": "date"}, {"length": 0, "name": "RECORD_COUNT", "nullable": false, "precision": 18, "scale": 0, "type": "fixed"}, {"length": 0, "name": "UNIQUE_WEEKS", "nullable": false, "precision": 18, "scale": 0, "type": "fixed"}]}, "statementHandle": "01c202da-081a-3bd5-0075-0383fdbca112"}], "charts": ["{"$schema": "https://vega.github.io/schema/vega-lite/v5.json", "title": "Top 10 HCP_ID ranked by TOTAL_ACUTE_TRX_LAAD", "transform": [{"window": [{"op": "rank", "as": "rank"}], "sort": [{"field": "TOTAL_ACUTE_TRX_LAAD", "order": "descending"}]}, {"filter": "datum.rank <= 10"}], "mark": "bar", "encoding": {"x": {"field": "TOTAL_ACUTE_TRX_LAAD", "title": "Total Acute TRX LAAD", "type": "quantitative", "sort": null, "axis": {"format": ".3~s", "labelExpr": "replace(datum.label, ''G'', ''B'')"}}, "y": {"field": "HCP_ID", "title": "HCP ID", "type": "nominal", "sort": null}, "tooltip": [{"field": "TOTAL_ACUTE_TRX_LAAD", "type": "quantitative", "title": "Total Acute TRX LAAD", "format": ",.6~f"}, {"field": "HCP_ID", "type": "nominal", "title": "HCP ID"}]}, "data": {"values": [{"HCP_ID": "9d2874e648c48c41632a3fc164312154", "TOTAL_ACUTE_TRX_LAAD": 83397.0}, {"HCP_ID": "426309c0bc85c6be8c65f5187f4cdb18", "TOTAL_ACUTE_TRX_LAAD": 8674.0}, {"HCP_ID": "07ab7d8e415c68a6c2d059355ed73e40", "TOTAL_ACUTE_TRX_LAAD": 6463.0}, {"HCP_ID": "c0a44a68867ddebaec6f9880a2a2ef86", "TOTAL_ACUTE_TRX_LAAD": 6199.0}, {"HCP_ID": "a253e32cfed3c7ff87e3c601a239f2eb", "TOTAL_ACUTE_TRX_LAAD": 5641.0}, {"HCP_ID": "6bb64dc65baa5bec6d7296e182a311cd", "TOTAL_ACUTE_TRX_LAAD": 5102.0}, {"HCP_ID": "377d582b8f1147bce1207d064e8fcea7", "TOTAL_ACUTE_TRX_LAAD": 4965.0}, {"HCP_ID": "9d8e38c37799e25b19085f735e472609", "TOTAL_ACUTE_TRX_LAAD": 4639.0}, {"HCP_ID": "45b1c3472aa95dbbafaf594e5b8c3e28", "TOTAL_ACUTE_TRX_LAAD": 4600.0}, {"HCP_ID": "9802c4d4a790ef2df205802da6cf5a65", "TOTAL_ACUTE_TRX_LAAD": 4592.0}]}}", "{"$schema": "https://vega.github.io/schema/vega-lite/v5.json", "title": "Top 10 HCP_ID ranked by TOTAL_ACUTE_TRX_LAAD", "transform": [{"window": [{"op": "rank", "as": "rank"}], "sort": [{"field": "TOTAL_ACUTE_TRX_LAAD", "order": "descending"}]}, {"filter": "datum.rank <= 10"}], "mark": "bar", "encoding": {"x": {"field": "TOTAL_ACUTE_TRX_LAAD", "title": "Total Acute TRX LAAD", "type": "quantitative", "sort": null, "axis": {"format": ".3~s", "labelExpr": "replace(datum.label, ''G'', ''B'')"}}, "y": {"field": "HCP_ID", "title": "HCP ID", "type": "nominal", "sort": null}, "tooltip": [{"field": "TOTAL_ACUTE_TRX_LAAD", "type": "quantitative", "title": "Total Acute TRX LAAD", "format": ",.6~f"}, {"field": "HCP_ID", "type": "nominal", "title": "HCP ID"}]}, "data": {"values": [{"HCP_ID": "9d2874e648c48c41632a3fc164312154", "TOTAL_ACUTE_TRX_LAAD": 83397.0}, {"HCP_ID": "426309c0bc85c6be8c65f5187f4cdb18", "TOTAL_ACUTE_TRX_LAAD": 8674.0}, {"HCP_ID": "07ab7d8e415c68a6c2d059355ed73e40", "TOTAL_ACUTE_TRX_LAAD": 6463.0}, {"HCP_ID": "c0a44a68867ddebaec6f9880a2a2ef86", "TOTAL_ACUTE_TRX_LAAD": 6199.0}, {"HCP_ID": "a253e32cfed3c7ff87e3c601a239f2eb", "TOTAL_ACUTE_TRX_LAAD": 5641.0}, {"HCP_ID": "6bb64dc65baa5bec6d7296e182a311cd", "TOTAL_ACUTE_TRX_LAAD": 5102.0}, {"HCP_ID": "377d582b8f1147bce1207d064e8fcea7", "TOTAL_ACUTE_TRX_LAAD": 4965.0}, {"HCP_ID": "9d8e38c37799e25b19085f735e472609", "TOTAL_ACUTE_TRX_LAAD": 4639.0}, {"HCP_ID": "45b1c3472aa95dbbafaf594e5b8c3e28", "TOTAL_ACUTE_TRX_LAAD": 4600.0}, {"HCP_ID": "9802c4d4a790ef2df205802da6cf5a65", "TOTAL_ACUTE_TRX_LAAD": 4592.0}]}}"], "full_pydantic_object": {"clean_answer_text": "The top 10 HCP_IDs ranked by ACUTE_TRX_LAAD over the last 12 months are displayed in the horizontal bar chart. The leading healthcare provider (HCP_ID: 9d2874e648c48c41632a3fc164312154) has 83,397 total acute transactions, significantly higher than the second-ranked provider at 8,674. The remaining providers range from approximately 4,600 to 6,500 total acute transactions.", "clarifying_question": null, "tables": [{"data": [["9d2874e648c48c41632a3fc164312154", "83397", "2025-01-31", "2025-10-03", "36547", "36"], ["426309c0bc85c6be8c65f5187f4cdb18", "8674", "2025-01-31", "2025-10-03", "3883", "36"], ["07ab7d8e415c68a6c2d059355ed73e40", "6463", "2025-01-31", "2025-10-03", "2632", "36"], ["c0a44a68867ddebaec6f9880a2a2ef86", "6199", "2025-01-31", "2025-10-03", "3027", "36"], ["a253e32cfed3c7ff87e3c601a239f2eb", "5641", "2025-01-31", "2025-10-03", "2282", "36"], ["6bb64dc65baa5bec6d7296e182a311cd", "5102", "2025-01-31", "2025-10-03", "1153", "36"], ["377d582b8f1147bce1207d064e8fcea7", "4965", "2025-01-31", "2025-10-03", "2259", "36"], ["9d8e38c37799e25b19085f735e472609", "4639", "2025-01-31", "2025-10-03", "258", "36"], ["45b1c3472aa95dbbafaf594e5b8c3e28", "4600", "2025-01-31", "2025-10-03", "2690", "36"], ["9802c4d4a790ef2df205802da6cf5a65", "4592", "2025-01-31", "2025-10-03", "2456", "36"]], "resultSetMetaData": {"format": "jsonv2", "numRows": 10, "partition": 0, "partitionInfo": [{"rowCount": 10, "uncompressedSize": 840}], "rowType": [{"length": 32, "name": "HCP_ID", "nullable": false, "precision": 0, "scale": 0, "type": "text"}, {"length": 0, "name": "TOTAL_ACUTE_TRX_LAAD", "nullable": true, "precision": 30, "scale": 0, "type": "fixed"}, {"length": 0, "name": "MIN_DATE", "nullable": true, "precision": 0, "scale": 0, "type": "date"}, {"length": 0, "name": "MAX_DATE", "nullable": true, "precision": 0, "scale": 0, "type": "date"}, {"length": 0, "name": "RECORD_COUNT", "nullable": false, "precision": 18, "scale": 0, "type": "fixed"}, {"length": 0, "name": "UNIQUE_WEEKS", "nullable": false, "precision": 18, "scale": 0, "type": "fixed"}]}, "statementHandle": "01c202da-081a-3bd5-0075-0383fdbca112"}], "charts": ["{"$schema": "https://vega.github.io/schema/vega-lite/v5.json", "title": "Top 10 HCP_ID ranked by TOTAL_ACUTE_TRX_LAAD", "transform": [{"window": [{"op": "rank", "as": "rank"}], "sort": [{"field": "TOTAL_ACUTE_TRX_LAAD", "order": "descending"}]}, {"filter": "datum.rank <= 10"}], "mark": "bar", "encoding": {"x": {"field": "TOTAL_ACUTE_TRX_LAAD", "title": "Total Acute TRX LAAD", "type": "quantitative", "sort": null, "axis": {"format": ".3~s", "labelExpr": "replace(datum.label, ''G'', ''B'')"}}, "y": {"field": "HCP_ID", "title": "HCP ID", "type": "nominal", "sort": null}, "tooltip": [{"field": "TOTAL_ACUTE_TRX_LAAD", "type": "quantitative", "title": "Total Acute TRX LAAD", "format": ",.6~f"}, {"field": "HCP_ID", "type": "nominal", "title": "HCP ID"}]}, "data": {"values": [{"HCP_ID": "9d2874e648c48c41632a3fc164312154", "TOTAL_ACUTE_TRX_LAAD": 83397.0}, {"HCP_ID": "426309c0bc85c6be8c65f5187f4cdb18", "TOTAL_ACUTE_TRX_LAAD": 8674.0}, {"HCP_ID": "07ab7d8e415c68a6c2d059355ed73e40", "TOTAL_ACUTE_TRX_LAAD": 6463.0}, {"HCP_ID": "c0a44a68867ddebaec6f9880a2a2ef86", "TOTAL_ACUTE_TRX_LAAD": 6199.0}, {"HCP_ID": "a253e32cfed3c7ff87e3c601a239f2eb", "TOTAL_ACUTE_TRX_LAAD": 5641.0}, {"HCP_ID": "6bb64dc65baa5bec6d7296e182a311cd", "TOTAL_ACUTE_TRX_LAAD": 5102.0}, {"HCP_ID": "377d582b8f1147bce1207d064e8fcea7", "TOTAL_ACUTE_TRX_LAAD": 4965.0}, {"HCP_ID": "9d8e38c37799e25b19085f735e472609", "TOTAL_ACUTE_TRX_LAAD": 4639.0}, {"HCP_ID": "45b1c3472aa95dbbafaf594e5b8c3e28", "TOTAL_ACUTE_TRX_LAAD": 4600.0}, {"HCP_ID": "9802c4d4a790ef2df205802da6cf5a65", "TOTAL_ACUTE_TRX_LAAD": 4592.0}]}}", "{"$schema": "https://vega.github.io/schema/vega-lite/v5.json", "title": "Top 10 HCP_ID ranked by TOTAL_ACUTE_TRX_LAAD", "transform": [{"window": [{"op": "rank", "as": "rank"}], "sort": [{"field": "TOTAL_ACUTE_TRX_LAAD", "order": "descending"}]}, {"filter": "datum.rank <= 10"}], "mark": "bar", "encoding": {"x": {"field": "TOTAL_ACUTE_TRX_LAAD", "title": "Total Acute TRX LAAD", "type": "quantitative", "sort": null, "axis": {"format": ".3~s", "labelExpr": "replace(datum.label, ''G'', ''B'')"}}, "y": {"field": "HCP_ID", "title": "HCP ID", "type": "nominal", "sort": null}, "tooltip": [{"field": "TOTAL_ACUTE_TRX_LAAD", "type": "quantitative", "title": "Total Acute TRX LAAD", "format": ",.6~f"}, {"field": "HCP_ID", "type": "nominal", "title": "HCP ID"}]}, "data": {"values": [{"HCP_ID": "9d2874e648c48c41632a3fc164312154", "TOTAL_ACUTE_TRX_LAAD": 83397.0}, {"HCP_ID": "426309c0bc85c6be8c65f5187f4cdb18", "TOTAL_ACUTE_TRX_LAAD": 8674.0}, {"HCP_ID": "07ab7d8e415c68a6c2d059355ed73e40", "TOTAL_ACUTE_TRX_LAAD": 6463.0}, {"HCP_ID": "c0a44a68867ddebaec6f9880a2a2ef86", "TOTAL_ACUTE_TRX_LAAD": 6199.0}, {"HCP_ID": "a253e32cfed3c7ff87e3c601a239f2eb", "TOTAL_ACUTE_TRX_LAAD": 5641.0}, {"HCP_ID": "6bb64dc65baa5bec6d7296e182a311cd", "TOTAL_ACUTE_TRX_LAAD": 5102.0}, {"HCP_ID": "377d582b8f1147bce1207d064e8fcea7", "TOTAL_ACUTE_TRX_LAAD": 4965.0}, {"HCP_ID": "9d8e38c37799e25b19085f735e472609", "TOTAL_ACUTE_TRX_LAAD": 4639.0}, {"HCP_ID": "45b1c3472aa95dbbafaf594e5b8c3e28", "TOTAL_ACUTE_TRX_LAAD": 4600.0}, {"HCP_ID": "9802c4d4a790ef2df205802da6cf5a65", "TOTAL_ACUTE_TRX_LAAD": 4592.0}]}}"], "sql_generated": "WITH __ard_giaco_tm_hcp_acute_mkt_weekly_laad AS (
  SELECT
    hcp_id,
    date_key,
    acute_trx_laad
  FROM DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.REPORTING.ARD_GIACO_TM_HCP_ACUTE_MKT_WEEKLY_LAAD
)
SELECT
  laad.hcp_id,
  SUM(laad.acute_trx_laad) AS total_acute_trx_laad,
  MIN(laad.date_key) AS min_date,
  MAX(laad.date_key) AS max_date,
  COUNT(laad.date_key) AS record_count,
  COUNT(DISTINCT laad.date_key) AS unique_weeks
FROM __ard_giaco_tm_hcp_acute_mkt_weekly_laad AS laad
WHERE
  laad.date_key <= CURRENT_DATE
  AND laad.date_key >= DATEADD(MONTH, -12, CURRENT_DATE)
GROUP BY
  laad.hcp_id
ORDER BY
  total_acute_trx_laad DESC NULLS LAST
LIMIT 10
 -- Generated by Cortex Analyst (request_id: fdecde98-305b-4296-b7d3-a8ef3e680e95)
;", "sql_explanation": null, "is_verified_query": false, "evaluation": {"score": 9, "reasoning": "Successfully generated the requested horizontal bar chart showing top 10 HCP_IDs by ACUTE_TRX_LAAD. The SQL correctly aggregated data over 12 months and the visualization matches the user''s request."}, "is_retry": true}}], "generated_at": "2026-01-27T12:11:13.167617"}')] in VALUES clause
 Audit Log Error: (1304): 01c202db-081a-3bd5-0075-0383fdbca646: 002023 (22000): 01c202db-081a-3bd5-0075-0383fdbca646: SQL compilation error:
Expression type does not match column data type, expecting VARIANT but got VARCHAR(134217728) for column FULL_RAW_JSON
 Process Completed



==================================================
 CHECKPOINT: MAIN: START
--------------------------------------------------
{'query': 'give me the top 10 prescribers from arizona', 'session': '1111'}
==================================================
 Retrieved 5 past messages for Session 1111
 Saved user message to history.
--- INVOKING AGENT: Rephraser Agent ---
--- INVOKING AGENT: Intent Agent ---
 Starting Data Agent Flows (Standard & Optimized)...
--- INVOKING AGENT: Data Agent ---
 IDENTIFYING RELEVANT TABLES...
 DESCRIBING SEMANTIC VIEW: DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.AI_POC.MASTERTABLE_V1...
 Metadata Loaded from DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.AI_POC.MASTERTABLE_V1
 Selected: ['MASTER_TABLE_V1']
 REWRITING QUERY...
 Optimized Query: Show the top 10 HCP_ID ranked by ACUTE_TRX_LAAD_12M with appropriate visualization
--- INVOKING AGENT: Data Agent (Optimized) ---
['{"$schema": "https://vega.github.io/schema/vega-lite/v5.json", "title": "Top 10 HCP_ID ranked by TOTAL_ACUTE_TRX_LAAD_12M", "transform": [{"window": [{"op": "rank", "as": "rank"}], "sort": [{"field": "TOTAL_ACUTE_TRX_LAAD_12M", "order": "descending"}]}, {"filter": "datum.rank <= 10"}], "mark": "bar", "encoding": {"x": {"field": "TOTAL_ACUTE_TRX_LAAD_12M", "title": "Total Acute TRX LAAD 12M", "type": "quantitative", "sort": null, "axis": {"format": ".3~s", "labelExpr": "replace(datum.label, \'G\', \'B\')"}}, "y": {"field": "HCP_ID", "title": "HCP ID", "type": "nominal", "sort": null}, "tooltip": [{"field": "TOTAL_ACUTE_TRX_LAAD_12M", "type": "quantitative", "title": "Total Acute TRX LAAD 12M", "format": ",.6~f"}, {"field": "HCP_ID", "type": "nominal", "title": "HCP ID"}]}, "data": {"values": [{"HCP_ID": "9d2874e648c48c41632a3fc164312154", "TOTAL_ACUTE_TRX_LAAD_12M": 128543.0}, {"HCP_ID": "426309c0bc85c6be8c65f5187f4cdb18", "TOTAL_ACUTE_TRX_LAAD_12M": 13003.0}, {"HCP_ID": "07ab7d8e415c68a6c2d059355ed73e40", "TOTAL_ACUTE_TRX_LAAD_12M": 9767.0}, {"HCP_ID": "a253e32cfed3c7ff87e3c601a239f2eb", "TOTAL_ACUTE_TRX_LAAD_12M": 7948.0}, {"HCP_ID": "377d582b8f1147bce1207d064e8fcea7", "TOTAL_ACUTE_TRX_LAAD_12M": 7751.0}, {"HCP_ID": "177a01e25b7907f644de400909faa674", "TOTAL_ACUTE_TRX_LAAD_12M": 7574.0}, {"HCP_ID": "c0a44a68867ddebaec6f9880a2a2ef86", "TOTAL_ACUTE_TRX_LAAD_12M": 7548.0}, {"HCP_ID": "9802c4d4a790ef2df205802da6cf5a65", "TOTAL_ACUTE_TRX_LAAD_12M": 6951.0}, {"HCP_ID": "6bb64dc65baa5bec6d7296e182a311cd", "TOTAL_ACUTE_TRX_LAAD_12M": 6949.0}, {"HCP_ID": "9d8e38c37799e25b19085f735e472609", "TOTAL_ACUTE_TRX_LAAD_12M": 6752.0}]}}']
['{"$schema": "https://vega.github.io/schema/vega-lite/v5.json", "title": "Top 10 HCP_ID ranked by TOTAL_ACUTE_TRX_LAAD_12M", "transform": [{"window": [{"op": "rank", "as": "rank"}], "sort": [{"field": "TOTAL_ACUTE_TRX_LAAD_12M", "order": "descending"}]}, {"filter": "datum.rank <= 10"}], "mark": "bar", "encoding": {"x": {"field": "TOTAL_ACUTE_TRX_LAAD_12M", "title": "Total Acute TRX LAAD 12M", "type": "quantitative", "sort": null, "axis": {"format": ".3~s", "labelExpr": "replace(datum.label, \'G\', \'B\')"}}, "y": {"field": "HCP_ID", "title": "HCP ID", "type": "nominal", "sort": null}, "tooltip": [{"field": "TOTAL_ACUTE_TRX_LAAD_12M", "type": "quantitative", "title": "Total Acute TRX LAAD 12M", "format": ",.6~f"}, {"field": "HCP_ID", "type": "nominal", "title": "HCP ID"}]}, "data": {"values": [{"HCP_ID": "9d2874e648c48c41632a3fc164312154", "TOTAL_ACUTE_TRX_LAAD_12M": 128543.0}, {"HCP_ID": "426309c0bc85c6be8c65f5187f4cdb18", "TOTAL_ACUTE_TRX_LAAD_12M": 13003.0}, {"HCP_ID": "07ab7d8e415c68a6c2d059355ed73e40", "TOTAL_ACUTE_TRX_LAAD_12M": 9767.0}, {"HCP_ID": "a253e32cfed3c7ff87e3c601a239f2eb", "TOTAL_ACUTE_TRX_LAAD_12M": 7948.0}, {"HCP_ID": "377d582b8f1147bce1207d064e8fcea7", "TOTAL_ACUTE_TRX_LAAD_12M": 7751.0}, {"HCP_ID": "177a01e25b7907f644de400909faa674", "TOTAL_ACUTE_TRX_LAAD_12M": 7574.0}, {"HCP_ID": "c0a44a68867ddebaec6f9880a2a2ef86", "TOTAL_ACUTE_TRX_LAAD_12M": 7548.0}, {"HCP_ID": "9802c4d4a790ef2df205802da6cf5a65", "TOTAL_ACUTE_TRX_LAAD_12M": 6951.0}, {"HCP_ID": "6bb64dc65baa5bec6d7296e182a311cd", "TOTAL_ACUTE_TRX_LAAD_12M": 6949.0}, {"HCP_ID": "9d8e38c37799e25b19085f735e472609", "TOTAL_ACUTE_TRX_LAAD_12M": 6752.0}]}}', '{"$schema": "https://vega.github.io/schema/vega-lite/v5.json", "title": "Top 10 HCP_ID ranked by TOTAL_ACUTE_TRX_LAAD_12M", "transform": [{"window": [{"op": "rank", "as": "rank"}], "sort": [{"field": "TOTAL_ACUTE_TRX_LAAD_12M", "order": "descending"}]}, {"filter": "datum.rank <= 10"}], "mark": "bar", "encoding": {"x": {"field": "TOTAL_ACUTE_TRX_LAAD_12M", "title": "Total Acute TRX LAAD 12M", "type": "quantitative", "sort": null, "axis": {"format": ".3~s", "labelExpr": "replace(datum.label, \'G\', \'B\')"}}, "y": {"field": "HCP_ID", "title": "HCP ID", "type": "nominal", "sort": null}, "tooltip": [{"field": "TOTAL_ACUTE_TRX_LAAD_12M", "type": "quantitative", "title": "Total Acute TRX LAAD 12M", "format": ",.6~f"}, {"field": "HCP_ID", "type": "nominal", "title": "HCP ID"}]}, "data": {"values": [{"HCP_ID": "9d2874e648c48c41632a3fc164312154", "TOTAL_ACUTE_TRX_LAAD_12M": 128543.0}, {"HCP_ID": "426309c0bc85c6be8c65f5187f4cdb18", "TOTAL_ACUTE_TRX_LAAD_12M": 13003.0}, {"HCP_ID": "07ab7d8e415c68a6c2d059355ed73e40", "TOTAL_ACUTE_TRX_LAAD_12M": 9767.0}, {"HCP_ID": "a253e32cfed3c7ff87e3c601a239f2eb", "TOTAL_ACUTE_TRX_LAAD_12M": 7948.0}, {"HCP_ID": "377d582b8f1147bce1207d064e8fcea7", "TOTAL_ACUTE_TRX_LAAD_12M": 7751.0}, {"HCP_ID": "177a01e25b7907f644de400909faa674", "TOTAL_ACUTE_TRX_LAAD_12M": 7574.0}, {"HCP_ID": "c0a44a68867ddebaec6f9880a2a2ef86", "TOTAL_ACUTE_TRX_LAAD_12M": 7548.0}, {"HCP_ID": "9802c4d4a790ef2df205802da6cf5a65", "TOTAL_ACUTE_TRX_LAAD_12M": 6951.0}, {"HCP_ID": "6bb64dc65baa5bec6d7296e182a311cd", "TOTAL_ACUTE_TRX_LAAD_12M": 6949.0}, {"HCP_ID": "9d8e38c37799e25b19085f735e472609", "TOTAL_ACUTE_TRX_LAAD_12M": 6752.0}]}}']
 Standard Score: 7 | Optimized Score: 9
 Switched to Optimized Result (Score: 9)
/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/pydantic/main.py:364: UserWarning: Pydantic serializer warnings:
  Expected `dict[any, any]` but got `str` - serialized value may not be as expected
  Expected `dict[any, any]` but got `str` - serialized value may not be as expected
  return self.__pydantic_serializer__.to_python(
 Save Message Failed: (1304): 01c202e7-081a-3d3b-0075-0383fdbedc56: 002014 (22000): 01c202e7-081a-3d3b-0075-0383fdbedc56: SQL compilation error:
Invalid expression [PARSE_JSON('{"intent_data": {"intent_type": "data_retrieval", "data_retrieval_query": "Show the top 10 healthcare prescribers in Arizona ranked by prescription volume with appropriate visualization", "root_cause_query": null, "direct_response": null, "clarification_question": null, "confidence": "high", "reasoning": "User explicitly requested to show top 10 prescribers with specific filtering criteria (healthcare prescribers in Arizona) and ranking by prescription volume, requesting visualization"}, "sql_generated": "WITH __ard_giaco_tm_hcp_acute_mkt_weekly_laad AS (\n  SELECT\n    hcp_id,\n    date_key,\n    acute_trx_laad\n  FROM DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.REPORTING.ARD_GIACO_TM_HCP_ACUTE_MKT_WEEKLY_LAAD\n), recent_12_months AS (\n  SELECT\n    hcp_id,\n    date_key,\n    acute_trx_laad\n  FROM __ard_giaco_tm_hcp_acute_mkt_weekly_laad\n  WHERE\n    date_key <= CURRENT_TIMESTAMP()\n    AND date_key >= DATEADD(\n      MONTH,\n      -12,\n      (\n        SELECT\n          MAX(date_key)\n        FROM __ard_giaco_tm_hcp_acute_mkt_weekly_laad\n        WHERE\n          date_key <= CURRENT_TIMESTAMP()\n      )\n    )\n), hcp_aggregated AS (\n  SELECT\n    hcp_id,\n    SUM(acute_trx_laad) AS total_acute_trx_laad_12m,\n    MIN(date_key) AS min_date,\n    MAX(date_key) AS max_date,\n    COUNT(date_key) AS record_count,\n    COUNT(DISTINCT date_key) AS unique_weeks\n  FROM recent_12_months\n  GROUP BY\n    hcp_id\n)\nSELECT\n  hcp_id,\n  total_acute_trx_laad_12m,\n  min_date,\n  max_date,\n  record_count,\n  unique_weeks\nFROM hcp_aggregated\nORDER BY\n  total_acute_trx_laad_12m DESC NULLS LAST\nLIMIT 10\n -- Generated by Cortex Analyst (request_id: ec11a32a-f91b-4778-98cc-0c3319c51fbf)\n;", "is_blocked": false, "tool_artifacts": [{"type": "data_analysis", "summary": "The top 10 HCP_IDs ranked by ACUTE_TRX_LAAD_12M are displayed in the visualization. The leading HCP has 128,543 acute transactions over the 12-month period from October 2024 to October 2025, significantly higher than the others which range from 6,752 to 13,003 transactions.", "tables": [{"data": [["9d2874e648c48c41632a3fc164312154", "128543", "2024-10-04", "2025-10-03", "55251", "53"], ["426309c0bc85c6be8c65f5187f4cdb18", "13003", "2024-10-04", "2025-10-03", "5771", "53"], ["07ab7d8e415c68a6c2d059355ed73e40", "9767", "2024-10-04", "2025-10-03", "3941", "53"], ["a253e32cfed3c7ff87e3c601a239f2eb", "7948", "2024-10-04", "2025-10-03", "3203", "53"], ["377d582b8f1147bce1207d064e8fcea7", "7751", "2024-10-04", "2025-10-03", "3455", "53"], ["177a01e25b7907f644de400909faa674", "7574", "2024-10-04", "2025-10-03", "3661", "53"], ["c0a44a68867ddebaec6f9880a2a2ef86", "7548", "2024-10-04", "2025-10-03", "3714", "53"], ["9802c4d4a790ef2df205802da6cf5a65", "6951", "2024-10-04", "2025-10-03", "3695", "53"], ["6bb64dc65baa5bec6d7296e182a311cd", "6949", "2024-10-04", "2025-10-03", "1619", "53"], ["9d8e38c37799e25b19085f735e472609", "6752", "2024-10-04", "2025-10-03", "374", "53"]], "resultSetMetaData": {"format": "jsonv2", "numRows": 10, "partition": 0, "partitionInfo": [{"rowCount": 10, "uncompressedSize": 842}], "rowType": [{"length": 32, "name": "HCP_ID", "nullable": false, "precision": 0, "scale": 0, "type": "text"}, {"length": 0, "name": "TOTAL_ACUTE_TRX_LAAD_12M", "nullable": true, "precision": 30, "scale": 0, "type": "fixed"}, {"length": 0, "name": "MIN_DATE", "nullable": true, "precision": 0, "scale": 0, "type": "date"}, {"length": 0, "name": "MAX_DATE", "nullable": true, "precision": 0, "scale": 0, "type": "date"}, {"length": 0, "name": "RECORD_COUNT", "nullable": false, "precision": 18, "scale": 0, "type": "fixed"}, {"length": 0, "name": "UNIQUE_WEEKS", "nullable": false, "precision": 18, "scale": 0, "type": "fixed"}]}, "statementHandle": "01c202e7-081a-3d3b-0075-0383fdbeda7a"}, {"data": [["9d2874e648c48c41632a3fc164312154", "128543", "2024-10-04", "2025-10-03", "55251", "53"], ["426309c0bc85c6be8c65f5187f4cdb18", "13003", "2024-10-04", "2025-10-03", "5771", "53"], ["07ab7d8e415c68a6c2d059355ed73e40", "9767", "2024-10-04", "2025-10-03", "3941", "53"], ["a253e32cfed3c7ff87e3c601a239f2eb", "7948", "2024-10-04", "2025-10-03", "3203", "53"], ["377d582b8f1147bce1207d064e8fcea7", "7751", "2024-10-04", "2025-10-03", "3455", "53"], ["177a01e25b7907f644de400909faa674", "7574", "2024-10-04", "2025-10-03", "3661", "53"], ["c0a44a68867ddebaec6f9880a2a2ef86", "7548", "2024-10-04", "2025-10-03", "3714", "53"], ["9802c4d4a790ef2df205802da6cf5a65", "6951", "2024-10-04", "2025-10-03", "3695", "53"], ["6bb64dc65baa5bec6d7296e182a311cd", "6949", "2024-10-04", "2025-10-03", "1619", "53"], ["9d8e38c37799e25b19085f735e472609", "6752", "2024-10-04", "2025-10-03", "374", "53"]], "resultSetMetaData": {"format": "jsonv2", "numRows": 10, "partition": 0, "rowType": [{"length": 32, "name": "HCP_ID", "nullable": false, "precision": 0, "scale": 0, "type": "text"}, {"length": 0, "name": "TOTAL_ACUTE_TRX_LAAD_12M", "nullable": true, "precision": 30, "scale": 0, "type": "fixed"}, {"length": 0, "name": "MIN_DATE", "nullable": true, "precision": 0, "scale": 0, "type": "date"}, {"length": 0, "name": "MAX_DATE", "nullable": true, "precision": 0, "scale": 0, "type": "date"}, {"length": 0, "name": "RECORD_COUNT", "nullable": false, "precision": 18, "scale": 0, "type": "fixed"}, {"length": 0, "name": "UNIQUE_WEEKS", "nullable": false, "precision": 18, "scale": 0, "type": "fixed"}]}, "statementHandle": "01c202e7-081a-3d3b-0075-0383fdbeda7a"}, {"data": [["9d2874e648c48c41632a3fc164312154", "128543", "2024-10-04", "2025-10-03", "55251", "53"], ["426309c0bc85c6be8c65f5187f4cdb18", "13003", "2024-10-04", "2025-10-03", "5771", "53"], ["07ab7d8e415c68a6c2d059355ed73e40", "9767", "2024-10-04", "2025-10-03", "3941", "53"], ["a253e32cfed3c7ff87e3c601a239f2eb", "7948", "2024-10-04", "2025-10-03", "3203", "53"], ["377d582b8f1147bce1207d064e8fcea7", "7751", "2024-10-04", "2025-10-03", "3455", "53"], ["177a01e25b7907f644de400909faa674", "7574", "2024-10-04", "2025-10-03", "3661", "53"], ["c0a44a68867ddebaec6f9880a2a2ef86", "7548", "2024-10-04", "2025-10-03", "3714", "53"], ["9802c4d4a790ef2df205802da6cf5a65", "6951", "2024-10-04", "2025-10-03", "3695", "53"], ["6bb64dc65baa5bec6d7296e182a311cd", "6949", "2024-10-04", "2025-10-03", "1619", "53"], ["9d8e38c37799e25b19085f735e472609", "6752", "2024-10-04", "2025-10-03", "374", "53"]], "resultSetMetaData": {"format": "jsonv2", "numRows": 10, "partition": 0, "rowType": [{"length": 32, "name": "HCP_ID", "nullable": false, "precision": 0, "scale": 0, "type": "text"}, {"length": 0, "name": "TOTAL_ACUTE_TRX_LAAD_12M", "nullable": true, "precision": 30, "scale": 0, "type": "fixed"}, {"length": 0, "name": "MIN_DATE", "nullable": true, "precision": 0, "scale": 0, "type": "date"}, {"length": 0, "name": "MAX_DATE", "nullable": true, "precision": 0, "scale": 0, "type": "date"}, {"length": 0, "name": "RECORD_COUNT", "nullable": false, "precision": 18, "scale": 0, "type": "fixed"}, {"length": 0, "name": "UNIQUE_WEEKS", "nullable": false, "precision": 18, "scale": 0, "type": "fixed"}]}, "statementHandle": "01c202e7-081a-3d3b-0075-0383fdbeda7a"}], "charts": ["{\"$schema\": \"https://vega.github.io/schema/vega-lite/v5.json\", \"title\": \"Top 10 HCP_ID ranked by TOTAL_ACUTE_TRX_LAAD_12M\", \"transform\": [{\"window\": [{\"op\": \"rank\", \"as\": \"rank\"}], \"sort\": [{\"field\": \"TOTAL_ACUTE_TRX_LAAD_12M\", \"order\": \"descending\"}]}, {\"filter\": \"datum.rank <= 10\"}], \"mark\": \"bar\", \"encoding\": {\"x\": {\"field\": \"TOTAL_ACUTE_TRX_LAAD_12M\", \"title\": \"Total Acute TRX LAAD 12M\", \"type\": \"quantitative\", \"sort\": null, \"axis\": {\"format\": \".3~s\", \"labelExpr\": \"replace(datum.label, ''G'', ''B'')\"}}, \"y\": {\"field\": \"HCP_ID\", \"title\": \"HCP ID\", \"type\": \"nominal\", \"sort\": null}, \"tooltip\": [{\"field\": \"TOTAL_ACUTE_TRX_LAAD_12M\", \"type\": \"quantitative\", \"title\": \"Total Acute TRX LAAD 12M\", \"format\": \",.6~f\"}, {\"field\": \"HCP_ID\", \"type\": \"nominal\", \"title\": \"HCP ID\"}]}, \"data\": {\"values\": [{\"HCP_ID\": \"9d2874e648c48c41632a3fc164312154\", \"TOTAL_ACUTE_TRX_LAAD_12M\": 128543.0}, {\"HCP_ID\": \"426309c0bc85c6be8c65f5187f4cdb18\", \"TOTAL_ACUTE_TRX_LAAD_12M\": 13003.0}, {\"HCP_ID\": \"07ab7d8e415c68a6c2d059355ed73e40\", \"TOTAL_ACUTE_TRX_LAAD_12M\": 9767.0}, {\"HCP_ID\": \"a253e32cfed3c7ff87e3c601a239f2eb\", \"TOTAL_ACUTE_TRX_LAAD_12M\": 7948.0}, {\"HCP_ID\": \"377d582b8f1147bce1207d064e8fcea7\", \"TOTAL_ACUTE_TRX_LAAD_12M\": 7751.0}, {\"HCP_ID\": \"177a01e25b7907f644de400909faa674\", \"TOTAL_ACUTE_TRX_LAAD_12M\": 7574.0}, {\"HCP_ID\": \"c0a44a68867ddebaec6f9880a2a2ef86\", \"TOTAL_ACUTE_TRX_LAAD_12M\": 7548.0}, {\"HCP_ID\": \"9802c4d4a790ef2df205802da6cf5a65\", \"TOTAL_ACUTE_TRX_LAAD_12M\": 6951.0}, {\"HCP_ID\": \"6bb64dc65baa5bec6d7296e182a311cd\", \"TOTAL_ACUTE_TRX_LAAD_12M\": 6949.0}, {\"HCP_ID\": \"9d8e38c37799e25b19085f735e472609\", \"TOTAL_ACUTE_TRX_LAAD_12M\": 6752.0}]}}", "{\"$schema\": \"https://vega.github.io/schema/vega-lite/v5.json\", \"title\": \"Top 10 HCP_ID ranked by TOTAL_ACUTE_TRX_LAAD_12M\", \"transform\": [{\"window\": [{\"op\": \"rank\", \"as\": \"rank\"}], \"sort\": [{\"field\": \"TOTAL_ACUTE_TRX_LAAD_12M\", \"order\": \"descending\"}]}, {\"filter\": \"datum.rank <= 10\"}], \"mark\": \"bar\", \"encoding\": {\"x\": {\"field\": \"TOTAL_ACUTE_TRX_LAAD_12M\", \"title\": \"Total Acute TRX LAAD 12M\", \"type\": \"quantitative\", \"sort\": null, \"axis\": {\"format\": \".3~s\", \"labelExpr\": \"replace(datum.label, ''G'', ''B'')\"}}, \"y\": {\"field\": \"HCP_ID\", \"title\": \"HCP ID\", \"type\": \"nominal\", \"sort\": null}, \"tooltip\": [{\"field\": \"TOTAL_ACUTE_TRX_LAAD_12M\", \"type\": \"quantitative\", \"title\": \"Total Acute TRX LAAD 12M\", \"format\": \",.6~f\"}, {\"field\": \"HCP_ID\", \"type\": \"nominal\", \"title\": \"HCP ID\"}]}, \"data\": {\"values\": [{\"HCP_ID\": \"9d2874e648c48c41632a3fc164312154\", \"TOTAL_ACUTE_TRX_LAAD_12M\": 128543.0}, {\"HCP_ID\": \"426309c0bc85c6be8c65f5187f4cdb18\", \"TOTAL_ACUTE_TRX_LAAD_12M\": 13003.0}, {\"HCP_ID\": \"07ab7d8e415c68a6c2d059355ed73e40\", \"TOTAL_ACUTE_TRX_LAAD_12M\": 9767.0}, {\"HCP_ID\": \"a253e32cfed3c7ff87e3c601a239f2eb\", \"TOTAL_ACUTE_TRX_LAAD_12M\": 7948.0}, {\"HCP_ID\": \"377d582b8f1147bce1207d064e8fcea7\", \"TOTAL_ACUTE_TRX_LAAD_12M\": 7751.0}, {\"HCP_ID\": \"177a01e25b7907f644de400909faa674\", \"TOTAL_ACUTE_TRX_LAAD_12M\": 7574.0}, {\"HCP_ID\": \"c0a44a68867ddebaec6f9880a2a2ef86\", \"TOTAL_ACUTE_TRX_LAAD_12M\": 7548.0}, {\"HCP_ID\": \"9802c4d4a790ef2df205802da6cf5a65\", \"TOTAL_ACUTE_TRX_LAAD_12M\": 6951.0}, {\"HCP_ID\": \"6bb64dc65baa5bec6d7296e182a311cd\", \"TOTAL_ACUTE_TRX_LAAD_12M\": 6949.0}, {\"HCP_ID\": \"9d8e38c37799e25b19085f735e472609\", \"TOTAL_ACUTE_TRX_LAAD_12M\": 6752.0}]}}"], "full_pydantic_object": {"clean_answer_text": "The top 10 HCP_IDs ranked by ACUTE_TRX_LAAD_12M are displayed in the visualization. The leading HCP has 128,543 acute transactions over the 12-month period from October 2024 to October 2025, significantly higher than the others which range from 6,752 to 13,003 transactions.", "clarifying_question": null, "tables": [{"data": [["9d2874e648c48c41632a3fc164312154", "128543", "2024-10-04", "2025-10-03", "55251", "53"], ["426309c0bc85c6be8c65f5187f4cdb18", "13003", "2024-10-04", "2025-10-03", "5771", "53"], ["07ab7d8e415c68a6c2d059355ed73e40", "9767", "2024-10-04", "2025-10-03", "3941", "53"], ["a253e32cfed3c7ff87e3c601a239f2eb", "7948", "2024-10-04", "2025-10-03", "3203", "53"], ["377d582b8f1147bce1207d064e8fcea7", "7751", "2024-10-04", "2025-10-03", "3455", "53"], ["177a01e25b7907f644de400909faa674", "7574", "2024-10-04", "2025-10-03", "3661", "53"], ["c0a44a68867ddebaec6f9880a2a2ef86", "7548", "2024-10-04", "2025-10-03", "3714", "53"], ["9802c4d4a790ef2df205802da6cf5a65", "6951", "2024-10-04", "2025-10-03", "3695", "53"], ["6bb64dc65baa5bec6d7296e182a311cd", "6949", "2024-10-04", "2025-10-03", "1619", "53"], ["9d8e38c37799e25b19085f735e472609", "6752", "2024-10-04", "2025-10-03", "374", "53"]], "resultSetMetaData": {"format": "jsonv2", "numRows": 10, "partition": 0, "partitionInfo": [{"rowCount": 10, "uncompressedSize": 842}], "rowType": [{"length": 32, "name": "HCP_ID", "nullable": false, "precision": 0, "scale": 0, "type": "text"}, {"length": 0, "name": "TOTAL_ACUTE_TRX_LAAD_12M", "nullable": true, "precision": 30, "scale": 0, "type": "fixed"}, {"length": 0, "name": "MIN_DATE", "nullable": true, "precision": 0, "scale": 0, "type": "date"}, {"length": 0, "name": "MAX_DATE", "nullable": true, "precision": 0, "scale": 0, "type": "date"}, {"length": 0, "name": "RECORD_COUNT", "nullable": false, "precision": 18, "scale": 0, "type": "fixed"}, {"length": 0, "name": "UNIQUE_WEEKS", "nullable": false, "precision": 18, "scale": 0, "type": "fixed"}]}, "statementHandle": "01c202e7-081a-3d3b-0075-0383fdbeda7a"}, {"data": [["9d2874e648c48c41632a3fc164312154", "128543", "2024-10-04", "2025-10-03", "55251", "53"], ["426309c0bc85c6be8c65f5187f4cdb18", "13003", "2024-10-04", "2025-10-03", "5771", "53"], ["07ab7d8e415c68a6c2d059355ed73e40", "9767", "2024-10-04", "2025-10-03", "3941", "53"], ["a253e32cfed3c7ff87e3c601a239f2eb", "7948", "2024-10-04", "2025-10-03", "3203", "53"], ["377d582b8f1147bce1207d064e8fcea7", "7751", "2024-10-04", "2025-10-03", "3455", "53"], ["177a01e25b7907f644de400909faa674", "7574", "2024-10-04", "2025-10-03", "3661", "53"], ["c0a44a68867ddebaec6f9880a2a2ef86", "7548", "2024-10-04", "2025-10-03", "3714", "53"], ["9802c4d4a790ef2df205802da6cf5a65", "6951", "2024-10-04", "2025-10-03", "3695", "53"], ["6bb64dc65baa5bec6d7296e182a311cd", "6949", "2024-10-04", "2025-10-03", "1619", "53"], ["9d8e38c37799e25b19085f735e472609", "6752", "2024-10-04", "2025-10-03", "374", "53"]], "resultSetMetaData": {"format": "jsonv2", "numRows": 10, "partition": 0, "rowType": [{"length": 32, "name": "HCP_ID", "nullable": false, "precision": 0, "scale": 0, "type": "text"}, {"length": 0, "name": "TOTAL_ACUTE_TRX_LAAD_12M", "nullable": true, "precision": 30, "scale": 0, "type": "fixed"}, {"length": 0, "name": "MIN_DATE", "nullable": true, "precision": 0, "scale": 0, "type": "date"}, {"length": 0, "name": "MAX_DATE", "nullable": true, "precision": 0, "scale": 0, "type": "date"}, {"length": 0, "name": "RECORD_COUNT", "nullable": false, "precision": 18, "scale": 0, "type": "fixed"}, {"length": 0, "name": "UNIQUE_WEEKS", "nullable": false, "precision": 18, "scale": 0, "type": "fixed"}]}, "statementHandle": "01c202e7-081a-3d3b-0075-0383fdbeda7a"}, {"data": [["9d2874e648c48c41632a3fc164312154", "128543", "2024-10-04", "2025-10-03", "55251", "53"], ["426309c0bc85c6be8c65f5187f4cdb18", "13003", "2024-10-04", "2025-10-03", "5771", "53"], ["07ab7d8e415c68a6c2d059355ed73e40", "9767", "2024-10-04", "2025-10-03", "3941", "53"], ["a253e32cfed3c7ff87e3c601a239f2eb", "7948", "2024-10-04", "2025-10-03", "3203", "53"], ["377d582b8f1147bce1207d064e8fcea7", "7751", "2024-10-04", "2025-10-03", "3455", "53"], ["177a01e25b7907f644de400909faa674", "7574", "2024-10-04", "2025-10-03", "3661", "53"], ["c0a44a68867ddebaec6f9880a2a2ef86", "7548", "2024-10-04", "2025-10-03", "3714", "53"], ["9802c4d4a790ef2df205802da6cf5a65", "6951", "2024-10-04", "2025-10-03", "3695", "53"], ["6bb64dc65baa5bec6d7296e182a311cd", "6949", "2024-10-04", "2025-10-03", "1619", "53"], ["9d8e38c37799e25b19085f735e472609", "6752", "2024-10-04", "2025-10-03", "374", "53"]], "resultSetMetaData": {"format": "jsonv2", "numRows": 10, "partition": 0, "rowType": [{"length": 32, "name": "HCP_ID", "nullable": false, "precision": 0, "scale": 0, "type": "text"}, {"length": 0, "name": "TOTAL_ACUTE_TRX_LAAD_12M", "nullable": true, "precision": 30, "scale": 0, "type": "fixed"}, {"length": 0, "name": "MIN_DATE", "nullable": true, "precision": 0, "scale": 0, "type": "date"}, {"length": 0, "name": "MAX_DATE", "nullable": true, "precision": 0, "scale": 0, "type": "date"}, {"length": 0, "name": "RECORD_COUNT", "nullable": false, "precision": 18, "scale": 0, "type": "fixed"}, {"length": 0, "name": "UNIQUE_WEEKS", "nullable": false, "precision": 18, "scale": 0, "type": "fixed"}]}, "statementHandle": "01c202e7-081a-3d3b-0075-0383fdbeda7a"}], "charts": ["{\"$schema\": \"https://vega.github.io/schema/vega-lite/v5.json\", \"title\": \"Top 10 HCP_ID ranked by TOTAL_ACUTE_TRX_LAAD_12M\", \"transform\": [{\"window\": [{\"op\": \"rank\", \"as\": \"rank\"}], \"sort\": [{\"field\": \"TOTAL_ACUTE_TRX_LAAD_12M\", \"order\": \"descending\"}]}, {\"filter\": \"datum.rank <= 10\"}], \"mark\": \"bar\", \"encoding\": {\"x\": {\"field\": \"TOTAL_ACUTE_TRX_LAAD_12M\", \"title\": \"Total Acute TRX LAAD 12M\", \"type\": \"quantitative\", \"sort\": null, \"axis\": {\"format\": \".3~s\", \"labelExpr\": \"replace(datum.label, ''G'', ''B'')\"}}, \"y\": {\"field\": \"HCP_ID\", \"title\": \"HCP ID\", \"type\": \"nominal\", \"sort\": null}, \"tooltip\": [{\"field\": \"TOTAL_ACUTE_TRX_LAAD_12M\", \"type\": \"quantitative\", \"title\": \"Total Acute TRX LAAD 12M\", \"format\": \",.6~f\"}, {\"field\": \"HCP_ID\", \"type\": \"nominal\", \"title\": \"HCP ID\"}]}, \"data\": {\"values\": [{\"HCP_ID\": \"9d2874e648c48c41632a3fc164312154\", \"TOTAL_ACUTE_TRX_LAAD_12M\": 128543.0}, {\"HCP_ID\": \"426309c0bc85c6be8c65f5187f4cdb18\", \"TOTAL_ACUTE_TRX_LAAD_12M\": 13003.0}, {\"HCP_ID\": \"07ab7d8e415c68a6c2d059355ed73e40\", \"TOTAL_ACUTE_TRX_LAAD_12M\": 9767.0}, {\"HCP_ID\": \"a253e32cfed3c7ff87e3c601a239f2eb\", \"TOTAL_ACUTE_TRX_LAAD_12M\": 7948.0}, {\"HCP_ID\": \"377d582b8f1147bce1207d064e8fcea7\", \"TOTAL_ACUTE_TRX_LAAD_12M\": 7751.0}, {\"HCP_ID\": \"177a01e25b7907f644de400909faa674\", \"TOTAL_ACUTE_TRX_LAAD_12M\": 7574.0}, {\"HCP_ID\": \"c0a44a68867ddebaec6f9880a2a2ef86\", \"TOTAL_ACUTE_TRX_LAAD_12M\": 7548.0}, {\"HCP_ID\": \"9802c4d4a790ef2df205802da6cf5a65\", \"TOTAL_ACUTE_TRX_LAAD_12M\": 6951.0}, {\"HCP_ID\": \"6bb64dc65baa5bec6d7296e182a311cd\", \"TOTAL_ACUTE_TRX_LAAD_12M\": 6949.0}, {\"HCP_ID\": \"9d8e38c37799e25b19085f735e472609\", \"TOTAL_ACUTE_TRX_LAAD_12M\": 6752.0}]}}", "{\"$schema\": \"https://vega.github.io/schema/vega-lite/v5.json\", \"title\": \"Top 10 HCP_ID ranked by TOTAL_ACUTE_TRX_LAAD_12M\", \"transform\": [{\"window\": [{\"op\": \"rank\", \"as\": \"rank\"}], \"sort\": [{\"field\": \"TOTAL_ACUTE_TRX_LAAD_12M\", \"order\": \"descending\"}]}, {\"filter\": \"datum.rank <= 10\"}], \"mark\": \"bar\", \"encoding\": {\"x\": {\"field\": \"TOTAL_ACUTE_TRX_LAAD_12M\", \"title\": \"Total Acute TRX LAAD 12M\", \"type\": \"quantitative\", \"sort\": null, \"axis\": {\"format\": \".3~s\", \"labelExpr\": \"replace(datum.label, ''G'', ''B'')\"}}, \"y\": {\"field\": \"HCP_ID\", \"title\": \"HCP ID\", \"type\": \"nominal\", \"sort\": null}, \"tooltip\": [{\"field\": \"TOTAL_ACUTE_TRX_LAAD_12M\", \"type\": \"quantitative\", \"title\": \"Total Acute TRX LAAD 12M\", \"format\": \",.6~f\"}, {\"field\": \"HCP_ID\", \"type\": \"nominal\", \"title\": \"HCP ID\"}]}, \"data\": {\"values\": [{\"HCP_ID\": \"9d2874e648c48c41632a3fc164312154\", \"TOTAL_ACUTE_TRX_LAAD_12M\": 128543.0}, {\"HCP_ID\": \"426309c0bc85c6be8c65f5187f4cdb18\", \"TOTAL_ACUTE_TRX_LAAD_12M\": 13003.0}, {\"HCP_ID\": \"07ab7d8e415c68a6c2d059355ed73e40\", \"TOTAL_ACUTE_TRX_LAAD_12M\": 9767.0}, {\"HCP_ID\": \"a253e32cfed3c7ff87e3c601a239f2eb\", \"TOTAL_ACUTE_TRX_LAAD_12M\": 7948.0}, {\"HCP_ID\": \"377d582b8f1147bce1207d064e8fcea7\", \"TOTAL_ACUTE_TRX_LAAD_12M\": 7751.0}, {\"HCP_ID\": \"177a01e25b7907f644de400909faa674\", \"TOTAL_ACUTE_TRX_LAAD_12M\": 7574.0}, {\"HCP_ID\": \"c0a44a68867ddebaec6f9880a2a2ef86\", \"TOTAL_ACUTE_TRX_LAAD_12M\": 7548.0}, {\"HCP_ID\": \"9802c4d4a790ef2df205802da6cf5a65\", \"TOTAL_ACUTE_TRX_LAAD_12M\": 6951.0}, {\"HCP_ID\": \"6bb64dc65baa5bec6d7296e182a311cd\", \"TOTAL_ACUTE_TRX_LAAD_12M\": 6949.0}, {\"HCP_ID\": \"9d8e38c37799e25b19085f735e472609\", \"TOTAL_ACUTE_TRX_LAAD_12M\": 6752.0}]}}"], "sql_generated": "WITH __ard_giaco_tm_hcp_acute_mkt_weekly_laad AS (\n  SELECT\n    hcp_id,\n    date_key,\n    acute_trx_laad\n  FROM DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.REPORTING.ARD_GIACO_TM_HCP_ACUTE_MKT_WEEKLY_LAAD\n), recent_12_months AS (\n  SELECT\n    hcp_id,\n    date_key,\n    acute_trx_laad\n  FROM __ard_giaco_tm_hcp_acute_mkt_weekly_laad\n  WHERE\n    date_key <= CURRENT_TIMESTAMP()\n    AND date_key >= DATEADD(\n      MONTH,\n      -12,\n      (\n        SELECT\n          MAX(date_key)\n        FROM __ard_giaco_tm_hcp_acute_mkt_weekly_laad\n        WHERE\n          date_key <= CURRENT_TIMESTAMP()\n      )\n    )\n), hcp_aggregated AS (\n  SELECT\n    hcp_id,\n    SUM(acute_trx_laad) AS total_acute_trx_laad_12m,\n    MIN(date_key) AS min_date,\n    MAX(date_key) AS max_date,\n    COUNT(date_key) AS record_count,\n    COUNT(DISTINCT date_key) AS unique_weeks\n  FROM recent_12_months\n  GROUP BY\n    hcp_id\n)\nSELECT\n  hcp_id,\n  total_acute_trx_laad_12m,\n  min_date,\n  max_date,\n  record_count,\n  unique_weeks\nFROM hcp_aggregated\nORDER BY\n  total_acute_trx_laad_12m DESC NULLS LAST\nLIMIT 10\n -- Generated by Cortex Analyst (request_id: ec11a32a-f91b-4778-98cc-0c3319c51fbf)\n;", "sql_explanation": null, "is_verified_query": false, "evaluation": {"score": 9, "reasoning": "Successfully calculated the 12-month sum of ACUTE_TRX_LAAD for each HCP_ID, ranked them correctly, and provided appropriate bar chart visualization. The SQL correctly aggregated weekly data over the trailing 12 months and returned the top 10 results as requested."}, "is_retry": true}}], "generated_at": "2026-01-27T12:23:43.939708"}')] in VALUES clause
 Audit Log Error: (1304): 01c202e7-081a-3d3b-0075-0383fdbedc76: 002023 (22000): 01c202e7-081a-3d3b-0075-0383fdbedc76: SQL compilation error:
Expression type does not match column data type, expecting VARCHAR(16777216) but got ARRAY for column DATA_CLARIFICATION
 Process Completed






import json
import logging
import pprint
import re
import _snowflake # Native Snowflake module for internal API calls
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import List, Dict, Any, Optional, Literal, Tuple
from pydantic import BaseModel, Field, field_validator
from snowflake.snowpark import Session
from snowflake.snowpark.functions import lit, parse_json, col
from collections import defaultdict
import datetime

# ==========================================
# 1. CONFIGURATION
# ==========================================

class AgentConfig(BaseModel):
    """Configuration for the agent execution"""
    # LLM Models
    model: str = "claude-sonnet-4-5" 
    
    # Snowflake Objects
    cortex_analyst_object_master: str = "DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.AI_POC.MASTERTABLE_V1"
    cortex_analyst_object_ards: str = "DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.REPORTING.BASIC_CORTEX_ANALYST"
    warehouse: str = "DEV_PAIN_SALES_PERFORMANCE_B_WH"
    
    # Tables
    messages_table: str = "DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.AI_POC.MESSAGES"
    audit_log_table: str = "DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.AI_POC.AGENT_DETAILED_HISTORY"
    
    # Tools
    diagnostic_udf: str = "DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.AI_POC.DIAGNOSTIC_TOOL"
    diagnostic_tree_id: str = "pharma_sales_v3" 
    
    enable_semantic_parsing: bool = True

CONFIG = AgentConfig()

# ==========================================
# 2. PYDANTIC MODELS
# ==========================================

class EvaluationResult(BaseModel):
    score: int = Field(default=0, description="Score 1-10.")
    reasoning: str = Field(default="No evaluation provided.", description="Justification.")

class IntentClassification(BaseModel):
    intent_type: str = Field(..., description="greeting, data_retrieval, root_cause_analysis, clarification_needed, general_question, off_topic, combined")
    data_retrieval_query: Optional[str] = None
    root_cause_query: Optional[str] = None
    direct_response: Optional[str] = None
    clarification_question: Optional[str] = None
    confidence: str = Field(..., description="high, medium, low")
    reasoning: str = Field(..., description="Reasoning")

class RephraserOutput(BaseModel):
    refined_query: str = Field(..., description="The fully contextualized query.")

class TableSelection(BaseModel):
    relevant_table_names: List[str] = Field(..., description="List of table names.")

class GuardResult(BaseModel):
    is_safe: bool = Field(...)
    message: Optional[str] = Field(None)

class SqlResult(BaseModel):
    clean_answer_text: str = Field(default="")
    clarifying_question: Optional[str] = None
    tables: List[Any] = Field(default_factory=list)
    charts: List[Dict] = Field(default_factory=list)
    sql_generated: Optional[str] = None
    sql_explanation: Optional[str] = None
    is_verified_query: bool = False
    evaluation: EvaluationResult = Field(default_factory=EvaluationResult)
    is_retry: bool = False

    @field_validator('charts', mode='before')
    @classmethod
    def parse_charts(cls, v):
        if not v: return []
        parsed = []
        for item in v:
            if isinstance(item, dict): parsed.append(item)
            elif isinstance(item, str):
                try: parsed.append(json.loads(item))
                except: continue 
        return parsed

class DiagnosticResult(BaseModel):
    clean_summary_text: str = Field(default="")
    clarifying_question: Optional[str] = None
    react_flow_json: Optional[Dict] = None
    evaluation: EvaluationResult = Field(default_factory=EvaluationResult)

# ==========================================
# 3. PROMPTS (RESTORED & ENHANCED)
# ==========================================

# --- REPHRASER ---
PROMPT_REPHRASER_SYSTEM = "You are a sophisticated Query Refinement Engine. Be polite, professional, and friendly. Be direct and unambiguous."

PROMPT_REPHRASER_ORCHESTRATION = """
<query_refinement_instructions>
<objective>
Transform the user's input into a standalone, context-complete query that can be understood without prior conversation history.
</objective>

<core_rules>
<rule id="1">Resolve all pronouns (it, they, that, this, those) to their specific referents based on chat history.</rule>
<rule id="2">Preserve ALL metrics, entity names, IDs, and numerical values EXACTLY as stated.</rule>
<rule id="3">Maintain the original intent and scope - do not expand or narrow the question.</rule>
<rule id="4">Keep technical terminology and domain-specific language intact.</rule>
<rule id="5">Ensure the output is grammatically correct and reads naturally.</rule>
</core_rules>

<follow_up_handling_rules>
<rule id="6">IF previous Bot response contained Data (e.g., "Sales are down") AND User asks "Why?", REPHRASE to "Why are sales down?"</rule>
<rule id="7">IF previous Bot response was a Clarification (e.g., "By region?"), AND User answers "Region", REPHRASE to combine them.</rule>
</follow_up_handling_rules>

<transformation_examples>
<example>
<input>What about Arizona?</input>
<context>Previous discussion about sales performance in Texas</context>
<output>What is the sales performance in Arizona?</output>
</example>

<example>
<input>Why is it down?</input>
<context>Previous mention of Q4 revenue</context>
<output>Why is Q4 revenue down?</output>
</example>
</transformation_examples>
</query_refinement_instructions>
"""

PROMPT_REPHRASER_RESPONSE = """
<output_format>
At the VERY END of your text response, YOU MUST output a JSON block STRICTLY in below format: 
Example: { "refined_query": "What is the sales performance in Arizona?" }
Do not include any other text or markdown outside the JSON object.
</output_format>
"""

# --- INTENT ---
PROMPT_INTENT_SYSTEM = "You are an Expert Intent Classification System. Be polite, professional, and friendly. Be direct and unambiguous."

PROMPT_INTENT_ORCHESTRATION = """
<intent_classification_instructions>

<mission>
Your ONLY job is to identify the user's INTENT. Do NOT retrieve data, do NOT answer questions, do NOT perform analysis.
Classify the intent type and route accordingly.
</mission>

<intent_categories>

<intent name="greeting">
<description>User is greeting, saying hello, or engaging in pleasantries</description>
<indicators>hi, hello, hey, good morning, how are you, thanks, thank you, goodbye, bye</indicators>
<action>Set direct_response with a friendly greeting. No other fields needed.</action>
</intent>

<intent name="data_retrieval">
<description>User wants to see/get/retrieve DATA - numbers, lists, metrics, tables</description>
<indicators>show, list, get, display, find, what is the value, how many, count, total, give me</indicators>
<action>Extract the data request to data_retrieval_query. Keep as natural language. Add "and generate a table and a visual".</action>
**CRITICAL VISUALIZATION LOGIC:**
Analyze the data request. If it implies trends (over time), comparisons (by region/product), or distributions, you MUST automatically append "and generate a table and a visual" to the query string.
</intent>

<intent name="root_cause_analysis">
<description>User wants to understand WHY, CAUSES, DRIVERS, REASONS, EXPLANATIONS</description>
<indicators>why, explain, what is driving, what is causing, what's behind, reason for, root cause, how come, what factors</indicators>
<action>Extract the causal question to root_cause_query. Keep VERBATIM - exact text from user.</action>
</intent>

<intent name="combined">
<description>User wants BOTH data AND causal analysis in one request</description>
<indicators>Contains both data keywords AND causal keywords</indicators>
<action>Split into data_retrieval_query AND root_cause_query. Keep both portions.</action>
</intent>

<intent name="clarification_needed">
<description>User's intent is unclear, vague, or ambiguous - you cannot determine what they want</description>
<indicators>Very short/vague input, unclear pronouns without context, incomplete thoughts</indicators>
<action>Set clarification_question asking user to be more specific.</action>
</intent>

<intent name="general_question">
<description>General questions about the system, capabilities, how to use features - not data or analysis requests</description>
<indicators>how do I, can you, what can you do, help me understand, how does this work</indicators>
<action>Set direct_response with helpful information about capabilities.</action>
</intent>

<intent name="off_topic">
<description>User is asking about unrelated topics not connected to data, analytics, or business questions</description>
<indicators>Questions about weather, sports, entertainment, personal topics unrelated to business/data</indicators>
<action>Set direct_response politely redirecting to business/data topics.</action>
</intent>

</intent_categories>

<CRITICAL_CLASSIFICATION_RULES>
 RULE 1: NEVER DO THE WORK - ONLY CLASSIFY.
 RULE 2: CAUSAL KEYWORD DETECTION (why, driving, causing) = root_cause_analysis.
 RULE 3: DATA KEYWORD DETECTION (show, list, get) = data_retrieval.
 RULE 4: DIRECT RESPONSE ONLY FOR SIMPLE CASES (Greetings, General, Off-topic).
 RULE 5: VERBATIM PRESERVATION FOR ROOT CAUSE.
 RULE 6: NO SQL CODE GENERATION.
 RULE 7: CONFIDENCE SCORING (high/medium/low).
</CRITICAL_CLASSIFICATION_RULES>
</intent_classification_instructions>
"""

PROMPT_INTENT_RESPONSE = """
<output_format>
At the VERY END of your text response, YOU MUST output a JSON block STRICTLY in below format:
{
  "intent_type": "data_retrieval",
  "data_retrieval_query": "Show me sales...",
  "root_cause_query": null,
  "direct_response": null,
  "clarification_question": null,
  "confidence": "high",
  "reasoning": "User used 'show me' keyword"
}
</output_format>
"""

# --- DATA AGENT ---
PROMPT_DATA_AGENT_SYSTEM = "You are an expert Data Analyst. Be polite, professional, and friendly. Be direct and unambiguous."

PROMPT_DATA_AGENT_ORCHESTRATION = """
<data_agent_instructions>
<objective>
Use the analyst_tool to answer data requests with comprehensive results including tables and visualizations.
</objective>

<clarification_protocol>
You have access to the Master Schema.
If the user asks a vague question like "Show me sales" without specifying time, product, or region:
1. CHECK the Master Schema for available dimensions (e.g., Region, Specialty, Brand).
2. DO NOT guess.
3. ASK a specific clarifying question: "Would you like to see sales broken down by Region, Specialty, or Brand?"
4. If the query is clear, proceed to generate SQL.
</clarification_protocol>

<execution_rules>
<rule id="1">ALWAYS generate a table (Result Set) for data requests</rule>
<rule id="2">Generate appropriate visualizations when data is suitable for charts</rule>
<rule id="3">Provide clear, concise summaries of the data findings</rule>
<rule id="4">Handle errors gracefully and explain any data limitations</rule>
</execution_rules>

<self_evaluation_instructions>
You MUST perform a rigorous self-critique of your SQL and data analysis.
1. **Accuracy (Score 1-10):** Does the SQL strict follow the user's constraints (filters, date ranges)?
2. **Data Integrity:** Are the results logical? (e.g., no negative counts where impossible).
3. **Clarity:** Is the summary accessible to a non-technical user?
</self_evaluation_instructions>
</data_agent_instructions>
"""

PROMPT_DATA_AGENT_RESPONSE = """
<output_format>
At the VERY END of your text response, YOU MUST output a JSON block STRICTLY in below format:
```json
{
  "clean_answer_text": "Summary of findings...",
  "clarifying_question": null,
  "evaluation": {
    "score": 8,
    "reasoning": "Data matches request."
  }
}
```
</output_format>
"""

# --- ROOT CAUSE ---
PROMPT_ROOT_CAUSE_SYSTEM = "You are an Autonomous Root Cause Analysis Agent. Be polite, professional, and friendly. Be direct and unambiguous."

PROMPT_ROOT_CAUSE_ORCHESTRATION = f"""
<root_cause_orchestration_prompt>
    <role_and_objective>
        You are an **Autonomous Root Cause Analysis Agent** designed to traverse a metric decision tree from the root node down to the leaf nodes. Your goal is to identify specific "bad" metrics driving a business problem by systematically drilling down into the data.
        
        ALWAYS USE tree_id as {CONFIG.diagnostic_tree_id}.
    </role_and_objective>

    <phase_1_clarification_check>
        **CRITICAL:** Before running any tools, analyze the USER_QUERY against the MASTER SCHEMA dimensions.
        
        MASTER SCHEMA:

        {CONFIG.cortex_analyst_object_master}
        
        IF the user asks a generic question like "Why is revenue down?" or "Explain the drop":
        1. You cannot run the tool efficiently without a starting point (Root Node context).
        2. Look at available schema dimensions (Region, Product, Specialty, Time).
        3. **STOP** and return a `clarifying_question`.
           Example: "To analyze the revenue drop, should I compare performance by Region, Product Class, or Customer Specialty?"
        
        IF the query contains specific context (e.g., "Why is Tylenol down in NY?"), PROCEED to Phase 2.
    </phase_1_clarification_check>

    <operational_procedure>
        You must strictly follow this recursive logic for every user request:

        **Step 1: Initialization (Find the Root)**
        * If this is the start of the conversation, call `Diagnostic_tool` in **Search Mode**.
        * **Action:** Call `Diagnostic_tool(USER_QUERY=user_question, PARENT_NODE_IDS_JSON=NULL, TREE_ID='{CONFIG.diagnostic_tree_id}')`.
        * **Next:** Proceed to Step 2 with the results.

        **Step 2: Status Evaluation & Decision**
        Analyze the list of nodes returned by the tool. Focus **only** on nodes where `"status": "bad"`.

        * **Check:** For every "bad" node, do you see its children in the current list?
        * **Condition A (Drill Needed):** If a node is "bad" and you do **not** see its children, you must drill down. Collect these Node IDs.
        * **Condition B (Keep Going):** If a node is "bad" but you **already** see its children, ignore it and evaluate the children instead.
        * **Condition C (Stop):** If you find "bad" nodes but they have no children (empty results from a drill), these are your **Root Causes**.

        **Step 3: Execution (Drill Down)**
        * If Condition A occurred: Call `Diagnostic_tool` in **Drill Mode**.
        * **Action:** Call `Diagnostic_tool(USER_QUERY=NULL, PARENT_NODE_IDS_JSON='["ID_1", "ID_2"]', TREE_ID='{CONFIG.diagnostic_tree_id}')`.
        * **Next:** Recursively repeat Step 2 with the new output.
        * If Condition C occurred: Present the final root causes to the user.
    </operational_procedure>

    <constraints>
        * **Never** guess the status of a metric; always use the tool.
        * **Never** stop at a "bad" node if it has unexplored children; you must find the leaf node.
        * Output your reasoning briefly before calling the tool.
    </constraints>

    <self_evaluation_instructions>
    You MUST perform a rigorous self-critique of your root cause logic.
    1. **Logic (Score 1-10):** Is the causal chain (Root -> Leaf) mathematically sound?
    2. **Driver Isolation:** Did we truly find the leaf node, or did we stop too early?
    3. **Completeness:** Did we explore all "bad" branches?
    </self_evaluation_instructions>
</root_cause_orchestration_prompt>
"""

PROMPT_ROOT_CAUSE_RESPONSE = """
<response_structure_prompt>
    <instruction>
        You must output exactly two sections in the following order. Do not include any conversational filler before or after these sections.
    </instruction>

    <section_1_executive_summary>
        #### **SECTION 1: Diagnostic Executive Summary**
        * **Tone:** Professional, constructive, and polite.
        * **Headline:** State the Root Cause clearly.
        * **The Narrative:** Briefly explain the chain of events in simple English.
        * **Actionable Insight:** Based on the metadata or description of the root node, suggest a generic, helpful next step.
    </section_1_executive_summary>

    <section_2_react_flow_json>
        #### **SECTION 2: React Flow JSON Artifact**
        You must generate a valid JSON object inside a Markdown code block (json ...).
        
        **4. JSON Schema (Must Follow Exactly):**
        {
          "nodes": [
            {
              "id": "N0",
              "type": "default",
              "data": { "label": "Metric Name: Value" },
              "position": { "x": 0, "y": 0 },
              "style": { "background": "#FFE2E5", "width": 180, "color": "#333", "border": "1px solid #777", "borderRadius": "8px" }
            }
          ],
          "edges": [
            {
              "id": "e-N0-N1",
              "source": "N0",
              "target": "N1",
              "label": "driven by",
              "animated": true,
              "style": { "stroke": "#555", "strokeWidth": 2 }
            }
          ]
        }
    </section_2_react_flow_json>
    
    <section_3_final_json>
        CRITICAL: Provide the final JSON block for the parser here as defined in the system prompt evaluation section.
    </section_3_final_json>
    
    **CRITICAL** : YOU MUST ONLY EXECUTE ATMOST 8 TOOL CALLS.
    
    <output_format>
    At the VERY END of your text response, YOU MUST output a JSON block STRICTLY in below format:
    ```json
    {
      "clean_summary_text": "Executive summary...",
      "clarifying_question": null,
      "react_flow_json": { "nodes": [], "edges": [] },
      "evaluation": { "score": 9, "reasoning": "Found root cause." }
    }
    ```
    </output_format>
</response_structure_prompt>
"""

# --- TABLE SELECTION ---
PROMPT_TABLE_SELECTION = """
<instruction>
You are an expert Database Architect and Schema Analyzer.
Your goal is to identify the subset of tables from the provided list that are strictly relevant to answering the user's query.

<rules>
1. **Analyze the Query**: Carefully understand the business entities, metrics, and dimensions requested.
2. **Review Summaries**: Check the Table Name and Description for each table provided.
3. **Strict Selection**: Select ONLY tables that contain the data needed. Do NOT include tables "just in case".
4. **Keyword Matching**: 
   - If the query mentions "sales" or "revenue", look for Fact tables with those metrics.
   - If the query mentions "location", "city", or "state", look for Geography Dimension tables.
   - If the query mentions "products", look for Product Dimension tables.
5. **Empty Return**: If no tables seem relevant, return an empty list.
</rules>

<output_format>
Output ONLY a valid JSON object with the following structure. Do not output markdown code blocks.
{
  "relevant_table_names": ["Table_A", "Table_B"]
}
</output_format>
</instruction>
"""

# --- SEMANTIC TRANSLATOR ---
PROMPT_SEMANTIC_TRANSLATOR = """
<instruction>
You are a Semantic Query Optimizer and SQL Expert.
Your goal is to rewrite the User's Natural Language Query so that it aligns perfectly with the provided Database Schema Context.

<rules>
1. **Vocabulary Mapping:** Replace generic business terms in the user query with the EXACT column names found in the Schema Context.
   - Example: If user says "revenue" and context has "TOTAL_SALES_AMT", use "TOTAL_SALES_AMT".
   - Example: If user says "doctors" and context has "HCP_ID", use "HCP_ID".
2. **Filter Alignment:** Check 'sample_values' in the context.
   - Example: If user says "in NY", and sample values for 'STATE_CD' are 'New York', rewrite to "STATE_CD is 'New York'".
3. **Disambiguation:** If a term matches multiple columns, use the column descriptions to pick the most relevant one.
4. **Preservation:** Do not change the user's core intent (e.g., ranking, aggregation, filtering). Just swap the terminology.
5. **Output**: Return ONLY the rewritten natural language query string. Do not output SQL. Do not output JSON.
</rules>
</instruction>
"""

# ==========================================
# 4. HELPER FUNCTIONS
# ==========================================

def log_checkpoint(step: str, details: Any):
    print(f"\n{'='*50}\n CHECKPOINT: {step}\n{'-'*50}")
    if isinstance(details, BaseModel): pprint.pprint(details.model_dump())
    elif isinstance(details, (dict, list)): pprint.pprint(details)
    else: print(str(details))
    print(f"{'='*50}\n")

# ==========================================
# HISTORY MANAGEMENT FUNCTIONS (UPDATED)
# ==========================================

def get_chat_history(session: Session, session_id: str, limit: int = 10) -> List[Dict]:
    """Retrieves chat history for a specific session_id formatted for Cortex."""
    if not session_id: return []
    try:
        # MAPS TO NEW SCHEMA: SENDER_TYPE, MESSAGE, CONVERSATION_ID
        sql = f"""
        SELECT SENDER_TYPE, MESSAGE 
        FROM {CONFIG.messages_table}
        WHERE CONVERSATION_ID = '{session_id}'
        ORDER BY CREATED_AT ASC
        LIMIT {limit}
        """
        rows = session.sql(sql).collect()
        history = []
        for r in rows:
            role = "user" if r['SENDER_TYPE'].lower() == 'user' else "assistant"
            history.append({"role": role, "content": [{"type": "text", "text": r['MESSAGE']}]})
        
        print(f" Retrieved {len(history)} past messages for Session {session_id}")
        return history
    except Exception as e:
        print(f" History Fetch Failed: {e}")
        return []

def save_chat_message(session: Session, session_id: str, role: str, content: str, metadata: Optional[Dict] = None):
    """Saves a message to the MESSAGES table. Maps to new schema with DOLLAR QUOTING."""
    if not session_id or not content: return
    try:
        safe_content = content.replace("'", "''")
        safe_session_id = str(session_id).replace("'", "''")
        
        # Metadata handling with Dollar Quoting to prevent SQL Injection/Breakage from quotes
        if metadata:
            meta_json = json.dumps(metadata) # No need to replace single quotes inside dollar quotes
            # Using $$ quoting for the JSON string
            meta_val = f"PARSE_JSON($${meta_json}$$)"
        else:
            meta_val = "NULL"

        # MAPS TO NEW SCHEMA
        sql = f"""
        INSERT INTO {CONFIG.messages_table} 
        (CONVERSATION_ID, SENDER_TYPE, MESSAGE, METADATA, CREATED_AT)
        VALUES 
        ('{safe_session_id}', '{role}', '{safe_content}', {meta_val}, CURRENT_TIMESTAMP())
        """
        session.sql(sql).collect()
        print(f" Saved {role} message to history.")
    except Exception as e:
        print(f" Save Message Failed: {e}")



def invoke_cortex_agent(session: Session, payload: Dict, agent_name: str) -> Dict:
    """Invokes 'agent:run'."""
    ENDPOINT = "/api/v2/cortex/agent:run"
    print(f"--- INVOKING AGENT: {agent_name} ---")

    try:
        resp = _snowflake.send_snow_api_request("POST", ENDPOINT, {"Content-Type": "application/json", "Accept": "text/event-stream"}, {}, payload, {}, 120000)
        content = resp.get("content")
        if not content: return {"error": "Empty"}
        
        extracted = {"text": "", "tables": [], "charts": [], "sql_generated": None, "sql_explanation": None}
        try: parsed = json.loads(content)
        except: parsed = [json.loads(line) for line in content.splitlines() if line.strip()]
        
        def process_event(evt, data):
            if evt == 'response.text.delta': 
                extracted["text"] += data.get('text', '')
            elif evt == 'response.chart': 
                extracted["charts"].append(data.get('chart') or data.get('chart_spec'))
                print(extracted["charts"])
            elif evt == 'response.table':
                rs = data.get('result_set', [])
                extracted["tables"].append(rs) 
            elif evt == 'response.tool_result.analyst.delta':
                print('response.tool_result.analyts.delt')
                print(delta)
                delta = data.get('delta', {})
                if delta.get('sql'): extracted["sql_generated"] = delta.get('sql')
                if delta.get('sql_explanation'): extracted["sql_explanation"] = delta.get('sql_explanation')
                if delta.get('result_set'): extracted["tables"].append(delta.get('result_set'))
            elif evt == 'response.tool_result':
                for item in data.get('content', []):
                    if item.get('type') == 'json':
                        json_p = item.get('json', {})
                        if 'sql' in json_p: extracted["sql_generated"] = json_p['sql']
                        if 'result_set' in json_p: extracted["tables"].append(json_p['result_set'])

        if isinstance(parsed, list):
            for item in parsed: process_event(item.get('event'), item.get('data', {}))
        
        return extracted
    except Exception as e: return {"error": str(e)}

def extract_pydantic_from_text(text: str, model_class: type[BaseModel]) -> BaseModel:
    """Robust JSON extraction."""
    if not text: return model_class()
    def try_parse(json_str):
        try: return json.loads(json_str)
        except: 
            try: return json.loads(json_str, strict=False)
            except: return None

    match = re.search(r'```json\s*(\{.*?\})\s*```', text, re.DOTALL)
    if match:
        data = try_parse(match.group(1))
        if data: 
            try: return model_class(**data)
            except: pass 

    start = text.find('{')
    end = text.rfind('}')
    if start != -1 and end != -1:
        data = try_parse(text[start:end+1])
        if data: 
            try: return model_class(**data)
            except: pass

    if model_class == RephraserOutput:
        return RephraserOutput(refined_query=text.strip())

    return model_class()

def check_input_guard(session: Session, user_input: str) -> GuardResult:
    try:
        safe_input = user_input.replace("'", "''")
        res = session.sql(f"SELECT SNOWFLAKE.CORTEX.COMPLETE('{CONFIG.model}', [{{'role': 'user', 'content': '{safe_input}'}}], {{'guardrails': true}}) as r").collect()
        if not res: return GuardResult(is_safe=True)
        is_unsafe = "Response filtered" in json.loads(res[0]['R'])['choices'][0]['messages']
        return GuardResult(is_safe=not is_unsafe, message="Blocked." if is_unsafe else None)
    except: return GuardResult(is_safe=True)

class PayloadFactory:
    @staticmethod
    def create(query: str, instructions: Any, tools: List = None, resources: Dict = None, history: List = None) -> Dict:
        messages = (history if history else []) + [{"role": "user", "content": [{"type": "text", "text": query}]}]
        inst_payload = instructions if isinstance(instructions, dict) else {"system": instructions}
        return {
            "messages": messages,
            "models": {"orchestration": CONFIG.model},
            "instructions": inst_payload,
            "tools": tools or [],
            "tool_resources": resources or {}
        }

def _save_audit_row(session: Session, data: dict, session_id: str):
    """Saves detailed execution logs."""
    try:
        data['SESSION_ID'] = session_id
        # Add Timestamp to ensure non-empty DataFrame if needed, though dict should suffice
        if 'CREATED_AT' not in data:
             data['CREATED_AT'] = datetime.datetime.now().isoformat()
             
        df = session.create_dataframe([data])
        # Force column ordering if possible or just use save_as_table default behavior
        # Note: If target table has 19 columns, and we provide 19 keys in 'data', it should map correctly.
        df.write.mode("append").save_as_table(CONFIG.audit_log_table)
        print(f" Audit log saved.")
    except Exception as e: print(f" Audit Log Error: {e}")


def get_cortex_completion(session: Session, prompt: str) -> str:
    try:
        safe_prompt = prompt.replace("'", "''")
        cmd = f"SELECT SNOWFLAKE.CORTEX.COMPLETE('{CONFIG.model}', '{safe_prompt}') as R"
        return session.sql(cmd).collect()[0]['R']
    except Exception as e: return ""
def get_cortex_completion(session: Session, prompt: str) -> str:
    try:
        safe_prompt = prompt.replace("'", "''")
        cmd = f"SELECT SNOWFLAKE.CORTEX.COMPLETE('{CONFIG.model}', '{safe_prompt}') as R"
        return session.sql(cmd).collect()[0]['R']
    except Exception as e: return ""

# ==========================================
# 5. SEMANTIC VIEW PARSER
# ==========================================

class SemanticViewParser:
    def __init__(self, session: Session, view_name: str):
        self.session = session
        self.view_name = view_name
        self.ca_json = {"tables": [], "relationships": []}
        self.table_comments = {} 
        self.column_metadata = defaultdict(lambda: defaultdict(dict)) 
        self.rel_metadata = defaultdict(dict) 
        # Note: We do NOT parse in __init__ to satisfy "orchestrator only" constraint.
        self.is_loaded = False

    def _fetch_and_parse(self):
        if self.is_loaded: return
        print(f" DESCRIBING SEMANTIC VIEW: {self.view_name}...")
        try:
            rows = self.session.sql(f"DESCRIBE SEMANTIC VIEW {self.view_name}").collect()
            data = [row.as_dict() for row in rows]
            ca_row = next((r for r in data if r.get('object_kind') == 'EXTENSION' and r.get('object_name') == 'CA'), None)
            if ca_row: self.ca_json = json.loads(ca_row['property_value'])

            for r in data:
                kind = r.get('object_kind')
                name = r.get('object_name')
                prop = r.get('property')
                val = r.get('property_value')
                
                if kind == 'TABLE' and prop == 'COMMENT':
                    self.table_comments[name.split('.')[-1]] = val
                elif kind in ['DIMENSION', 'FACT', 'COLUMN']:
                    t_name = r.get('parent_entity', '').split('.')[-1]
                    if t_name:
                        if prop == 'COMMENT': self.column_metadata[t_name][name]['description'] = val
                        elif prop == 'DATA_TYPE': self.column_metadata[t_name][name]['data_type'] = val
                elif kind == 'RELATIONSHIP':
                    if prop == 'TABLE': self.rel_metadata[name]['source_table'] = val.split('.')[-1]
                    elif prop == 'REF_TABLE': self.rel_metadata[name]['target_table'] = val.split('.')[-1]
                    elif prop == 'FOREIGN_KEY': self.rel_metadata[name]['keys'] = val
            
            self.is_loaded = True
            print(f" Metadata Loaded from {self.view_name}")
        except Exception as e: print(f" Metadata Parse Failed: {e}")

    def get_context_summary(self) -> str:
        """Returns a summarized string of the schema for LLM Context (Master)."""
        self._fetch_and_parse() # Load on demand
        summary = "Available Data Schema:\n"
        for t in self.ca_json.get('tables', []):
            summary += f"- Table: {t.get('name')}\n"
            summary += f"  Columns: {', '.join([c['name'] for c in t.get('dimensions', []) + t.get('facts', [])])}\n"
        return summary

    def get_table_summaries(self) -> str:
        """Returns detailed table summaries for selection."""
        self._fetch_and_parse()
        summary_list = []
        for t in self.ca_json.get('tables', []):
            t_name = t.get('name')
            desc = self.table_comments.get(t_name, "No description.")
            summary_list.append(f"- Table: {t_name}\n  Description: {desc}")
        return "\n".join(summary_list) if summary_list else ""

    def get_pruned_context(self, selected_tables: List[str]) -> str:
        """Generates a pruned JSON schema based on selected tables."""
        self._fetch_and_parse()
        pruned = {"tables": [], "relationships": []}
        for t in self.ca_json.get('tables', []):
            t_name = t['name']
            if t_name in selected_tables:
                table_copy = t.copy()
                table_copy['description'] = self.table_comments.get(t_name, "")
                for category in ['dimensions', 'facts', 'time_dimensions']:
                    if category in table_copy:
                        enriched_cols = []
                        for col in table_copy[category]:
                            col_copy = col.copy()
                            meta = self.column_metadata[t_name].get(col['name'], {})
                            if 'description' in meta: col_copy['description'] = meta['description']
                            if 'data_type' in meta: col_copy['data_type'] = meta['data_type']
                            enriched_cols.append(col_copy)
                        table_copy[category] = enriched_cols
                pruned['tables'].append(table_copy)
        
        if 'relationships' in self.ca_json:
            for rel in self.ca_json['relationships']:
                r_name = rel.get('name')
                source = self.rel_metadata.get(r_name, {}).get('source_table')
                if source in selected_tables:
                    pruned['relationships'].append(rel)
        return json.dumps(pruned, indent=2)

# ==========================================
# 6. AGENT MANAGER
# ==========================================

class AgentManager:
    def __init__(self, session: Session):
        self.session = session
        # We only initialize the Parser object, we DO NOT load data here.
        # Data loading happens inside run_data_orchestrator calls.
        self.parser = SemanticViewParser(session, CONFIG.cortex_analyst_object_master)

    def identify_needed_tables(self, query: str) -> List[str]:
        print(" IDENTIFYING RELEVANT TABLES...")
        summaries = self.parser.get_table_summaries() # Triggers load if needed
        if not summaries: return []
        prompt = f"{PROMPT_TABLE_SELECTION}\n\nUser Query: {query}\n\nTable Summaries:\n{summaries}"
        res_text = get_cortex_completion(self.session, prompt)
        result = extract_pydantic_from_text(res_text, TableSelection)
        print(f" Selected: {result.relevant_table_names}")
        return result.relevant_table_names

    def run_semantic_translator(self, query: str, relevant_tables: List[str]) -> str:
        print(f" REWRITING QUERY...")
        pruned_json = self.parser.get_pruned_context(relevant_tables)
        prompt = f"{PROMPT_SEMANTIC_TRANSLATOR}\n\nSchema Context:\n{pruned_json}\n\nUser Query: {query}"
        return get_cortex_completion(self.session, prompt).strip()

    def run_rephraser(self, query: str, history: List[Dict]) -> RephraserOutput:
        inst = {
            "system": PROMPT_REPHRASER_SYSTEM,
            "orchestration": PROMPT_REPHRASER_ORCHESTRATION,
            "response": PROMPT_REPHRASER_RESPONSE
        }
        payload = PayloadFactory.create(query, inst, history=history)
        resp = invoke_cortex_agent(self.session, payload, "Rephraser Agent")
        return extract_pydantic_from_text(resp.get("text", ""), RephraserOutput)

    def run_intent_classifier(self, query: str) -> IntentClassification:
        inst = {
            "system": PROMPT_INTENT_SYSTEM, 
            "orchestration": PROMPT_INTENT_ORCHESTRATION,
            "response": PROMPT_INTENT_RESPONSE
        }
        payload = PayloadFactory.create(query, inst)
        resp = invoke_cortex_agent(self.session, payload, "Intent Agent")
        return extract_pydantic_from_text(resp.get("text", ""), IntentClassification)

    def run_data_agent(self, query: str, schema_context: Optional[str] = None, is_optimized: bool = False) -> SqlResult:
        # Determine correct object and context
        target_view = CONFIG.cortex_analyst_object_ards if is_optimized else CONFIG.cortex_analyst_object_master
        
        tools = [{"tool_spec": {"type": "cortex_analyst_text_to_sql", "name": "analyst_tool"}}]
        res_def = {
            "analyst_tool": {
                "type": "cortex_analyst_text_to_sql",
                "semantic_view": target_view, 
                "execution_environment": {"type": "warehouse", "warehouse": CONFIG.warehouse}
            }
        }
        
        # Inject Master Schema Context into System Prompt if provided
        system_prompt = PROMPT_DATA_AGENT_SYSTEM
        if is_optimized == False:
             system_prompt += f"Enrich the user question with the below schema. \n\nMASTER SCHEMA CONTEXT:\n{CONFIG.cortex_analyst_object_master}"
        
        inst = {
            "system": system_prompt, 
            "orchestration": PROMPT_DATA_AGENT_ORCHESTRATION,
            "response": PROMPT_DATA_AGENT_RESPONSE
        }
        payload = PayloadFactory.create(query, inst, tools, res_def)
        resp = invoke_cortex_agent(self.session, payload, "Data Agent" + (" (Optimized)" if is_optimized else ""))
        
        raw_text = resp.get('text', '')
        parsed = extract_pydantic_from_text(raw_text, SqlResult)
        
        parsed.tables = resp.get('tables', [])
        parsed.sql_generated = resp.get('sql_generated')
        parsed.sql_explanation = resp.get('sql_explanation')
        parsed.charts = resp.get('charts')
        return parsed

    def run_data_flow_orchestrator(self, query: str) -> SqlResult:
        """Handles standard execution vs optimized self-healing execution via parallelism."""
        
        def run_optimization_sequence():
            try:
                # Optimization logic...
                needed_tables = self.identify_needed_tables(query)
                if needed_tables:
                    optimized_q = self.run_semantic_translator(query, needed_tables)
                    print(f" Optimized Query: {optimized_q}")
                    # No schema context needed for optimized run (relies on translation + ARDS view)
                    return self.run_data_agent(optimized_q, schema_context=None, is_optimized=True)
            except Exception as e:
                print(f"Optimization failed: {e}")
            return SqlResult(clean_answer_text="Optimization Failed", evaluation=EvaluationResult(score=0))

        def run_standard_sequence():
    
            return self.run_data_agent(query, schema_context=None, is_optimized=False)

        print(" Starting Data Agent Flows (Standard & Optimized)...")
        with ThreadPoolExecutor(max_workers=2) as executor:
            future_std = executor.submit(run_standard_sequence)
            future_opt = executor.submit(run_optimization_sequence)
            res_std = future_std.result()
            res_opt = future_opt.result()

        print(f" Standard Score: {res_std.evaluation.score} | Optimized Score: {res_opt.evaluation.score}")
        
        # Decision Logic
        if res_std.evaluation.score >= 8:
            return res_std
        elif (res_std.evaluation.score < 8 and res_opt.evaluation.score < 8) or \
             (res_std.evaluation.score == res_opt.evaluation.score and res_std.evaluation.score > 0):
             
             print(" Scores Low/Equal. Combining Summaries.")
             base = res_opt if res_opt.evaluation.score > 0 else res_std
             combined_text = (f"**Standard Analysis:**\n{res_std.clean_answer_text}\n\n"
                              f"**Deep Context Analysis:**\n{res_opt.clean_answer_text}")
             
             final_res = SqlResult(
                 clean_answer_text=combined_text,
                 tables=base.tables,
                 charts=base.charts,
                 sql_generated=base.sql_generated, 
                 sql_explanation=base.sql_explanation,
                 evaluation=base.evaluation,
                 is_retry=True
             )
             return final_res
        elif res_opt.evaluation.score > res_std.evaluation.score:
            print(f" Switched to Optimized Result (Score: {res_opt.evaluation.score})")
            res_opt.is_retry = True
            return res_opt
            
        return res_std
    def run_root_cause_agent(self, query: str) -> DiagnosticResult:
        tools = [{"tool_spec": {"type": "generic", "name": "Diagnostic_tool", "input_schema": {"type": "object", "properties": {"USER_QUERY": {"type": "string"}, "PARENT_NODE_IDS_JSON": {"type": "string"}, "TREE_ID": {"type": "string"}}, "required": ["USER_QUERY", "PARENT_NODE_IDS_JSON", "TREE_ID"]}}}]
        res_def = {"Diagnostic_tool": {"type": "procedure", "execution_environment": {"type": "warehouse", "warehouse": CONFIG.warehouse}, "identifier": CONFIG.diagnostic_udf}}
        
        
        
        inst = {
            "system": PROMPT_REPHRASER_SYSTEM, 
            "orchestration": PROMPT_ROOT_CAUSE_ORCHESTRATION,
            "response": PROMPT_ROOT_CAUSE_RESPONSE
        }
        payload = PayloadFactory.create(query, inst, tools, res_def)
        resp = invoke_cortex_agent(self.session, payload, "Root Cause Agent")
        
        raw_text = resp.get('text', '')
        parsed = extract_pydantic_from_text(raw_text, DiagnosticResult)

        return parsed

# ==========================================
# 7. MAIN EXECUTION
# ==========================================

def main(session: Session):
    """Main Orchestrator Entry Point."""
    manager = AgentManager(session)
    session_id:str="1111"
    user_query:str="give me the top 10 prescribers from arizona"
    # Fully initialize row_data with ALL 19 columns to match schema requirements
    # and default to None where appropriate to prevent 'expecting 19 got 9' errors.
    row_data = {
        "SESSION_ID": session_id,
        "USER_QUERY": user_query,
        "REPHRASED_QUERY": None,
        "INTENT_TYPE": None,
        "INTENT_CONFIDENCE": None, # Added
        "DATA_SUMMARY": None,
        "DATA_SQL": None,          # Added
        "DATA_SQL_EXPLANATION": None, # Added
        "DATA_CLARIFICATION": None,   # Added
        "DATA_RESULT_SET": None,    # Added
        "DATA_EVAL_SCORE": None,    # Added
        "DATA_EVAL_REASONING": None, # Added
        "RC_SUMMARY": None,
        "RC_GRAPH_JSON": None,      # Added
        "RC_EVAL_SCORE": None,      # Added
        "RC_EVAL_REASONING": None,  # Added
        "IS_BLOCKED": False,
        "FULL_RAW_JSON": None
        # CREATED_AT handled by _save_audit_row if missing, or schema default
    }
    
    log_checkpoint("MAIN: START", {"query": user_query, "session": session_id})

    # 1. Fetch History
    history = get_chat_history(session, session_id)

    # 2. Input Guard
    guard = check_input_guard(session, user_query)
    if not guard.is_safe:
        row_data["IS_BLOCKED"] = True
        _save_audit_row(session, row_data, session_id)
        return {"status": "blocked", "message": guard.message}

    # 3. Save User Message
    save_chat_message(session, session_id, "user", user_query)

    # 4. Rephrase
    rephrased = manager.run_rephraser(user_query, history)
    effective_query = rephrased.refined_query or user_query
    
    # 5. Intent Classification
    intent = manager.run_intent_classifier(effective_query)
    
    row_data["REPHRASED_QUERY"] = effective_query
    row_data["INTENT_TYPE"] = intent.intent_type
    row_data["INTENT_CONFIDENCE"] = intent.confidence

    final_output = {
        "original": user_query, 
        "processed": effective_query, 
        "intent": intent.model_dump(), 
        "results": []
    }

    bot_response_text = ""

    # 6. Execute based on Intent
    if intent.direct_response:
        msg = intent.direct_response
        final_output["results"].append({"type": "direct", "message": msg})
        bot_response_text = msg

    else:
        futures = {}
        with ThreadPoolExecutor(max_workers=2) as executor:
            
            # Data Flow (Uses Parallel Orchestrator)
            if intent.intent_type in ["data_retrieval", "combined", "clarification_needed"]:
                q = intent.data_retrieval_query or effective_query
                futures["data"] = executor.submit(manager.run_data_flow_orchestrator, q)
            
            # Root Cause Flow
            if intent.intent_type in ["root_cause_analysis", "combined"]:
                q = intent.root_cause_query or effective_query
                futures["rc"] = executor.submit(manager.run_root_cause_agent, q)

        # Process Results
        if "data" in futures:
            res = futures["data"].result()
            res_dump = res.model_dump()
            
            row_data["DATA_EVAL_SCORE"] = res.evaluation.score
            row_data["DATA_EVAL_REASONING"] = res.evaluation.reasoning
            row_data["DATA_SQL"] = res.sql_generated
            row_data["DATA_SQL_EXPLANATION"] = res.sql_explanation
            if res.tables: row_data["DATA_RESULT_SET"] = res.tables # FIXED: Pass list directly for Variant
            
            if res.clarifying_question:
                response_text = res.clarifying_question
                final_output["results"].append({
                    "type": "clarification", 
                    "message": response_text,
                    "full_pydantic_object": res_dump 
                })
                row_data["DATA_CLARIFICATION"] = response_text
            else:
                response_text = res.clean_answer_text
                final_output["results"].append({
                    "type": "data_analysis", 
                    "summary": response_text, 
                    "tables": res.tables,
                    "charts": res.charts, # Added charts here
                    "full_pydantic_object": res_dump 
                })
                row_data["DATA_SUMMARY"] = response_text
            
            bot_response_text += response_text + "\n"

        if "rc" in futures:
            res_rc = futures["rc"].result()
            res_rc_dump = res_rc.model_dump()
            
            row_data["RC_EVAL_SCORE"] = res_rc.evaluation.score
            row_data["RC_EVAL_REASONING"] = res_rc.evaluation.reasoning
            
            if res_rc.clarifying_question:
                response_text = res_rc.clarifying_question
                final_output["results"].append({
                    "type": "clarification", 
                    "message": response_text,
                    "full_pydantic_object": res_rc_dump 
                })
            else:
                response_text = res_rc.clean_summary_text
                final_output["results"].append({
                    "type": "root_cause", 
                    "summary": response_text, 
                    "graph": res_rc.react_flow_json,
                    "full_pydantic_object": res_rc_dump 
                })
            
            bot_response_text += response_text + "\n"
            row_data["RC_SUMMARY"] = res_rc.clean_summary_text
            if res_rc.react_flow_json: row_data["RC_GRAPH_JSON"] = res_rc.react_flow_json # FIXED: Pass dict directly

    # 7. Save Bot Response
    if bot_response_text:
        # Save structured metadata to METADATA column
        message_metadata = {
            "intent_data": intent.model_dump(),
            "sql_generated": row_data.get("DATA_SQL"),
            "is_blocked": row_data.get("IS_BLOCKED"),
            "tool_artifacts": final_output.get("results"), # Contains full pydantic dump including charts
            "generated_at": datetime.datetime.now().isoformat()
        }
        
        save_chat_message(session, session_id, "assistant", bot_response_text.strip(), metadata=message_metadata)

    # 8. Save Audit Log
    row_data["FULL_RAW_JSON"] = final_output # FIXED: Pass dict directly for Variant
    _save_audit_row(session, row_data, session_id)
    
    print(" Process Completed")
    return final_output

if __name__ == "__main__":
    pass



 Switched to Optimized Result (Score: 9)
/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/pydantic/main.py:364: UserWarning: Pydantic serializer warnings:
  Expected `dict[any, any]` but got `str` - serialized value may not be as expected
  Expected `dict[any, any]` but got `str` - serialized value may not be as expected
  return self.__pydantic_serializer__.to_python(
 Save Message Failed: (1304): 01c202ff-081a-368c-0075-0383fdc1d4ba: 001003 (42000): 01c202ff-081a-368c-0075-0383fdc1d4ba: SQL compilation error:
syntax error line 4 at position 30 unexpected '%'.
syntax error line 4 at position 29 unexpected '('.
 Audit Log Error: (1304): 01c202ff-081a-368c-0075-0383fdc1d4ce: 002023 (22000): 01c202ff-081a-368c-0075-0383fdc1d4ce: SQL compilation error:
Expression type does not match column data type, expecting VARIANT but got VARCHAR(134217728) for column FULL_RAW_JSON
 Process Completed
Databases
Worksheets
Data products
Try nested folders in Workspaces

In Workspaces, organize your files by putting folders in folders.
    results_cursor = self.execute_and_notify_query_listener(
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/snowpark/_internal/server_connection.py", line 459, in execute_and_notify_query_listener
    raise ex
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/snowpark/_internal/server_connection.py", line 450, in execute_and_notify_query_listener
    results_cursor = self._cursor.execute(query, **kwargs)
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/connector/cursor.py", line 1142, in execute
    Error.errorhandler_wrapper(self.connection, self, error_class, errvalue)
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/connector/errors.py", line 286, in errorhandler_wrapper
    handed_over = Error.hand_to_other_handler(
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/connector/errors.py", line 341, in hand_to_other_handler
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/connector/errors.py", line 217, in default_errorhandler
    raise error_class(
snowflake.snowpark.exceptions.SnowparkSQLException: (1304): 01c2031a-081a-3683-0075-0383fdc61cfa: 002020 (21S01): 01c2031a-081a-3683-0075-0383fdc61cfa: SQL compilation error:
Insert value list does not match column list expecting 22 but got 21
 Process Completed
  Total Execution Time: 113726ms
Databases
Worksheets
Data products
Try nested folders in Workspaces

In Workspaces, organize your files by putting folders in folders.

Search


    results_cursor = self.execute_and_notify_query_listener(
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/snowpark/_internal/server_connection.py", line 459, in execute_and_notify_query_listener
    raise ex
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/snowpark/_internal/server_connection.py", line 450, in execute_and_notify_query_listener
    results_cursor = self._cursor.execute(query, **kwargs)
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/connector/cursor.py", line 1142, in execute
    Error.errorhandler_wrapper(self.connection, self, error_class, errvalue)
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/connector/errors.py", line 286, in errorhandler_wrapper
    handed_over = Error.hand_to_other_handler(
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/connector/errors.py", line 341, in hand_to_other_handler
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/connector/errors.py", line 217, in default_errorhandler
    raise error_class(
snowflake.snowpark.exceptions.SnowparkSQLException: (1304): 01c2031a-081a-3683-0075-0383fdc61cfa: 002020 (21S01): 01c2031a-081a-3683-0075-0383fdc61cfa: SQL compilation error:
Insert value list does not match column list expecting 22 but got 21
 Process Completed
  Total Execution Time: 113726ms
Databases
Worksheets
Data products
Try nested folders in Workspaces

In Workspaces, organize your files by putting folders in folders.

Search
    results_cursor = self.execute_and_notify_query_listener(
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/snowpark/_internal/server_connection.py", line 459, in execute_and_notify_query_listener
    raise ex
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/snowpark/_internal/server_connection.py", line 450, in execute_and_notify_query_listener
    results_cursor = self._cursor.execute(query, **kwargs)
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/connector/cursor.py", line 1142, in execute
    Error.errorhandler_wrapper(self.connection, self, error_class, errvalue)
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/connector/errors.py", line 286, in errorhandler_wrapper
    handed_over = Error.hand_to_other_handler(
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/connector/errors.py", line 341, in hand_to_other_handler
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/connector/errors.py", line 217, in default_errorhandler
    raise error_class(
snowflake.snowpark.exceptions.SnowparkSQLException: (1304): 01c2031a-081a-3683-0075-0383fdc61cfa: 002020 (21S01): 01c2031a-081a-3683-0075-0383fdc61cfa: SQL compilation error:
Insert value list does not match column list expecting 22 but got 21
 Process Completed
  Total Execution Time: 113726ms
Databases
Worksheets
Data products
Try nested folders in Workspaces

In Workspaces, organize your files by putting folders in folders.

Search
    results_cursor = self.execute_and_notify_query_listener(
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/snowpark/_internal/server_connection.py", line 459, in execute_and_notify_query_listener
    raise ex
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/snowpark/_internal/server_connection.py", line 450, in execute_and_notify_query_listener
    results_cursor = self._cursor.execute(query, **kwargs)
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/connector/cursor.py", line 1142, in execute
    Error.errorhandler_wrapper(self.connection, self, error_class, errvalue)
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/connector/errors.py", line 286, in errorhandler_wrapper
    handed_over = Error.hand_to_other_handler(
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/connector/errors.py", line 341, in hand_to_other_handler
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/connector/errors.py", line 217, in default_errorhandler
    raise error_class(
snowflake.snowpark.exceptions.SnowparkSQLException: (1304): 01c2031a-081a-3683-0075-0383fdc61cfa: 002020 (21S01): 01c2031a-081a-3683-0075-0383fdc61cfa: SQL compilation error:
Insert value list does not match column list expecting 22 but got 21
 Process Completed
  Total Execution Time: 113726ms
Databases
Worksheets
Data products
Try nested folders in Workspaces

In Workspaces, organize your files by putting folders in folders.

Search
    results_cursor = self.execute_and_notify_query_listener(
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/snowpark/_internal/server_connection.py", line 459, in execute_and_notify_query_listener
    raise ex
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/snowpark/_internal/server_connection.py", line 450, in execute_and_notify_query_listener
    results_cursor = self._cursor.execute(query, **kwargs)
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/connector/cursor.py", line 1142, in execute
    Error.errorhandler_wrapper(self.connection, self, error_class, errvalue)
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/connector/errors.py", line 286, in errorhandler_wrapper
    handed_over = Error.hand_to_other_handler(
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/connector/errors.py", line 341, in hand_to_other_handler
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/connector/errors.py", line 217, in default_errorhandler
    raise error_class(
snowflake.snowpark.exceptions.SnowparkSQLException: (1304): 01c2031a-081a-3683-0075-0383fdc61cfa: 002020 (21S01): 01c2031a-081a-3683-0075-0383fdc61cfa: SQL compilation error:
Insert value list does not match column list expecting 22 but got 21
 Process Completed
  Total Execution Time: 113726ms
Databases
Worksheets
Data products
Try nested folders in Workspaces

In Workspaces, organize your files by putting folders in folders.

Search


Search





 Audit Log Error: (1304): 01c2031a-081a-3683-0075-0383fdc61cfa: 002020 (21S01): 01c2031a-081a-3683-0075-0383fdc61cfa: SQL compilation error:
Insert value list does not match column list expecting 22 but got 21
Traceback (most recent call last):
  File "_udf_code.py", line 1640, in _save_audit_row
    df.write.mode("append").save_as_table(CONFIG.audit_log_table)
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/snowpark/_internal/telemetry.py", line 333, in wrap
    result = func(*args, **kwargs)
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/snowpark/_internal/utils.py", line 1148, in call_wrapper
    return func(*args, **kwargs)
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/snowpark/dataframe_writer.py", line 570, in save_as_table
    result = session._conn.execute(
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/snowpark/_internal/server_connection.py", line 648, in execute
    result_set, result_meta = self.get_result_set(
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/snowpark/_internal/analyzer/snowflake_plan.py", line 426, in wrap
    raise ne.with_traceback(tb) from None
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/snowpark/_internal/analyzer/snowflake_plan.py", line 179, in wrap
    return func(*args, **kwargs)
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/snowpark/_internal/server_connection.py", line 770, in get_result_set
    result = self.run_query(
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/snowpark/_internal/server_connection.py", line 137, in wrap
    raise ex
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/snowpark/_internal/server_connection.py", line 131, in wrap
    return func(*args, **kwargs)
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/snowpark/_internal/server_connection.py", line 544, in run_query
    raise ex
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/snowpark/_internal/server_connection.py", line 529, in run_query
    results_cursor = self.execute_and_notify_query_listener(
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/snowpark/_internal/server_connection.py", line 459, in execute_and_notify_query_listener
    raise ex
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/snowpark/_internal/server_connection.py", line 450, in execute_and_notify_query_listener
    results_cursor = self._cursor.execute(query, **kwargs)
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/connector/cursor.py", line 1142, in execute
    Error.errorhandler_wrapper(self.connection, self, error_class, errvalue)
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/connector/errors.py", line 286, in errorhandler_wrapper
    handed_over = Error.hand_to_other_handler(
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/connector/errors.py", line 341, in hand_to_other_handler
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/connector/errors.py", line 217, in default_errorhandler
    raise error_class(
snowflake.snowpark.exceptions.SnowparkSQLException: (1304): 01c2031a-081a-3683-0075-0383fdc61cfa: 002020 (21S01): 01c2031a-081a-3683-0075-0383fdc61cfa: SQL compilation error:
Insert value list does not match column list expecting 22 but got 21
 Process Completed
  Total Execution Time: 113726ms




Insert value list does not match column list expecting 7 but got 5
 Saved assistant message via SQL fallback.
 Audit Log Error: (1304): 01c2031a-081a-3683-0075-0383fdc61cfa: 002020 (21S01): 01c2031a-081a-3683-0075-0383fdc61cfa: SQL compilation error:
Insert value list does not match column list expecting 22 but got 21
Traceback (most recent call last):
  File "_udf_code.py", line 1640, in _save_audit_row
    df.write.mode("append").save_as_table(CONFIG.audit_log_table)
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/snowpark/_internal/telemetry.py", line 333, in wrap
    result = func(*args, **kwargs)
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/snowpark/_internal/utils.py", line 1148, in call_wrapper
    return func(*args, **kwargs)
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/snowpark/dataframe_writer.py", line 570, in save_as_table
    result = session._conn.execute(
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/snowpark/_internal/server_connection.py", line 648, in execute
    result_set, result_meta = self.get_result_set(
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/snowpark/_internal/analyzer/snowflake_plan.py", line 426, in wrap
    raise ne.with_traceback(tb) from None
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/snowpark/_internal/analyzer/snowflake_plan.py", line 179, in wrap
    return func(*args, **kwargs)
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/snowpark/_internal/server_connection.py", line 770, in get_result_set
    result = self.run_query(
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/snowpark/_internal/server_connection.py", line 137, in wrap
    raise ex
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/snowpark/_internal/server_connection.py", line 131, in wrap
    return func(*args, **kwargs)
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/snowpark/_internal/server_connection.py", line 544, in run_query
    raise ex
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/snowpark/_internal/server_connection.py", line 529, in run_query
    results_cursor = self.execute_and_notify_query_listener(
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/snowpark/_internal/server_connection.py", line 459, in execute_and_notify_query_listener
    raise ex
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/snowpark/_internal/server_connection.py", line 450, in execute_and_notify_query_listener
    results_cursor = self._cursor.execute(query, **kwargs)
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/connector/cursor.py", line 1142, in execute
    Error.errorhandler_wrapper(self.connection, self, error_class, errvalue)
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/connector/errors.py", line 286, in errorhandler_wrapper
    handed_over = Error.hand_to_other_handler(
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/connector/errors.py", line 341, in hand_to_other_handler
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/connector/errors.py", line 217, in default_errorhandler
    raise error_class(
snowflake.snowpark.exceptions.SnowparkSQLException: (1304): 01c2031a-081a-3683-0075-0383fdc61cfa: 002020 (21S01): 01c2031a-081a-3683-0075-0383fdc61cfa: SQL compilation error:
Insert value list does not match column list expecting 22 but got 21
 Process Completed
  Total Execution Time: 113726ms
Databases
Worksheets
Data products
Try nested folders in Workspaces

In Workspaces, organize your files by putting folders in folders.

Search

==================================================
 CHECKPOINT: MAIN: START
--------------------------------------------------
{'query': 'give me the top 10 prescribers from arizona', 'session': '1111'}
==================================================
 Retrieved 0 past messages for Session 1111
 Save Message Failed: (1304): 01c20318-081a-3683-0075-0383fdc5cc5a: 002020 (21S01): 01c20318-081a-3683-0075-0383fdc5cc5a: SQL compilation error:
Insert value list does not match column list expecting 7 but got 5
 Saved user message via SQL fallback.
--- INVOKING AGENT: Rephraser Agent ---
--- INVOKING AGENT: Intent Agent ---
 Starting Data Agent Flows (Standard & Optimized)...
--- INVOKING AGENT: Data Agent ---
 IDENTIFYING RELEVANT TABLES...
 DESCRIBING SEMANTIC VIEW: DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.AI_POC.MASTERTABLE_V1...
 Metadata Loaded from DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.AI_POC.MASTERTABLE_V1
 Selected: ['MASTER_TABLE_V1']
 REWRITING QUERY...
 Optimized Query: Show me the top 10 HCP_ID ranked by ACUTE_TRX_LAAD_12M where ZIP_CODE is in Arizona
--- INVOKING AGENT: Data Agent (Optimized) ---
['{"$schema": "https://vega.github.io/schema/vega-lite/v5.json", "title": "Top 10 HCP_ID ranked by total ACUTE_TRX_LAAD over the last 12 months in Arizona", "transform": [{"window": [{"op": "rank", "as": "rank"}], "sort": [{"field": "TOTAL_ACUTE_TRX_LAAD", "order": "descending"}]}, {"filter": "datum.rank <= 10"}], "mark": "bar", "encoding": {"x": {"field": "TOTAL_ACUTE_TRX_LAAD", "title": "Total ACUTE TRX LAAD", "type": "quantitative", "sort": null}, "y": {"field": "HCP_ID", "title": "HCP ID", "type": "nominal", "sort": null}, "tooltip": [{"field": "TOTAL_ACUTE_TRX_LAAD", "type": "quantitative", "title": "Total ACUTE TRX LAAD", "format": ",.6~f"}, {"field": "HCP_ID", "type": "nominal", "title": "HCP ID"}]}, "data": {"values": [{"HCP_ID": "0bf82f40f6b804c9df0d8aa6fe6f74bf", "TOTAL_ACUTE_TRX_LAAD": 3132.0}, {"HCP_ID": "ab0584c6fba654da008e10302186feb3", "TOTAL_ACUTE_TRX_LAAD": 2517.0}, {"HCP_ID": "6faf1b18ab6e6fa39503feddec59ed80", "TOTAL_ACUTE_TRX_LAAD": 2448.0}, {"HCP_ID": "893ea63d5966cd84231f8d7547a2ed12", "TOTAL_ACUTE_TRX_LAAD": 1963.0}, {"HCP_ID": "d6795edda2b6ea887378cace5c91f4d4", "TOTAL_ACUTE_TRX_LAAD": 1904.0}, {"HCP_ID": "a38c69fd62b809e1d9ffa22239882138", "TOTAL_ACUTE_TRX_LAAD": 1872.0}, {"HCP_ID": "742751ad30971a025e2387eeec778e11", "TOTAL_ACUTE_TRX_LAAD": 1757.0}, {"HCP_ID": "7b421e990acf702c8150d25adb805681", "TOTAL_ACUTE_TRX_LAAD": 1725.0}, {"HCP_ID": "0ce8797c130fea656290cefe5654c6e3", "TOTAL_ACUTE_TRX_LAAD": 1715.0}, {"HCP_ID": "ae5842733a7f735d6feafbeaf8301eef", "TOTAL_ACUTE_TRX_LAAD": 1605.0}]}}']
['{"$schema": "https://vega.github.io/schema/vega-lite/v5.json", "title": "Top 10 HCP_ID ranked by total ACUTE_TRX_LAAD over the last 12 months in Arizona", "transform": [{"window": [{"op": "rank", "as": "rank"}], "sort": [{"field": "TOTAL_ACUTE_TRX_LAAD", "order": "descending"}]}, {"filter": "datum.rank <= 10"}], "mark": "bar", "encoding": {"x": {"field": "TOTAL_ACUTE_TRX_LAAD", "title": "Total ACUTE TRX LAAD", "type": "quantitative", "sort": null}, "y": {"field": "HCP_ID", "title": "HCP ID", "type": "nominal", "sort": null}, "tooltip": [{"field": "TOTAL_ACUTE_TRX_LAAD", "type": "quantitative", "title": "Total ACUTE TRX LAAD", "format": ",.6~f"}, {"field": "HCP_ID", "type": "nominal", "title": "HCP ID"}]}, "data": {"values": [{"HCP_ID": "0bf82f40f6b804c9df0d8aa6fe6f74bf", "TOTAL_ACUTE_TRX_LAAD": 3132.0}, {"HCP_ID": "ab0584c6fba654da008e10302186feb3", "TOTAL_ACUTE_TRX_LAAD": 2517.0}, {"HCP_ID": "6faf1b18ab6e6fa39503feddec59ed80", "TOTAL_ACUTE_TRX_LAAD": 2448.0}, {"HCP_ID": "893ea63d5966cd84231f8d7547a2ed12", "TOTAL_ACUTE_TRX_LAAD": 1963.0}, {"HCP_ID": "d6795edda2b6ea887378cace5c91f4d4", "TOTAL_ACUTE_TRX_LAAD": 1904.0}, {"HCP_ID": "a38c69fd62b809e1d9ffa22239882138", "TOTAL_ACUTE_TRX_LAAD": 1872.0}, {"HCP_ID": "742751ad30971a025e2387eeec778e11", "TOTAL_ACUTE_TRX_LAAD": 1757.0}, {"HCP_ID": "7b421e990acf702c8150d25adb805681", "TOTAL_ACUTE_TRX_LAAD": 1725.0}, {"HCP_ID": "0ce8797c130fea656290cefe5654c6e3", "TOTAL_ACUTE_TRX_LAAD": 1715.0}, {"HCP_ID": "ae5842733a7f735d6feafbeaf8301eef", "TOTAL_ACUTE_TRX_LAAD": 1605.0}]}}', '{"$schema": "https://vega.github.io/schema/vega-lite/v5.json", "title": "Top 10 HCP_ID ranked by total ACUTE_TRX_LAAD over the last 12 months in Arizona", "transform": [{"window": [{"op": "rank", "as": "rank"}], "sort": [{"field": "TOTAL_ACUTE_TRX_LAAD", "order": "descending"}]}, {"filter": "datum.rank <= 10"}], "mark": "bar", "encoding": {"x": {"field": "TOTAL_ACUTE_TRX_LAAD", "title": "Total ACUTE TRX LAAD", "type": "quantitative", "sort": null}, "y": {"field": "HCP_ID", "title": "HCP ID", "type": "nominal", "sort": null}, "tooltip": [{"field": "TOTAL_ACUTE_TRX_LAAD", "type": "quantitative", "title": "Total ACUTE TRX LAAD", "format": ",.6~f"}, {"field": "HCP_ID", "type": "nominal", "title": "HCP ID"}]}, "data": {"values": [{"HCP_ID": "0bf82f40f6b804c9df0d8aa6fe6f74bf", "TOTAL_ACUTE_TRX_LAAD": 3132.0}, {"HCP_ID": "ab0584c6fba654da008e10302186feb3", "TOTAL_ACUTE_TRX_LAAD": 2517.0}, {"HCP_ID": "6faf1b18ab6e6fa39503feddec59ed80", "TOTAL_ACUTE_TRX_LAAD": 2448.0}, {"HCP_ID": "893ea63d5966cd84231f8d7547a2ed12", "TOTAL_ACUTE_TRX_LAAD": 1963.0}, {"HCP_ID": "d6795edda2b6ea887378cace5c91f4d4", "TOTAL_ACUTE_TRX_LAAD": 1904.0}, {"HCP_ID": "a38c69fd62b809e1d9ffa22239882138", "TOTAL_ACUTE_TRX_LAAD": 1872.0}, {"HCP_ID": "742751ad30971a025e2387eeec778e11", "TOTAL_ACUTE_TRX_LAAD": 1757.0}, {"HCP_ID": "7b421e990acf702c8150d25adb805681", "TOTAL_ACUTE_TRX_LAAD": 1725.0}, {"HCP_ID": "0ce8797c130fea656290cefe5654c6e3", "TOTAL_ACUTE_TRX_LAAD": 1715.0}, {"HCP_ID": "ae5842733a7f735d6feafbeaf8301eef", "TOTAL_ACUTE_TRX_LAAD": 1605.0}]}}']
 Standard Score: 8 | Optimized Score: 9
 Save Message Failed: (1304): 01c2031a-081a-3683-0075-0383fdc61cc6: 002020 (21S01): 01c2031a-081a-3683-0075-0383fdc61cc6: SQL compilation error:
Insert value list does not match column list expecting 7 but got 5
 Saved assistant message via SQL fallback.
 Audit Log Error: (1304): 01c2031a-081a-3683-0075-0383fdc61cfa: 002020 (21S01): 01c2031a-081a-3683-0075-0383fdc61cfa: SQL compilation error:
Insert value list does not match column list expecting 22 but got 21
Traceback (most recent call last):
  File "_udf_code.py", line 1640, in _save_audit_row
    df.write.mode("append").save_as_table(CONFIG.audit_log_table)
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/snowpark/_internal/telemetry.py", line 333, in wrap
    result = func(*args, **kwargs)
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/snowpark/_internal/utils.py", line 1148, in call_wrapper
    return func(*args, **kwargs)
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/snowpark/dataframe_writer.py", line 570, in save_as_table
    result = session._conn.execute(
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/snowpark/_internal/server_connection.py", line 648, in execute
    result_set, result_meta = self.get_result_set(
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/snowpark/_internal/analyzer/snowflake_plan.py", line 426, in wrap
    raise ne.with_traceback(tb) from None
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/snowpark/_internal/analyzer/snowflake_plan.py", line 179, in wrap
    return func(*args, **kwargs)
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/snowpark/_internal/server_connection.py", line 770, in get_result_set
    result = self.run_query(
Databases
Worksheets
Data products
Try nested folders in Workspaces

In Workspaces, organize your files by putting folders in folders.

Search


    return self._session._conn.execute(
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/snowpark/_internal/server_connection.py", line 648, in execute
    result_set, result_meta = self.get_result_set(
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/snowpark/_internal/analyzer/snowflake_plan.py", line 426, in wrap
    raise ne.with_traceback(tb) from None
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/snowpark/_internal/analyzer/snowflake_plan.py", line 179, in wrap
    return func(*args, **kwargs)
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/snowpark/_internal/server_connection.py", line 770, in get_result_set
    result = self.run_query(
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/snowpark/_internal/server_connection.py", line 137, in wrap
    raise ex
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/snowpark/_internal/server_connection.py", line 131, in wrap
    return func(*args, **kwargs)
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/snowpark/_internal/server_connection.py", line 544, in run_query
    raise ex
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/snowpark/_internal/server_connection.py", line 529, in run_query
    results_cursor = self.execute_and_notify_query_listener(
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/snowpark/_internal/server_connection.py", line 459, in execute_and_notify_query_listener
    raise ex
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/snowpark/_internal/server_connection.py", line 450, in execute_and_notify_query_listener
    results_cursor = self._cursor.execute(query, **kwargs)
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/connector/cursor.py", line 1142, in execute
    Error.errorhandler_wrapper(self.connection, self, error_class, errvalue)
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/connector/errors.py", line 286, in errorhandler_wrapper
    handed_over = Error.hand_to_other_handler(
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/connector/errors.py", line 341, in hand_to_other_handler
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/usr/lib/python_udf/6663554fb95721a9f4065a5cde67480069f1a73f0215d55614d1058297a86474/lib/python3.10/site-packages/snowflake/connector/errors.py", line 217, in default_errorhandler
    raise error_class(
snowflake.snowpark.exceptions.SnowparkSQLException: (1304): 01c2032b-081a-3683-0075-0383fdc7cc92: 002014 (22000): 01c2032b-081a-3683-0075-0383fdc7cc92: SQL compilation error:
Invalid expression [PARSE_JSON('[{"data": [["9d2874e648c48c41632a3fc164312154", "83397", "2025-01-31", "2025-10-03", "36547", "1"], ["0bf82f40f6b804c9df0d8aa6fe6f74bf", "3132", "2025-01-31", "2025-10-03", "2210", "1"], ["ab0584c6fba654da008e10302186feb3", "2517", "2025-01-31", "2025-10-03", "1773", "1"], ["6faf1b18ab6e6fa39503feddec59ed80", "2448", "2025-01-31", "2025-10-03", "1789", "1"], ["f14713e706849122cdcf2ffd9b4e9841", "2242", "2025-01-31", "2025-10-03", "914", "1"], ["4888edd38d18efd284d7473e81e70b21", "2174", "2025-01-31", "2025-10-03", "746", "1"], ["26cc431b3390379f937b09518e139782", "2150", "2025-01-31", "2025-10-03", "1043", "1"], ["c6e6c5a2a9e93f8c4bc1f965242b40d3", "2129", "2025-01-31", "2025-10-03", "605", "1"], ["10889a1b4265e0a7d140a831c83b4663", "2086", "2025-01-31", "2025-10-03", "1637", "1"], ["8c7b26e9e607829e09d38491aede7722", "1995", "2025-01-31", "2025-10-03", "1575", "1"]], "resultSetMetaData": {"format": "jsonv2", "numRows": 10, "partition": 0, "partitionInfo": [{"rowCount": 10, "uncompressedSize": 828}], "rowType": [{"length": 32, "name": "HCP_ID", "nullable": false, "precision": 0, "scale": 0, "type": "text"}, {"length": 0, "name": "TOTAL_ACUTE_TRX_LAAD_12M", "nullable": true, "precision": 30, "scale": 0, "type": "fixed"}, {"length": 0, "name": "MIN_DATE", "nullable": true, "precision": 0, "scale": 0, "type": "date"}, {"length": 0, "name": "MAX_DATE", "nullable": true, "precision": 0, "scale": 0, "type": "date"}, {"length": 0, "name": "RECORD_COUNT", "nullable": false, "precision": 18, "scale": 0, "type": "fixed"}, {"length": 0, "name": "UNIQUE_ZIP_CODES", "nullable": false, "precision": 18, "scale": 0, "type": "fixed"}]}, "statementHandle": "01c2032a-081a-3683-0075-0383fdc7c6f6"}]')] in VALUES clause
 Process Completed
  Total Execution Time: 111581ms


import json
import logging
import pprint
import re
import _snowflake # Native Snowflake module for internal API calls
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import List, Dict, Any, Optional, Literal, Tuple
from pydantic import BaseModel, Field, field_validator
from snowflake.snowpark import Session
from snowflake.snowpark.functions import lit, parse_json, col
from collections import defaultdict
import datetime
import traceback

# ==========================================
# 1. CONFIGURATION
# ==========================================

class AgentConfig(BaseModel):
    """Configuration for the agent execution"""
    # LLM Models
    model: str = "claude-sonnet-4-5" 
    
    # Snowflake Objects
    cortex_analyst_object_master: str = "DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.AI_POC.MASTERTABLE_V1"
    cortex_analyst_object_ards: str = "DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.REPORTING.BASIC_CORTEX_ANALYST"
    warehouse: str = "DEV_PAIN_SALES_PERFORMANCE_B_WH"
    
    # Tables - Updated to V2
    messages_table: str = "DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.AI_POC.MESSAGES_V2"
    audit_log_table: str = "DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.AI_POC.AGENT_DETAILED_HISTORY_V2"
    
    
    # Tools
    diagnostic_udf: str = "DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.AI_POC.DIAGNOSTIC_TOOL"
    diagnostic_tree_id: str = "pharma_sales_v3" 
    
    enable_semantic_parsing: bool = True

CONFIG = AgentConfig()

# ==========================================
# 2. PYDANTIC MODELS
# ==========================================

class EvaluationResult(BaseModel):
    score: int = Field(default=0, description="Score 1-10.")
    reasoning: str = Field(default="No evaluation provided.", description="Justification.")

class IntentClassification(BaseModel):
    intent_type: str = Field(..., description="greeting, data_retrieval, root_cause_analysis, clarification_needed, general_question, off_topic, combined")
    data_retrieval_query: Optional[str] = None
    root_cause_query: Optional[str] = None
    direct_response: Optional[str] = None
    clarification_question: Optional[str] = None
    confidence: str = Field(..., description="high, medium, low")
    reasoning: str = Field(..., description="Reasoning")

class RephraserOutput(BaseModel):
    refined_query: str = Field(..., description="The fully contextualized query.")

class TableSelection(BaseModel):
    relevant_table_names: List[str] = Field(..., description="List of table names.")

class GuardResult(BaseModel):
    is_safe: bool = Field(...)
    message: Optional[str] = Field(None)

class SqlResult(BaseModel):
    clean_answer_text: str = Field(default="")
    clarifying_question: Optional[str] = None
    tables: List[Any] = Field(default_factory=list)
    charts: List[Any] = Field(default_factory=list)  # Changed from List[Dict]
    sql_generated: Optional[str] = None
    sql_explanation: Optional[str] = None
    is_verified_query: bool = False
    evaluation: EvaluationResult = Field(default_factory=EvaluationResult)
    is_retry: bool = False

    @field_validator('charts', mode='before')
    @classmethod
    def parse_charts(cls, v):
        if not v: 
            return []
        parsed = []
        for item in v:
            if isinstance(item, dict): 
                parsed.append(item)
            elif isinstance(item, str):
                try: 
                    parsed_item = json.loads(item)
                    parsed.append(parsed_item)
                except: 
                    # Keep as string if can't parse
                    parsed.append(item)
        return parsed

class DiagnosticResult(BaseModel):
    clean_summary_text: str = Field(default="")
    clarifying_question: Optional[str] = None
    react_flow_json: Optional[Dict] = None
    evaluation: EvaluationResult = Field(default_factory=EvaluationResult)

# ==========================================
# 3. PROMPTS (RESTORED & ENHANCED)
# ==========================================

# --- REPHRASER ---
PROMPT_REPHRASER_SYSTEM = "You are a sophisticated Query Refinement Engine. Be polite, professional, and friendly. Be direct and unambiguous."

PROMPT_REPHRASER_ORCHESTRATION = """
<query_refinement_instructions>
<objective>
Transform the user's input into a standalone, context-complete query that can be understood without prior conversation history.
</objective>

<core_rules>
<rule id="1">Resolve all pronouns (it, they, that, this, those) to their specific referents based on chat history.</rule>
<rule id="2">Preserve ALL metrics, entity names, IDs, and numerical values EXACTLY as stated.</rule>
<rule id="3">Maintain the original intent and scope - do not expand or narrow the question.</rule>
<rule id="4">Keep technical terminology and domain-specific language intact.</rule>
<rule id="5">Ensure the output is grammatically correct and reads naturally.</rule>
</core_rules>

<follow_up_handling_rules>
<rule id="6">IF previous Bot response contained Data (e.g., "Sales are down") AND User asks "Why?", REPHRASE to "Why are sales down?"</rule>
<rule id="7">IF previous Bot response was a Clarification (e.g., "By region?"), AND User answers "Region", REPHRASE to combine them.</rule>
</follow_up_handling_rules>

<transformation_examples>
<example>
<input>What about Arizona?</input>
<context>Previous discussion about sales performance in Texas</context>
<output>What is the sales performance in Arizona?</output>
</example>

<example>
<input>Why is it down?</input>
<context>Previous mention of Q4 revenue</context>
<output>Why is Q4 revenue down?</output>
</example>
</transformation_examples>
</query_refinement_instructions>
"""

PROMPT_REPHRASER_RESPONSE = """
<output_format>
At the VERY END of your text response, YOU MUST output a JSON block STRICTLY in below format: 
Example: { "refined_query": "What is the sales performance in Arizona?" }
Do not include any other text or markdown outside the JSON object.
</output_format>
"""

# --- INTENT ---
PROMPT_INTENT_SYSTEM = "You are an Expert Intent Classification System. Be polite, professional, and friendly. Be direct and unambiguous."

PROMPT_INTENT_ORCHESTRATION = """
<intent_classification_instructions>

<mission>
Your ONLY job is to identify the user's INTENT. Do NOT retrieve data, do NOT answer questions, do NOT perform analysis.
Classify the intent type and route accordingly.
</mission>

<intent_categories>

<intent name="greeting">
<description>User is greeting, saying hello, or engaging in pleasantries</description>
<indicators>hi, hello, hey, good morning, how are you, thanks, thank you, goodbye, bye</indicators>
<action>Set direct_response with a friendly greeting. No other fields needed.</action>
</intent>

<intent name="data_retrieval">
<description>User wants to see/get/retrieve DATA - numbers, lists, metrics, tables</description>
<indicators>show, list, get, display, find, what is the value, how many, count, total, give me</indicators>
<action>Extract the data request to data_retrieval_query. Keep as natural language. Add "and generate a table and a visual".</action>
**CRITICAL VISUALIZATION LOGIC:**
Analyze the data request. If it implies trends (over time), comparisons (by region/product), or distributions, you MUST automatically append "and generate a table and a visual" to the query string.
</intent>

<intent name="root_cause_analysis">
<description>User wants to understand WHY, CAUSES, DRIVERS, REASONS, EXPLANATIONS</description>
<indicators>why, explain, what is driving, what is causing, what's behind, reason for, root cause, how come, what factors</indicators>
<action>Extract the causal question to root_cause_query. Keep VERBATIM - exact text from user.</action>
</intent>

<intent name="combined">
<description>User wants BOTH data AND causal analysis in one request</description>
<indicators>Contains both data keywords AND causal keywords</indicators>
<action>Split into data_retrieval_query AND root_cause_query. Keep both portions.</action>
</intent>

<intent name="clarification_needed">
<description>User's intent is unclear, vague, or ambiguous - you cannot determine what they want</description>
<indicators>Very short/vague input, unclear pronouns without context, incomplete thoughts</indicators>
<action>Set clarification_question asking user to be more specific.</action>
</intent>

<intent name="general_question">
<description>General questions about the system, capabilities, how to use features - not data or analysis requests</description>
<indicators>how do I, can you, what can you do, help me understand, how does this work</indicators>
<action>Set direct_response with helpful information about capabilities.</action>
</intent>

<intent name="off_topic">
<description>User is asking about unrelated topics not connected to data, analytics, or business questions</description>
<indicators>Questions about weather, sports, entertainment, personal topics unrelated to business/data</indicators>
<action>Set direct_response politely redirecting to business/data topics.</action>
</intent>

</intent_categories>

<CRITICAL_CLASSIFICATION_RULES>
 RULE 1: NEVER DO THE WORK - ONLY CLASSIFY.
 RULE 2: CAUSAL KEYWORD DETECTION (why, driving, causing) = root_cause_analysis.
 RULE 3: DATA KEYWORD DETECTION (show, list, get) = data_retrieval.
 RULE 4: DIRECT RESPONSE ONLY FOR SIMPLE CASES (Greetings, General, Off-topic).
 RULE 5: VERBATIM PRESERVATION FOR ROOT CAUSE.
 RULE 6: NO SQL CODE GENERATION.
 RULE 7: CONFIDENCE SCORING (high/medium/low).
</CRITICAL_CLASSIFICATION_RULES>
</intent_classification_instructions>
"""

PROMPT_INTENT_RESPONSE = """
<output_format>
At the VERY END of your text response, YOU MUST output a JSON block STRICTLY in below format:
{
  "intent_type": "data_retrieval",
  "data_retrieval_query": "Show me sales...",
  "root_cause_query": null,
  "direct_response": null,
  "clarification_question": null,
  "confidence": "high",
  "reasoning": "User used 'show me' keyword"
}
</output_format>
"""

# --- DATA AGENT ---
PROMPT_DATA_AGENT_SYSTEM = "You are an expert Data Analyst. Be polite, professional, and friendly. Be direct and unambiguous."

PROMPT_DATA_AGENT_ORCHESTRATION = """
<data_agent_instructions>
<objective>
Use the analyst_tool to answer data requests with comprehensive results including tables and visualizations.
</objective>

<clarification_protocol>
You have access to the Master Schema.
If the user asks a vague question like "Show me sales" without specifying time, product, or region:
1. CHECK the Master Schema for available dimensions (e.g., Region, Specialty, Brand).
2. DO NOT guess.
3. ASK a specific clarifying question: "Would you like to see sales broken down by Region, Specialty, or Brand?"
4. If the query is clear, proceed to generate SQL.
</clarification_protocol>

<execution_rules>
<rule id="1">ALWAYS generate a table (Result Set) for data requests</rule>
<rule id="2">Generate appropriate visualizations when data is suitable for charts</rule>
<rule id="3">Provide clear, concise summaries of the data findings</rule>
<rule id="4">Handle errors gracefully and explain any data limitations</rule>
</execution_rules>

<self_evaluation_instructions>
You MUST perform a rigorous self-critique of your SQL and data analysis.
1. **Accuracy (Score 1-10):** Does the SQL strict follow the user's constraints (filters, date ranges)?
2. **Data Integrity:** Are the results logical? (e.g., no negative counts where impossible).
3. **Clarity:** Is the summary accessible to a non-technical user?
</self_evaluation_instructions>
</data_agent_instructions>
"""

PROMPT_DATA_AGENT_RESPONSE = """
<output_format>
At the VERY END of your text response, YOU MUST output a JSON block STRICTLY in below format:
```json
{
  "clean_answer_text": "Summary of findings...",
  "clarifying_question": null,
  "evaluation": {
    "score": 8,
    "reasoning": "Data matches request."
  }
}
```
</output_format>
"""

# --- ROOT CAUSE ---
PROMPT_ROOT_CAUSE_SYSTEM = "You are an Autonomous Root Cause Analysis Agent. Be polite, professional, and friendly. Be direct and unambiguous."

PROMPT_ROOT_CAUSE_ORCHESTRATION = f"""
<root_cause_orchestration_prompt>
    <role_and_objective>
        You are an **Autonomous Root Cause Analysis Agent** designed to traverse a metric decision tree from the root node down to the leaf nodes. Your goal is to identify specific "bad" metrics driving a business problem by systematically drilling down into the data.
        
        ALWAYS USE tree_id as {CONFIG.diagnostic_tree_id}.
    </role_and_objective>

    <phase_1_clarification_check>
        **CRITICAL:** Before running any tools, analyze the USER_QUERY against the MASTER SCHEMA dimensions.
        
        MASTER SCHEMA:

        {CONFIG.cortex_analyst_object_master}
        
        IF the user asks a generic question like "Why is revenue down?" or "Explain the drop":
        1. You cannot run the tool efficiently without a starting point (Root Node context).
        2. Look at available schema dimensions (Region, Product, Specialty, Time).
        3. **STOP** and return a `clarifying_question`.
           Example: "To analyze the revenue drop, should I compare performance by Region, Product Class, or Customer Specialty?"
        
        IF the query contains specific context (e.g., "Why is Tylenol down in NY?"), PROCEED to Phase 2.
    </phase_1_clarification_check>

    <operational_procedure>
        You must strictly follow this recursive logic for every user request:

        **Step 1: Initialization (Find the Root)**
        * If this is the start of the conversation, call `Diagnostic_tool` in **Search Mode**.
        * **Action:** Call `Diagnostic_tool(USER_QUERY=user_question, PARENT_NODE_IDS_JSON=NULL, TREE_ID='{CONFIG.diagnostic_tree_id}')`.
        * **Next:** Proceed to Step 2 with the results.

        **Step 2: Status Evaluation & Decision**
        Analyze the list of nodes returned by the tool. Focus **only** on nodes where `"status": "bad"`.

        * **Check:** For every "bad" node, do you see its children in the current list?
        * **Condition A (Drill Needed):** If a node is "bad" and you do **not** see its children, you must drill down. Collect these Node IDs.
        * **Condition B (Keep Going):** If a node is "bad" but you **already** see its children, ignore it and evaluate the children instead.
        * **Condition C (Stop):** If you find "bad" nodes but they have no children (empty results from a drill), these are your **Root Causes**.

        **Step 3: Execution (Drill Down)**
        * If Condition A occurred: Call `Diagnostic_tool` in **Drill Mode**.
        * **Action:** Call `Diagnostic_tool(USER_QUERY=NULL, PARENT_NODE_IDS_JSON='["ID_1", "ID_2"]', TREE_ID='{CONFIG.diagnostic_tree_id}')`.
        * **Next:** Recursively repeat Step 2 with the new output.
        * If Condition C occurred: Present the final root causes to the user.
    </operational_procedure>

    <constraints>
        * **Never** guess the status of a metric; always use the tool.
        * **Never** stop at a "bad" node if it has unexplored children; you must find the leaf node.
        * Output your reasoning briefly before calling the tool.
    </constraints>

    <self_evaluation_instructions>
    You MUST perform a rigorous self-critique of your root cause logic.
    1. **Logic (Score 1-10):** Is the causal chain (Root -> Leaf) mathematically sound?
    2. **Driver Isolation:** Did we truly find the leaf node, or did we stop too early?
    3. **Completeness:** Did we explore all "bad" branches?
    </self_evaluation_instructions>
</root_cause_orchestration_prompt>
"""

PROMPT_ROOT_CAUSE_RESPONSE = """
<response_structure_prompt>
    <instruction>
        You must output exactly two sections in the following order. Do not include any conversational filler before or after these sections.
    </instruction>

    <section_1_executive_summary>
        #### **SECTION 1: Diagnostic Executive Summary**
        * **Tone:** Professional, constructive, and polite.
        * **Headline:** State the Root Cause clearly.
        * **The Narrative:** Briefly explain the chain of events in simple English.
        * **Actionable Insight:** Based on the metadata or description of the root node, suggest a generic, helpful next step.
    </section_1_executive_summary>

    <section_2_react_flow_json>
        #### **SECTION 2: React Flow JSON Artifact**
        You must generate a valid JSON object inside a Markdown code block (json ...).
        
        **4. JSON Schema (Must Follow Exactly):**
        {
          "nodes": [
            {
              "id": "N0",
              "type": "default",
              "data": { "label": "Metric Name: Value" },
              "position": { "x": 0, "y": 0 },
              "style": { "background": "#FFE2E5", "width": 180, "color": "#333", "border": "1px solid #777", "borderRadius": "8px" }
            }
          ],
          "edges": [
            {
              "id": "e-N0-N1",
              "source": "N0",
              "target": "N1",
              "label": "driven by",
              "animated": true,
              "style": { "stroke": "#555", "strokeWidth": 2 }
            }
          ]
        }
    </section_2_react_flow_json>
    
    <section_3_final_json>
        CRITICAL: Provide the final JSON block for the parser here as defined in the system prompt evaluation section.
    </section_3_final_json>
    
    **CRITICAL** : YOU MUST ONLY EXECUTE ATMOST 8 TOOL CALLS.
    
    <output_format>
    At the VERY END of your text response, YOU MUST output a JSON block STRICTLY in below format:
    ```json
    {
      "clean_summary_text": "Executive summary...",
      "clarifying_question": null,
      "react_flow_json": { "nodes": [], "edges": [] },
      "evaluation": { "score": 9, "reasoning": "Found root cause." }
    }
    ```
    </output_format>
</response_structure_prompt>
"""

# --- TABLE SELECTION ---
PROMPT_TABLE_SELECTION = """
<instruction>
You are an expert Database Architect and Schema Analyzer.
Your goal is to identify the subset of tables from the provided list that are strictly relevant to answering the user's query.

<rules>
1. **Analyze the Query**: Carefully understand the business entities, metrics, and dimensions requested.
2. **Review Summaries**: Check the Table Name and Description for each table provided.
3. **Strict Selection**: Select ONLY tables that contain the data needed. Do NOT include tables "just in case".
4. **Keyword Matching**: 
   - If the query mentions "sales" or "revenue", look for Fact tables with those metrics.
   - If the query mentions "location", "city", or "state", look for Geography Dimension tables.
   - If the query mentions "products", look for Product Dimension tables.
5. **Empty Return**: If no tables seem relevant, return an empty list.
</rules>

<output_format>
Output ONLY a valid JSON object with the following structure. Do not output markdown code blocks.
{
  "relevant_table_names": ["Table_A", "Table_B"]
}
</output_format>
</instruction>
"""

# --- SEMANTIC TRANSLATOR ---
PROMPT_SEMANTIC_TRANSLATOR = """
<instruction>
You are a Semantic Query Optimizer and SQL Expert.
Your goal is to rewrite the User's Natural Language Query so that it aligns perfectly with the provided Database Schema Context.

<rules>
1. **Vocabulary Mapping:** Replace generic business terms in the user query with the EXACT column names found in the Schema Context.
   - Example: If user says "revenue" and context has "TOTAL_SALES_AMT", use "TOTAL_SALES_AMT".
   - Example: If user says "doctors" and context has "HCP_ID", use "HCP_ID".
2. **Filter Alignment:** Check 'sample_values' in the context.
   - Example: If user says "in NY", and sample values for 'STATE_CD' are 'New York', rewrite to "STATE_CD is 'New York'".
3. **Disambiguation:** If a term matches multiple columns, use the column descriptions to pick the most relevant one.
4. **Preservation:** Do not change the user's core intent (e.g., ranking, aggregation, filtering). Just swap the terminology.
5. **Output**: Return ONLY the rewritten natural language query string. Do not output SQL. Do not output JSON.
</rules>
</instruction>
"""

# ==========================================
# 4. HELPER FUNCTIONS
# ==========================================

def log_checkpoint(step: str, details: Any):
    print(f"\n{'='*50}\n CHECKPOINT: {step}\n{'-'*50}")
    if isinstance(details, BaseModel): pprint.pprint(details.model_dump())
    elif isinstance(details, (dict, list)): pprint.pprint(details)
    else: print(str(details))
    print(f"{'='*50}\n")

# ==========================================
# HISTORY MANAGEMENT FUNCTIONS (UPDATED)
# ==========================================

def get_chat_history(session: Session, session_id: str, limit: int = 10) -> List[Dict]:
    """Retrieves chat history for a specific session_id formatted for Cortex."""
    if not session_id: 
        return []
    
    try:
        sql = f"""
        SELECT SENDER_TYPE, MESSAGE_TEXT 
        FROM {CONFIG.messages_table}
        WHERE CONVERSATION_ID = '{session_id}'
        ORDER BY CREATED_AT ASC
        LIMIT {limit}
        """
        rows = session.sql(sql).collect()
        
        history = []
        for r in rows:
            role = "user" if r['SENDER_TYPE'].lower() == 'user' else "assistant"
            history.append({
                "role": role, 
                "content": [{"type": "text", "text": r['MESSAGE_TEXT']}]
            })
        
        print(f" Retrieved {len(history)} past messages for Session {session_id}")
        return history
        
    except Exception as e:
        print(f" History Fetch Failed: {e}")
        return []

def save_chat_message(session: Session, session_id: str, role: str, content: str, metadata: Optional[Dict] = None):
    """Saves a message to the MESSAGES_V2 table with proper VARIANT handling."""
    if not session_id or not content: 
        return
    
    try:
        # Use SQL INSERT with explicit column specification
        safe_content = content.replace("'", "''")
        safe_session_id = str(session_id).replace("'", "''")
        
        if metadata:
            # Convert to JSON and escape properly
            meta_json = json.dumps(metadata).replace("\\", "\\\\").replace("'", "''")
            sql = f"""
            INSERT INTO {CONFIG.messages_table} 
            (CONVERSATION_ID, SENDER_TYPE, MESSAGE_TEXT, METADATA)
            SELECT '{safe_session_id}', '{role}', '{safe_content}', 
                   PARSE_JSON('{meta_json}')
            """
        else:
            sql = f"""
            INSERT INTO {CONFIG.messages_table} 
            (CONVERSATION_ID, SENDER_TYPE, MESSAGE_TEXT)
            VALUES ('{safe_session_id}', '{role}', '{safe_content}')
            """
        
        session.sql(sql).collect()
        print(f" Saved {role} message to history.")
        
    except Exception as e:
        print(f" Save Message Failed: {e}")
        raise


def invoke_cortex_agent(session: Session, payload: Dict, agent_name: str) -> Dict:
    """Invokes 'agent:run'."""
    ENDPOINT = "/api/v2/cortex/agent:run"
    print(f"--- INVOKING AGENT: {agent_name} ---")

    try:
        resp = _snowflake.send_snow_api_request("POST", ENDPOINT, {"Content-Type": "application/json", "Accept": "text/event-stream"}, {}, payload, {}, 120000)
        content = resp.get("content")
        if not content: return {"error": "Empty"}
        
        extracted = {"text": "", "tables": [], "charts": [], "sql_generated": None, "sql_explanation": None}
        try: parsed = json.loads(content)
        except: parsed = [json.loads(line) for line in content.splitlines() if line.strip()]
        
        def process_event(evt, data):
            if evt == 'response.text.delta': 
                extracted["text"] += data.get('text', '')
            elif evt == 'response.chart': 
                extracted["charts"].append(data.get('chart') or data.get('chart_spec'))
                print(extracted["charts"])
            elif evt == 'response.table':
                rs = data.get('result_set', [])
                extracted["tables"].append(rs) 
            elif evt == 'response.tool_result.analyst.delta':
                print('response.tool_result.analyts.delt')
                print(delta)
                delta = data.get('delta', {})
                if delta.get('sql'): extracted["sql_generated"] = delta.get('sql')
                if delta.get('sql_explanation'): extracted["sql_explanation"] = delta.get('sql_explanation')
                if delta.get('result_set'): extracted["tables"].append(delta.get('result_set'))
            elif evt == 'response.tool_result':
                for item in data.get('content', []):
                    if item.get('type') == 'json':
                        json_p = item.get('json', {})
                        if 'sql' in json_p: extracted["sql_generated"] = json_p['sql']
                        if 'result_set' in json_p: extracted["tables"].append(json_p['result_set'])

        if isinstance(parsed, list):
            for item in parsed: process_event(item.get('event'), item.get('data', {}))
        
        return extracted
    except Exception as e: return {"error": str(e)}

def extract_pydantic_from_text(text: str, model_class: type[BaseModel]) -> BaseModel:
    """Robust JSON extraction."""
    if not text: return model_class()
    def try_parse(json_str):
        try: return json.loads(json_str)
        except: 
            try: return json.loads(json_str, strict=False)
            except: return None

    match = re.search(r'```json\s*(\{.*?\})\s*```', text, re.DOTALL)
    if match:
        data = try_parse(match.group(1))
        if data: 
            try: return model_class(**data)
            except: pass 

    start = text.find('{')
    end = text.rfind('}')
    if start != -1 and end != -1:
        data = try_parse(text[start:end+1])
        if data: 
            try: return model_class(**data)
            except: pass

    if model_class == RephraserOutput:
        return RephraserOutput(refined_query=text.strip())

    return model_class()

def check_input_guard(session: Session, user_input: str) -> GuardResult:
    try:
        safe_input = user_input.replace("'", "''")
        res = session.sql(f"SELECT SNOWFLAKE.CORTEX.COMPLETE('{CONFIG.model}', [{{'role': 'user', 'content': '{safe_input}'}}], {{'guardrails': true}}) as r").collect()
        if not res: return GuardResult(is_safe=True)
        is_unsafe = "Response filtered" in json.loads(res[0]['R'])['choices'][0]['messages']
        return GuardResult(is_safe=not is_unsafe, message="Blocked." if is_unsafe else None)
    except: return GuardResult(is_safe=True)

class PayloadFactory:
    @staticmethod
    def create(query: str, instructions: Any, tools: List = None, resources: Dict = None, history: List = None) -> Dict:
        messages = (history if history else []) + [{"role": "user", "content": [{"type": "text", "text": query}]}]
        inst_payload = instructions if isinstance(instructions, dict) else {"system": instructions}
        return {
            "messages": messages,
            "models": {"orchestration": CONFIG.model},
            "instructions": inst_payload,
            "tools": tools or [],
            "tool_resources": resources or {}
        }

def _save_audit_row(session: Session, data: dict, session_id: str):
    """Saves detailed execution logs using a staged approach for complex VARIANT data."""
    try:
        # Prepare the complete record
        record = {
            "SESSION_ID": session_id,
            "USER_QUERY": data.get("USER_QUERY"),
            "REPHRASED_QUERY": data.get("REPHRASED_QUERY"),
            "INTENT_TYPE": data.get("INTENT_TYPE"),
            "INTENT_CONFIDENCE": data.get("INTENT_CONFIDENCE"),
            "DATA_SUMMARY": data.get("DATA_SUMMARY"),
            "DATA_SQL": data.get("DATA_SQL"),
            "DATA_SQL_EXPLANATION": data.get("DATA_SQL_EXPLANATION"),
            "DATA_CLARIFICATION": data.get("DATA_CLARIFICATION"),
            "DATA_EVAL_SCORE": data.get("DATA_EVAL_SCORE"),
            "DATA_EVAL_REASONING": data.get("DATA_EVAL_REASONING"),
            "RC_SUMMARY": data.get("RC_SUMMARY"),
            "RC_EVAL_SCORE": data.get("RC_EVAL_SCORE"),
            "RC_EVAL_REASONING": data.get("RC_EVAL_REASONING"),
            "IS_BLOCKED": data.get("IS_BLOCKED", False),
            "EXECUTION_TIME_MS": data.get("EXECUTION_TIME_MS"),
            "DATA_RESULT_SET": data.get("DATA_RESULT_SET"),
            "DATA_CHARTS": data.get("DATA_CHARTS"),
            "RC_GRAPH_JSON": data.get("RC_GRAPH_JSON"),
            "FULL_RAW_JSON": data.get("FULL_RAW_JSON"),
            "CREATED_AT": datetime.datetime.now()
        }
        
        # Convert VARIANT fields to JSON strings within the dict
        for field in ["DATA_RESULT_SET", "DATA_CHARTS", "RC_GRAPH_JSON", "FULL_RAW_JSON"]:
            if record[field] is not None and not isinstance(record[field], str):
                record[field] = json.dumps(record[field])
        
        # Create DataFrame with the record
        df = session.create_dataframe([record])
        
        # Convert JSON strings to VARIANT using PARSE_JSON
        for field in ["DATA_RESULT_SET", "DATA_CHARTS", "RC_GRAPH_JSON", "FULL_RAW_JSON"]:
            if record[field] is not None:
                df = df.with_column(field, parse_json(col(field)))
        
        # Write to table
        df.write.mode("append").save_as_table(CONFIG.audit_log_table)
        
        print(f" Audit log saved for session {session_id}.")
        
    except Exception as e:
        print(f" Audit Log Error (DataFrame approach): {e}")
        
        # Fallback: Insert with simplified data (without complex VARIANT fields)
        try:
            print(" Attempting simplified insert without VARIANT fields...")
            
            safe_session = session_id.replace("'", "''")
            safe_query = str(data.get("USER_QUERY", "")).replace("'", "''")
            safe_rephrased = str(data.get("REPHRASED_QUERY", "")).replace("'", "''") if data.get("REPHRASED_QUERY") else "NULL"
            safe_intent = str(data.get("INTENT_TYPE", "")).replace("'", "''") if data.get("INTENT_TYPE") else "NULL"
            
            fallback_sql = f"""
            INSERT INTO {CONFIG.audit_log_table} 
            (SESSION_ID, USER_QUERY, REPHRASED_QUERY, INTENT_TYPE, INTENT_CONFIDENCE, 
             DATA_EVAL_SCORE, RC_EVAL_SCORE, IS_BLOCKED, EXECUTION_TIME_MS)
            VALUES (
                '{safe_session}',
                '{safe_query}',
                {f"'{safe_rephrased}'" if data.get("REPHRASED_QUERY") else "NULL"},
                {f"'{safe_intent}'" if data.get("INTENT_TYPE") else "NULL"},
                {f"'{data.get('INTENT_CONFIDENCE')}'" if data.get("INTENT_CONFIDENCE") else "NULL"},
                {data.get("DATA_EVAL_SCORE") if data.get("DATA_EVAL_SCORE") is not None else "NULL"},
                {data.get("RC_EVAL_SCORE") if data.get("RC_EVAL_SCORE") is not None else "NULL"},
                {str(data.get("IS_BLOCKED", False)).upper()},
                {data.get("EXECUTION_TIME_MS") if data.get("EXECUTION_TIME_MS") is not None else "NULL"}
            )
            """
            
            session.sql(fallback_sql).collect()
            print(f" Audit log saved with simplified data (VARIANT fields skipped).")
            
        except Exception as e2:
            print(f" Fallback Insert Failed: {e2}")
            import traceback
            traceback.print_exc()
        
def get_cortex_completion(session: Session, prompt: str) -> str:
    try:
        safe_prompt = prompt.replace("'", "''")
        cmd = f"SELECT SNOWFLAKE.CORTEX.COMPLETE('{CONFIG.model}', '{safe_prompt}') as R"
        return session.sql(cmd).collect()[0]['R']
    except Exception as e: return ""

# ==========================================
# 5. SEMANTIC VIEW PARSER
# ==========================================

class SemanticViewParser:
    def __init__(self, session: Session, view_name: str):
        self.session = session
        self.view_name = view_name
        self.ca_json = {"tables": [], "relationships": []}
        self.table_comments = {} 
        self.column_metadata = defaultdict(lambda: defaultdict(dict)) 
        self.rel_metadata = defaultdict(dict) 
        # Note: We do NOT parse in __init__ to satisfy "orchestrator only" constraint.
        self.is_loaded = False

    def _fetch_and_parse(self):
        if self.is_loaded: return
        print(f" DESCRIBING SEMANTIC VIEW: {self.view_name}...")
        try:
            rows = self.session.sql(f"DESCRIBE SEMANTIC VIEW {self.view_name}").collect()
            data = [row.as_dict() for row in rows]
            ca_row = next((r for r in data if r.get('object_kind') == 'EXTENSION' and r.get('object_name') == 'CA'), None)
            if ca_row: self.ca_json = json.loads(ca_row['property_value'])

            for r in data:
                kind = r.get('object_kind')
                name = r.get('object_name')
                prop = r.get('property')
                val = r.get('property_value')
                
                if kind == 'TABLE' and prop == 'COMMENT':
                    self.table_comments[name.split('.')[-1]] = val
                elif kind in ['DIMENSION', 'FACT', 'COLUMN']:
                    t_name = r.get('parent_entity', '').split('.')[-1]
                    if t_name:
                        if prop == 'COMMENT': self.column_metadata[t_name][name]['description'] = val
                        elif prop == 'DATA_TYPE': self.column_metadata[t_name][name]['data_type'] = val
                elif kind == 'RELATIONSHIP':
                    if prop == 'TABLE': self.rel_metadata[name]['source_table'] = val.split('.')[-1]
                    elif prop == 'REF_TABLE': self.rel_metadata[name]['target_table'] = val.split('.')[-1]
                    elif prop == 'FOREIGN_KEY': self.rel_metadata[name]['keys'] = val
            
            self.is_loaded = True
            print(f" Metadata Loaded from {self.view_name}")
        except Exception as e: print(f" Metadata Parse Failed: {e}")

    def get_context_summary(self) -> str:
        """Returns a summarized string of the schema for LLM Context (Master)."""
        self._fetch_and_parse() # Load on demand
        summary = "Available Data Schema:\n"
        for t in self.ca_json.get('tables', []):
            summary += f"- Table: {t.get('name')}\n"
            summary += f"  Columns: {', '.join([c['name'] for c in t.get('dimensions', []) + t.get('facts', [])])}\n"
        return summary

    def get_table_summaries(self) -> str:
        """Returns detailed table summaries for selection."""
        self._fetch_and_parse()
        summary_list = []
        for t in self.ca_json.get('tables', []):
            t_name = t.get('name')
            desc = self.table_comments.get(t_name, "No description.")
            summary_list.append(f"- Table: {t_name}\n  Description: {desc}")
        return "\n".join(summary_list) if summary_list else ""

    def get_pruned_context(self, selected_tables: List[str]) -> str:
        """Generates a pruned JSON schema based on selected tables."""
        self._fetch_and_parse()
        pruned = {"tables": [], "relationships": []}
        for t in self.ca_json.get('tables', []):
            t_name = t['name']
            if t_name in selected_tables:
                table_copy = t.copy()
                table_copy['description'] = self.table_comments.get(t_name, "")
                for category in ['dimensions', 'facts', 'time_dimensions']:
                    if category in table_copy:
                        enriched_cols = []
                        for col in table_copy[category]:
                            col_copy = col.copy()
                            meta = self.column_metadata[t_name].get(col['name'], {})
                            if 'description' in meta: col_copy['description'] = meta['description']
                            if 'data_type' in meta: col_copy['data_type'] = meta['data_type']
                            enriched_cols.append(col_copy)
                        table_copy[category] = enriched_cols
                pruned['tables'].append(table_copy)
        
        if 'relationships' in self.ca_json:
            for rel in self.ca_json['relationships']:
                r_name = rel.get('name')
                source = self.rel_metadata.get(r_name, {}).get('source_table')
                if source in selected_tables:
                    pruned['relationships'].append(rel)
        return json.dumps(pruned, indent=2)

# ==========================================
# 6. AGENT MANAGER
# ==========================================

class AgentManager:
    def __init__(self, session: Session):
        self.session = session
        # We only initialize the Parser object, we DO NOT load data here.
        # Data loading happens inside run_data_orchestrator calls.
        self.parser = SemanticViewParser(session, CONFIG.cortex_analyst_object_master)

    def identify_needed_tables(self, query: str) -> List[str]:
        print(" IDENTIFYING RELEVANT TABLES...")
        summaries = self.parser.get_table_summaries() # Triggers load if needed
        if not summaries: return []
        prompt = f"{PROMPT_TABLE_SELECTION}\n\nUser Query: {query}\n\nTable Summaries:\n{summaries}"
        res_text = get_cortex_completion(self.session, prompt)
        result = extract_pydantic_from_text(res_text, TableSelection)
        print(f" Selected: {result.relevant_table_names}")
        return result.relevant_table_names

    def run_semantic_translator(self, query: str, relevant_tables: List[str]) -> str:
        print(f" REWRITING QUERY...")
        pruned_json = self.parser.get_pruned_context(relevant_tables)
        prompt = f"{PROMPT_SEMANTIC_TRANSLATOR}\n\nSchema Context:\n{pruned_json}\n\nUser Query: {query}"
        return get_cortex_completion(self.session, prompt).strip()

    def run_rephraser(self, query: str, history: List[Dict]) -> RephraserOutput:
        inst = {
            "system": PROMPT_REPHRASER_SYSTEM,
            "orchestration": PROMPT_REPHRASER_ORCHESTRATION,
            "response": PROMPT_REPHRASER_RESPONSE
        }
        payload = PayloadFactory.create(query, inst, history=history)
        resp = invoke_cortex_agent(self.session, payload, "Rephraser Agent")
        return extract_pydantic_from_text(resp.get("text", ""), RephraserOutput)

    def run_intent_classifier(self, query: str) -> IntentClassification:
        inst = {
            "system": PROMPT_INTENT_SYSTEM, 
            "orchestration": PROMPT_INTENT_ORCHESTRATION,
            "response": PROMPT_INTENT_RESPONSE
        }
        payload = PayloadFactory.create(query, inst)
        resp = invoke_cortex_agent(self.session, payload, "Intent Agent")
        return extract_pydantic_from_text(resp.get("text", ""), IntentClassification)

    def run_data_agent(self, query: str, schema_context: Optional[str] = None, is_optimized: bool = False) -> SqlResult:
        # Determine correct object and context
        target_view = CONFIG.cortex_analyst_object_ards if is_optimized else CONFIG.cortex_analyst_object_master
        
        tools = [{"tool_spec": {"type": "cortex_analyst_text_to_sql", "name": "analyst_tool"}}]
        res_def = {
            "analyst_tool": {
                "type": "cortex_analyst_text_to_sql",
                "semantic_view": target_view, 
                "execution_environment": {"type": "warehouse", "warehouse": CONFIG.warehouse}
            }
        }
        
        # Inject Master Schema Context into System Prompt if provided
        system_prompt = PROMPT_DATA_AGENT_SYSTEM
        if is_optimized == False:
             system_prompt += f"Enrich the user question with the below schema. \n\nMASTER SCHEMA CONTEXT:\n{CONFIG.cortex_analyst_object_master}"
        
        inst = {
            "system": system_prompt, 
            "orchestration": PROMPT_DATA_AGENT_ORCHESTRATION,
            "response": PROMPT_DATA_AGENT_RESPONSE
        }
        payload = PayloadFactory.create(query, inst, tools, res_def)
        resp = invoke_cortex_agent(self.session, payload, "Data Agent" + (" (Optimized)" if is_optimized else ""))
        
        raw_text = resp.get('text', '')
        parsed = extract_pydantic_from_text(raw_text, SqlResult)
        
        parsed.tables = resp.get('tables', [])
        parsed.sql_generated = resp.get('sql_generated')
        parsed.sql_explanation = resp.get('sql_explanation')
        parsed.charts = resp.get('charts')
        return parsed

    def run_data_flow_orchestrator(self, query: str) -> SqlResult:
        """Handles standard execution vs optimized self-healing execution via parallelism."""
        
        def run_optimization_sequence():
            try:
                # Optimization logic...
                needed_tables = self.identify_needed_tables(query)
                if needed_tables:
                    optimized_q = self.run_semantic_translator(query, needed_tables)
                    print(f" Optimized Query: {optimized_q}")
                    # No schema context needed for optimized run (relies on translation + ARDS view)
                    return self.run_data_agent(optimized_q, schema_context=None, is_optimized=True)
            except Exception as e:
                print(f"Optimization failed: {e}")
            return SqlResult(clean_answer_text="Optimization Failed", evaluation=EvaluationResult(score=0))

        def run_standard_sequence():
    
            return self.run_data_agent(query, schema_context=None, is_optimized=False)

        print(" Starting Data Agent Flows (Standard & Optimized)...")
        with ThreadPoolExecutor(max_workers=2) as executor:
            future_std = executor.submit(run_standard_sequence)
            future_opt = executor.submit(run_optimization_sequence)
            res_std = future_std.result()
            res_opt = future_opt.result()

        print(f" Standard Score: {res_std.evaluation.score} | Optimized Score: {res_opt.evaluation.score}")
        
        # Decision Logic
        if res_std.evaluation.score >= 8:
            return res_std
        elif (res_std.evaluation.score < 8 and res_opt.evaluation.score < 8) or \
             (res_std.evaluation.score == res_opt.evaluation.score and res_std.evaluation.score > 0):
             
             print(" Scores Low/Equal. Combining Summaries.")
             base = res_opt if res_opt.evaluation.score > 0 else res_std
             combined_text = (f"**Standard Analysis:**\n{res_std.clean_answer_text}\n\n"
                              f"**Deep Context Analysis:**\n{res_opt.clean_answer_text}")
             
             final_res = SqlResult(
                 clean_answer_text=combined_text,
                 tables=base.tables,
                 charts=base.charts,
                 sql_generated=base.sql_generated, 
                 sql_explanation=base.sql_explanation,
                 evaluation=base.evaluation,
                 is_retry=True
             )
             return final_res
        elif res_opt.evaluation.score > res_std.evaluation.score:
            print(f" Switched to Optimized Result (Score: {res_opt.evaluation.score})")
            res_opt.is_retry = True
            return res_opt
            
        return res_std
    def run_root_cause_agent(self, query: str) -> DiagnosticResult:
        tools = [{"tool_spec": {"type": "generic", "name": "Diagnostic_tool", "input_schema": {"type": "object", "properties": {"USER_QUERY": {"type": "string"}, "PARENT_NODE_IDS_JSON": {"type": "string"}, "TREE_ID": {"type": "string"}}, "required": ["USER_QUERY", "PARENT_NODE_IDS_JSON", "TREE_ID"]}}}]
        res_def = {"Diagnostic_tool": {"type": "procedure", "execution_environment": {"type": "warehouse", "warehouse": CONFIG.warehouse}, "identifier": CONFIG.diagnostic_udf}}
        
        
        
        inst = {
            "system": PROMPT_REPHRASER_SYSTEM, 
            "orchestration": PROMPT_ROOT_CAUSE_ORCHESTRATION,
            "response": PROMPT_ROOT_CAUSE_RESPONSE
        }
        payload = PayloadFactory.create(query, inst, tools, res_def)
        resp = invoke_cortex_agent(self.session, payload, "Root Cause Agent")
        
        raw_text = resp.get('text', '')
        parsed = extract_pydantic_from_text(raw_text, DiagnosticResult)

        return parsed

# ==========================================
# 7. MAIN EXECUTION
# ==========================================

def main(session: Session):
    """Main Orchestrator Entry Point."""
    
    
    session_id = "1111"
    
    user_query = "give me the top 10 prescribers from arizona"
    
    # Start timing
    start_time = datetime.datetime.now()
    
    manager = AgentManager(session)
    
    # Initialize row_data with ALL required columns for audit table
    row_data = {
        "SESSION_ID": session_id,
        "USER_QUERY": user_query,
        "REPHRASED_QUERY": None,
        "INTENT_TYPE": None,
        "INTENT_CONFIDENCE": None,
        "DATA_SUMMARY": None,
        "DATA_SQL": None,
        "DATA_SQL_EXPLANATION": None,
        "DATA_CLARIFICATION": None,
        "DATA_RESULT_SET": None,
        "DATA_CHARTS": None,
        "DATA_EVAL_SCORE": None,
        "DATA_EVAL_REASONING": None,
        "RC_SUMMARY": None,
        "RC_GRAPH_JSON": None,
        "RC_EVAL_SCORE": None,
        "RC_EVAL_REASONING": None,
        "IS_BLOCKED": False,
        "FULL_RAW_JSON": None,
        "EXECUTION_TIME_MS": None
    }
    
    log_checkpoint("MAIN: START", {"query": user_query, "session": session_id})

    # 1. Fetch History
    history = get_chat_history(session, session_id)

    # 2. Input Guard
    guard = check_input_guard(session, user_query)
    if not guard.is_safe:
        row_data["IS_BLOCKED"] = True
        
        # Calculate execution time
        end_time = datetime.datetime.now()
        row_data["EXECUTION_TIME_MS"] = int((end_time - start_time).total_seconds() * 1000)
        
        # Save audit log
        row_data["FULL_RAW_JSON"] = {"status": "blocked", "message": guard.message}
        _save_audit_row(session, row_data, session_id)
        
        return {"status": "blocked", "message": guard.message}

    # 3. Save User Message
    save_chat_message(session, session_id, "user", user_query)

    # 4. Rephrase
    try:
        rephrased = manager.run_rephraser(user_query, history)
        effective_query = rephrased.refined_query or user_query
    except Exception as e:
        print(f" Rephraser failed: {e}")
        effective_query = user_query
    
    # 5. Intent Classification
    try:
        intent = manager.run_intent_classifier(effective_query)
    except Exception as e:
        print(f" Intent classification failed: {e}")
        # Default to data retrieval if intent fails
        intent = IntentClassification(
            intent_type="data_retrieval",
            data_retrieval_query=effective_query,
            confidence="low",
            reasoning=f"Failed to classify intent: {str(e)}"
        )
    
    row_data["REPHRASED_QUERY"] = effective_query
    row_data["INTENT_TYPE"] = intent.intent_type
    row_data["INTENT_CONFIDENCE"] = intent.confidence

    final_output = {
        "original": user_query, 
        "processed": effective_query, 
        "intent": intent.model_dump(), 
        "results": []
    }

    bot_response_text = ""

    # 6. Execute based on Intent
    if intent.direct_response:
        msg = intent.direct_response
        final_output["results"].append({"type": "direct", "message": msg})
        bot_response_text = msg

    else:
        futures = {}
        with ThreadPoolExecutor(max_workers=2) as executor:
            
            # Data Flow (Uses Parallel Orchestrator)
            if intent.intent_type in ["data_retrieval", "combined", "clarification_needed"]:
                q = intent.data_retrieval_query or effective_query
                futures["data"] = executor.submit(manager.run_data_flow_orchestrator, q)
            
            # Root Cause Flow
            if intent.intent_type in ["root_cause_analysis", "combined"]:
                q = intent.root_cause_query or effective_query
                futures["rc"] = executor.submit(manager.run_root_cause_agent, q)

        # Process Data Results
        if "data" in futures:
            try:
                res = futures["data"].result()
                res_dump = res.model_dump()
                
                row_data["DATA_EVAL_SCORE"] = res.evaluation.score
                row_data["DATA_EVAL_REASONING"] = res.evaluation.reasoning
                row_data["DATA_SQL"] = res.sql_generated
                row_data["DATA_SQL_EXPLANATION"] = res.sql_explanation
                
                # Store as dict/list - will be converted to JSON in _save_audit_row
                if res.tables: 
                    row_data["DATA_RESULT_SET"] = res.tables
                if res.charts:
                    row_data["DATA_CHARTS"] = res.charts
                
                if res.clarifying_question:
                    response_text = res.clarifying_question
                    final_output["results"].append({
                        "type": "clarification", 
                        "message": response_text,
                        "full_pydantic_object": res_dump 
                    })
                    row_data["DATA_CLARIFICATION"] = response_text
                else:
                    response_text = res.clean_answer_text
                    final_output["results"].append({
                        "type": "data_analysis", 
                        "summary": response_text, 
                        "tables": res.tables,
                        "charts": res.charts,
                        "sql_generated": res.sql_generated,
                        "sql_explanation": res.sql_explanation,
                        "full_pydantic_object": res_dump 
                    })
                    row_data["DATA_SUMMARY"] = response_text
                
                bot_response_text += response_text + "\n"
                
            except Exception as e:
                error_msg = f"Data analysis failed: {str(e)}"
                print(f" {error_msg}")
                final_output["results"].append({
                    "type": "error",
                    "message": error_msg
                })
                bot_response_text += error_msg + "\n"

        # Process Root Cause Results
        if "rc" in futures:
            try:
                res_rc = futures["rc"].result()
                res_rc_dump = res_rc.model_dump()
                
                row_data["RC_EVAL_SCORE"] = res_rc.evaluation.score
                row_data["RC_EVAL_REASONING"] = res_rc.evaluation.reasoning
                
                if res_rc.clarifying_question:
                    response_text = res_rc.clarifying_question
                    final_output["results"].append({
                        "type": "clarification", 
                        "message": response_text,
                        "full_pydantic_object": res_rc_dump 
                    })
                else:
                    response_text = res_rc.clean_summary_text
                    final_output["results"].append({
                        "type": "root_cause", 
                        "summary": response_text, 
                        "graph": res_rc.react_flow_json,
                        "full_pydantic_object": res_rc_dump 
                    })
                    row_data["RC_SUMMARY"] = res_rc.clean_summary_text
                    if res_rc.react_flow_json:
                        row_data["RC_GRAPH_JSON"] = res_rc.react_flow_json
                
                bot_response_text += response_text + "\n"
                
            except Exception as e:
                error_msg = f"Root cause analysis failed: {str(e)}"
                print(f" {error_msg}")
                final_output["results"].append({
                    "type": "error",
                    "message": error_msg
                })
                bot_response_text += error_msg + "\n"

    # 7. Save Bot Response
    if bot_response_text:
        # Save structured metadata to METADATA column
        message_metadata = {
            "intent_data": intent.model_dump(),
            "sql_generated": row_data.get("DATA_SQL"),
            "is_blocked": row_data.get("IS_BLOCKED"),
            "tool_artifacts": final_output.get("results"),
            "generated_at": datetime.datetime.now().isoformat()
        }
        
        try:
            save_chat_message(
                session, 
                session_id, 
                "assistant", 
                bot_response_text.strip(), 
                metadata=message_metadata
            )
        except Exception as e:
            print(f" Failed to save assistant message: {e}")

    # 8. Calculate execution time
    end_time = datetime.datetime.now()
    row_data["EXECUTION_TIME_MS"] = int((end_time - start_time).total_seconds() * 1000)
    
    # 9. Save Audit Log
    row_data["FULL_RAW_JSON"] = final_output
    try:
        _save_audit_row(session, row_data, session_id)
    except Exception as e:
        print(f" Failed to save audit log: {e}")
        import traceback
        traceback.print_exc()
    
    print(" Process Completed")
    print(f"  Total Execution Time: {row_data['EXECUTION_TIME_MS']}ms")
    
    return final_output


# Helper wrapper for Snowflake stored procedure
def handler(session: Session, session_id: str, user_query: str) -> str:
    """
    Snowflake Stored Procedure Handler
    
    Usage:
    CALL AGENT_HANDLER('session_123', 'Show me top prescribers');
    """
    try:
        result = main(session, session_id, user_query)
        return json.dumps(result, indent=2)
    except Exception as e:
        error_result = {
            "status": "error",
            "message": str(e),
            "traceback": traceback.format_exc()
        }
        return json.dumps(error_result, indent=2)


if __name__ == "__main__":
    # For local testing
    pass




name: MASTERTABLE_V1
tables:
  - name: MASTER_TABLE_V1
    description: The table contains records of healthcare professionals and their prescribing activities. Each record represents a healthcare provider with their demographic information, specialty, affiliated organization, and prescription transaction metrics across various time periods for acute care products.
    base_table:
      database: DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB
      schema: AI_POC
      table: MASTER_TABLE_V1
    dimensions:
      - name: HCO_NAME
        synonyms:
          - clinic_name
          - facility_name
          - health_system_name
          - healthcare_organization_name
          - hospital_name
          - institution_name
          - medical_center_name
          - medical_facility_name
          - organization_name
          - provider_organization
        description: Healthcare organization names.
        expr: HCO_NAME
        data_type: VARCHAR(16777216)
        cortex_search_service:
          database: DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB
          schema: AI_POC
          service: _CORTEX_ANALYST_MASTER_TABLE_V1_HCO_NAME_91EA1418_A291_4D58_BF65_75BF1AF28F6E
        sample_values:
          - BAPTIST HEALTHCARE SYSTEM, INC
          - UPMC
          - UNIVERSITY HOSPITALS
      - name: HCP_FIRST_NAME
        synonyms:
          - clinician_first_name
          - doctor_first_name
          - first_name
          - forename
          - given_name
          - personal_name
          - physician_first_name
          - practitioner_first_name
          - provider_first_name
        description: Healthcare provider first names.
        expr: HCP_FIRST_NAME
        data_type: VARCHAR(16777216)
        cortex_search_service:
          database: DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB
          schema: AI_POC
          service: _CORTEX_ANALYST_MASTER_TABLE_V1_HCP_FIRST_NAME_66D01364_C77D_45D4_B02D_D71CEBDFAA23
        sample_values:
          - TIMOTHY
          - JASON
          - KATLYN
      - name: HCP_ID
        description: Unique identifier for healthcare providers.
        expr: HCP_ID
        data_type: VARCHAR(32)
        sample_values:
          - 4817ce0a1104686405eb72f5db6d8849
          - 6fa5a694bb142b049f8145f9ea5da727
          - 8afa4f843217ce3439bddfceeaabb9d0
      - name: HCP_LAST_NAME
        synonyms:
          - clinician_last_name
          - doctor_last_name
          - family_name
          - healthcare_provider_surname
          - last_name
          - medical_professional_surname
          - physician_surname
          - practitioner_surname
          - provider_surname
          - surname
        description: Last names of healthcare providers.
        expr: HCP_LAST_NAME
        data_type: VARCHAR(16777216)
        cortex_search_service:
          database: DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB
          schema: AI_POC
          service: _CORTEX_ANALYST_MASTER_TABLE_V1_HCP_LAST_NAME_134C0347_3EB8_4EC5_AEC7_F717EDF82B5E
        sample_values:
          - RIGONI
          - ORAZULIKE
          - HAILES
      - name: HCP_SPECIALTY
        synonyms:
          - clinician_specialty
          - doctor_specialty
          - healthcare_provider_specialty
          - medical_specialty
          - physician_specialty
          - practice_area
          - practitioner_specialty
          - provider_field
        description: Medical specialties of healthcare providers.
        expr: HCP_SPECIALTY
        data_type: VARCHAR(16777216)
        cortex_search_service:
          database: DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB
          schema: AI_POC
          service: _CORTEX_ANALYST_MASTER_TABLE_V1_HCP_SPECIALTY_05580C7E_FBE4_46A0_B31B_13436B7062A4
        sample_values:
          - INTERNAL MEDICINE
          - GENERAL SURGERY
          - FAMILY MEDICINE
      - name: ONEKEY_HCP_ID
        synonyms:
          - clinician_id
          - doctor_id
          - HCP_ID
          - hcp_identifier
          - healthcare_provider_id
          - medical_provider_id
          - physician_id
          - practitioner_id
          - provider_identifier
          - provider_key
        description: OneKey healthcare provider identifier.
        expr: ONEKEY_HCP_ID
        data_type: VARCHAR(16777216)
        sample_values:
          - WUSM01326080
          - WUSM03825060
      - name: PROD_CAT_CD
        synonyms:
          - category_code
          - item_category_code
          - merchandise_category_code
          - prod_category_cd
          - product_cat_code
          - product_category_code
          - product_classification_code
        description: Pharmaceutical product category codes indicating the therapeutic classification of pain management medications.
        expr: PROD_CAT_CD
        data_type: VARCHAR(256)
        sample_values:
          - NSAID
          - MODERATE OPIOID COMBINATIONS
      - name: PROD_FAMGRP_CD
        synonyms:
          - product_family_code
          - product_family_group_code
          - product_family_id
          - product_group_code
        description: Pharmaceutical product family group codes representing categories of pain management medications.
        expr: PROD_FAMGRP_CD
        data_type: VARCHAR(256)
        sample_values:
          - MELOXICAM
          - ETODOLAC
          - NAPROXEN
      - name: PTAM_TERRITORY_ID
        synonyms:
          - territory_code
          - territory_id
          - zone_id
        description: PTAM territory identifier used for sales performance tracking and analytics.
        expr: PTAM_TERRITORY_ID
        data_type: VARCHAR(255)
        sample_values:
          - V1NAUSA-5731503
      - name: ZIP_CODE
        synonyms:
          - address_code
          - area_code
          - location_code
          - postal_code
          - postcode
          - zip
          - zipcode
        description: Postal ZIP codes for geographic locations.
        expr: ZIP_CODE
        data_type: VARCHAR(16777216)
        cortex_search_service:
          database: DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB
          schema: AI_POC
          service: _CORTEX_ANALYST_MASTER_TABLE_V1_ZIP_CODE_09836730_2BEB_48E9_A65B_C2D9268AC769
        sample_values:
          - '29715'
          - '29201'
    facts:
      - name: ACUTE_NRX_XPO_12M
        synonyms:
          - acute_new_prescriptions_12m
          - acute_new_prescriptions_exposure_12_months
          - acute_new_rx_annual_exposure
          - acute_new_rx_xpo_annual
          - acute_nrx_exposure_yearly
          - acute_nrx_yearly_exposure
          - new_acute_prescriptions_12_months
          - nrx_acute_exposure_12m
        description: Twelve-month exposure metric for acute new prescriptions.
        expr: ACUTE_NRX_XPO_12M
        data_type: NUMBER(38,2)
        access_modifier: public_access
        default_aggregation: 0
        sample_values:
          - '1.22'
          - '106.73'
      - name: ACUTE_NRX_XPO_1M
        description: Acute new prescription exposure over a one-month period.
        expr: ACUTE_NRX_XPO_1M
        data_type: NUMBER(38,2)
        access_modifier: public_access
        sample_values:
          - '7.27'
          - '1.33'
          - '6.36'
      - name: ACUTE_NRX_XPO_1W
        description: Acute new prescription exposure over a one-week period.
        expr: ACUTE_NRX_XPO_1W
        data_type: NUMBER(38,2)
        access_modifier: public_access
        sample_values:
          - '7.61'
          - '4.80'
          - '11.78'
      - name: ACUTE_NRX_XPO_2W
        description: Acute new prescription exposure over a two-week period.
        expr: ACUTE_NRX_XPO_2W
        data_type: NUMBER(38,2)
        access_modifier: public_access
        sample_values:
          - '13.81'
          - '1.06'
          - '2.17'
      - name: ACUTE_NRX_XPO_3M
        description: Acute new prescription exposure over a three-month period.
        expr: ACUTE_NRX_XPO_3M
        data_type: NUMBER(38,2)
        access_modifier: public_access
        sample_values:
          - '6.05'
          - '0.99'
          - '3.79'
      - name: ACUTE_NRX_XPO_3W
        description: Acute new prescription exposure over a three-week period.
        expr: ACUTE_NRX_XPO_3W
        data_type: NUMBER(38,2)
        access_modifier: public_access
        sample_values:
          - '5.26'
          - '16.13'
          - '11.11'
      - name: ACUTE_NRX_XPO_6M
        description: Acute new prescription exposure over a six-month period.
        expr: ACUTE_NRX_XPO_6M
        data_type: NUMBER(38,2)
        access_modifier: public_access
        sample_values:
          - '26.70'
          - '3.91'
          - '7.30'
      - name: ACUTE_TRX_LAAD_12M
        description: The number of acute transactions with left anterior descending artery involvement in the past 12 months.
        expr: ACUTE_TRX_LAAD_12M
        data_type: NUMBER(30,0)
        access_modifier: public_access
        sample_values:
          - '52'
          - '48'
          - '98'
      - name: ACUTE_TRX_LAAD_1M
        description: The number of acute transactions for left anterior descending artery procedures within a one-month period.
        expr: ACUTE_TRX_LAAD_1M
        data_type: NUMBER(30,0)
        access_modifier: public_access
        sample_values:
          - '0'
          - '1'
          - '7'
      - name: ACUTE_TRX_LAAD_1W
        description: The number of acute transactions with a one-week look-ahead period.
        expr: ACUTE_TRX_LAAD_1W
        data_type: NUMBER(30,0)
        access_modifier: public_access
        sample_values:
          - '2'
          - '1'
          - '0'
      - name: ACUTE_TRX_LAAD_2W
        description: The number of acute transactions for left anterior descending artery procedures within a two-week period.
        expr: ACUTE_TRX_LAAD_2W
        data_type: NUMBER(30,0)
        access_modifier: public_access
        sample_values:
          - '1'
          - '0'
          - '16'
      - name: ACUTE_TRX_LAAD_3M
        description: The number of acute transactions with left anterior descending artery involvement within a three-month period.
        expr: ACUTE_TRX_LAAD_3M
        data_type: NUMBER(30,0)
        access_modifier: public_access
        sample_values:
          - '1'
          - '44'
          - '11'
      - name: ACUTE_TRX_LAAD_3W
        description: The number of acute transactions with left anterior descending artery disease within a 3-week period.
        expr: ACUTE_TRX_LAAD_3W
        data_type: NUMBER(30,0)
        access_modifier: public_access
        sample_values:
          - '2'
          - '14'
          - '6'
      - name: ACUTE_TRX_LAAD_6M
        description: The number of acute transactions with left anterior descending artery involvement within a six-month period.
        expr: ACUTE_TRX_LAAD_6M
        data_type: NUMBER(30,0)
        access_modifier: public_access
        sample_values:
          - '0'
          - '1'
          - '16'
      - name: ACUTE_TRX_XPO_12M
        description: Acute transaction exposure over a 12-month period.
        expr: ACUTE_TRX_XPO_12M
        data_type: NUMBER(38,2)
        access_modifier: public_access
        sample_values:
          - '106.73'
          - '5.96'
          - '7.97'
      - name: ACUTE_TRX_XPO_1M
        description: Acute transaction exposure over a one-month period.
        expr: ACUTE_TRX_XPO_1M
        data_type: NUMBER(38,2)
        access_modifier: public_access
        sample_values:
          - '0.00'
          - '9.15'
          - '1.06'
      - name: ACUTE_TRX_XPO_1W
        description: Acute transaction exposure over a one-week period.
        expr: ACUTE_TRX_XPO_1W
        data_type: NUMBER(38,2)
        access_modifier: public_access
        sample_values:
          - '8.98'
          - '5.46'
          - '11.30'
      - name: ACUTE_TRX_XPO_2W
        description: Acute transaction exposure over a two-week period.
        expr: ACUTE_TRX_XPO_2W
        data_type: NUMBER(38,2)
        access_modifier: public_access
        sample_values:
          - '16.50'
          - '31.73'
          - '2.12'
      - name: ACUTE_TRX_XPO_3M
        description: Acute transaction exposure over a three-month period.
        expr: ACUTE_TRX_XPO_3M
        data_type: NUMBER(38,2)
        access_modifier: public_access
        sample_values:
          - '2.01'
          - '4.10'
          - '10.10'
      - name: ACUTE_TRX_XPO_3W
        description: Acute transaction exposure over a three-week period.
        expr: ACUTE_TRX_XPO_3W
        data_type: NUMBER(38,2)
        access_modifier: public_access
        sample_values:
          - '3.22'
          - '38.05'
          - '9.22'
      - name: ACUTE_TRX_XPO_6M
        description: Acute transaction exposure over a six-month period.
        expr: ACUTE_TRX_XPO_6M
        data_type: NUMBER(38,2)
        access_modifier: public_access
        sample_values:
          - '4.89'
          - '1.22'
          - '26.70'
verified_queries:
  - name: '"Can you show me my top 5 prescribers in my territiory id  V1NAUSA-5731503 for last 6 months consider total prescriptions "'
    sql: |-
      SELECT
        hcp_first_name,
        hcp_last_name,
        hcp_id,
        hcp_specialty,
        SUM(acute_trx_xpo_6m) AS total_prescriptions_6m
      FROM
        master_table_v1
      WHERE
        ptam_territory_id = 'V1NAUSA-5731503'
      GROUP BY
        hcp_first_name,
        hcp_last_name,
        hcp_id,
        hcp_specialty
      ORDER BY
        total_prescriptions_6m DESC NULLS LAST
      LIMIT
        5
        /* Generated by Cortex Analyst (request_id: d96f3a06-ebe8-4853-bda3-0005c7093f31) */
    question: 'Can you show me my top 5 prescribers in my territiory id  V1NAUSA-5731503 for last 6 months consider total prescriptions '
    verified_at: 1769064648
    verified_by: Rakesh Nadukuda
    use_as_onboarding_question: false
  - name: '"Which zip codes are outperforming the nation under total prescriptions  for last 3 months "'
    sql: |-
      WITH zip_totals AS (
        SELECT
          zip_code,
          SUM(acute_nrx_xpo_3m + acute_trx_xpo_3m) AS total_prescriptions_3m
        FROM
          master_table_v1
        GROUP BY
          zip_code
      ),
      national_avg AS (
        SELECT
          AVG(total_prescriptions_3m) AS nat_avg_prescriptions_3m
        FROM
          zip_totals
      )
      SELECT
        zt.zip_code,
        zt.total_prescriptions_3m,
        na.nat_avg_prescriptions_3m
      FROM
        zip_totals AS zt
        CROSS JOIN national_avg AS na
      WHERE
        zt.total_prescriptions_3m > na.nat_avg_prescriptions_3m
      ORDER BY
        zt.total_prescriptions_3m DESC NULLS LAST
        /* Generated by Cortex Analyst (request_id: 01710a90-c307-4b13-a8ee-5ff6213161ca) */
    question: 'Which zip codes are outperforming the nation under total prescriptions  for last 3 months '
    verified_at: 1769065286
    verified_by: Rakesh Nadukuda
    use_as_onboarding_question: false
  - name: '"Show me providers who are underperforming compared to their specialty peers in the same zipcode."'
    sql: |-
      WITH specialty_zip_avg AS (
        SELECT
          hcp_specialty,
          zip_code,
          AVG(acute_nrx_xpo_12m + acute_trx_xpo_12m) AS avg_prescriptions
        FROM
          master_table_v1
        GROUP BY
          hcp_specialty,
          zip_code
      ),
      provider_performance AS (
        SELECT
          mt.hcp_id,
          mt.hcp_first_name,
          mt.hcp_last_name,
          mt.hcp_specialty,
          mt.zip_code,
          (mt.acute_nrx_xpo_12m + mt.acute_trx_xpo_12m) AS total_prescriptions,
          sza.avg_prescriptions AS specialty_zip_avg
        FROM
          master_table_v1 AS mt
          JOIN specialty_zip_avg AS sza ON mt.hcp_specialty = sza.hcp_specialty
          AND mt.zip_code = sza.zip_code
      )
      SELECT
        hcp_id,
        hcp_first_name,
        hcp_last_name,
        hcp_specialty,
        zip_code,
        total_prescriptions,
        specialty_zip_avg
      FROM
        provider_performance
      WHERE
        total_prescriptions < specialty_zip_avg
      ORDER BY
        hcp_specialty,
        zip_code,
        total_prescriptions DESC NULLS LAST
        /* Generated by Cortex Analyst (request_id: 18f10eaf-1b9e-43b9-8e83-7fd1d5d9be46) */
    question: Show me providers who are underperforming compared to their specialty peers in the same zipcode.
    verified_at: 1769067279
    verified_by: Rakesh Nadukuda
    use_as_onboarding_question: false




--------------------------------------------------
{'query': 'Why is Tramadol showing higher prescription volume than Diclofenac '
          'for last three months?',
 'session': '1112'}
==================================================
 Retrieved 0 past messages for Session 1112
 Saved user message to history.
--- INVOKING AGENT: Rephraser Agent ---
--- INVOKING AGENT: Intent Agent ---
--- INVOKING AGENT: Root Cause Agent ---
 Audit Log Error (DataFrame approach): (1304): 01c20364-081a-386d-0075-0383fdcff41e: 002020 (21S01): 01c20364-081a-386d-0075-0383fdcff41e: SQL compilation error:
Insert value list does not match column list expecting 22 but got 21
 Attempting simplified insert without VARIANT fields...
 Audit log saved with simplified data (VARIANT fields skipped).
 Process Completed
  Total Execution Time: 250707ms




import json
import logging
import pprint
import re
import _snowflake # Native Snowflake module for internal API calls
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import List, Dict, Any, Optional, Literal, Tuple
from pydantic import BaseModel, Field, field_validator
from snowflake.snowpark import Session
from snowflake.snowpark.functions import lit, parse_json, col
from collections import defaultdict
import datetime
import traceback

# ==========================================
# 1. CONFIGURATION
# ==========================================

class AgentConfig(BaseModel):
    """Configuration for the agent execution"""
    # LLM Models
    model: str = "claude-sonnet-4-5" 
    
    # Snowflake Objects
    cortex_analyst_object_master: str = "DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.AI_POC.MASTERTABLE_V1"
    cortex_analyst_object_ards: str = "DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.REPORTING.BASIC_CORTEX_ANALYST"
    warehouse: str = "DEV_PAIN_SALES_PERFORMANCE_B_WH"
    
    # Tables - Updated to V2
    messages_table: str = "DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.AI_POC.MESSAGES_V2"
    audit_log_table: str = "DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.AI_POC.AGENT_DETAILED_HISTORY_V2"
    
    
    # Tools
    diagnostic_udf: str = "DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.AI_POC.DIAGNOSTIC_TOOL"
    diagnostic_tree_id: str = "pharma_sales_v3" 
    
    enable_semantic_parsing: bool = True

CONFIG = AgentConfig()

# ==========================================
# 2. PYDANTIC MODELS
# ==========================================

class EvaluationResult(BaseModel):
    score: int = Field(default=0, description="Score 1-10.")
    reasoning: str = Field(default="No evaluation provided.", description="Justification.")

class IntentClassification(BaseModel):
    intent_type: str = Field(..., description="greeting, data_retrieval, root_cause_analysis, clarification_needed, general_question, off_topic, combined")
    data_retrieval_query: Optional[str] = None
    root_cause_query: Optional[str] = None
    direct_response: Optional[str] = None
    clarification_question: Optional[str] = None
    confidence: str = Field(..., description="high, medium, low")
    reasoning: str = Field(..., description="Reasoning")

class RephraserOutput(BaseModel):
    refined_query: str = Field(..., description="The fully contextualized query.")

class TableSelection(BaseModel):
    relevant_table_names: List[str] = Field(..., description="List of table names.")

class GuardResult(BaseModel):
    is_safe: bool = Field(...)
    message: Optional[str] = Field(None)

class SqlResult(BaseModel):
    clean_answer_text: str = Field(default="")
    clarifying_question: Optional[str] = None
    tables: List[Any] = Field(default_factory=list)
    charts: List[Any] = Field(default_factory=list)  # Changed from List[Dict]
    sql_generated: Optional[str] = None
    sql_explanation: Optional[str] = None
    is_verified_query: bool = False
    evaluation: EvaluationResult = Field(default_factory=EvaluationResult)
    is_retry: bool = False

    @field_validator('charts', mode='before')
    @classmethod
    def parse_charts(cls, v):
        if not v: 
            return []
        parsed = []
        for item in v:
            if isinstance(item, dict): 
                parsed.append(item)
            elif isinstance(item, str):
                try: 
                    parsed_item = json.loads(item)
                    parsed.append(parsed_item)
                except: 
                    # Keep as string if can't parse
                    parsed.append(item)
        return parsed

class DiagnosticResult(BaseModel):
    clean_summary_text: str = Field(default="")
    clarifying_question: Optional[str] = None
    react_flow_json: Optional[Dict] = None
    evaluation: EvaluationResult = Field(default_factory=EvaluationResult)

# ==========================================
# 3. PROMPTS (RESTORED & ENHANCED)
# ==========================================

# --- REPHRASER ---
PROMPT_REPHRASER_SYSTEM = "You are a sophisticated Query Refinement Engine. Be polite, professional, and friendly. Be direct and unambiguous."

PROMPT_REPHRASER_ORCHESTRATION = """
<query_refinement_instructions>
<objective>
Transform the user's input into a standalone, context-complete query that can be understood without prior conversation history.
</objective>

<core_rules>
<rule id="1">Resolve all pronouns (it, they, that, this, those) to their specific referents based on chat history.</rule>
<rule id="2">Preserve ALL metrics, entity names, IDs, and numerical values EXACTLY as stated.</rule>
<rule id="3">Maintain the original intent and scope - do not expand or narrow the question.</rule>
<rule id="4">Keep technical terminology and domain-specific language intact.</rule>
<rule id="5">Ensure the output is grammatically correct and reads naturally.</rule>
</core_rules>

<follow_up_handling_rules>
<rule id="6">IF previous Bot response contained Data (e.g., "Sales are down") AND User asks "Why?", REPHRASE to "Why are sales down?"</rule>
<rule id="7">IF previous Bot response was a Clarification (e.g., "By region?"), AND User answers "Region", REPHRASE to combine them.</rule>
</follow_up_handling_rules>

<transformation_examples>
<example>
<input>What about Arizona?</input>
<context>Previous discussion about sales performance in Texas</context>
<output>What is the sales performance in Arizona?</output>
</example>

<example>
<input>Why is it down?</input>
<context>Previous mention of Q4 revenue</context>
<output>Why is Q4 revenue down?</output>
</example>
</transformation_examples>
</query_refinement_instructions>
"""

PROMPT_REPHRASER_RESPONSE = """
<output_format>
At the VERY END of your text response, YOU MUST output a JSON block STRICTLY in below format: 
Example: { "refined_query": "What is the sales performance in Arizona?" }
Do not include any other text or markdown outside the JSON object.
</output_format>
"""

# --- INTENT ---
PROMPT_INTENT_SYSTEM = "You are an Expert Intent Classification System. Be polite, professional, and friendly. Be direct and unambiguous."

PROMPT_INTENT_ORCHESTRATION = """
<intent_classification_instructions>

<mission>
Your ONLY job is to identify the user's INTENT. Do NOT retrieve data, do NOT answer questions, do NOT perform analysis.
Classify the intent type and route accordingly. If you can answer directly (like greetings), provide direct_response.
</mission>

<intent_categories>

<intent name="greeting">
<description>User is greeting, saying hello, or engaging in pleasantries</description>
<indicators>hi, hello, hey, good morning, how are you, thanks, thank you, goodbye, bye</indicators>
<action>Set direct_response with a friendly greeting. No other fields needed.</action>
</intent>

<intent name="data_retrieval">
<description>User wants to see/get/retrieve DATA - numbers, lists, metrics, tables</description>
<indicators>show, list, get, display, find, what is the value, how many, count, total, give me</indicators>
<action>Extract the data request to data_retrieval_query. Keep as natural language. Add "and generate a table and a visual".</action>
**CRITICAL VISUALIZATION LOGIC:**
Analyze the data request. If it implies trends (over time), comparisons (by region/product), or distributions, you MUST automatically append "and generate a table and a visual" to the query string, even if the user did not explicitly ask for a chart.
</intent>

<intent name="root_cause_analysis">
<description>User wants to understand WHY, CAUSES, DRIVERS, REASONS, EXPLANATIONS</description>
<indicators>why, explain, what is driving, what is causing, what's behind, reason for, root cause, how come, what factors</indicators>
<action>Extract the causal question to root_cause_query. Keep VERBATIM - exact text from user.</action>
</intent>

<intent name="combined">
<description>User wants BOTH data AND causal analysis in one request</description>
<indicators>Contains both data keywords AND causal keywords</indicators>
<action>Split into data_retrieval_query AND root_cause_query. Keep both portions.</action>
</intent>

<intent name="clarification_needed">
<description>User's intent is unclear, vague, or ambiguous - you cannot determine what they want</description>
<indicators>Very short/vague input, unclear pronouns without context, incomplete thoughts</indicators>
<action>Set clarification_question asking user to be more specific.</action>
</intent>

<intent name="general_question">
<description>General questions about the system, capabilities, how to use features - not data or analysis requests</description>
<indicators>how do I, can you, what can you do, help me understand, how does this work</indicators>
<action>Set direct_response with helpful information about capabilities.</action>
</intent>

<intent name="off_topic">
<description>User is asking about unrelated topics not connected to data, analytics, or business questions</description>
<indicators>Questions about weather, sports, entertainment, personal topics unrelated to business/data</indicators>
<action>Set direct_response politely redirecting to business/data topics.</action>
</intent>

</intent_categories>

<CRITICAL_CLASSIFICATION_RULES>

 RULE 1: NEVER DO THE WORK - ONLY CLASSIFY
You are NOT a data analyst. You are NOT an answering agent. You ONLY identify intent type.
Do NOT retrieve data. Do NOT answer analytical questions. ONLY classify and route.

 RULE 2: CAUSAL KEYWORD DETECTION
These ALWAYS indicate root_cause_analysis intent:
- "what is driving"
- "what is causing"
- "what's driving"  
- "what's causing"
- "why is/are"
- "explain why"
- "reason for"
- "root cause"
- "what factors"
- "what's behind"
- "how come"

 RULE 3: DATA KEYWORD DETECTION  
These ALWAYS indicate data_retrieval intent:
- "show me"
- "list"
- "get"
- "display"
- "find all"
- "what is the value/total/count of"
- "how many"

 RULE 4: DIRECT RESPONSE ONLY FOR SIMPLE CASES
Use direct_response ONLY for:
- Greetings (hi, hello, thanks)
- General system questions (what can you do)
- Off-topic redirects

Do NOT use direct_response for data or analytical questions - those need agent processing.

 RULE 5: VERBATIM PRESERVATION FOR ROOT CAUSE
For root_cause_query: Copy EXACT text from user. No paraphrasing, no summarizing.

 RULE 6: NO SQL CODE GENERATION
NEVER write SELECT/FROM/WHERE statements. Keep everything as natural language.

 RULE 7: CONFIDENCE SCORING
- high: Intent is crystal clear
- medium: Intent is likely but has some ambiguity
- low: Intent is very unclear, might need clarification

</CRITICAL_CLASSIFICATION_RULES>
</intent_classification_instructions>
"""

PROMPT_INTENT_RESPONSE = """
<output_format>
At the VERY END of your text response, YOU MUST output a JSON block STRICTLY in below format:
{
  "intent_type": "data_retrieval",
  "data_retrieval_query": "Show me sales...",
  "root_cause_query": null,
  "direct_response": null,
  "clarification_question": null,
  "confidence": "high",
  "reasoning": "User used 'show me' keyword"
}
</output_format>
"""

# --- DATA AGENT ---
PROMPT_DATA_AGENT_SYSTEM = "You are an expert Data Analyst. Be polite, professional, and friendly. Be direct and unambiguous."

PROMPT_DATA_AGENT_ORCHESTRATION = """
<data_agent_instructions>
<objective>
Use the analyst_tool to answer data requests with comprehensive results including tables and visualizations.
</objective>

<clarification_protocol>
You have access to the Master Schema.
If the user asks a vague question like "Show me sales" without specifying time, product, or region:
1. CHECK the Master Schema for available dimensions (e.g., Region, Specialty, Brand).
2. DO NOT guess.
3. ASK a specific clarifying question: "Would you like to see sales broken down by Region, Specialty, or Brand?"
4. If the query is clear, proceed to generate SQL.
</clarification_protocol>

<execution_rules>
<rule id="1">ALWAYS generate a table (Result Set) for data requests</rule>
<rule id="2">Generate appropriate visualizations when data is suitable for charts</rule>
<rule id="3">Provide clear, concise summaries of the data findings</rule>
<rule id="4">Handle errors gracefully and explain any data limitations</rule>
</execution_rules>

<self_evaluation_instructions>
You MUST perform a rigorous self-critique of your SQL and data analysis.
1. **Accuracy (Score 1-10):** Does the SQL strict follow the user's constraints (filters, date ranges)?
2. **Data Integrity:** Are the results logical? (e.g., no negative counts where impossible).
3. **Clarity:** Is the summary accessible to a non-technical user?
</self_evaluation_instructions>
</data_agent_instructions>
"""

PROMPT_DATA_AGENT_RESPONSE = """
<output_format>
At the VERY END of your text response, YOU MUST output a JSON block STRICTLY in below format:
```json
{
  "clean_answer_text": "Summary of findings...",
  "clarifying_question": null,
  "evaluation": {
    "score": 8,
    "reasoning": "Data matches request."
  }
}
```
</output_format>
"""

# --- ROOT CAUSE ---
PROMPT_ROOT_CAUSE_SYSTEM = "You are an Autonomous Root Cause Analysis Agent. Be polite, professional, and friendly. Be direct and unambiguous."

PROMPT_ROOT_CAUSE_ORCHESTRATION = f"""
<root_cause_orchestration_prompt>
    <role_and_objective>
        You are an **Autonomous Root Cause Analysis Agent** designed to traverse a metric decision tree from the root node down to the leaf nodes. Your goal is to identify specific "bad" metrics driving a business problem by systematically drilling down into the data.
        
        ALWAYS USE tree_id as {CONFIG.diagnostic_tree_id}.
    </role_and_objective>

    <phase_1_clarification_check>
        **CRITICAL:** Before running any tools, analyze the USER_QUERY against the MASTER SCHEMA dimensions.
        
        MASTER SCHEMA:

        {CONFIG.cortex_analyst_object_master}
        
        IF the user asks a generic question like "Why is revenue down?" or "Explain the drop":
        1. You cannot run the tool efficiently without a starting point (Root Node context).
        2. Look at available schema dimensions (Region, Product, Specialty, Time).
        3. **STOP** and return a `clarifying_question`.
           Example: "To analyze the revenue drop, should I compare performance by Region, Product Class, or Customer Specialty?"
        
        IF the query contains specific context (e.g., "Why is Tylenol down in NY?"), PROCEED to Phase 2.
    </phase_1_clarification_check>

    <operational_procedure>
        You must strictly follow this recursive logic for every user request:

        **Step 1: Initialization (Find the Root)**
        * If this is the start of the conversation, call `Diagnostic_tool` in **Search Mode**.
        * **Action:** Call `Diagnostic_tool(USER_QUERY=user_question, PARENT_NODE_IDS_JSON=NULL, TREE_ID='{CONFIG.diagnostic_tree_id}')`.
        * **Next:** Proceed to Step 2 with the results.

        **Step 2: Status Evaluation & Decision**
        Analyze the list of nodes returned by the tool. Focus **only** on nodes where `"status": "bad"`.

        * **Check:** For every "bad" node, do you see its children in the current list?
        * **Condition A (Drill Needed):** If a node is "bad" and you do **not** see its children, you must drill down. Collect these Node IDs.
        * **Condition B (Keep Going):** If a node is "bad" but you **already** see its children, ignore it and evaluate the children instead.
        * **Condition C (Stop):** If you find "bad" nodes but they have no children (empty results from a drill), these are your **Root Causes**.

        **Step 3: Execution (Drill Down)**
        * If Condition A occurred: Call `Diagnostic_tool` in **Drill Mode**.
        * **Action:** Call `Diagnostic_tool(USER_QUERY=NULL, PARENT_NODE_IDS_JSON='["ID_1", "ID_2"]', TREE_ID='{CONFIG.diagnostic_tree_id}')`.
        * **Next:** Recursively repeat Step 2 with the new output.
        * If Condition C occurred: Present the final root causes to the user.
    </operational_procedure>

    <constraints>
        * **Never** guess the status of a metric; always use the tool.
        * **Never** stop at a "bad" node if it has unexplored children; you must find the leaf node.
        * Output your reasoning briefly before calling the tool.
    </constraints>

    <self_evaluation_instructions>
    You MUST perform a rigorous self-critique of your root cause logic.
    1. **Logic (Score 1-10):** Is the causal chain (Root -> Leaf) mathematically sound?
    2. **Driver Isolation:** Did we truly find the leaf node, or did we stop too early?
    3. **Completeness:** Did we explore all "bad" branches?
    </self_evaluation_instructions>
</root_cause_orchestration_prompt>
"""

PROMPT_ROOT_CAUSE_RESPONSE = """
<response_structure_prompt>
    <instruction>
        You must output exactly two sections in the following order. Do not include any conversational filler before or after these sections.
    </instruction>

    <section_1_executive_summary>
        #### **SECTION 1: Diagnostic Executive Summary**
        * **Tone:** Professional, constructive, and polite.
        * **Headline:** State the Root Cause clearly.
        * **The Narrative:** Briefly explain the chain of events in simple English.
        * **Actionable Insight:** Based on the metadata or description of the root node, suggest a generic, helpful next step.
    </section_1_executive_summary>

    <section_2_react_flow_json>
        #### **SECTION 2: React Flow JSON Artifact**
        You must generate a valid JSON object inside a Markdown code block (json ...).
        
        **4. JSON Schema (Must Follow Exactly):**
        {
          "nodes": [
            {
              "id": "N0",
              "type": "default",
              "data": { "label": "Metric Name: Value" },
              "position": { "x": 0, "y": 0 },
              "style": { "background": "#FFE2E5", "width": 180, "color": "#333", "border": "1px solid #777", "borderRadius": "8px" }
            }
          ],
          "edges": [
            {
              "id": "e-N0-N1",
              "source": "N0",
              "target": "N1",
              "label": "driven by",
              "animated": true,
              "style": { "stroke": "#555", "strokeWidth": 2 }
            }
          ]
        }
    </section_2_react_flow_json>
    
    <section_3_final_json>
        CRITICAL: Provide the final JSON block for the parser here as defined in the system prompt evaluation section.
    </section_3_final_json>
    
    **CRITICAL** : YOU MUST ONLY EXECUTE ATMOST 8 TOOL CALLS.
    
    <output_format>
    At the VERY END of your text response, YOU MUST output a JSON block STRICTLY in below format:
    ```json
    {
      "clean_summary_text": "Executive summary...",
      "clarifying_question": null,
      "react_flow_json": { "nodes": [], "edges": [] },
      "evaluation": { "score": 9, "reasoning": "Found root cause." }
    }
    ```
    </output_format>
</response_structure_prompt>
"""

# --- TABLE SELECTION ---
PROMPT_TABLE_SELECTION = """
<instruction>
You are an expert Database Architect and Schema Analyzer.
Your goal is to identify the subset of tables from the provided list that are strictly relevant to answering the user's query.

<rules>
1. **Analyze the Query**: Carefully understand the business entities, metrics, and dimensions requested.
2. **Review Summaries**: Check the Table Name and Description for each table provided.
3. **Strict Selection**: Select ONLY tables that contain the data needed. Do NOT include tables "just in case".
4. **Keyword Matching**: 
   - If the query mentions "sales" or "revenue", look for Fact tables with those metrics.
   - If the query mentions "location", "city", or "state", look for Geography Dimension tables.
   - If the query mentions "products", look for Product Dimension tables.
5. **Empty Return**: If no tables seem relevant, return an empty list.
</rules>

<output_format>
Output ONLY a valid JSON object with the following structure. Do not output markdown code blocks.
{
  "relevant_table_names": ["Table_A", "Table_B"]
}
</output_format>
</instruction>
"""

# --- SEMANTIC TRANSLATOR ---
PROMPT_SEMANTIC_TRANSLATOR = """
<instruction>
You are a Semantic Query Optimizer and SQL Expert.
Your goal is to rewrite the User's Natural Language Query so that it aligns perfectly with the provided Database Schema Context.

<rules>
1. **Vocabulary Mapping:** Replace generic business terms in the user query with the EXACT column names found in the Schema Context.
   - Example: If user says "revenue" and context has "TOTAL_SALES_AMT", use "TOTAL_SALES_AMT".
   - Example: If user says "doctors" and context has "HCP_ID", use "HCP_ID".
2. **Filter Alignment:** Check 'sample_values' in the context.
   - Example: If user says "in NY", and sample values for 'STATE_CD' are 'New York', rewrite to "STATE_CD is 'New York'".
3. **Disambiguation:** If a term matches multiple columns, use the column descriptions to pick the most relevant one.
4. **Preservation:** Do not change the user's core intent (e.g., ranking, aggregation, filtering). Just swap the terminology.
5. **Output**: Return ONLY the rewritten natural language query string. Do not output SQL. Do not output JSON.
</rules>
</instruction>
"""

# ==========================================
# 4. HELPER FUNCTIONS
# ==========================================

def log_checkpoint(step: str, details: Any):
    print(f"\n{'='*50}\n CHECKPOINT: {step}\n{'-'*50}")
    if isinstance(details, BaseModel): pprint.pprint(details.model_dump())
    elif isinstance(details, (dict, list)): pprint.pprint(details)
    else: print(str(details))
    print(f"{'='*50}\n")

# ==========================================
# HISTORY MANAGEMENT FUNCTIONS (UPDATED)
# ==========================================

def get_chat_history(session: Session, session_id: str, limit: int = 10) -> List[Dict]:
    """Retrieves chat history for a specific session_id formatted for Cortex."""
    if not session_id: 
        return []
    
    try:
        sql = f"""
        SELECT SENDER_TYPE, MESSAGE_TEXT 
        FROM {CONFIG.messages_table}
        WHERE CONVERSATION_ID = '{session_id}'
        ORDER BY CREATED_AT ASC
        LIMIT {limit}
        """
        rows = session.sql(sql).collect()
        
        history = []
        for r in rows:
            role = "user" if r['SENDER_TYPE'].lower() == 'user' else "assistant"
            history.append({
                "role": role, 
                "content": [{"type": "text", "text": r['MESSAGE_TEXT']}]
            })
        
        print(f" Retrieved {len(history)} past messages for Session {session_id}")
        return history
        
    except Exception as e:
        print(f" History Fetch Failed: {e}")
        return []

def save_chat_message(session: Session, session_id: str, role: str, content: str, metadata: Optional[Dict] = None):
    """Saves a message to the MESSAGES_V2 table with proper VARIANT handling."""
    if not session_id or not content: 
        return
    
    try:
        # Use SQL INSERT with explicit column specification
        safe_content = content.replace("'", "''")
        safe_session_id = str(session_id).replace("'", "''")
        
        if metadata:
            # Convert to JSON and escape properly
            meta_json = json.dumps(metadata).replace("\\", "\\\\").replace("'", "''")
            sql = f"""
            INSERT INTO {CONFIG.messages_table} 
            (CONVERSATION_ID, SENDER_TYPE, MESSAGE_TEXT, METADATA)
            SELECT '{safe_session_id}', '{role}', '{safe_content}', 
                   PARSE_JSON('{meta_json}')
            """
        else:
            sql = f"""
            INSERT INTO {CONFIG.messages_table} 
            (CONVERSATION_ID, SENDER_TYPE, MESSAGE_TEXT)
            VALUES ('{safe_session_id}', '{role}', '{safe_content}')
            """
        
        session.sql(sql).collect()
        print(f" Saved {role} message to history.")
        
    except Exception as e:
        print(f" Save Message Failed: {e}")
        raise


def invoke_cortex_agent(session: Session, payload: Dict, agent_name: str) -> Dict:
    """Invokes 'agent:run'."""
    ENDPOINT = "/api/v2/cortex/agent:run"
    print(f"--- INVOKING AGENT: {agent_name} ---")

    try:
        resp = _snowflake.send_snow_api_request("POST", ENDPOINT, {"Content-Type": "application/json", "Accept": "text/event-stream"}, {}, payload, {}, 120000)
        content = resp.get("content")
        if not content: return {"error": "Empty"}
        
        extracted = {"text": "", "tables": [], "charts": [], "sql_generated": None, "sql_explanation": None}
        try: parsed = json.loads(content)
        except: parsed = [json.loads(line) for line in content.splitlines() if line.strip()]
        
        def process_event(evt, data):
            if evt == 'response.text.delta': 
                extracted["text"] += data.get('text', '')
            elif evt == 'response.chart': 
                extracted["charts"].append(data.get('chart') or data.get('chart_spec'))
                print(extracted["charts"])
            elif evt == 'response.table':
                rs = data.get('result_set', [])
                extracted["tables"].append(rs) 
            elif evt == 'response.tool_result.analyst.delta':
                print('response.tool_result.analyts.delt')
                print(delta)
                delta = data.get('delta', {})
                if delta.get('sql'): extracted["sql_generated"] = delta.get('sql')
                if delta.get('sql_explanation'): extracted["sql_explanation"] = delta.get('sql_explanation')
                if delta.get('result_set'): extracted["tables"].append(delta.get('result_set'))
            elif evt == 'response.tool_result':
                for item in data.get('content', []):
                    if item.get('type') == 'json':
                        json_p = item.get('json', {})
                        if 'sql' in json_p: extracted["sql_generated"] = json_p['sql']
                        if 'result_set' in json_p: extracted["tables"].append(json_p['result_set'])

        if isinstance(parsed, list):
            for item in parsed: process_event(item.get('event'), item.get('data', {}))
        
        return extracted
    except Exception as e: return {"error": str(e)}

def extract_pydantic_from_text(text: str, model_class: type[BaseModel]) -> BaseModel:
    """Robust JSON extraction."""
    if not text: return model_class()
    def try_parse(json_str):
        try: return json.loads(json_str)
        except: 
            try: return json.loads(json_str, strict=False)
            except: return None

    match = re.search(r'```json\s*(\{.*?\})\s*```', text, re.DOTALL)
    if match:
        data = try_parse(match.group(1))
        if data: 
            try: return model_class(**data)
            except: pass 

    start = text.find('{')
    end = text.rfind('}')
    if start != -1 and end != -1:
        data = try_parse(text[start:end+1])
        if data: 
            try: return model_class(**data)
            except: pass

    if model_class == RephraserOutput:
        return RephraserOutput(refined_query=text.strip())

    return model_class()

def check_input_guard(session: Session, user_input: str) -> GuardResult:
    try:
        safe_input = user_input.replace("'", "''")
        res = session.sql(f"SELECT SNOWFLAKE.CORTEX.COMPLETE('{CONFIG.model}', [{{'role': 'user', 'content': '{safe_input}'}}], {{'guardrails': true}}) as r").collect()
        if not res: return GuardResult(is_safe=True)
        is_unsafe = "Response filtered" in json.loads(res[0]['R'])['choices'][0]['messages']
        return GuardResult(is_safe=not is_unsafe, message="Blocked." if is_unsafe else None)
    except: return GuardResult(is_safe=True)

class PayloadFactory:
    @staticmethod
    def create(query: str, instructions: Any, tools: List = None, resources: Dict = None, history: List = None) -> Dict:
        messages = (history if history else []) + [{"role": "user", "content": [{"type": "text", "text": query}]}]
        inst_payload = instructions if isinstance(instructions, dict) else {"system": instructions}
        return {
            "messages": messages,
            "models": {"orchestration": CONFIG.model},
            "instructions": inst_payload,
            "tools": tools or [],
            "tool_resources": resources or {}
        }

def _save_audit_row(session: Session, data: dict, session_id: str):
    """Saves detailed execution logs using a staged approach for complex VARIANT data."""
    try:
        # Prepare the complete record
        record = {
            "SESSION_ID": session_id,
            "USER_QUERY": data.get("USER_QUERY"),
            "REPHRASED_QUERY": data.get("REPHRASED_QUERY"),
            "INTENT_TYPE": data.get("INTENT_TYPE"),
            "INTENT_CONFIDENCE": data.get("INTENT_CONFIDENCE"),
            "DATA_SUMMARY": data.get("DATA_SUMMARY"),
            "DATA_SQL": data.get("DATA_SQL"),
            "DATA_SQL_EXPLANATION": data.get("DATA_SQL_EXPLANATION"),
            "DATA_CLARIFICATION": data.get("DATA_CLARIFICATION"),
            "DATA_EVAL_SCORE": data.get("DATA_EVAL_SCORE"),
            "DATA_EVAL_REASONING": data.get("DATA_EVAL_REASONING"),
            "RC_SUMMARY": data.get("RC_SUMMARY"),
            "RC_EVAL_SCORE": data.get("RC_EVAL_SCORE"),
            "RC_EVAL_REASONING": data.get("RC_EVAL_REASONING"),
            "IS_BLOCKED": data.get("IS_BLOCKED", False),
            "EXECUTION_TIME_MS": data.get("EXECUTION_TIME_MS"),
            "DATA_RESULT_SET": data.get("DATA_RESULT_SET"),
            "DATA_CHARTS": data.get("DATA_CHARTS"),
            "RC_GRAPH_JSON": data.get("RC_GRAPH_JSON"),
            "FULL_RAW_JSON": data.get("FULL_RAW_JSON"),
            "CREATED_AT": datetime.datetime.now()
        }
        
        # Convert VARIANT fields to JSON strings within the dict
        for field in ["DATA_RESULT_SET", "DATA_CHARTS", "RC_GRAPH_JSON", "FULL_RAW_JSON"]:
            if record[field] is not None and not isinstance(record[field], str):
                record[field] = json.dumps(record[field])
        
        # Create DataFrame with the record
        df = session.create_dataframe([record])
        
        # Convert JSON strings to VARIANT using PARSE_JSON
        for field in ["DATA_RESULT_SET", "DATA_CHARTS", "RC_GRAPH_JSON", "FULL_RAW_JSON"]:
            if record[field] is not None:
                df = df.with_column(field, parse_json(col(field)))
        
        # Write to table
        df.write.mode("append").save_as_table(CONFIG.audit_log_table)
        
        print(f" Audit log saved for session {session_id}.")
        
    except Exception as e:
        print(f" Audit Log Error (DataFrame approach): {e}")
        
        # Fallback: Insert with simplified data (without complex VARIANT fields)
        try:
            print(" Attempting simplified insert without VARIANT fields...")
            
            safe_session = session_id.replace("'", "''")
            safe_query = str(data.get("USER_QUERY", "")).replace("'", "''")
            safe_rephrased = str(data.get("REPHRASED_QUERY", "")).replace("'", "''") if data.get("REPHRASED_QUERY") else "NULL"
            safe_intent = str(data.get("INTENT_TYPE", "")).replace("'", "''") if data.get("INTENT_TYPE") else "NULL"
            
            fallback_sql = f"""
            INSERT INTO {CONFIG.audit_log_table} 
            (SESSION_ID, USER_QUERY, REPHRASED_QUERY, INTENT_TYPE, INTENT_CONFIDENCE, 
             DATA_EVAL_SCORE, RC_EVAL_SCORE, IS_BLOCKED, EXECUTION_TIME_MS)
            VALUES (
                '{safe_session}',
                '{safe_query}',
                {f"'{safe_rephrased}'" if data.get("REPHRASED_QUERY") else "NULL"},
                {f"'{safe_intent}'" if data.get("INTENT_TYPE") else "NULL"},
                {f"'{data.get('INTENT_CONFIDENCE')}'" if data.get("INTENT_CONFIDENCE") else "NULL"},
                {data.get("DATA_EVAL_SCORE") if data.get("DATA_EVAL_SCORE") is not None else "NULL"},
                {data.get("RC_EVAL_SCORE") if data.get("RC_EVAL_SCORE") is not None else "NULL"},
                {str(data.get("IS_BLOCKED", False)).upper()},
                {data.get("EXECUTION_TIME_MS") if data.get("EXECUTION_TIME_MS") is not None else "NULL"}
            )
            """
            
            session.sql(fallback_sql).collect()
            print(f" Audit log saved with simplified data (VARIANT fields skipped).")
            
        except Exception as e2:
            print(f" Fallback Insert Failed: {e2}")
            import traceback
            traceback.print_exc()
        
def get_cortex_completion(session: Session, prompt: str) -> str:
    try:
        safe_prompt = prompt.replace("'", "''")
        cmd = f"SELECT SNOWFLAKE.CORTEX.COMPLETE('{CONFIG.model}', '{safe_prompt}') as R"
        return session.sql(cmd).collect()[0]['R']
    except Exception as e: return ""

# ==========================================
# 5. SEMANTIC VIEW PARSER
# ==========================================

class SemanticViewParser:
    def __init__(self, session: Session, view_name: str):
        self.session = session
        self.view_name = view_name
        self.ca_json = {"tables": [], "relationships": []}
        self.table_comments = {} 
        self.column_metadata = defaultdict(lambda: defaultdict(dict)) 
        self.rel_metadata = defaultdict(dict) 
        # Note: We do NOT parse in __init__ to satisfy "orchestrator only" constraint.
        self.is_loaded = False

    def _fetch_and_parse(self):
        if self.is_loaded: return
        print(f" DESCRIBING SEMANTIC VIEW: {self.view_name}...")
        try:
            rows = self.session.sql(f"DESCRIBE SEMANTIC VIEW {self.view_name}").collect()
            data = [row.as_dict() for row in rows]
            ca_row = next((r for r in data if r.get('object_kind') == 'EXTENSION' and r.get('object_name') == 'CA'), None)
            if ca_row: self.ca_json = json.loads(ca_row['property_value'])

            for r in data:
                kind = r.get('object_kind')
                name = r.get('object_name')
                prop = r.get('property')
                val = r.get('property_value')
                
                if kind == 'TABLE' and prop == 'COMMENT':
                    self.table_comments[name.split('.')[-1]] = val
                elif kind in ['DIMENSION', 'FACT', 'COLUMN']:
                    t_name = r.get('parent_entity', '').split('.')[-1]
                    if t_name:
                        if prop == 'COMMENT': self.column_metadata[t_name][name]['description'] = val
                        elif prop == 'DATA_TYPE': self.column_metadata[t_name][name]['data_type'] = val
                elif kind == 'RELATIONSHIP':
                    if prop == 'TABLE': self.rel_metadata[name]['source_table'] = val.split('.')[-1]
                    elif prop == 'REF_TABLE': self.rel_metadata[name]['target_table'] = val.split('.')[-1]
                    elif prop == 'FOREIGN_KEY': self.rel_metadata[name]['keys'] = val
            
            self.is_loaded = True
            print(f" Metadata Loaded from {self.view_name}")
        except Exception as e: print(f" Metadata Parse Failed: {e}")

    def get_context_summary(self) -> str:
        """Returns a summarized string of the schema for LLM Context (Master)."""
        self._fetch_and_parse() # Load on demand
        summary = "Available Data Schema:\n"
        for t in self.ca_json.get('tables', []):
            summary += f"- Table: {t.get('name')}\n"
            summary += f"  Columns: {', '.join([c['name'] for c in t.get('dimensions', []) + t.get('facts', [])])}\n"
        return summary

    def get_table_summaries(self) -> str:
        """Returns detailed table summaries for selection."""
        self._fetch_and_parse()
        summary_list = []
        for t in self.ca_json.get('tables', []):
            t_name = t.get('name')
            desc = self.table_comments.get(t_name, "No description.")
            summary_list.append(f"- Table: {t_name}\n  Description: {desc}")
        return "\n".join(summary_list) if summary_list else ""

    def get_pruned_context(self, selected_tables: List[str]) -> str:
        """Generates a pruned JSON schema based on selected tables."""
        self._fetch_and_parse()
        pruned = {"tables": [], "relationships": []}
        for t in self.ca_json.get('tables', []):
            t_name = t['name']
            if t_name in selected_tables:
                table_copy = t.copy()
                table_copy['description'] = self.table_comments.get(t_name, "")
                for category in ['dimensions', 'facts', 'time_dimensions']:
                    if category in table_copy:
                        enriched_cols = []
                        for col in table_copy[category]:
                            col_copy = col.copy()
                            meta = self.column_metadata[t_name].get(col['name'], {})
                            if 'description' in meta: col_copy['description'] = meta['description']
                            if 'data_type' in meta: col_copy['data_type'] = meta['data_type']
                            enriched_cols.append(col_copy)
                        table_copy[category] = enriched_cols
                pruned['tables'].append(table_copy)
        
        if 'relationships' in self.ca_json:
            for rel in self.ca_json['relationships']:
                r_name = rel.get('name')
                source = self.rel_metadata.get(r_name, {}).get('source_table')
                if source in selected_tables:
                    pruned['relationships'].append(rel)
        return json.dumps(pruned, indent=2)

# ==========================================
# 6. AGENT MANAGER
# ==========================================

class AgentManager:
    def __init__(self, session: Session):
        self.session = session
        # We only initialize the Parser object, we DO NOT load data here.
        # Data loading happens inside run_data_orchestrator calls.
        self.parser = SemanticViewParser(session, CONFIG.cortex_analyst_object_master)

    def identify_needed_tables(self, query: str) -> List[str]:
        print(" IDENTIFYING RELEVANT TABLES...")
        summaries = self.parser.get_table_summaries() # Triggers load if needed
        if not summaries: return []
        prompt = f"{PROMPT_TABLE_SELECTION}\n\nUser Query: {query}\n\nTable Summaries:\n{summaries}"
        res_text = get_cortex_completion(self.session, prompt)
        result = extract_pydantic_from_text(res_text, TableSelection)
        print(f" Selected: {result.relevant_table_names}")
        return result.relevant_table_names

    def run_semantic_translator(self, query: str, relevant_tables: List[str]) -> str:
        print(f" REWRITING QUERY...")
        pruned_json = self.parser.get_pruned_context(relevant_tables)
        prompt = f"{PROMPT_SEMANTIC_TRANSLATOR}\n\nSchema Context:\n{pruned_json}\n\nUser Query: {query}"
        return get_cortex_completion(self.session, prompt).strip()

    def run_rephraser(self, query: str, history: List[Dict]) -> RephraserOutput:
        inst = {
            "system": PROMPT_REPHRASER_SYSTEM,
            "orchestration": PROMPT_REPHRASER_ORCHESTRATION,
            "response": PROMPT_REPHRASER_RESPONSE
        }
        payload = PayloadFactory.create(query, inst, history=history)
        resp = invoke_cortex_agent(self.session, payload, "Rephraser Agent")
        return extract_pydantic_from_text(resp.get("text", ""), RephraserOutput)

    def run_intent_classifier(self, query: str) -> IntentClassification:
        inst = {
            "system": PROMPT_INTENT_SYSTEM, 
            "orchestration": PROMPT_INTENT_ORCHESTRATION,
            "response": PROMPT_INTENT_RESPONSE
        }
        payload = PayloadFactory.create(query, inst)
        resp = invoke_cortex_agent(self.session, payload, "Intent Agent")
        return extract_pydantic_from_text(resp.get("text", ""), IntentClassification)

    def run_data_agent(self, query: str, schema_context: Optional[str] = None, is_optimized: bool = False) -> SqlResult:
        # Determine correct object and context
        target_view = CONFIG.cortex_analyst_object_ards if is_optimized else CONFIG.cortex_analyst_object_master
        
        tools = [{"tool_spec": {"type": "cortex_analyst_text_to_sql", "name": "analyst_tool"}}]
        res_def = {
            "analyst_tool": {
                "type": "cortex_analyst_text_to_sql",
                "semantic_view": target_view, 
                "execution_environment": {"type": "warehouse", "warehouse": CONFIG.warehouse}
            }
        }
        
        # Inject Master Schema Context into System Prompt if provided
        system_prompt = PROMPT_DATA_AGENT_SYSTEM
        if is_optimized == False:
             system_prompt += f"Enrich the user question with the below schema. \n\nMASTER SCHEMA CONTEXT:\n{CONFIG.cortex_analyst_object_master}"
        
        inst = {
            "system": system_prompt, 
            "orchestration": PROMPT_DATA_AGENT_ORCHESTRATION,
            "response": PROMPT_DATA_AGENT_RESPONSE
        }
        payload = PayloadFactory.create(query, inst, tools, res_def)
        resp = invoke_cortex_agent(self.session, payload, "Data Agent" + (" (Optimized)" if is_optimized else ""))
        
        raw_text = resp.get('text', '')
        parsed = extract_pydantic_from_text(raw_text, SqlResult)
        
        parsed.tables = resp.get('tables', [])
        parsed.sql_generated = resp.get('sql_generated')
        parsed.sql_explanation = resp.get('sql_explanation')
        parsed.charts = resp.get('charts')
        return parsed

    def run_data_flow_orchestrator(self, query: str) -> SqlResult:
        """Handles standard execution vs optimized self-healing execution via parallelism."""
        
        def run_optimization_sequence():
            try:
                # Optimization logic...
                needed_tables = self.identify_needed_tables(query)
                if needed_tables:
                    optimized_q = self.run_semantic_translator(query, needed_tables)
                    print(f" Optimized Query: {optimized_q}")
                    # No schema context needed for optimized run (relies on translation + ARDS view)
                    return self.run_data_agent(optimized_q, schema_context=None, is_optimized=True)
            except Exception as e:
                print(f"Optimization failed: {e}")
            return SqlResult(clean_answer_text="Optimization Failed", evaluation=EvaluationResult(score=0))

        def run_standard_sequence():
    
            return self.run_data_agent(query, schema_context=None, is_optimized=False)

        print(" Starting Data Agent Flows (Standard & Optimized)...")
        with ThreadPoolExecutor(max_workers=2) as executor:
            future_std = executor.submit(run_standard_sequence)
            future_opt = executor.submit(run_optimization_sequence)
            res_std = future_std.result()
            res_opt = future_opt.result()

        print(f" Standard Score: {res_std.evaluation.score} | Optimized Score: {res_opt.evaluation.score}")
        
        # Decision Logic
        if res_std.evaluation.score >= 8:
            return res_std
        elif (res_std.evaluation.score < 8 and res_opt.evaluation.score < 8) or \
             (res_std.evaluation.score == res_opt.evaluation.score and res_std.evaluation.score > 0):
             
             print(" Scores Low/Equal. Combining Summaries.")
             base = res_opt if res_opt.evaluation.score > 0 else res_std
             combined_text = (f"**Standard Analysis:**\n{res_std.clean_answer_text}\n\n"
                              f"**Deep Context Analysis:**\n{res_opt.clean_answer_text}")
             
             final_res = SqlResult(
                 clean_answer_text=combined_text,
                 tables=base.tables,
                 charts=base.charts,
                 sql_generated=base.sql_generated, 
                 sql_explanation=base.sql_explanation,
                 evaluation=base.evaluation,
                 is_retry=True
             )
             return final_res
        elif res_opt.evaluation.score > res_std.evaluation.score:
            print(f" Switched to Optimized Result (Score: {res_opt.evaluation.score})")
            res_opt.is_retry = True
            return res_opt
            
        return res_std
    def run_root_cause_agent(self, query: str) -> DiagnosticResult:
        tools = [{"tool_spec": {"type": "generic", "name": "Diagnostic_tool", "input_schema": {"type": "object", "properties": {"USER_QUERY": {"type": "string"}, "PARENT_NODE_IDS_JSON": {"type": "string"}, "TREE_ID": {"type": "string"}}, "required": ["USER_QUERY", "PARENT_NODE_IDS_JSON", "TREE_ID"]}}}]
        res_def = {"Diagnostic_tool": {"type": "procedure", "execution_environment": {"type": "warehouse", "warehouse": CONFIG.warehouse}, "identifier": CONFIG.diagnostic_udf}}
        
        
        
        inst = {
            "system": PROMPT_REPHRASER_SYSTEM, 
            "orchestration": PROMPT_ROOT_CAUSE_ORCHESTRATION,
            "response": PROMPT_ROOT_CAUSE_RESPONSE
        }
        payload = PayloadFactory.create(query, inst, tools, res_def)
        resp = invoke_cortex_agent(self.session, payload, "Root Cause Agent")
        
        raw_text = resp.get('text', '')
        parsed = extract_pydantic_from_text(raw_text, DiagnosticResult)

        return parsed

# ==========================================
# 7. MAIN EXECUTION
# ==========================================

def main(session: Session):
    """Main Orchestrator Entry Point."""
    
    
    session_id = "1112"
    
    user_query = "Why is Tramadol showing higher prescription volume than Diclofenac for last three months?"
    
    # Start timing
    start_time = datetime.datetime.now()
    
    manager = AgentManager(session)
    
    # Initialize row_data with ALL required columns for audit table
    row_data = {
        "SESSION_ID": session_id,
        "USER_QUERY": user_query,
        "REPHRASED_QUERY": None,
        "INTENT_TYPE": None,
        "INTENT_CONFIDENCE": None,
        "DATA_SUMMARY": None,
        "DATA_SQL": None,
        "DATA_SQL_EXPLANATION": None,
        "DATA_CLARIFICATION": None,
        "DATA_RESULT_SET": None,
        "DATA_CHARTS": None,
        "DATA_EVAL_SCORE": None,
        "DATA_EVAL_REASONING": None,
        "RC_SUMMARY": None,
        "RC_GRAPH_JSON": None,
        "RC_EVAL_SCORE": None,
        "RC_EVAL_REASONING": None,
        "IS_BLOCKED": False,
        "FULL_RAW_JSON": None,
        "EXECUTION_TIME_MS": None
    }
    
    log_checkpoint("MAIN: START", {"query": user_query, "session": session_id})

    # 1. Fetch History
    history = get_chat_history(session, session_id)

    # 2. Input Guard
    guard = check_input_guard(session, user_query)
    if not guard.is_safe:
        row_data["IS_BLOCKED"] = True
        
        # Calculate execution time
        end_time = datetime.datetime.now()
        row_data["EXECUTION_TIME_MS"] = int((end_time - start_time).total_seconds() * 1000)
        
        # Save audit log
        row_data["FULL_RAW_JSON"] = {"status": "blocked", "message": guard.message}
        _save_audit_row(session, row_data, session_id)
        
        return {"status": "blocked", "message": guard.message}

    # 3. Save User Message
    save_chat_message(session, session_id, "user", user_query)

    # 4. Rephrase
    try:
        rephrased = manager.run_rephraser(user_query, history)
        effective_query = rephrased.refined_query or user_query
    except Exception as e:
        print(f" Rephraser failed: {e}")
        effective_query = user_query
    
    # 5. Intent Classification
    try:
        intent = manager.run_intent_classifier(effective_query)
    except Exception as e:
        print(f" Intent classification failed: {e}")
        # Default to data retrieval if intent fails
        intent = IntentClassification(
            intent_type="data_retrieval",
            data_retrieval_query=effective_query,
            confidence="low",
            reasoning=f"Failed to classify intent: {str(e)}"
        )
    
    row_data["REPHRASED_QUERY"] = effective_query
    row_data["INTENT_TYPE"] = intent.intent_type
    row_data["INTENT_CONFIDENCE"] = intent.confidence

    final_output = {
        "original": user_query, 
        "processed": effective_query, 
        "intent": intent.model_dump(), 
        "results": []
    }

    bot_response_text = ""

    # 6. Execute based on Intent
    if intent.direct_response:
        msg = intent.direct_response
        final_output["results"].append({"type": "direct", "message": msg})
        bot_response_text = msg

    else:
        futures = {}
        with ThreadPoolExecutor(max_workers=2) as executor:
            
            # Data Flow (Uses Parallel Orchestrator)
            if intent.intent_type in ["data_retrieval", "combined", "clarification_needed"]:
                q = intent.data_retrieval_query or effective_query
                futures["data"] = executor.submit(manager.run_data_flow_orchestrator, q)
            
            # Root Cause Flow
            if intent.intent_type in ["root_cause_analysis", "combined"]:
                q = intent.root_cause_query or effective_query
                futures["rc"] = executor.submit(manager.run_root_cause_agent, q)

        # Process Data Results
        if "data" in futures:
            try:
                res = futures["data"].result()
                res_dump = res.model_dump()
                
                row_data["DATA_EVAL_SCORE"] = res.evaluation.score
                row_data["DATA_EVAL_REASONING"] = res.evaluation.reasoning
                row_data["DATA_SQL"] = res.sql_generated
                row_data["DATA_SQL_EXPLANATION"] = res.sql_explanation
                
                # Store as dict/list - will be converted to JSON in _save_audit_row
                if res.tables: 
                    row_data["DATA_RESULT_SET"] = res.tables
                if res.charts:
                    row_data["DATA_CHARTS"] = res.charts
                
                if res.clarifying_question:
                    response_text = res.clarifying_question
                    final_output["results"].append({
                        "type": "clarification", 
                        "message": response_text,
                        "full_pydantic_object": res_dump 
                    })
                    row_data["DATA_CLARIFICATION"] = response_text
                else:
                    response_text = res.clean_answer_text
                    final_output["results"].append({
                        "type": "data_analysis", 
                        "summary": response_text, 
                        "tables": res.tables,
                        "charts": res.charts,
                        "sql_generated": res.sql_generated,
                        "sql_explanation": res.sql_explanation,
                        "full_pydantic_object": res_dump 
                    })
                    row_data["DATA_SUMMARY"] = response_text
                
                bot_response_text += response_text + "\n"
                
            except Exception as e:
                error_msg = f"Data analysis failed: {str(e)}"
                print(f" {error_msg}")
                final_output["results"].append({
                    "type": "error",
                    "message": error_msg
                })
                bot_response_text += error_msg + "\n"

        # Process Root Cause Results
        if "rc" in futures:
            try:
                res_rc = futures["rc"].result()
                res_rc_dump = res_rc.model_dump()
                
                row_data["RC_EVAL_SCORE"] = res_rc.evaluation.score
                row_data["RC_EVAL_REASONING"] = res_rc.evaluation.reasoning
                
                if res_rc.clarifying_question:
                    response_text = res_rc.clarifying_question
                    final_output["results"].append({
                        "type": "clarification", 
                        "message": response_text,
                        "full_pydantic_object": res_rc_dump 
                    })
                else:
                    response_text = res_rc.clean_summary_text
                    final_output["results"].append({
                        "type": "root_cause", 
                        "summary": response_text, 
                        "graph": res_rc.react_flow_json,
                        "full_pydantic_object": res_rc_dump 
                    })
                    row_data["RC_SUMMARY"] = res_rc.clean_summary_text
                    if res_rc.react_flow_json:
                        row_data["RC_GRAPH_JSON"] = res_rc.react_flow_json
                
                bot_response_text += response_text + "\n"
                
            except Exception as e:
                error_msg = f"Root cause analysis failed: {str(e)}"
                print(f" {error_msg}")
                final_output["results"].append({
                    "type": "error",
                    "message": error_msg
                })
                bot_response_text += error_msg + "\n"

    # 7. Save Bot Response
    if bot_response_text:
        # Save structured metadata to METADATA column
        message_metadata = {
            "intent_data": intent.model_dump(),
            "sql_generated": row_data.get("DATA_SQL"),
            "is_blocked": row_data.get("IS_BLOCKED"),
            "tool_artifacts": final_output.get("results"),
            "generated_at": datetime.datetime.now().isoformat()
        }
        
        try:
            save_chat_message(
                session, 
                session_id, 
                "assistant", 
                bot_response_text.strip(), 
                metadata=message_metadata
            )
        except Exception as e:
            print(f" Failed to save assistant message: {e}")

    # 8. Calculate execution time
    end_time = datetime.datetime.now()
    row_data["EXECUTION_TIME_MS"] = int((end_time - start_time).total_seconds() * 1000)
    
    # 9. Save Audit Log
    row_data["FULL_RAW_JSON"] = final_output
    try:
        _save_audit_row(session, row_data, session_id)
    except Exception as e:
        print(f" Failed to save audit log: {e}")
        import traceback
        traceback.print_exc()
    
    print(" Process Completed")
    print(f"  Total Execution Time: {row_data['EXECUTION_TIME_MS']}ms")
    
    return final_output


# Helper wrapper for Snowflake stored procedure
def handler(session: Session, session_id: str, user_query: str) -> str:
    """
    Snowflake Stored Procedure Handler
    
    Usage:
    CALL AGENT_HANDLER('session_123', 'Show me top prescribers');
    """
    try:
        result = main(session, session_id, user_query)
        return json.dumps(result, indent=2)
    except Exception as e:
        error_result = {
            "status": "error",
            "message": str(e),
            "traceback": traceback.format_exc()
        }
        return json.dumps(error_result, indent=2)


if __name__ == "__main__":
    # For local testing
    pass



 Audit Log Error (DataFrame approach): (1304): 01c203ab-081a-3d3b-0075-0383fddaa48e: 002020 (21S01): 01c203ab-081a-3d3b-0075-0383fddaa48e: SQL compilation error:
Insert value list does not match column list expecting 22 but got 21
 Attempting simplified insert without VARIANT fields...
 Audit log saved with simplified data (VARIANT fields skipped).
 Process Completed
  Total Execution Time: 129731ms



 Audit Log Error (DataFrame approach): (1304): 01c203b6-081a-3ea7-0075-0383fddb88b6: 002023 (22000): 01c203b6-081a-3ea7-0075-0383fddb88b6: SQL compilation error:
Expression type does not match column data type, expecting VARIANT but got TIMESTAMP_NTZ(9) for column FULL_RAW_JSON
 Attempting simplified insert without VARIANT fields...
 Audit log saved with simplified data (VARIANT fields skipped).
 Process Completed
  Total Execution Time: 115055ms




import json
import logging
import pprint
import re
import _snowflake # Native Snowflake module for internal API calls
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import List, Dict, Any, Optional, Literal, Tuple
from pydantic import BaseModel, Field, field_validator
from snowflake.snowpark import Session
from snowflake.snowpark.functions import lit, parse_json, col
from collections import defaultdict
import datetime
import traceback

# ==========================================
# 1. CONFIGURATION
# ==========================================

class AgentConfig(BaseModel):
    """Configuration for the agent execution"""
    # LLM Models
    model: str = "claude-sonnet-4-5" 
    
    # Snowflake Objects
    cortex_analyst_object_master: str = "DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.AI_POC.MASTERTABLE_V1"
    cortex_analyst_object_ards: str = "DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.REPORTING.BASIC_CORTEX_ANALYST"
    warehouse: str = "DEV_PAIN_SALES_PERFORMANCE_B_WH"
    
    # Tables - Updated to V2
    messages_table: str = "DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.AI_POC.MESSAGES_V2"
    audit_log_table: str = "DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.AI_POC.AGENT_DETAILED_HISTORY_V2"
    
    
    # Tools
    diagnostic_udf: str = "DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.AI_POC.DIAGNOSTIC_TOOL"
    diagnostic_tree_id: str = "pharma_sales_v3" 
    
    enable_semantic_parsing: bool = True

CONFIG = AgentConfig()

# ==========================================
# 2. PYDANTIC MODELS
# ==========================================

class EvaluationResult(BaseModel):
    score: int = Field(default=0, description="Score 1-10.")
    reasoning: str = Field(default="No evaluation provided.", description="Justification.")

class IntentClassification(BaseModel):
    intent_type: str = Field(..., description="greeting, data_retrieval, root_cause_analysis, clarification_needed, general_question, off_topic, combined")
    data_retrieval_query: Optional[str] = None
    root_cause_query: Optional[str] = None
    direct_response: Optional[str] = None
    clarification_question: Optional[str] = None
    confidence: str = Field(..., description="high, medium, low")
    reasoning: str = Field(..., description="Reasoning")

class RephraserOutput(BaseModel):
    refined_query: str = Field(..., description="The fully contextualized query.")

class TableSelection(BaseModel):
    relevant_table_names: List[str] = Field(..., description="List of table names.")

class GuardResult(BaseModel):
    is_safe: bool = Field(...)
    message: Optional[str] = Field(None)

class SqlResult(BaseModel):
    clean_answer_text: str = Field(default="")
    clarifying_question: Optional[str] = None
    tables: List[Any] = Field(default_factory=list)
    charts: List[Any] = Field(default_factory=list)  # Changed from List[Dict]
    sql_generated: Optional[str] = None
    sql_explanation: Optional[str] = None
    is_verified_query: bool = False
    evaluation: EvaluationResult = Field(default_factory=EvaluationResult)
    is_retry: bool = False

    @field_validator('charts', mode='before')
    @classmethod
    def parse_charts(cls, v):
        if not v: 
            return []
        parsed = []
        for item in v:
            if isinstance(item, dict): 
                parsed.append(item)
            elif isinstance(item, str):
                try: 
                    parsed_item = json.loads(item)
                    parsed.append(parsed_item)
                except: 
                    # Keep as string if can't parse
                    parsed.append(item)
        return parsed

class DiagnosticResult(BaseModel):
    clean_summary_text: str = Field(default="")
    clarifying_question: Optional[str] = None
    react_flow_json: Optional[Dict] = None
    evaluation: EvaluationResult = Field(default_factory=EvaluationResult)

# ==========================================
# 3. PROMPTS (RESTORED & ENHANCED)
# ==========================================

# --- REPHRASER ---
PROMPT_REPHRASER_SYSTEM = "You are a sophisticated Query Refinement Engine. Be polite, professional, and friendly. Be direct and unambiguous."

PROMPT_REPHRASER_ORCHESTRATION = """
<query_refinement_instructions>
<objective>
Transform the user's input into a standalone, context-complete query that can be understood without prior conversation history.
</objective>

<core_rules>
<rule id="1">Resolve all pronouns (it, they, that, this, those) to their specific referents based on chat history.</rule>
<rule id="2">Preserve ALL metrics, entity names, IDs, and numerical values EXACTLY as stated.</rule>
<rule id="3">Maintain the original intent and scope - do not expand or narrow the question.</rule>
<rule id="4">Keep technical terminology and domain-specific language intact.</rule>
<rule id="5">Ensure the output is grammatically correct and reads naturally.</rule>
</core_rules>

<follow_up_handling_rules>
<rule id="6">IF previous Bot response contained Data (e.g., "Sales are down") AND User asks "Why?", REPHRASE to "Why are sales down?"</rule>
<rule id="7">IF previous Bot response was a Clarification (e.g., "By region?"), AND User answers "Region", REPHRASE to combine them.</rule>
</follow_up_handling_rules>

<transformation_examples>
<example>
<input>What about Arizona?</input>
<context>Previous discussion about sales performance in Texas</context>
<output>What is the sales performance in Arizona?</output>
</example>

<example>
<input>Why is it down?</input>
<context>Previous mention of Q4 revenue</context>
<output>Why is Q4 revenue down?</output>
</example>
</transformation_examples>
</query_refinement_instructions>
"""

PROMPT_REPHRASER_RESPONSE = """
<output_format>
At the VERY END of your text response, YOU MUST output a JSON block STRICTLY in below format: 
Example: { "refined_query": "What is the sales performance in Arizona?" }
Do not include any other text or markdown outside the JSON object.
</output_format>
"""

# --- INTENT ---
PROMPT_INTENT_SYSTEM = "You are an Expert Intent Classification System. Be polite, professional, and friendly. Be direct and unambiguous."

PROMPT_INTENT_ORCHESTRATION = """
<intent_classification_instructions>

<mission>
Your ONLY job is to identify the user's INTENT. Do NOT retrieve data, do NOT answer questions, do NOT perform analysis.
Classify the intent type and route accordingly. If you can answer directly (like greetings), provide direct_response.
</mission>

<intent_categories>

<intent name="greeting">
<description>User is greeting, saying hello, or engaging in pleasantries</description>
<indicators>hi, hello, hey, good morning, how are you, thanks, thank you, goodbye, bye</indicators>
<action>Set direct_response with a friendly greeting. No other fields needed.</action>
</intent>

<intent name="data_retrieval">
<description>User wants to see/get/retrieve DATA - numbers, lists, metrics, tables</description>
<indicators>show, list, get, display, find, what is the value, how many, count, total, give me</indicators>
<action>Extract the data request to data_retrieval_query. Keep as natural language. Add "and generate a table and a visual".</action>
**CRITICAL VISUALIZATION LOGIC:**
Analyze the data request. If it implies trends (over time), comparisons (by region/product), or distributions, you MUST automatically append "and generate a table and a visual" to the query string, even if the user did not explicitly ask for a chart.
</intent>

<intent name="root_cause_analysis">
<description>User wants to understand WHY, CAUSES, DRIVERS, REASONS, EXPLANATIONS</description>
<indicators>why, explain, what is driving, what is causing, what's behind, reason for, root cause, how come, what factors</indicators>
<action>Extract the causal question to root_cause_query. Keep VERBATIM - exact text from user.</action>
</intent>

<intent name="combined">
<description>User wants BOTH data AND causal analysis in one request</description>
<indicators>Contains both data keywords AND causal keywords</indicators>
<action>Split into data_retrieval_query AND root_cause_query. Keep both portions.</action>
</intent>

<intent name="clarification_needed">
<description>User's intent is unclear, vague, or ambiguous - you cannot determine what they want</description>
<indicators>Very short/vague input, unclear pronouns without context, incomplete thoughts</indicators>
<action>Set clarification_question asking user to be more specific.</action>
</intent>

<intent name="general_question">
<description>General questions about the system, capabilities, how to use features - not data or analysis requests</description>
<indicators>how do I, can you, what can you do, help me understand, how does this work</indicators>
<action>Set direct_response with helpful information about capabilities.</action>
</intent>

<intent name="off_topic">
<description>User is asking about unrelated topics not connected to data, analytics, or business questions</description>
<indicators>Questions about weather, sports, entertainment, personal topics unrelated to business/data</indicators>
<action>Set direct_response politely redirecting to business/data topics.</action>
</intent>

</intent_categories>

<CRITICAL_CLASSIFICATION_RULES>

 RULE 1: NEVER DO THE WORK - ONLY CLASSIFY
You are NOT a data analyst. You are NOT an answering agent. You ONLY identify intent type.
Do NOT retrieve data. Do NOT answer analytical questions. ONLY classify and route.

 RULE 2: CAUSAL KEYWORD DETECTION
These ALWAYS indicate root_cause_analysis intent:
- "what is driving"
- "what is causing"
- "what's driving"  
- "what's causing"
- "why is/are"
- "explain why"
- "reason for"
- "root cause"
- "what factors"
- "what's behind"
- "how come"

 RULE 3: DATA KEYWORD DETECTION  
These ALWAYS indicate data_retrieval intent:
- "show me"
- "list"
- "get"
- "display"
- "find all"
- "what is the value/total/count of"
- "how many"

 RULE 4: DIRECT RESPONSE ONLY FOR SIMPLE CASES
Use direct_response ONLY for:
- Greetings (hi, hello, thanks)
- General system questions (what can you do)
- Off-topic redirects

Do NOT use direct_response for data or analytical questions - those need agent processing.

 RULE 5: VERBATIM PRESERVATION FOR ROOT CAUSE
For root_cause_query: Copy EXACT text from user. No paraphrasing, no summarizing.

 RULE 6: NO SQL CODE GENERATION
NEVER write SELECT/FROM/WHERE statements. Keep everything as natural language.

 RULE 7: CONFIDENCE SCORING
- high: Intent is crystal clear
- medium: Intent is likely but has some ambiguity
- low: Intent is very unclear, might need clarification


Examples:

Example 1: Data Retrieval
Input: "What was the total revenue for Q3?"
Output:
{
  "intent_type": "data_retrieval",
  "data_retrieval": "What was the total revenue for Q3?",
  "root_cause": null,
  "clarification": null,
  "confidence": "high",
  "reasoning": "User is asking for a specific absolute value (ID 2).",
  "secondary_category": [2]
}

Example 2: Root Cause Analysis
Input: "Why did sales drop in November?"
Output:
{
  "intent_type": "root_cause_analysis",
  "data_retrieval": null,
  "root_cause": "Why did sales drop in November?",
  "clarification": null,
  "confidence": "high",
  "reasoning": "User is inquiring about the driver behind a negative trend (ID 12).",
  "secondary_category": [12]
}

Example 3: Combined
Input: "Show me the churn rate and explain the main driver for the increase."
Output:

{
  "intent_type": "combined",
  "data_retrieval": "Show me the churn rate",
  "root_cause": "explain the main driver for the increase",
  "clarification": null,
  "confidence": "high",
  "reasoning": "Query requests a specific metric (ID 2) and an explanation of the driver (ID 12).",
  "secondary_category": [2, 12]
}

Example 4: Clarification Needed
Input: "Show me the data."
Output:
{
  "intent_type": "clarification_needed",
  "data_retrieval": null,
  "root_cause": null,
  "clarification": "The user has not specified which metric, time period, or entity to retrieve.",
  "confidence": "high",
  "reasoning": "The request is too vague to map to a database query.",
  "secondary_category": [22]
}

Example 5: Follow-up
Input: "And for the North region?"
Output:

{
  "intent_type": "follow_up",
  "data_retrieval": "And for the North region?",
  "root_cause": null,
  "clarification": null,
  "confidence": "high",
  "reasoning": "Contextual continuation applying a filter (ID 17) to previous turn.",
  "secondary_category": [17, 21]
}



</CRITICAL_CLASSIFICATION_RULES>
</intent_classification_instructions>
"""

PROMPT_INTENT_RESPONSE = """
<output_format>
At the VERY END of your text response, YOU MUST output a JSON block STRICTLY in below format:
{
  "intent_type": "data_retrieval",
  "data_retrieval_query": "Show me sales...",
  "root_cause_query": null,
  "direct_response": null,
  "clarification_question": null,
  "confidence": "high",
  "reasoning": "User used 'show me' keyword"
}
</output_format>
"""

# --- DATA AGENT ---
PROMPT_DATA_AGENT_SYSTEM = "You are an expert Data Analyst. Be polite, professional, and friendly. Be direct and unambiguous."

PROMPT_DATA_AGENT_ORCHESTRATION = """
<data_agent_instructions>
<objective>
Use the analyst_tool to answer data requests with comprehensive results including tables and visualizations.
</objective>

<clarification_protocol>
You have access to the Master Schema.
If the user asks a vague question like "Show me sales" without specifying time, product, or region:
1. CHECK the Master Schema for available dimensions (e.g., Region, Specialty, Brand).
2. DO NOT guess.
3. ASK a specific clarifying question: "Would you like to see sales broken down by Region, Specialty, or Brand?"
4. If the query is clear, proceed to generate SQL.
</clarification_protocol>

<execution_rules>
<rule id="1">ALWAYS generate a table (Result Set) for data requests</rule>
<rule id="2">Generate appropriate visualizations when data is suitable for charts</rule>
<rule id="3">Provide clear, concise summaries of the data findings</rule>
<rule id="4">Handle errors gracefully and explain any data limitations</rule>
</execution_rules>

<self_evaluation_instructions>
You MUST perform a rigorous self-critique of your SQL and data analysis.
1. **Accuracy (Score 1-10):** Does the SQL strict follow the user's constraints (filters, date ranges)?
2. **Data Integrity:** Are the results logical? (e.g., no negative counts where impossible).
3. **Clarity:** Is the summary accessible to a non-technical user?
</self_evaluation_instructions>
</data_agent_instructions>
"""

PROMPT_DATA_AGENT_RESPONSE = """
<output_format>
At the VERY END of your text response, YOU MUST output a JSON block STRICTLY in below format:
```json
{
  "clean_answer_text": "Summary of findings...",
  "clarifying_question": null,
  "evaluation": {
    "score": 8,
    "reasoning": "Data matches request."
  }
}
```
</output_format>
"""

# --- ROOT CAUSE ---
PROMPT_ROOT_CAUSE_SYSTEM = "You are an Autonomous Root Cause Analysis Agent. Be polite, professional, and friendly. Be direct and unambiguous."

PROMPT_ROOT_CAUSE_ORCHESTRATION = f"""
<root_cause_orchestration_prompt>
    <role_and_objective>
        You are an **Autonomous Root Cause Analysis Agent** designed to traverse a metric decision tree from the root node down to the leaf nodes. Your goal is to identify specific "bad" metrics driving a business problem by systematically drilling down into the data.
        
        ALWAYS USE tree_id as {CONFIG.diagnostic_tree_id}.
    </role_and_objective>

    <phase_1_clarification_check>
        **CRITICAL:** Before running any tools, analyze the USER_QUERY against the MASTER SCHEMA dimensions.
        
        MASTER SCHEMA:

        {CONFIG.cortex_analyst_object_master}
        
        IF the user asks a generic question like "Why is revenue down?" or "Explain the drop":
        1. You cannot run the tool efficiently without a starting point (Root Node context).
        2. Look at available schema dimensions (Region, Product, Specialty, Time).
        3. **STOP** and return a `clarifying_question`.
            Example: "To analyze the revenue drop, should I compare performance by Region, Product Class, or Customer Specialty?"
        
        IF the query contains specific context (e.g., "Why is Tylenol down in NY?"), PROCEED to Phase 2.
    </phase_1_clarification_check>

    <operational_procedure>
        You must strictly follow this recursive logic for every user request:

        **Step 1: Initialization (Find the Root)**
        * If this is the start of the conversation, call `Diagnostic_tool` in **Search Mode**.
        * **Action:** Call `Diagnostic_tool(USER_QUERY=user_question, PARENT_NODE_IDS_JSON=NULL, TREE_ID='{CONFIG.diagnostic_tree_id}')`.
        * **Next:** Proceed to Step 2 with the results.

        **Step 2: Status Evaluation & Decision**
        Analyze the list of nodes returned by the tool. Focus **only** on nodes where `"status": "bad"`.

        * **Check:** For every "bad" node, do you see its children in the current list?
        * **Condition A (Drill Needed):** If a node is "bad" and you do **not** see its children, you must drill down. Collect these Node IDs.
        * **Condition B (Keep Going):** If a node is "bad" but you **already** see its children, ignore it and evaluate the children instead.
        * **Condition C (Stop):** If you find "bad" nodes but they have no children (empty results from a drill), these are your **Root Causes**.

        **Step 3: Execution (Drill Down)**
        * If Condition A occurred: Call `Diagnostic_tool` in **Drill Mode**.
        * **Action:** Call `Diagnostic_tool(USER_QUERY=NULL, PARENT_NODE_IDS_JSON='["ID_1", "ID_2"]', TREE_ID='{CONFIG.diagnostic_tree_id}')`.
        * **Next:** Recursively repeat Step 2 with the new output.
        * If Condition C occurred: Present the final root causes to the user.
    </operational_procedure>

    <constraints>
        * **Never** guess the status of a metric; always use the tool.
        * **Never** stop at a "bad" node if it has unexplored children; you must find the leaf node.
        * Output your reasoning briefly before calling the tool.
    </constraints>

    <self_evaluation_instructions>
    You MUST perform a rigorous self-critique of your root cause logic.
    1. **Logic (Score 1-10):** Is the causal chain (Root -> Leaf) mathematically sound?
    2. **Driver Isolation:** Did we truly find the leaf node, or did we stop too early?
    3. **Completeness:** Did we explore all "bad" branches?
    </self_evaluation_instructions>
</root_cause_orchestration_prompt>
"""

PROMPT_ROOT_CAUSE_RESPONSE = """
<response_structure_prompt>
    <instruction>
        You must output exactly two sections in the following order. Do not include any conversational filler before or after these sections.
    </instruction>

    <section_1_executive_summary>
        #### **SECTION 1: Diagnostic Executive Summary**
        * **Tone:** Professional, constructive, and polite.
        * **Headline:** State the Root Cause clearly.
        * **The Narrative:** Briefly explain the chain of events in simple English.
        * **Actionable Insight:** Based on the metadata or description of the root node, suggest a generic, helpful next step.
    </section_1_executive_summary>

    <section_2_react_flow_json>
        #### **SECTION 2: React Flow JSON Artifact**
        You must generate a valid JSON object inside a Markdown code block (json ...).
        
        **4. JSON Schema (Must Follow Exactly):**
        {
          "nodes": [
            {
              "id": "N0",
              "type": "default",
              "data": { "label": "Metric Name: Value" },
              "position": { "x": 0, "y": 0 },
              "style": { "background": "#FFE2E5", "width": 180, "color": "#333", "border": "1px solid #777", "borderRadius": "8px" }
            }
          ],
          "edges": [
            {
              "id": "e-N0-N1",
              "source": "N0",
              "target": "N1",
              "label": "driven by",
              "animated": true,
              "style": { "stroke": "#555", "strokeWidth": 2 }
            }
          ]
        }
    </section_2_react_flow_json>
    
    <section_3_final_json>
        CRITICAL: Provide the final JSON block for the parser here as defined in the system prompt evaluation section.
    </section_3_final_json>
    
    **CRITICAL** : YOU MUST ONLY EXECUTE ATMOST 8 TOOL CALLS.
    
    <output_format>
    At the VERY END of your text response, YOU MUST output a JSON block STRICTLY in below format:
    ```json
    {
      "clean_summary_text": "Executive summary...",
      "clarifying_question": null,
      "react_flow_json": { "nodes": [], "edges": [] },
      "evaluation": { "score": 9, "reasoning": "Found root cause." }
    }
    ```
    </output_format>
</response_structure_prompt>
"""

# --- TABLE SELECTION ---
PROMPT_TABLE_SELECTION = """
<instruction>
You are an expert Database Architect and Schema Analyzer.
Your goal is to identify the subset of tables from the provided list that are strictly relevant to answering the user's query.

<rules>
1. **Analyze the Query**: Carefully understand the business entities, metrics, and dimensions requested.
2. **Review Summaries**: Check the Table Name and Description for each table provided.
3. **Strict Selection**: Select ONLY tables that contain the data needed. Do NOT include tables "just in case".
4. **Keyword Matching**: 
   - If the query mentions "sales" or "revenue", look for Fact tables with those metrics.
   - If the query mentions "location", "city", or "state", look for Geography Dimension tables.
   - If the query mentions "products", look for Product Dimension tables.
5. **Empty Return**: If no tables seem relevant, return an empty list.
</rules>

<output_format>
Output ONLY a valid JSON object with the following structure. Do not output markdown code blocks.
{
  "relevant_table_names": ["Table_A", "Table_B"]
}
</output_format>
</instruction>
"""

# --- SEMANTIC TRANSLATOR ---
PROMPT_SEMANTIC_TRANSLATOR = """
<instruction>
You are a Semantic Query Optimizer and SQL Expert.
Your goal is to rewrite the User's Natural Language Query so that it aligns perfectly with the provided Database Schema Context.

<rules>
1. **Vocabulary Mapping:** Replace generic business terms in the user query with the EXACT column names found in the Schema Context.
   - Example: If user says "revenue" and context has "TOTAL_SALES_AMT", use "TOTAL_SALES_AMT".
   - Example: If user says "doctors" and context has "HCP_ID", use "HCP_ID".
2. **Filter Alignment:** Check 'sample_values' in the context.
   - Example: If user says "in NY", and sample values for 'STATE_CD' are 'New York', rewrite to "STATE_CD is 'New York'".
3. **Disambiguation:** If a term matches multiple columns, use the column descriptions to pick the most relevant one.
4. **Preservation:** Do not change the user's core intent (e.g., ranking, aggregation, filtering). Just swap the terminology.
5. **Output**: Return ONLY the rewritten natural language query string. Do not output SQL. Do not output JSON.
</rules>
</instruction>
"""

# ==========================================
# 4. HELPER FUNCTIONS
# ==========================================

def log_checkpoint(step: str, details: Any):
    print(f"\n{'='*50}\n CHECKPOINT: {step}\n{'-'*50}")
    if isinstance(details, BaseModel): pprint.pprint(details.model_dump())
    elif isinstance(details, (dict, list)): pprint.pprint(details)
    else: print(str(details))
    print(f"{'='*50}\n")

# ==========================================
# HISTORY MANAGEMENT FUNCTIONS (UPDATED)
# ==========================================

def get_chat_history(session: Session, session_id: str, limit: int = 10) -> List[Dict]:
    """Retrieves chat history for a specific session_id formatted for Cortex."""
    if not session_id: 
        return []
    
    try:
        sql = f"""
        SELECT SENDER_TYPE, MESSAGE_TEXT 
        FROM {CONFIG.messages_table}
        WHERE CONVERSATION_ID = '{session_id}'
        ORDER BY CREATED_AT ASC
        LIMIT {limit}
        """
        rows = session.sql(sql).collect()
        
        history = []
        for r in rows:
            role = "user" if r['SENDER_TYPE'].lower() == 'user' else "assistant"
            history.append({
                "role": role, 
                "content": [{"type": "text", "text": r['MESSAGE_TEXT']}]
            })
        
        print(f" Retrieved {len(history)} past messages for Session {session_id}")
        return history
        
    except Exception as e:
        print(f" History Fetch Failed: {e}")
        return []

def save_chat_message(session: Session, session_id: str, role: str, content: str, metadata: Optional[Dict] = None):
    """Saves a message to the MESSAGES_V2 table with proper VARIANT handling."""
    if not session_id or not content: 
        return
    
    try:
        # Use SQL INSERT with explicit column specification
        safe_content = content.replace("'", "''")
        safe_session_id = str(session_id).replace("'", "''")
        
        if metadata:
            # Convert to JSON and escape properly
            meta_json = json.dumps(metadata).replace("\\", "\\\\").replace("'", "''")
            sql = f"""
            INSERT INTO {CONFIG.messages_table} 
            (CONVERSATION_ID, SENDER_TYPE, MESSAGE_TEXT, METADATA)
            SELECT '{safe_session_id}', '{role}', '{safe_content}', 
                    PARSE_JSON('{meta_json}')
            """
        else:
            sql = f"""
            INSERT INTO {CONFIG.messages_table} 
            (CONVERSATION_ID, SENDER_TYPE, MESSAGE_TEXT)
            VALUES ('{safe_session_id}', '{role}', '{safe_content}')
            """
        
        session.sql(sql).collect()
        print(f" Saved {role} message to history.")
        
    except Exception as e:
        print(f" Save Message Failed: {e}")
        raise


def invoke_cortex_agent(session: Session, payload: Dict, agent_name: str) -> Dict:
    """Invokes 'agent:run'."""
    ENDPOINT = "/api/v2/cortex/agent:run"
    print(f"--- INVOKING AGENT: {agent_name} ---")

    try:
        resp = _snowflake.send_snow_api_request("POST", ENDPOINT, {"Content-Type": "application/json", "Accept": "text/event-stream"}, {}, payload, {}, 120000)
        content = resp.get("content")
        if not content: return {"error": "Empty"}
        
        extracted = {"text": "", "tables": [], "charts": [], "sql_generated": None, "sql_explanation": None}
        try: parsed = json.loads(content)
        except: parsed = [json.loads(line) for line in content.splitlines() if line.strip()]
        
        def process_event(evt, data):
            if evt == 'response.text.delta': 
                extracted["text"] += data.get('text', '')
            elif evt == 'response.chart': 
                extracted["charts"].append(data.get('chart') or data.get('chart_spec'))
                print(extracted["charts"])
            elif evt == 'response.table':
                rs = data.get('result_set', [])
                extracted["tables"].append(rs) 
            elif evt == 'response.tool_result.analyst.delta':
                print('response.tool_result.analyts.delt')
                print(delta)
                delta = data.get('delta', {})
                if delta.get('sql'): extracted["sql_generated"] = delta.get('sql')
                if delta.get('sql_explanation'): extracted["sql_explanation"] = delta.get('sql_explanation')
                if delta.get('result_set'): extracted["tables"].append(delta.get('result_set'))
            elif evt == 'response.tool_result':
                for item in data.get('content', []):
                    if item.get('type') == 'json':
                        json_p = item.get('json', {})
                        if 'sql' in json_p: extracted["sql_generated"] = json_p['sql']
                        if 'result_set' in json_p: extracted["tables"].append(json_p['result_set'])

        if isinstance(parsed, list):
            for item in parsed: process_event(item.get('event'), item.get('data', {}))
        
        return extracted
    except Exception as e: return {"error": str(e)}

def extract_pydantic_from_text(text: str, model_class: type[BaseModel]) -> BaseModel:
    """Robust JSON extraction."""
    if not text: return model_class()
    def try_parse(json_str):
        try: return json.loads(json_str)
        except: 
            try: return json.loads(json_str, strict=False)
            except: return None

    match = re.search(r'```json\s*(\{.*?\})\s*```', text, re.DOTALL)
    if match:
        data = try_parse(match.group(1))
        if data: 
            try: return model_class(**data)
            except: pass 

    start = text.find('{')
    end = text.rfind('}')
    if start != -1 and end != -1:
        data = try_parse(text[start:end+1])
        if data: 
            try: return model_class(**data)
            except: pass

    if model_class == RephraserOutput:
        return RephraserOutput(refined_query=text.strip())

    return model_class()

def check_input_guard(session: Session, user_input: str) -> GuardResult:
    try:
        safe_input = user_input.replace("'", "''")
        res = session.sql(f"SELECT SNOWFLAKE.CORTEX.COMPLETE('{CONFIG.model}', [{{'role': 'user', 'content': '{safe_input}'}}], {{'guardrails': true}}) as r").collect()
        if not res: return GuardResult(is_safe=True)
        is_unsafe = "Response filtered" in json.loads(res[0]['R'])['choices'][0]['messages']
        return GuardResult(is_safe=not is_unsafe, message="Blocked." if is_unsafe else None)
    except: return GuardResult(is_safe=True)

class PayloadFactory:
    @staticmethod
    def create(query: str, instructions: Any, tools: List = None, resources: Dict = None, history: List = None) -> Dict:
        messages = (history if history else []) + [{"role": "user", "content": [{"type": "text", "text": query}]}]
        inst_payload = instructions if isinstance(instructions, dict) else {"system": instructions}
        return {
            "messages": messages,
            "models": {"orchestration": CONFIG.model},
            "instructions": inst_payload,
            "tools": tools or [],
            "tool_resources": resources or {}
        }

def _save_audit_row(session: Session, data: dict, session_id: str):
    """Saves detailed execution logs using a staged approach for complex VARIANT data."""
    try:
        import uuid
        # Prepare the complete record
        # UPDATED: Matches AGENT_DETAILED_HISTORY_V2 structure exactly.
        # Excludes IS_RETRY which is not in the DDL.
        record = {
            "AUDIT_ID": str(uuid.uuid4()), # Added to match table column count (22)
            "SESSION_ID": session_id,
            "USER_QUERY": data.get("USER_QUERY"),
            "REPHRASED_QUERY": data.get("REPHRASED_QUERY"),
            "INTENT_TYPE": data.get("INTENT_TYPE"),
            "INTENT_CONFIDENCE": data.get("INTENT_CONFIDENCE"),
            "DATA_SUMMARY": data.get("DATA_SUMMARY"),
            "DATA_SQL": data.get("DATA_SQL"),
            "DATA_SQL_EXPLANATION": data.get("DATA_SQL_EXPLANATION"),
            "DATA_CLARIFICATION": data.get("DATA_CLARIFICATION"),
            "DATA_RESULT_SET": data.get("DATA_RESULT_SET"),
            "DATA_CHARTS": data.get("DATA_CHARTS"),
            "DATA_EVAL_SCORE": data.get("DATA_EVAL_SCORE"),
            "DATA_EVAL_REASONING": data.get("DATA_EVAL_REASONING"),
            "RC_SUMMARY": data.get("RC_SUMMARY"),
            "RC_GRAPH_JSON": data.get("RC_GRAPH_JSON"),
            "RC_EVAL_SCORE": data.get("RC_EVAL_SCORE"),
            "RC_EVAL_REASONING": data.get("RC_EVAL_REASONING"),
            "IS_BLOCKED": data.get("IS_BLOCKED", False),
            "FULL_RAW_JSON": data.get("FULL_RAW_JSON"),
            "EXECUTION_TIME_MS": data.get("EXECUTION_TIME_MS"),
            "CREATED_AT": datetime.datetime.now()
        }
        
        # Convert VARIANT fields to JSON strings within the dict
        for field in ["DATA_RESULT_SET", "DATA_CHARTS", "RC_GRAPH_JSON", "FULL_RAW_JSON"]:
            if record[field] is not None and not isinstance(record[field], str):
                record[field] = json.dumps(record[field])
        
        # Create DataFrame with the record
        df = session.create_dataframe([record])
        
        # Convert JSON strings to VARIANT using PARSE_JSON
        for field in ["DATA_RESULT_SET", "DATA_CHARTS", "RC_GRAPH_JSON", "FULL_RAW_JSON"]:
            if record[field] is not None:
                df = df.with_column(field, parse_json(col(field)))
        
        # Enforce exact column order to match table DDL and prevent type mismatches
        column_order = [
            "AUDIT_ID", "SESSION_ID", "USER_QUERY", "REPHRASED_QUERY", "INTENT_TYPE", 
            "INTENT_CONFIDENCE", "DATA_SUMMARY", "DATA_SQL", "DATA_SQL_EXPLANATION", 
            "DATA_CLARIFICATION", "DATA_RESULT_SET", "DATA_CHARTS", "DATA_EVAL_SCORE", 
            "DATA_EVAL_REASONING", "RC_SUMMARY", "RC_GRAPH_JSON", "RC_EVAL_SCORE", 
            "RC_EVAL_REASONING", "IS_BLOCKED", "FULL_RAW_JSON", "EXECUTION_TIME_MS", 
            "CREATED_AT"
        ]
        df = df.select([col(c) for c in column_order])
        
        # Write to table
        df.write.mode("append").save_as_table(CONFIG.audit_log_table)
        
        print(f" Audit log saved for session {session_id}.")
        
    except Exception as e:
        print(f" Audit Log Error (DataFrame approach): {e}")
        
        # Fallback: Insert with simplified data (without complex VARIANT fields)
        try:
            print(" Attempting simplified insert without VARIANT fields...")
            
            safe_session = session_id.replace("'", "''")
            safe_query = str(data.get("USER_QUERY", "")).replace("'", "''")
            safe_rephrased = str(data.get("REPHRASED_QUERY", "")).replace("'", "''") if data.get("REPHRASED_QUERY") else "NULL"
            safe_intent = str(data.get("INTENT_TYPE", "")).replace("'", "''") if data.get("INTENT_TYPE") else "NULL"
            
            fallback_sql = f"""
            INSERT INTO {CONFIG.audit_log_table} 
            (SESSION_ID, USER_QUERY, REPHRASED_QUERY, INTENT_TYPE, INTENT_CONFIDENCE, 
             DATA_EVAL_SCORE, RC_EVAL_SCORE, IS_BLOCKED, EXECUTION_TIME_MS)
            VALUES (
                '{safe_session}',
                '{safe_query}',
                {f"'{safe_rephrased}'" if data.get("REPHRASED_QUERY") else "NULL"},
                {f"'{safe_intent}'" if data.get("INTENT_TYPE") else "NULL"},
                {f"'{data.get('INTENT_CONFIDENCE')}'" if data.get("INTENT_CONFIDENCE") else "NULL"},
                {data.get("DATA_EVAL_SCORE") if data.get("DATA_EVAL_SCORE") is not None else "NULL"},
                {data.get("RC_EVAL_SCORE") if data.get("RC_EVAL_SCORE") is not None else "NULL"},
                {str(data.get("IS_BLOCKED", False)).upper()},
                {data.get("EXECUTION_TIME_MS") if data.get("EXECUTION_TIME_MS") is not None else "NULL"}
            )
            """
            
            session.sql(fallback_sql).collect()
            print(f" Audit log saved with simplified data (VARIANT fields skipped).")
            
        except Exception as e2:
            print(f" Fallback Insert Failed: {e2}")
            import traceback
            traceback.print_exc()
            
        
def get_cortex_completion(session: Session, prompt: str) -> str:
    try:
        safe_prompt = prompt.replace("'", "''")
        cmd = f"SELECT SNOWFLAKE.CORTEX.COMPLETE('{CONFIG.model}', '{safe_prompt}') as R"
        return session.sql(cmd).collect()[0]['R']
    except Exception as e: return ""

# ==========================================
# 5. SEMANTIC VIEW PARSER
# ==========================================

class SemanticViewParser:
    def __init__(self, session: Session, view_name: str):
        self.session = session
        self.view_name = view_name
        self.ca_json = {"tables": [], "relationships": []}
        self.table_comments = {} 
        self.column_metadata = defaultdict(lambda: defaultdict(dict)) 
        self.rel_metadata = defaultdict(dict) 
        # Note: We do NOT parse in __init__ to satisfy "orchestrator only" constraint.
        self.is_loaded = False

    def _fetch_and_parse(self):
        if self.is_loaded: return
        print(f" DESCRIBING SEMANTIC VIEW: {self.view_name}...")
        try:
            rows = self.session.sql(f"DESCRIBE SEMANTIC VIEW {self.view_name}").collect()
            data = [row.as_dict() for row in rows]
            ca_row = next((r for r in data if r.get('object_kind') == 'EXTENSION' and r.get('object_name') == 'CA'), None)
            if ca_row: self.ca_json = json.loads(ca_row['property_value'])

            for r in data:
                kind = r.get('object_kind')
                name = r.get('object_name')
                prop = r.get('property')
                val = r.get('property_value')
                
                if kind == 'TABLE' and prop == 'COMMENT':
                    self.table_comments[name.split('.')[-1]] = val
                elif kind in ['DIMENSION', 'FACT', 'COLUMN']:
                    t_name = r.get('parent_entity', '').split('.')[-1]
                    if t_name:
                        if prop == 'COMMENT': self.column_metadata[t_name][name]['description'] = val
                        elif prop == 'DATA_TYPE': self.column_metadata[t_name][name]['data_type'] = val
                elif kind == 'RELATIONSHIP':
                    if prop == 'TABLE': self.rel_metadata[name]['source_table'] = val.split('.')[-1]
                    elif prop == 'REF_TABLE': self.rel_metadata[name]['target_table'] = val.split('.')[-1]
                    elif prop == 'FOREIGN_KEY': self.rel_metadata[name]['keys'] = val
            
            self.is_loaded = True
            print(f" Metadata Loaded from {self.view_name}")
        except Exception as e: print(f" Metadata Parse Failed: {e}")

    def get_context_summary(self) -> str:
        """Returns a summarized string of the schema for LLM Context (Master)."""
        self._fetch_and_parse() # Load on demand
        summary = "Available Data Schema:\n"
        for t in self.ca_json.get('tables', []):
            summary += f"- Table: {t.get('name')}\n"
            summary += f"  Columns: {', '.join([c['name'] for c in t.get('dimensions', []) + t.get('facts', [])])}\n"
        return summary

    def get_table_summaries(self) -> str:
        """Returns detailed table summaries for selection."""
        self._fetch_and_parse()
        summary_list = []
        for t in self.ca_json.get('tables', []):
            t_name = t.get('name')
            desc = self.table_comments.get(t_name, "No description.")
            summary_list.append(f"- Table: {t_name}\n  Description: {desc}")
        return "\n".join(summary_list) if summary_list else ""

    def get_pruned_context(self, selected_tables: List[str]) -> str:
        """Generates a pruned JSON schema based on selected tables."""
        self._fetch_and_parse()
        pruned = {"tables": [], "relationships": []}
        for t in self.ca_json.get('tables', []):
            t_name = t['name']
            if t_name in selected_tables:
                table_copy = t.copy()
                table_copy['description'] = self.table_comments.get(t_name, "")
                for category in ['dimensions', 'facts', 'time_dimensions']:
                    if category in table_copy:
                        enriched_cols = []
                        for col in table_copy[category]:
                            col_copy = col.copy()
                            meta = self.column_metadata[t_name].get(col['name'], {})
                            if 'description' in meta: col_copy['description'] = meta['description']
                            if 'data_type' in meta: col_copy['data_type'] = meta['data_type']
                            enriched_cols.append(col_copy)
                        table_copy[category] = enriched_cols
                pruned['tables'].append(table_copy)
        
        if 'relationships' in self.ca_json:
            for rel in self.ca_json['relationships']:
                r_name = rel.get('name')
                source = self.rel_metadata.get(r_name, {}).get('source_table')
                if source in selected_tables:
                    pruned['relationships'].append(rel)
        return json.dumps(pruned, indent=2)

# ==========================================
# 6. AGENT MANAGER
# ==========================================

class AgentManager:
    def __init__(self, session: Session):
        self.session = session
        # We only initialize the Parser object, we DO NOT load data here.
        # Data loading happens inside run_data_orchestrator calls.
        self.parser = SemanticViewParser(session, CONFIG.cortex_analyst_object_master)

    def identify_needed_tables(self, query: str) -> List[str]:
        print(" IDENTIFYING RELEVANT TABLES...")
        summaries = self.parser.get_table_summaries() # Triggers load if needed
        if not summaries: return []
        prompt = f"{PROMPT_TABLE_SELECTION}\n\nUser Query: {query}\n\nTable Summaries:\n{summaries}"
        res_text = get_cortex_completion(self.session, prompt)
        result = extract_pydantic_from_text(res_text, TableSelection)
        print(f" Selected: {result.relevant_table_names}")
        return result.relevant_table_names

    def run_semantic_translator(self, query: str, relevant_tables: List[str]) -> str:
        print(f" REWRITING QUERY...")
        pruned_json = self.parser.get_pruned_context(relevant_tables)
        prompt = f"{PROMPT_SEMANTIC_TRANSLATOR}\n\nSchema Context:\n{pruned_json}\n\nUser Query: {query}"
        return get_cortex_completion(self.session, prompt).strip()

    def run_rephraser(self, query: str, history: List[Dict]) -> RephraserOutput:
        inst = {
            "system": PROMPT_REPHRASER_SYSTEM,
            "orchestration": PROMPT_REPHRASER_ORCHESTRATION,
            "response": PROMPT_REPHRASER_RESPONSE
        }
        payload = PayloadFactory.create(query, inst, history=history)
        resp = invoke_cortex_agent(self.session, payload, "Rephraser Agent")
        return extract_pydantic_from_text(resp.get("text", ""), RephraserOutput)

    def run_intent_classifier(self, query: str) -> IntentClassification:
        inst = {
            "system": PROMPT_INTENT_SYSTEM, 
            "orchestration": PROMPT_INTENT_ORCHESTRATION,
            "response": PROMPT_INTENT_RESPONSE
        }
        payload = PayloadFactory.create(query, inst)
        resp = invoke_cortex_agent(self.session, payload, "Intent Agent")
        return extract_pydantic_from_text(resp.get("text", ""), IntentClassification)

    def run_data_agent(self, query: str, schema_context: Optional[str] = None, is_optimized: bool = False) -> SqlResult:
        # Determine correct object and context
        target_view = CONFIG.cortex_analyst_object_ards if is_optimized else CONFIG.cortex_analyst_object_master
        
        tools = [{"tool_spec": {"type": "cortex_analyst_text_to_sql", "name": "analyst_tool"}}]
        res_def = {
            "analyst_tool": {
                "type": "cortex_analyst_text_to_sql",
                "semantic_view": target_view, 
                "execution_environment": {"type": "warehouse", "warehouse": CONFIG.warehouse}
            }
        }
        
        # Inject Master Schema Context into System Prompt if provided
        system_prompt = PROMPT_DATA_AGENT_SYSTEM
        if is_optimized == False:
             system_prompt += f"Enrich the user question with the below schema. \n\nMASTER SCHEMA CONTEXT:\n{CONFIG.cortex_analyst_object_master}"
        
        inst = {
            "system": system_prompt, 
            "orchestration": PROMPT_DATA_AGENT_ORCHESTRATION,
            "response": PROMPT_DATA_AGENT_RESPONSE
        }
        payload = PayloadFactory.create(query, inst, tools, res_def)
        resp = invoke_cortex_agent(self.session, payload, "Data Agent" + (" (Optimized)" if is_optimized else ""))
        
        raw_text = resp.get('text', '')
        parsed = extract_pydantic_from_text(raw_text, SqlResult)
        
        parsed.tables = resp.get('tables', [])
        parsed.sql_generated = resp.get('sql_generated')
        parsed.sql_explanation = resp.get('sql_explanation')
        parsed.charts = resp.get('charts')
        return parsed

    def run_data_flow_orchestrator(self, query: str) -> SqlResult:
        """Handles standard execution vs optimized self-healing execution via parallelism."""
        
        def run_optimization_sequence():
            try:
                # Optimization logic...
                needed_tables = self.identify_needed_tables(query)
                if needed_tables:
                    optimized_q = self.run_semantic_translator(query, needed_tables)
                    print(f" Optimized Query: {optimized_q}")
                    # No schema context needed for optimized run (relies on translation + ARDS view)
                    return self.run_data_agent(optimized_q, schema_context=None, is_optimized=True)
            except Exception as e:
                print(f"Optimization failed: {e}")
            return SqlResult(clean_answer_text="Optimization Failed", evaluation=EvaluationResult(score=0))

        def run_standard_sequence():
   
            return self.run_data_agent(query, schema_context=None, is_optimized=False)

        print(" Starting Data Agent Flows (Standard & Optimized)...")
        with ThreadPoolExecutor(max_workers=2) as executor:
            future_std = executor.submit(run_standard_sequence)
            future_opt = executor.submit(run_optimization_sequence)
            res_std = future_std.result()
            res_opt = future_opt.result()

        print(f" Standard Score: {res_std.evaluation.score} | Optimized Score: {res_opt.evaluation.score}")
        
        # Decision Logic
        if res_std.evaluation.score >= 8:
            return res_std
        elif (res_std.evaluation.score < 8 and res_opt.evaluation.score < 8) or \
             (res_std.evaluation.score == res_opt.evaluation.score and res_std.evaluation.score > 0):
             
             print(" Scores Low/Equal. Combining Summaries.")
             base = res_opt if res_opt.evaluation.score > 0 else res_std
             combined_text = (f"**Standard Analysis:**\n{res_std.clean_answer_text}\n\n"
                              f"**Deep Context Analysis:**\n{res_opt.clean_answer_text}")
             
             final_res = SqlResult(
                 clean_answer_text=combined_text,
                 tables=base.tables,
                 charts=base.charts,
                 sql_generated=base.sql_generated, 
                 sql_explanation=base.sql_explanation,
                 evaluation=base.evaluation,
                 is_retry=True
             )
             return final_res
        elif res_opt.evaluation.score > res_std.evaluation.score:
            print(f" Switched to Optimized Result (Score: {res_opt.evaluation.score})")
            res_opt.is_retry = True
            return res_opt
            
        return res_std
    def run_root_cause_agent(self, query: str) -> DiagnosticResult:
        tools = [{"tool_spec": {"type": "generic", "name": "Diagnostic_tool", "input_schema": {"type": "object", "properties": {"USER_QUERY": {"type": "string"}, "PARENT_NODE_IDS_JSON": {"type": "string"}, "TREE_ID": {"type": "string"}}, "required": ["USER_QUERY", "PARENT_NODE_IDS_JSON", "TREE_ID"]}}}]
        res_def = {"Diagnostic_tool": {"type": "procedure", "execution_environment": {"type": "warehouse", "warehouse": CONFIG.warehouse}, "identifier": CONFIG.diagnostic_udf}}
        
        
        
        inst = {
            "system": PROMPT_ROOT_CAUSE_SYSTEM, 
            "orchestration": PROMPT_ROOT_CAUSE_ORCHESTRATION,
            "response": PROMPT_ROOT_CAUSE_RESPONSE
        }
        payload = PayloadFactory.create(query, inst, tools, res_def)
        resp = invoke_cortex_agent(self.session, payload, "Root Cause Agent")
        
        raw_text = resp.get('text', '')
        print(raw_text)
        parsed = extract_pydantic_from_text(raw_text, DiagnosticResult)
        print(parsed)
        return parsed

# ==========================================
# 7. MAIN EXECUTION
# ==========================================

def main(session: Session):
    """Main Orchestrator Entry Point."""
    
    # Start timing
    start_time = datetime.datetime.now()
    
    manager = AgentManager(session)
    user_query="Why is the NSAID Market Volume rising in Internal Medicine while Tramadol Brand Volume is falling in the same specialty(root cause query)?"
    session_id="11343"
    # Initialize row_data with ALL required columns for audit table
    row_data = {
        "SESSION_ID": session_id,
        "USER_QUERY": user_query,
        "REPHRASED_QUERY": None,
        "INTENT_TYPE": None,
        "INTENT_CONFIDENCE": None,
        "DATA_SUMMARY": None,
        "DATA_SQL": None,
        "DATA_SQL_EXPLANATION": None,
        "DATA_CLARIFICATION": None,
        "DATA_RESULT_SET": None,
        "DATA_CHARTS": None,
        "DATA_EVAL_SCORE": None,
        "DATA_EVAL_REASONING": None,
        "RC_SUMMARY": None,
        "RC_GRAPH_JSON": None,
        "RC_EVAL_SCORE": None,
        "RC_EVAL_REASONING": None,
        "IS_BLOCKED": False,
        "IS_RETRY": False,
        "FULL_RAW_JSON": None,
        "EXECUTION_TIME_MS": None
    }
    
    log_checkpoint("MAIN: START", {"query": user_query, "session": session_id})

    # 1. Fetch History
    history = get_chat_history(session, session_id)

    # 2. Input Guard
    guard = check_input_guard(session, user_query)
    if not guard.is_safe:
        row_data["IS_BLOCKED"] = True
        
        # Calculate execution time
        end_time = datetime.datetime.now()
        row_data["EXECUTION_TIME_MS"] = int((end_time - start_time).total_seconds() * 1000)
        
        # Save audit log
        row_data["FULL_RAW_JSON"] = {"status": "blocked", "message": guard.message}
        _save_audit_row(session, row_data, session_id)
        
        return {"status": "blocked", "message": guard.message}

    # 3. Save User Message
    save_chat_message(session, session_id, "user", user_query)

    # 4. Rephrase
    try:
        rephrased = manager.run_rephraser(user_query, history)
        effective_query = rephrased.refined_query or user_query
    except Exception as e:
        print(f" Rephraser failed: {e}")
        effective_query = user_query
    
    # 5. Intent Classification
    try:
        intent = manager.run_intent_classifier(effective_query)
    except Exception as e:
        print(f" Intent classification failed: {e}")
        # Default to data retrieval if intent fails
        intent = IntentClassification(
            intent_type="data_retrieval",
            data_retrieval_query=effective_query,
            confidence="low",
            reasoning=f"Failed to classify intent: {str(e)}"
        )
    
    row_data["REPHRASED_QUERY"] = effective_query
    row_data["INTENT_TYPE"] = intent.intent_type
    row_data["INTENT_CONFIDENCE"] = intent.confidence

    final_output = {
        "original": user_query, 
        "processed": effective_query, 
        "intent": intent.model_dump(), 
        "results": []
    }

    bot_response_text = ""

    # 6. Execute based on Intent
    if intent.direct_response:
        msg = intent.direct_response
        final_output["results"].append({"type": "direct", "message": msg})
        bot_response_text = msg

    else:
        futures = {}
        with ThreadPoolExecutor(max_workers=2) as executor:
            
            # Data Flow (Uses Parallel Orchestrator)
            if intent.intent_type in ["data_retrieval", "combined", "clarification_needed"]:
                q = intent.data_retrieval_query or effective_query
                futures["data"] = executor.submit(manager.run_data_flow_orchestrator, q)
            
            # Root Cause Flow
            if intent.intent_type in ["root_cause_analysis", "combined"]:
                q = intent.root_cause_query or effective_query
                futures["rc"] = executor.submit(manager.run_root_cause_agent, q)

        # Process Data Results
        if "data" in futures:
            try:
                res = futures["data"].result()
                res_dump = res.model_dump()
                
                row_data["DATA_EVAL_SCORE"] = res.evaluation.score
                row_data["DATA_EVAL_REASONING"] = res.evaluation.reasoning
                row_data["DATA_SQL"] = res.sql_generated
                row_data["DATA_SQL_EXPLANATION"] = res.sql_explanation
                
                if res.is_retry:
                    row_data["IS_RETRY"] = True
                
                # Store as dict/list - will be converted to JSON in _save_audit_row
                if res.tables: 
                    row_data["DATA_RESULT_SET"] = res.tables
                if res.charts:
                    row_data["DATA_CHARTS"] = res.charts
                
                if res.clarifying_question:
                    response_text = res.clarifying_question
                    final_output["results"].append({
                        "type": "clarification", 
                        "message": response_text,
                        "full_pydantic_object": res_dump 
                    })
                    row_data["DATA_CLARIFICATION"] = response_text
                else:
                    response_text = res.clean_answer_text
                    final_output["results"].append({
                        "type": "data_analysis", 
                        "summary": response_text, 
                        "tables": res.tables,
                        "charts": res.charts,
                        "sql_generated": res.sql_generated,
                        "sql_explanation": res.sql_explanation,
                        "full_pydantic_object": res_dump 
                    })
                    row_data["DATA_SUMMARY"] = response_text
                
                bot_response_text += response_text + "\n"
                
            except Exception as e:
                error_msg = f"Data analysis failed: {str(e)}"
                print(f" {error_msg}")
                final_output["results"].append({
                    "type": "error",
                    "message": error_msg
                })
                bot_response_text += error_msg + "\n"

        # Process Root Cause Results
        if "rc" in futures:
            try:
                res_rc = futures["rc"].result()
                res_rc_dump = res_rc.model_dump()
                print(res_rc)
                row_data["RC_EVAL_SCORE"] = res_rc.evaluation.score
                row_data["RC_EVAL_REASONING"] = res_rc.evaluation.reasoning
                
                if res_rc.clarifying_question:
                    response_text = res_rc.clarifying_question
                    final_output["results"].append({
                        "type": "clarification", 
                        "message": response_text,
                        "full_pydantic_object": res_rc_dump 
                    })
                else:
                    response_text = res_rc.clean_summary_text
                    final_output["results"].append({
                        "type": "root_cause", 
                        "summary": response_text, 
                        "graph": res_rc.react_flow_json,
                        "full_pydantic_object": res_rc_dump 
                    })
                    row_data["RC_SUMMARY"] = res_rc.clean_summary_text
                    if res_rc.react_flow_json:
                        row_data["RC_GRAPH_JSON"] = res_rc.react_flow_json
                
                bot_response_text += response_text + "\n"
                
            except Exception as e:
                error_msg = f"Root cause analysis failed: {str(e)}"
                print(f" {error_msg}")
                final_output["results"].append({
                    "type": "error",
                    "message": error_msg
                })
                bot_response_text += error_msg + "\n"

    # 7. Save Bot Response
    if bot_response_text:
        # Save structured metadata to METADATA column
        message_metadata = {
            "intent_data": intent.model_dump(),
            "sql_generated": row_data.get("DATA_SQL"),
            "is_blocked": row_data.get("IS_BLOCKED"),
            "tool_artifacts": final_output.get("results"),
            "generated_at": datetime.datetime.now().isoformat()
        }
        
        try:
            save_chat_message(
                session, 
                session_id, 
                "assistant", 
                bot_response_text.strip(), 
                metadata=message_metadata
            )
        except Exception as e:
            print(f" Failed to save assistant message: {e}")

    # 8. Calculate execution time
    end_time = datetime.datetime.now()
    row_data["EXECUTION_TIME_MS"] = int((end_time - start_time).total_seconds() * 1000)
    
    # 9. Save Audit Log
    row_data["FULL_RAW_JSON"] = final_output
    try:
        _save_audit_row(session, row_data, session_id)
    except Exception as e:
        print(f" Failed to save audit log: {e}")
        import traceback
        traceback.print_exc()
    
    print(" Process Completed")
    print(f"  Total Execution Time: {row_data['EXECUTION_TIME_MS']}ms")
    
    return final_output


# Helper wrapper for Snowflake stored procedure
def handler(session: Session, session_id: str, user_query: str) -> str:
    """
    Snowflake Stored Procedure Handler
    
    Usage:
    CALL AGENT_HANDLER('session_123', 'Show me top prescribers');
    """
    try:
        result = main(session, session_id, user_query)
        return json.dumps(result, indent=2)
    except Exception as e:
        error_result = {
            "status": "error",
            "message": str(e),
            "traceback": traceback.format_exc()
        }
        return json.dumps(error_result, indent=2)


if __name__ == "__main__":
    # For local testing
    pass


        "type": "default",
        "data": { "label": "Tramadol Retention (Refills)\n36,370.24 units" },
        "position": { "x": 200, "y": 120 },
        "style": { "background": "#FFCDD2", "width": 220, "color": "#333", "border": "2px solid #c62828", "borderRadius": "8px", "fontSize": "13px" }
      },
      {
        "id": "K13",
        "type": "default",
        "data": { "label": "NSAID Market Volume\n551,076.76 units\n(Growing)" },
        "position": { "x": 480, "y": 0 },
        "style": { "background": "#C8E6C9", "width": 200, "color": "#333", "border": "2px solid #388e3c", "borderRadius": "8px", "fontSize": "13px" }
      }
    ],
    "edges": [
      {
        "id": "e-K8-K5",
        "source": "K8",
        "target": "K5",
        "label": "drives decline",
        "animated": true,
        "style": { "stroke": "#d32f2f", "strokeWidth": 3 },
        "labelStyle": { "fill": "#d32f2f", "fontWeight": "bold" }
      }
    ]
  },
  "evaluation": {
    "score": 9,
    "reasoning": "Successfully identified the leaf-level root cause (K8: Tramadol Retention) through systematic drilling. The causal chain is mathematically sound: poor retention directly drives lower brand volume. Explored both phenomena (NSAID increase and Tramadol decrease) as requested. Drilling confirmed K8 is a true leaf node with no further decomposition available. The only limitation is that the tree structure doesn't provide deeper segmentation of retention factors (e.g., by physician, patient demographics, or specific reasons for discontinuation), but this appears to be a data availability constraint rather than analytical oversight."
  }
}
```
clean_summary_text='' clarifying_question=None react_flow_json=None evaluation=EvaluationResult(score=0, reasoning='No evaluation provided.')
clean_summary_text='' clarifying_question=None react_flow_json=None evaluation=EvaluationResult(score=0, reasoning='No evaluation provided.')
 Audit log saved for session 11343.
 Process Completed
  Total Execution Time: 273141ms





Skip to main content
Skip to editor
Skip to results
Site


Work with data

Projects
Ingestion
Transformation
AI & ML
Monitoring
Marketplace
Horizon Catalog

Catalog
Data sharing
Governance & security
Manage

Compute
Postgres
Admin
Worksheets
678
679
680
681
682
683
684
685
686
687
688
689
690
691
692
693
694
695
696
697
698
699
700
701
702
703
704
705
706
707
708
709
710
711
712
713
714
715
716
717
718
719
720
721
722
723
724
725
726
727
728
729
730
731
732
733
734
735
736
737
738
739
740
741
742
743
744
745
746
747
748
749
750
751
752
753
import json
                print('response.tool_result.analyts.delt')
                print(delta)
                delta = data.get('delta', {})
                if delta.get('sql'): extracted["sql_generated"] = delta.get('sql')
                if delta.get('sql_explanation'): extracted["sql_explanation"] = delta.get('sql_explanation')
                if delta.get('result_set'): extracted["tables"].append(delta.get('result_set'))
            elif evt == 'response.tool_result':
                for item in data.get('content', []):
                    if item.get('type') == 'json':
                        json_p = item.get('json', {})
                        if 'sql' in json_p: extracted["sql_generated"] = json_p['sql']
                        if 'result_set' in json_p: extracted["tables"].append(json_p['result_set'])

        if isinstance(parsed, list):
            for item in parsed: process_event(item.get('event'), item.get('data', {}))
        
        return extracted
    except Exception as e: return {"error": str(e)}

def extract_pydantic_from_text(text: str, model_class: type[BaseModel]) -> BaseModel:
    """Robust JSON extraction."""
    if not text: return model_class()
    def try_parse(json_str):
        try: return json.loads(json_str)
        except: 
            try: return json.loads(json_str, strict=False)
            except: return None

    match = re.search(r'```json\s*(\{.*?\})\s*```', text, re.DOTALL)
    if match:
        data = try_parse(match.group(1))
        if data: 
            try: return model_class(**data)
            except: pass 

    start = text.find('{')
    end = text.rfind('}')
    if start != -1 and end != -1:
        data = try_parse(text[start:end+1])
        if data: 
            try: return model_class(**data)
            except: pass

    if model_class == RephraserOutput:
        return RephraserOutput(refined_query=text.strip())

    return model_class()

def check_input_guard(session: Session, user_input: str) -> GuardResult:
    try:
        safe_input = user_input.replace("'", "''")
        res = session.sql(f"SELECT SNOWFLAKE.CORTEX.COMPLETE('{CONFIG.model}', [{{'role': 'user', 'content': '{safe_input}'}}], {{'guardrails': true}}) as r").collect()
        if not res: return GuardResult(is_safe=True)
        is_unsafe = "Response filtered" in json.loads(res[0]['R'])['choices'][0]['messages']
        return GuardResult(is_safe=not is_unsafe, message="Blocked." if is_unsafe else None)
    except: return GuardResult(is_safe=True)

class PayloadFactory:
    @staticmethod
    def create(query: str, instructions: Any, tools: List = None, resources: Dict = None, history: List = None) -> Dict:
        messages = (history if history else []) + [{"role": "user", "content": [{"type": "text", "text": query}]}]
        inst_payload = instructions if isinstance(instructions, dict) else {"system": instructions}
        return {
            "messages": messages,
            "models": {"orchestration": CONFIG.model},
            "instructions": inst_payload,
            "tools": tools or [],
            "tool_resources": resources or {}
        }

def _save_audit_row(session: Session, data: dict, session_id: str):
    """Saves detailed execution logs using a staged approach for complex VARIANT data."""
    try:
        import uuid
        # Prepare the complete record
        # UPDATED: Matches AGENT_DETAILED_HISTORY_V2 structure exactly.
    pass
        "type": "default",
        "data": { "label": "Tramadol Retention (Refills)\n36,370.24 units" },
        "position": { "x": 200, "y": 120 },
        "style": { "background": "#FFCDD2", "width": 220, "color": "#333", "border": "2px solid #c62828", "borderRadius": "8px", "fontSize": "13px" }
      },
      {
        "id": "K13",
        "type": "default",
        "data": { "label": "NSAID Market Volume\n551,076.76 units\n(Growing)" },
        "position": { "x": 480, "y": 0 },
        "style": { "background": "#C8E6C9", "width": 200, "color": "#333", "border": "2px solid #388e3c", "borderRadius": "8px", "fontSize": "13px" }
      }
    ],
    "edges": [
      {
        "id": "e-K8-K5",
        "source": "K8",
        "target": "K5",
        "label": "drives decline",
        "animated": true,
        "style": { "stroke": "#d32f2f", "strokeWidth": 3 },
        "labelStyle": { "fill": "#d32f2f", "fontWeight": "bold" }
      }
    ]
  },
  "evaluation": {
    "score": 9,
    "reasoning": "Successfully identified the leaf-level root cause (K8: Tramadol Retention) through systematic drilling. The causal chain is mathematically sound: poor retention directly drives lower brand volume. Explored both phenomena (NSAID increase and Tramadol decrease) as requested. Drilling confirmed K8 is a true leaf node with no further decomposition available. The only limitation is that the tree structure doesn't provide deeper segmentation of retention factors (e.g., by physician, patient demographics, or specific reasons for discontinuation), but this appears to be a data availability constraint rather than analytical oversight."
  }
}
```
clean_summary_text='' clarifying_question=None react_flow_json=None evaluation=EvaluationResult(score=0, reasoning='No evaluation provided.')
clean_summary_text='' clarifying_question=None react_flow_json=None evaluation=EvaluationResult(score=0, reasoning='No evaluation provided.')
 Audit log saved for session 11343.
 Process Completed
  Total Execution Time: 273141ms
Databases
Worksheets
Data products
Try nested folders in Workspaces

In Workspaces, organize your files by putting folders in folders.

Search

Sorted by Viewed descending



      },
      {
        "id": "K13",
        "type": "default",
        "data": { "label": "NSAID Market Volume\n551,076.76 units\n(Growing)" },
        "position": { "x": 480, "y": 0 },
        "style": { "background": "#C8E6C9", "width": 200, "color": "#333", "border": "2px solid #388e3c", "borderRadius": "8px", "fontSize": "13px" }
      }
    ],
    "edges": [
      {
        "id": "e-K8-K5",
        "source": "K8",
        "target": "K5",
        "label": "drives decline",
        "animated": true,
        "style": { "stroke": "#d32f2f", "strokeWidth": 3 },
        "labelStyle": { "fill": "#d32f2f", "fontWeight": "bold" }
      }
    ]
  },
  "evaluation": {
    "score": 9,
    "reasoning": "Successfully identified the leaf-level root cause (K8: Tramadol Retention) through systematic drilling. The causal chain is mathematically sound: poor retention directly drives lower brand volume. Explored both phenomena (NSAID increase and Tramadol decrease) as requested. Drilling confirmed K8 is a true leaf node with no further decomposition available. The only limitation is that the tree structure doesn't provide deeper segmentation of retention factors (e.g., by physician, patient demographics, or specific reasons for discontinuation), but this appears to be a data availability constraint rather than analytical oversight."
  }
}
```
clean_summary_text='' clarifying_question=None react_flow_json=None evaluation=EvaluationResult(score=0, reasoning='No evaluation provided.')
clean_summary_text='' clarifying_question=None react_flow_json=None evaluation=EvaluationResult(score=0, reasoning='No evaluation provided.')
 Audit log saved for session 11343.
 Process Completed
  Total Execution Time: 273141ms
Databases
Worksheets
Data products
Try nested folders in Workspaces

In Workspaces, organize your files by putting folders in folders.

Search





        "style": { "background": "#FFCDD2", "width": 220, "color": "#333", "border": "2px solid #c62828", "borderRadius": "8px", "fontSize": "13px" }
      },
      {
        "id": "K13",
        "type": "default",
        "data": { "label": "NSAID Market Volume\n551,076.76 units\n(Growing)" },
        "position": { "x": 480, "y": 0 },
        "style": { "background": "#C8E6C9", "width": 200, "color": "#333", "border": "2px solid #388e3c", "borderRadius": "8px", "fontSize": "13px" }
      }
    ],
    "edges": [
      {
        "id": "e-K8-K5",
        "source": "K8",
        "target": "K5",
        "label": "drives decline",
        "animated": true,
        "style": { "stroke": "#d32f2f", "strokeWidth": 3 },
        "labelStyle": { "fill": "#d32f2f", "fontWeight": "bold" }
      }
    ]
  },
  "evaluation": {
    "score": 9,
    "reasoning": "Successfully identified the leaf-level root cause (K8: Tramadol Retention) through systematic drilling. The causal chain is mathematically sound: poor retention directly drives lower brand volume. Explored both phenomena (NSAID increase and Tramadol decrease) as requested. Drilling confirmed K8 is a true leaf node with no further decomposition available. The only limitation is that the tree structure doesn't provide deeper segmentation of retention factors (e.g., by physician, patient demographics, or specific reasons for discontinuation), but this appears to be a data availability constraint rather than analytical oversight."
  }
}
```
clean_summary_text='' clarifying_question=None react_flow_json=None evaluation=EvaluationResult(score=0, reasoning='No evaluation provided.')
clean_summary_text='' clarifying_question=None react_flow_json=None evaluation=EvaluationResult(score=0, reasoning='No evaluation provided.')
 Audit log saved for session 11343.
 Process Completed
  Total Execution Time: 273141ms
Databases
Worksheets
Data products
Try nested folders in Workspaces

In Workspaces, organize your files by putting folders in folders.

Search


      },
      {
        "id": "K13",
        "type": "default",
        "data": { "label": "NSAID Market Volume\n551,076.76 units\n(Growing)" },
        "position": { "x": 480, "y": 0 },
        "style": { "background": "#C8E6C9", "width": 200, "color": "#333", "border": "2px solid #388e3c", "borderRadius": "8px", "fontSize": "13px" }
      }
    ],
    "edges": [
      {
        "id": "e-K8-K5",
        "source": "K8",
        "target": "K5",
        "label": "drives decline",
        "animated": true,
        "style": { "stroke": "#d32f2f", "strokeWidth": 3 },
        "labelStyle": { "fill": "#d32f2f", "fontWeight": "bold" }
      }
    ]
  },
  "evaluation": {
    "score": 9,
    "reasoning": "Successfully identified the leaf-level root cause (K8: Tramadol Retention) through systematic drilling. The causal chain is mathematically sound: poor retention directly drives lower brand volume. Explored both phenomena (NSAID increase and Tramadol decrease) as requested. Drilling confirmed K8 is a true leaf node with no further decomposition available. The only limitation is that the tree structure doesn't provide deeper segmentation of retention factors (e.g., by physician, patient demographics, or specific reasons for discontinuation), but this appears to be a data availability constraint rather than analytical oversight."
  }
}
```
clean_summary_text='' clarifying_question=None react_flow_json=None evaluation=EvaluationResult(score=0, reasoning='No evaluation provided.')
clean_summary_text='' clarifying_question=None react_flow_json=None evaluation=EvaluationResult(score=0, reasoning='No evaluation provided.')
 Audit log saved for session 11343.
 Process Completed
  Total Execution Time: 273141ms
Databases
Worksheets
Data products
Try nested folders in Workspaces

In Workspaces, organize your files by putting folders in folders.

Search



==================================================
 CHECKPOINT: MAIN: START
--------------------------------------------------
{'query': 'Why is the NSAID Market Volume rising in Internal Medicine while '
          'Tramadol Brand Volume is falling in the same specialty(root cause '
          'query)?',
 'session': '11343'}
==================================================
 Retrieved 6 past messages for Session 11343
 Saved user message to history.
--- INVOKING AGENT: Rephraser Agent ---
--- INVOKING AGENT: Intent Agent ---
--- INVOKING AGENT: Root Cause Agent ---
## SECTION 1: Diagnostic Executive Summary
**Root Cause: Poor Tramadol Patient Retention (Refills)**
Within the Internal Medicine specialty, the decrease in Tramadol brand volume is primarily driven by **low retention rates** - specifically, refill prescriptions totaling only 36,370.24 units. While the NSAID market overall is experiencing growth (551,076.76 units), Tramadol is struggling to retain patients who have been prescribed the medication initially.
**The Narrative:**
Patients in Internal Medicine who are prescribed Tramadol are not returning for refills at sufficient rates. This retention problem is the isolated root cause of declining Tramadol brand volume. Meanwhile, the NSAID market is growing, suggesting potential competitive pressure or physician preference shifts toward NSAIDs over opioid-based pain management like Tramadol.
**Actionable Insight:**
Investigate patient adherence barriers and physician prescribing patterns. Consider:
- Patient education programs to improve treatment compliance
- Understanding why patients discontinue Tramadol therapy
- Analyzing whether physicians are switching patients from Tramadol to NSAIDs mid-treatment
- Reviewing competitive NSAID messaging in the Internal Medicine channel
---
Databases
Worksheets
Data products
Try nested folders in Workspaces

In Workspaces, organize your files by putting folders in folders.

Search

==================================================
 CHECKPOINT: MAIN: START
--------------------------------------------------
{'query': 'Why is the NSAID Market Volume rising in Internal Medicine while '
          'Tramadol Brand Volume is falling in the same specialty(root cause '
          'query)?',
 'session': '11343'}
==================================================
 Retrieved 6 past messages for Session 11343
 Saved user message to history.
--- INVOKING AGENT: Rephraser Agent ---
--- INVOKING AGENT: Intent Agent ---
--- INVOKING AGENT: Root Cause Agent ---
## SECTION 1: Diagnostic Executive Summary
**Root Cause: Poor Tramadol Patient Retention (Refills)**
Within the Internal Medicine specialty, the decrease in Tramadol brand volume is primarily driven by **low retention rates** - specifically, refill prescriptions totaling only 36,370.24 units. While the NSAID market overall is experiencing growth (551,076.76 units), Tramadol is struggling to retain patients who have been prescribed the medication initially.
**The Narrative:**
Patients in Internal Medicine who are prescribed Tramadol are not returning for refills at sufficient rates. This retention problem is the isolated root cause of declining Tramadol brand volume. Meanwhile, the NSAID market is growing, suggesting potential competitive pressure or physician preference shifts toward NSAIDs over opioid-based pain management like Tramadol.
**Actionable Insight:**
Investigate patient adherence barriers and physician prescribing patterns. Consider:
- Patient education programs to improve treatment compliance
- Understanding why patients discontinue Tramadol therapy
- Analyzing whether physicians are switching patients from Tramadol to NSAIDs mid-treatment
- Reviewing competitive NSAID messaging in the Internal Medicine channel
---
Databases
Worksheets
Data products
Try nested folders in Workspaces

In Workspaces, organize your files by putting folders in folders.

Search



        "target": "N2",
        "label": "driven by",
        "animated": true,
        "style": { "stroke": "#C41E3A", "strokeWidth": 2 }
      },
      {
        "id": "e-N1-N3",
        "source": "N1",
        "target": "N3",
        "label": "shift to",
        "animated": false,
        "style": { "stroke": "#555", "strokeWidth": 1.5, "strokeDasharray": "5,5" }
      }
    ]
  },
  "evaluation": {
    "score": 7,
    "reasoning": "The analysis successfully identified two leaf-node root causes (declining new prescriptions and reduced retention) driving Tramadol brand volume decline in Internal Medicine, and confirmed the concurrent NSAID market growth. However, the tool's limited granularity prevented deeper exploration of the specific factors requested by the user (regulatory changes, generic competition rates, formulary positioning, prescriber-level behavioral data). The causal chain is mathematically sound, but completeness is constrained by available tree depth. Score: 7/10 due to leaf node identification but limited visibility into underlying mechanism drivers."
  }
}
```
 Attempting to extract DiagnosticResult from text...
 Text length: 6695 characters
 Strategy 1: Trying markdown ```json block...
 Strategy 1 succeeded with pattern: ```json\s*\n(.*?)\n```
clean_summary_text='' clarifying_question=None react_flow_json=None evaluation=EvaluationResult(score=0, reasoning='No evaluation provided.')
clean_summary_text='' clarifying_question=None react_flow_json=None evaluation=EvaluationResult(score=0, reasoning='No evaluation provided.')
 Audit log saved for session 11343.
 Process Completed
  Total Execution Time: 283506ms
Databases
Worksheets
Data products
Try nested folders in Workspaces

In Workspaces, organize your files by putting folders in folders.

Search




==================================================
 CHECKPOINT: MAIN: START
--------------------------------------------------
{'query': 'Why is the NSAID Market Volume rising in Internal Medicine while '
          'Tramadol Brand Volume is falling in the same specialty(root cause '
          'query)?',
 'session': '11343'}
==================================================
 Retrieved 8 past messages for Session 11343
 Saved user message to history.
--- INVOKING AGENT: Rephraser Agent ---
 Attempting to extract RephraserOutput from text...
 Text length: 1847 characters
 Strategy 1: Trying markdown ```json block...
 Strategy 1 succeeded with pattern: ```json\s*\n(.*?)\n```
--- INVOKING AGENT: Intent Agent ---
 Attempting to extract IntentClassification from text...
 Text length: 2060 characters
 Strategy 1: Trying markdown ```json block...
 Strategy 1 succeeded with pattern: ```json\s*\n(.*?)\n```
--- INVOKING AGENT: Root Cause Agent ---
## Section 1: Diagnostic Executive Summary
**Root Cause:** The decrease in Tramadol brand volume within Internal Medicine is driven by two primary factors: **declining new prescription starts** (10,304.64 TRx) and **reduced patient retention/refills** (36,370.24 TRx). Simultaneously, the NSAID market is experiencing volume growth (551,076.76 TRx), indicating a prescriber preference shift away from Tramadol toward NSAIDs within this specialty.
**The Narrative:** Internal Medicine practitioners are initiating fewer new Tramadol prescriptions, and existing patients are not refilling at previous rates. This dual decline in acquisition and retention is causing overall brand volume contraction. Concurrently, NSAIDs are gaining market share, suggesting that prescribers are choosing non-opioid alternatives for pain managementlikely influenced by heightened regulatory scrutiny of opioid prescribing, evolving clinical guidelines favoring non-opioid first-line therapy, potential formulary restrictions on opioids, and growing awareness of opioid-related risks.
Databases
Worksheets
Data products
Try nested folders in Workspaces

In Workspaces, organize your files by putting folders in folders.

Search





DROP PROCEDURE DIAGNOSTIC_TOOL(VARCHAR, VARCHAR, VARCHAR);
CREATE OR REPLACE PROCEDURE DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.AI_POC.DIAGNOSTIC_TOOL("USER_QUERY" VARCHAR, "PARENT_NODE_IDS_JSON" VARCHAR, "TREE_ID" VARCHAR)
RETURNS VARCHAR
LANGUAGE PYTHON
RUNTIME_VERSION = '3.10'
PACKAGES = ('snowflake-snowpark-python','pandas','simplejson','pydantic')
HANDLER = 'main'
EXECUTE AS OWNER
AS '
import simplejson as json
import concurrent.futures
import traceback
from pydantic import BaseModel, Field
from snowflake.snowpark import Session

# ==========================================
# 1. DATA MODELS
# ==========================================
class SqlGenerationResponse(BaseModel):
    sql_query: str = Field(description="The executable Snowflake SQL query")
    filters_applied: list[str] = Field(description="List of specific filters applied from the user request")

class StatusCheckResponse(BaseModel):
    is_bad: bool = Field(description="True if the metric value indicates a negative business outcome")
    reason: str = Field(description="Concise business reason (max 10 words)")

# ==========================================
# 2. HELPER FUNCTIONS
# ==========================================
def log_debug(session: Session, step_name: str, message: str):
    """Logs debug information to the database securely using Dollar Quoting."""
    try:
        DQ = "$" + "$"
        safe_msg = str(message)[:100000]
        safe_step = str(step_name)[:50]
        query = (
            "INSERT INTO DEBUG_LOGS_NEW "
            "(STEP_NAME, LOG_MESSAGE) VALUES (" + DQ + safe_step + DQ + ", " + DQ + safe_msg + DQ + ")"
        )
        session.sql(query).collect()
    except Exception:
        pass # Fail silently to strictly avoid interrupting main flow

# ==========================================
# 3. CORE LOGIC: PROCESS SINGLE NODE
# ==========================================
def process_node(session: Session, node: dict, user_query: str, meta_map: dict) -> dict:
    metric_name = node[''metric'']
    node_id = node[''id'']
    polarity = node.get(''polarity'', 0)
    DQ = "$" + "$"

    # --- Step 0: Validation ---
    log_debug(session, f"NODE_START_{node_id}", f"Processing Metric: {metric_name}")
    
    meta = meta_map.get(metric_name)
    if not meta:
        error_msg = f"Metadata missing for metric: {metric_name}"
        log_debug(session, f"NODE_ERROR_{node_id}", error_msg)
        return {"id": node_id, "status": "error", "error": error_msg}

    static_query = meta[''SQL_QUERY'']
    final_query = static_query
    query_type = "static"
    executed_sql = static_query

    # --- Step 1: Dynamic SQL Generation (Claude Sonnet 4.5) ---
    if user_query and len(user_query) > 5:
        try:
            log_debug(session, f"GEN_SQL_START_{node_id}", "Initiating prompt construction...")
            
            # Build Few-Shot Examples
            examples_text = ""
            ex_json = meta.get(''FEW_SHOT_EXAMPLES'')
            if ex_json:
                ex_list = json.loads(ex_json) if isinstance(ex_json, str) else ex_json
                for i, ex in enumerate(ex_list):
                    examples_text += "\\nExample {}: User Request=''{}'' -> SQL=''{}''".format(i+1, ex[''question''], ex[''sql''])

            # Expert Prompt Engineering
            prompt_content = """
            You are an expert Snowflake SQL Architect. 
            Your goal is to adapt a Standard SQL Logic to answer a specific User Request.

            **Context:**
            - Metric Name: {}
            - Standard Logic: {}
            - User Request: "{}"

            **Guidelines:**
            1. Keep the base logic of the Standard Logic (tables, joins, core calculations).
            2. Apply filters (WHERE clauses) based on the User Request (e.g., date ranges, regions, segments).
            3. Ensure the syntax is valid Snowflake SQL.
            4. If the User Request is irrelevant to this metric, return the Standard Logic unchanged.

            **Reference Examples:**
            {}
            """.format(metric_name, static_query, user_query, examples_text)

            # Sanitize Prompt
            safe_prompt = prompt_content.replace(DQ, "")
            
            # Define Output Schema
            options_str = json.dumps({
                "type": "json",
                "schema": {
                    "type": "object",
                    "properties": {
                        "sql_query": { "type": "string" },
                        "filters_applied": { "type": "array", "items": { "type": "string" } }
                    },
                    "required": ["sql_query", "filters_applied"],
                    "additionalProperties": False  # <--- ADD THIS LINE
                }
            })

            # Call Cortex (claude-sonnet-4-5)
            cmd = (
                "SELECT AI_COMPLETE("
                "model => ''claude-sonnet-4-5'', "
                "prompt => " + DQ + safe_prompt + DQ + ", "
                "response_format => PARSE_JSON(" + DQ + options_str + DQ + ")"
                ")"
            )
            
            resp = session.sql(cmd).collect()
            raw_result = resp[0][0]
            log_debug(session, f"GEN_SQL_RESPONSE_{node_id}", str(raw_result))

            # Parse Response
            if isinstance(raw_result, str):
                parsed = SqlGenerationResponse.model_validate_json(raw_result)
            else:
                parsed = SqlGenerationResponse.model_validate(raw_result)
                
            final_query = parsed.sql_query
            query_type = "dynamic"
            
        except Exception as e:
            log_debug(session, f"GEN_SQL_FAIL_{node_id}", f"Error: {str(e)}. Fallback to static.")
            final_query = static_query
            query_type = "static_fallback"

    # --- Step 2: Query Execution ---
    val = "No Data"
    executed_sql = final_query
    
    try:
        log_debug(session, f"EXEC_START_{node_id}", f"Running SQL: {final_query}")
        df = session.sql(final_query).to_pandas()
        val = df.iloc[0,0] if not df.empty else "No Data"
        log_debug(session, f"EXEC_SUCCESS_{node_id}", f"Result Value: {val}")
        
    except Exception as e:
        log_debug(session, f"EXEC_FAIL_{node_id}", f"Primary SQL failed. Attempting recovery with static query. Error: {str(e)}")
        try:
            df = session.sql(static_query).to_pandas()
            val = df.iloc[0,0] if not df.empty else "No Data"
            executed_sql = static_query
            query_type = "static_recovery"
            log_debug(session, f"EXEC_RECOVERY_{node_id}", f"Recovery Value: {val}")
        except Exception as e2:
            return {"id": node_id, "status": "error", "error": f"Execution failed: {str(e2)}"}

    # --- Step 3: Status Analysis (openai-gpt-4.1) ---
    try:
        pol_txt = "Higher is BAD" if polarity == -1 else "Lower is BAD" if polarity == 1 else "Context dependent"
        
        status_prompt = """
        You are a Business Intelligence Analyst.
        Analyze the following metric result to determine if it represents a negative business outcome (''Bad'').

        - Metric: {}
        - Value: {}
        - Business Rule: {}
        - User Context: "{}"

        Determine if this is ''Bad'' for the business. Provide a concise reason.
        """.format(metric_name, val, pol_txt, user_query)

        safe_status_prompt = status_prompt.replace(DQ, "")
        
        status_options_str = json.dumps({
            "type": "json",
            "schema": {
                "type": "object",
                "properties": {
                    "is_bad": { "type": "boolean" },
                    "reason": { "type": "string" }
                },
                "required": ["is_bad", "reason"],
                "additionalProperties": False  # <--- ADD THIS LINE
            }
        })

        cmd = (
            "SELECT AI_COMPLETE("
            "model => ''openai-gpt-4.1'', "
            "prompt => " + DQ + safe_status_prompt + DQ + ", "
            "response_format => PARSE_JSON(" + DQ + status_options_str + DQ + ")"
            ")"
        )
        
        resp = session.sql(cmd).collect()
        raw_result = resp[0][0]
        
        if isinstance(raw_result, str):
            status_obj = StatusCheckResponse.model_validate_json(raw_result)
        else:
            status_obj = StatusCheckResponse.model_validate(raw_result)
            
        status = "bad" if status_obj.is_bad else "good"
        
        return {
            "id": node_id,
            "name": metric_name,
            "value": str(val),
            "status": status,
            "reason": status_obj.reason,
            "query_type": query_type,
            "executed_sql": executed_sql
        }
        
    except Exception as e:
        log_debug(session, f"STATUS_FAIL_{node_id}", str(e))
        return {
            "id": node_id, 
            "name": metric_name, 
            "value": str(val), 
            "status": "unknown", 
            "error": "Status check failed",
            "query_type": query_type,
            "executed_sql": executed_sql
        }

# ==========================================
# 4. BATCH EXECUTOR
# ==========================================
def execute_batch(session: Session, nodes_list: list, user_query: str) -> list:
    if not nodes_list: 
        return []
    
    log_debug(session, "BATCH_START", f"Processing batch of {len(nodes_list)} nodes")
    
    # Efficient Metadata Loading
    DQ = "$" + "$"
    safe_names = [f"{DQ}{n[''metric'']}{DQ}" for n in nodes_list]
    names_str = ",".join(safe_names)
    
    meta_sql = f"SELECT METRIC_NAME, SQL_QUERY, FEW_SHOT_EXAMPLES FROM KPI_KNOWLEDGE_BASE_NEW WHERE METRIC_NAME IN ({names_str})"
    meta_df = session.sql(meta_sql).to_pandas()
    meta_map = {row[''METRIC_NAME'']: row.to_dict() for _, row in meta_df.iterrows()}
    
    results = []
    # Parallel Processing
    with concurrent.futures.ThreadPoolExecutor(max_workers=16) as executor:
        futures = [executor.submit(process_node, session, n, user_query, meta_map) for n in nodes_list]
        for f in concurrent.futures.as_completed(futures):
            results.append(f.result())
            
    return results

# ==========================================
# 5. MAIN ENTRY POINT
# ==========================================
def main(session: Session, user_query: str, parent_node_ids_json: str, tree_id: str):
    try:
        log_debug(session, "MAIN_ENTRY", f"TreeID: {tree_id}, Query: {user_query}")

        # 1. Load Decision Tree Structure
        tree_row = session.sql("SELECT GRAPH_JSON FROM DECISION_TREE_STORE_NEW WHERE TREE_ID = ?", params=[tree_id]).collect()
        
        if not tree_row: 
            return json.dumps({"error": f"Tree ID not found: {tree_id}"})
        
        full_json = json.loads(tree_row[0][''GRAPH_JSON''])
        graph = full_json.get(''graph'', full_json)
        
        # Build Lookup Maps
        all_nodes_map = {n[''id'']: n for n in graph.get(''nodes'', [])}
        name_to_node_map = {n[''metric'']: n for n in graph.get(''nodes'', [])}
        all_edges = graph.get(''edges'', [])

        # 2. Determine Strategy (Search vs Drill)
        targets_phase_1 = []
        
        # Robust Null Check
        is_drill_mode = (
            parent_node_ids_json is not None and 
            parent_node_ids_json != '''' and 
            parent_node_ids_json.upper() != ''NULL'' and 
            parent_node_ids_json != ''[]''
        )

        if not is_drill_mode and user_query:
            log_debug(session, "STRATEGY", "Vector Search (No parent IDs provided)")
            # Vector Search for Entry Point
            vec_sql = """
            SELECT METRIC_NAME FROM KPI_KNOWLEDGE_BASE_NEW 
            ORDER BY VECTOR_L2_DISTANCE(SNOWFLAKE.CORTEX.EMBED_TEXT_768(''snowflake-arctic-embed-m-v1.5'', ?), KPI_EMBEDDING) ASC 
            LIMIT 1
            """
            kb_row = session.sql(vec_sql, params=[user_query]).collect()
            if kb_row and kb_row[0][''METRIC_NAME''] in name_to_node_map:
                found_metric = kb_row[0][''METRIC_NAME'']
                targets_phase_1.append(name_to_node_map[found_metric])
                log_debug(session, "ANCHOR_FOUND", f"Matched: {found_metric}")

        elif is_drill_mode:
            log_debug(session, "STRATEGY", "Drill Down (Parent IDs provided)")
            try:
                p_ids = json.loads(parent_node_ids_json)
                if not isinstance(p_ids, list): p_ids = [p_ids]
                parent_set = set(p_ids)
                
                # Find children of provided parents
                for edge in all_edges:
                    if edge[''source''] in all_nodes_map and edge[''target''] in parent_set:
                         # Note: Depending on edge direction (source->target), adjust accordingly.
                         # Assuming Source=Parent, Target=Child? Or Source=Metric, Target=Root?
                         # Usually standard DAG is Parent -> Child. 
                         # If input is ''Parent Nodes'', we want their children.
                         # CHECK: Your previous code checked ''target'' in parent_set. 
                         # If Edge is Source(Parent)->Target(Child), then Target in ParentSet means we are looking for parents?
                         # Let''s assume the previous logic was correct: "Find nodes connected to these parents"
                         if edge[''target''] in parent_set:
                             targets_phase_1.append(all_nodes_map[edge[''source'']])
            except Exception as e:
                log_debug(session, "DRILL_ERROR", str(e))

        # 3. Execute Phase 1 (Entry Nodes)
        results_phase_1 = execute_batch(session, targets_phase_1, user_query)

        # 4. Execute Phase 2 (Greedy Traversal of "Bad" Nodes)
        bad_ids = {r[''id''] for r in results_phase_1 if r.get(''status'') == ''bad''}
        targets_phase_2 = []
        
        if bad_ids:
            log_debug(session, "PHASE_2", f"Expanding bad nodes: {list(bad_ids)}")
            for edge in all_edges:
                # If a node was bad, check its relationships
                if edge[''target''] in bad_ids and edge[''source''] in all_nodes_map:
                    targets_phase_2.append(all_nodes_map[edge[''source'']])
        
        results_phase_2 = execute_batch(session, targets_phase_2, user_query)

        # 5. Final Output
        return json.dumps({
            "nodes_analyzed": results_phase_1 + results_phase_2,
            "edges_traversed": [e for e in all_edges if e[''target''] in bad_ids or e[''source''] in bad_ids]
        })

    except Exception as e:
        log_debug(session, "MAIN_CRASH", str(e))
        return json.dumps({"error": "Critical Procedure Error", "details": str(e), "trace": traceback.format_exc()})
';




DROP PROCEDURE DIAGNOSTIC_TOOL(VARCHAR, VARCHAR, VARCHAR);
CREATE OR REPLACE PROCEDURE DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.AI_POC.DIAGNOSTIC_TOOL("USER_QUERY" VARCHAR, "PARENT_NODE_IDS_JSON" VARCHAR, "TREE_ID" VARCHAR)
RETURNS VARCHAR
LANGUAGE PYTHON
RUNTIME_VERSION = '3.10'
PACKAGES = ('snowflake-snowpark-python','pandas','simplejson','pydantic')
HANDLER = 'main'
EXECUTE AS OWNER
AS '
import simplejson as json
import concurrent.futures
import traceback
from pydantic import BaseModel, Field
from snowflake.snowpark import Session

# ==========================================
# 1. DATA MODELS
# ==========================================
class SqlGenerationResponse(BaseModel):
    sql_query: str = Field(description="The executable Snowflake SQL query")
    filters_applied: list[str] = Field(description="List of specific filters applied from the user request")

class StatusCheckResponse(BaseModel):
    is_bad: bool = Field(description="True if the metric value indicates a negative business outcome")
    reason: str = Field(description="Concise business reason (max 10 words)")

SCHEMA_CONTEXT = """
TABLE: MASTER_TABLE_V1
DESCRIPTION: Healthcare provider prescribing data with demographic and transaction metrics.

COLUMNS (DIMENSIONS):
- HCO_NAME (VARCHAR): Health Organization Name (e.g., BAPTIST HEALTHCARE)
- HCP_FIRST_NAME (VARCHAR): Provider First Name
- HCP_LAST_NAME (VARCHAR): Provider Last Name
- HCP_ID (VARCHAR): Internal Unique Provider ID
- ONEKEY_HCP_ID (VARCHAR): External OneKey ID
- HCP_SPECIALTY (VARCHAR): Medical Specialty (e.g., INTERNAL MEDICINE, ORTHOPEDIC SURGERY)
- PROD_CAT_CD (VARCHAR): Product Category (e.g., OPIOID, NSAID)
- PROD_FAMGRP_CD (VARCHAR): Product Family (e.g., TRAMADOL, DICLOFENAC)
- PTAM_TERRITORY_ID (VARCHAR): Sales Territory ID
- ZIP_CODE (VARCHAR): Provider Postal Code

COLUMNS (METRICS - NEW PRESCRIPTIONS / NRX):
- ACUTE_NRX_XPO_1W (NUMBER): New Prescriptions (1 Week)
- ACUTE_NRX_XPO_2W (NUMBER): New Prescriptions (2 Weeks)
- ACUTE_NRX_XPO_3W (NUMBER): New Prescriptions (3 Weeks)
- ACUTE_NRX_XPO_1M (NUMBER): New Prescriptions (1 Month)
- ACUTE_NRX_XPO_3M (NUMBER): New Prescriptions (3 Months)
- ACUTE_NRX_XPO_6M (NUMBER): New Prescriptions (6 Months)
- ACUTE_NRX_XPO_12M (NUMBER): New Prescriptions (12 Months)

COLUMNS (METRICS - TOTAL PRESCRIPTIONS / TRX):
- ACUTE_TRX_XPO_1W (NUMBER): Total Prescriptions (1 Week)
- ACUTE_TRX_XPO_2W (NUMBER): Total Prescriptions (2 Weeks)
- ACUTE_TRX_XPO_3W (NUMBER): Total Prescriptions (3 Weeks)
- ACUTE_TRX_XPO_1M (NUMBER): Total Prescriptions (1 Month)
- ACUTE_TRX_XPO_3M (NUMBER): Total Prescriptions (3 Months)
- ACUTE_TRX_XPO_6M (NUMBER): Total Prescriptions (6 Months)
- ACUTE_TRX_XPO_12M (NUMBER): Total Prescriptions (12 Months)

COLUMNS (METRICS - LEAD / LAAD):
- ACUTE_TRX_LAAD_1W (NUMBER): Left Anterior Descending Artery Transactions (1 Week)
- ACUTE_TRX_LAAD_2W (NUMBER): Left Anterior Descending Artery Transactions (2 Weeks)
- ACUTE_TRX_LAAD_3W (NUMBER): Left Anterior Descending Artery Transactions (3 Weeks)
- ACUTE_TRX_LAAD_1M (NUMBER): Left Anterior Descending Artery Transactions (1 Month)
- ACUTE_TRX_LAAD_3M (NUMBER): Left Anterior Descending Artery Transactions (3 Months)
- ACUTE_TRX_LAAD_6M (NUMBER): Left Anterior Descending Artery Transactions (6 Months)
- ACUTE_TRX_LAAD_12M (NUMBER): Left Anterior Descending Artery Transactions (12 Months)
"""
# ==========================================
# 2. HELPER FUNCTIONS
# ==========================================
def log_debug(session: Session, step_name: str, message: str):
    """Logs debug information to the database securely using Dollar Quoting."""
    try:
        DQ = "$" + "$"
        safe_msg = str(message)[:100000]
        safe_step = str(step_name)[:50]
        query = (
            "INSERT INTO DEBUG_LOGS_NEW "
            "(STEP_NAME, LOG_MESSAGE) VALUES (" + DQ + safe_step + DQ + ", " + DQ + safe_msg + DQ + ")"
        )
        session.sql(query).collect()
    except Exception:
        pass # Fail silently to strictly avoid interrupting main flow

# ==========================================
# 3. CORE LOGIC: PROCESS SINGLE NODE
# ==========================================
def process_node(session: Session, node: dict, user_query: str, meta_map: dict) -> dict:
    metric_name = node[''metric'']
    node_id = node[''id'']
    polarity = node.get(''polarity'', 0)
    DQ = "$" + "$"

    # --- Step 0: Validation ---
    log_debug(session, f"NODE_START_{node_id}", f"Processing Metric: {metric_name}")
    
    meta = meta_map.get(metric_name)
    if not meta:
        error_msg = f"Metadata missing for metric: {metric_name}"
        log_debug(session, f"NODE_ERROR_{node_id}", error_msg)
        return {"id": node_id, "status": "error", "error": error_msg}

    static_query = meta[''SQL_QUERY'']
    final_query = static_query
    query_type = "static"
    executed_sql = static_query

    # --- Step 1: Dynamic SQL Generation (Claude Sonnet 4.5) ---
    if user_query and len(user_query) > 5:
        try:
            log_debug(session, f"GEN_SQL_START_{node_id}", "Initiating prompt construction...")
            
            # Build Few-Shot Examples
            examples_text = ""
            ex_json = meta.get(''FEW_SHOT_EXAMPLES'')
            if ex_json:
                ex_list = json.loads(ex_json) if isinstance(ex_json, str) else ex_json
                for i, ex in enumerate(ex_list):
                    examples_text += "\\nExample {}: User Request=''{}'' -> SQL=''{}''".format(i+1, ex[''question''], ex[''sql''])

            # Expert Prompt Engineering
            prompt_content = """
            You are an expert Snowflake SQL Architect. 
            Your goal is to adapt a Standard SQL Logic to answer a specific User Request.

            **Schema Context (STRICTLY USE THESE COLUMNS ONLY):**
            {}

            **Task Context:**
            - Metric Name: {}
            - Standard Logic: {}
            - User Request: "{}"

            **Guidelines:**
            1. Keep the base logic of the Standard Logic (tables, joins, core calculations).
            2. Apply filters (WHERE clauses) based on the User Request using ONLY the columns listed in Schema Context.
            3. Ensure the syntax is valid Snowflake SQL.
            4. If the User Request is irrelevant to this metric, return the Standard Logic unchanged.

            **Reference Examples:**
            {}
            """.format(SCHEMA_CONTEXT, metric_name, static_query, user_query, examples_text)

            # Sanitize Prompt
            safe_prompt = prompt_content.replace(DQ, "")
            
            # Define Output Schema
            options_str = json.dumps({
                "type": "json",
                "schema": {
                    "type": "object",
                    "properties": {
                        "sql_query": { "type": "string" },
                        "filters_applied": { "type": "array", "items": { "type": "string" } }
                    },
                    "required": ["sql_query", "filters_applied"],
                    "additionalProperties": False 
                }
            })

            # Call Cortex (claude-sonnet-4-5)
            cmd = (
                "SELECT AI_COMPLETE("
                "model => ''claude-sonnet-4-5'', "
                "prompt => " + DQ + safe_prompt + DQ + ", "
                "response_format => PARSE_JSON(" + DQ + options_str + DQ + ")"
                ")"
            )
            
            resp = session.sql(cmd).collect()
            raw_result = resp[0][0]
            log_debug(session, f"GEN_SQL_RESPONSE_{node_id}", str(raw_result))

            # Parse Response
            if isinstance(raw_result, str):
                parsed = SqlGenerationResponse.model_validate_json(raw_result)
            else:
                parsed = SqlGenerationResponse.model_validate(raw_result)
                
            final_query = parsed.sql_query
            query_type = "dynamic"
            
        except Exception as e:
            log_debug(session, f"GEN_SQL_FAIL_{node_id}", f"Error: {str(e)}. Fallback to static.")
            final_query = static_query
            query_type = "static_fallback"

    # --- Step 2: Query Execution ---
    val = "No Data"
    executed_sql = final_query
    
    try:
        log_debug(session, f"EXEC_START_{node_id}", f"Running SQL: {final_query}")
        df = session.sql(final_query).to_pandas()
        val = df.iloc[0,0] if not df.empty else "No Data"
        log_debug(session, f"EXEC_SUCCESS_{node_id}", f"Result Value: {val}")
        
    except Exception as e:
        log_debug(session, f"EXEC_FAIL_{node_id}", f"Primary SQL failed. Attempting recovery with static query. Error: {str(e)}")
        try:
            df = session.sql(static_query).to_pandas()
            val = df.iloc[0,0] if not df.empty else "No Data"
            executed_sql = static_query
            query_type = "static_recovery"
            log_debug(session, f"EXEC_RECOVERY_{node_id}", f"Recovery Value: {val}")
        except Exception as e2:
            return {"id": node_id, "status": "error", "error": f"Execution failed: {str(e2)}"}

    # --- Step 3: Status Analysis (openai-gpt-4.1) ---
    try:
        pol_txt = "Higher is BAD" if polarity == -1 else "Lower is BAD" if polarity == 1 else "Context dependent"
        
        status_prompt = """
        You are a Business Intelligence Analyst.
        Analyze the following metric result to determine if it represents a negative business outcome (''Bad'').

        - Metric: {}
        - Value: {}
        - Business Rule: {}
        - User Context: "{}"

        Determine if this is ''Bad'' for the business. Provide a concise reason.
        """.format(metric_name, val, pol_txt, user_query)

        safe_status_prompt = status_prompt.replace(DQ, "")
        
        status_options_str = json.dumps({
            "type": "json",
            "schema": {
                "type": "object",
                "properties": {
                    "is_bad": { "type": "boolean" },
                    "reason": { "type": "string" }
                },
                "required": ["is_bad", "reason"],
                "additionalProperties": False  # <--- ADD THIS LINE
            }
        })

        cmd = (
            "SELECT AI_COMPLETE("
            "model => ''openai-gpt-4.1'', "
            "prompt => " + DQ + safe_status_prompt + DQ + ", "
            "response_format => PARSE_JSON(" + DQ + status_options_str + DQ + ")"
            ")"
        )
        
        resp = session.sql(cmd).collect()
        raw_result = resp[0][0]
        
        if isinstance(raw_result, str):
            status_obj = StatusCheckResponse.model_validate_json(raw_result)
        else:
            status_obj = StatusCheckResponse.model_validate(raw_result)
            
        status = "bad" if status_obj.is_bad else "good"
        
        return {
            "id": node_id,
            "name": metric_name,
            "value": str(val),
            "status": status,
            "reason": status_obj.reason,
            "query_type": query_type,
            "executed_sql": executed_sql
        }
        
    except Exception as e:
        log_debug(session, f"STATUS_FAIL_{node_id}", str(e))
        return {
            "id": node_id, 
            "name": metric_name, 
            "value": str(val), 
            "status": "unknown", 
            "error": "Status check failed",
            "query_type": query_type,
            "executed_sql": executed_sql
        }

# ==========================================
# 4. BATCH EXECUTOR
# ==========================================
def execute_batch(session: Session, nodes_list: list, user_query: str) -> list:
    if not nodes_list: 
        return []
    
    log_debug(session, "BATCH_START", f"Processing batch of {len(nodes_list)} nodes")
    
    # Efficient Metadata Loading
    DQ = "$" + "$"
    safe_names = [f"{DQ}{n[''metric'']}{DQ}" for n in nodes_list]
    names_str = ",".join(safe_names)
    
    meta_sql = f"SELECT METRIC_NAME, SQL_QUERY, FEW_SHOT_EXAMPLES FROM KPI_KNOWLEDGE_BASE_NEW WHERE METRIC_NAME IN ({names_str})"
    meta_df = session.sql(meta_sql).to_pandas()
    meta_map = {row[''METRIC_NAME'']: row.to_dict() for _, row in meta_df.iterrows()}
    
    results = []
    # Parallel Processing
    with concurrent.futures.ThreadPoolExecutor(max_workers=16) as executor:
        futures = [executor.submit(process_node, session, n, user_query, meta_map) for n in nodes_list]
        for f in concurrent.futures.as_completed(futures):
            results.append(f.result())
            
    return results

# ==========================================
# 5. MAIN ENTRY POINT
# ==========================================
def main(session: Session, user_query: str, parent_node_ids_json: str, tree_id: str):
    try:
        log_debug(session, "MAIN_ENTRY", f"TreeID: {tree_id}, Query: {user_query}")

        # 1. Load Decision Tree Structure
        tree_row = session.sql("SELECT GRAPH_JSON FROM DECISION_TREE_STORE_NEW WHERE TREE_ID = ?", params=[tree_id]).collect()
        
        if not tree_row: 
            return json.dumps({"error": f"Tree ID not found: {tree_id}"})
        
        full_json = json.loads(tree_row[0][''GRAPH_JSON''])
        graph = full_json.get(''graph'', full_json)
        
        # Build Lookup Maps
        all_nodes_map = {n[''id'']: n for n in graph.get(''nodes'', [])}
        name_to_node_map = {n[''metric'']: n for n in graph.get(''nodes'', [])}
        all_edges = graph.get(''edges'', [])

        # 2. Determine Strategy (Search vs Drill)
        targets_phase_1 = []
        
        # Robust Null Check
        is_drill_mode = (
            parent_node_ids_json is not None and 
            parent_node_ids_json != '''' and 
            parent_node_ids_json.upper() != ''NULL'' and 
            parent_node_ids_json != ''[]''
        )

        if not is_drill_mode and user_query:
            log_debug(session, "STRATEGY", "Vector Search (No parent IDs provided)")
            # Vector Search for Entry Point
            vec_sql = """
            SELECT METRIC_NAME FROM KPI_KNOWLEDGE_BASE_NEW 
            ORDER BY VECTOR_L2_DISTANCE(SNOWFLAKE.CORTEX.EMBED_TEXT_768(''snowflake-arctic-embed-m-v1.5'', ?), KPI_EMBEDDING) ASC 
            LIMIT 1
            """
            kb_row = session.sql(vec_sql, params=[user_query]).collect()
            if kb_row and kb_row[0][''METRIC_NAME''] in name_to_node_map:
                found_metric = kb_row[0][''METRIC_NAME'']
                targets_phase_1.append(name_to_node_map[found_metric])
                log_debug(session, "ANCHOR_FOUND", f"Matched: {found_metric}")

        elif is_drill_mode:
            log_debug(session, "STRATEGY", "Drill Down (Parent IDs provided)")
            try:
                p_ids = json.loads(parent_node_ids_json)
                if not isinstance(p_ids, list): p_ids = [p_ids]
                parent_set = set(p_ids)
                
                # Find children of provided parents
                for edge in all_edges:
                    if edge[''source''] in all_nodes_map and edge[''target''] in parent_set:
                         # Note: Depending on edge direction (source->target), adjust accordingly.
                         # Assuming Source=Parent, Target=Child? Or Source=Metric, Target=Root?
                         # Usually standard DAG is Parent -> Child. 
                         # If input is ''Parent Nodes'', we want their children.
                         # CHECK: Your previous code checked ''target'' in parent_set. 
                         # If Edge is Source(Parent)->Target(Child), then Target in ParentSet means we are looking for parents?
                         # Let''s assume the previous logic was correct: "Find nodes connected to these parents"
                         if edge[''target''] in parent_set:
                             targets_phase_1.append(all_nodes_map[edge[''source'']])
            except Exception as e:
                log_debug(session, "DRILL_ERROR", str(e))

        # 3. Execute Phase 1 (Entry Nodes)
        results_phase_1 = execute_batch(session, targets_phase_1, user_query)

        # 4. Execute Phase 2 (Greedy Traversal of "Bad" Nodes)
        bad_ids = {r[''id''] for r in results_phase_1 if r.get(''status'') == ''bad''}
        targets_phase_2 = []
        
        if bad_ids:
            log_debug(session, "PHASE_2", f"Expanding bad nodes: {list(bad_ids)}")
            for edge in all_edges:
                # If a node was bad, check its relationships
                if edge[''target''] in bad_ids and edge[''source''] in all_nodes_map:
                    targets_phase_2.append(all_nodes_map[edge[''source'']])
        
        results_phase_2 = execute_batch(session, targets_phase_2, user_query)

        # 5. Final Output
        return json.dumps({
            "nodes_analyzed": results_phase_1 + results_phase_2,
            "edges_traversed": [e for e in all_edges if e[''target''] in bad_ids or e[''source''] in bad_ids]
        })

    except Exception as e:
        log_debug(session, "MAIN_CRASH", str(e))
        return json.dumps({"error": "Critical Procedure Error", "details": str(e), "trace": traceback.format_exc()})
';


**Role & Objective**
You are an **Autonomous Root Cause Analysis Agent** designed to traverse a metric decision tree from the root node down to the leaf nodes. Your goal is to identify specific "bad" metrics driving a business problem by systematically drilling down into the data.

ALWAYS USE tree_id as pharma_sales_v3.

**Available Tools**
You have access to a single diagnostic tool. You must use this tool for all data retrieval.

* `Diagnostic_tool(USER_QUERY: str, PARENT_NODE_IDS_JSON: str)`
* **Description:** Retrieves metric status for a given context. It operates in two modes:
1. **Search Mode:** Used to find the starting "Root" node based on a user's question.
2. **Drill Mode:** Used to find the children of specific parent nodes to investigate "bad" metrics further.


* **Arguments:**
* `USER_QUERY`: The user's natural language question (e.g., "Why is cost high?"). Set to `NULL` during Drill Mode.
* `PARENT_NODE_IDS_JSON`: A JSON string list of Node IDs (e.g., `'["node_123", "node_456"]'`). Set to `NULL` during Search Mode.


**Operational Procedure (The Analysis Loop)**
You must strictly follow this recursive logic for every user request:

**Step 1: Initialization (Find the Root)**

* If this is the start of the conversation, call `Diagnostic_tool` in **Search Mode**.
* **Action:** Call `Diagnostic_tool(USER_QUERY=user_question, PARENT_NODE_IDS_JSON=NULL)`.
* **Next:** Proceed to Step 2 with the results.

**Step 2: Status Evaluation & Decision**
* Try to categorize the node as 'good' or 'bad'.:
* Condition for 'Root' node:
A 'good' node value is when the node value is moving according to the user query. It will not be investigated further.
A 'bad' node is when the node value is moving in opposite direction to mentioned in the user query. This will be investigated further.

For non-root nodes, try to analyse and make the node 'bad' if it needs to be investigates further and 'good' if no further investigation needed.


Analyze the list of nodes returned by the tool. Focus **only** on nodes where `"status": "bad"`.

* **Check:** For every "bad" node, do you see its children in the current list?
* **Condition A (Drill Needed):** If a node is "bad" and you do **not** see its children, you must drill down. Collect these Node IDs.
* **Condition B (Keep Going):** If a node is "bad" but you **already** see its children, ignore it and evaluate the children instead.
* **Condition C (Stop):** If you find "bad" nodes but they have no children (empty results from a drill), these are your **Root Causes**.

**Step 3: Execution (Drill Down)**

* If Condition A occurred: Call `Diagnostic_tool` in **Drill Mode**.
* **Action:** Call `Diagnostic_tool(USER_QUERY=NULL, PARENT_NODE_IDS_JSON='["ID_1", "ID_2"]')`.


* **Next:** Recursively repeat Step 2 with the new output.
* If Condition C occurred: Present the final root causes to the user.

**Constraints**

* **Never** guess the status of a metric; always use the tool.
* **Never** stop at a "bad" node if it has unexplored children; you must find the leaf node.
* Output your reasoning briefly before calling the tool.

---

### **Few-Shot Example: Root Cause Analysis**

**User:** "Why is profitability down?"

**Assistant:**
*Thought: The user is asking a high-level question about a metric. I need to find the starting node and its immediate children to see what is happening.*
**Tool Use:** `Diagnostic_tool(USER_QUERY='Why is profitability down?', PARENT_NODE_IDS_JSON=NULL)`

**Tool Output:**

```json
[
  {"id": "N0", "metric": "Profitability", "status": "bad"},
  {"id": "N1", "metric": "Revenue", "status": "good"},
  {"id": "N2", "metric": "Total Cost", "status": "bad"}
]

```

**Assistant:**
*Thought: I have the initial results. `N0` (Profitability) is "bad", which confirms the user's issue. I see two children: `N1` (Revenue) is "good", so that branch is healthy. However, `N2` (Total Cost) is "bad". Since I do not see the children of `N2` in the current list, I must drill down into `N2` to understand what is driving the high cost.*
**Tool Use:** `Diagnostic_tool(USER_QUERY=NULL, PARENT_NODE_IDS_JSON='["N2"]')`

**Tool Output:**

```json
[
  {"id": "N3", "metric": "Fixed Cost", "status": "good"},
  {"id": "N4", "metric": "Variable Cost", "status": "bad"}
]

```

**Assistant:**
*Thought: I have drilled into Total Cost. `N3` (Fixed Cost) is "good", so I can ignore it. `N4` (Variable Cost) is "bad". I do not see the children of `N4` yet. I need to drill deeper to see if there is a more specific cause.*
**Tool Use:** `Diagnostic_tool(USER_QUERY=NULL, PARENT_NODE_IDS_JSON='["N4"]')`

**Tool Output:**

```json
[]

```

**Assistant:**
*Thought: The tool returned an empty list for `N4`. This indicates that `N4` (Variable Cost) is a leaf node in the decision tree. I have reached the bottom of the "bad" chain. I can now conclude the diagnosis.*
**Final Answer:** Profitability is down because **Variable Cost (N4)** is performing poorly. While Revenue and Fixed Costs are stable, the high Variable Cost is driving the overall decline.

**CRITICAL** : ONLY EXECUTE 5 TOOL CALLS ATMOST





PROMPT_INTENT_ORCHESTRATION = """
<intent_classification_instructions>

<mission>
Your ONLY job is to identify the user's INTENT. Do NOT retrieve data, do NOT answer questions, do NOT perform analysis.
Classify the intent type and route accordingly. If you can answer directly (like greetings), provide direct_response.
</mission>

<intent_categories>

<intent name="greeting">
<description>User is greeting, saying hello, or engaging in pleasantries</description>
<indicators>hi, hello, hey, good morning, how are you, thanks, thank you, goodbye, bye</indicators>
<action>Set direct_response with a friendly greeting. No other fields needed.</action>
</intent>

<intent name="data_retrieval">
<description>User wants to see/get/retrieve DATA - numbers, lists, metrics, tables</description>
<indicators>show, list, get, display, find, what is the value, how many, count, total, give me</indicators>
<action>Extract the data request to data_retrieval_query. Keep as natural language. Add "and generate a table and a visual".</action>
**CRITICAL VISUALIZATION LOGIC:**
Analyze the data request. If it implies trends (over time), comparisons (by region/product), or distributions, you MUST automatically append "and generate a table and a visual" to the query string, even if the user did not explicitly ask for a chart.
</intent>

<intent name="root_cause_analysis">
<description>User wants to understand WHY, CAUSES, DRIVERS, REASONS, EXPLANATIONS</description>
<indicators>why, explain, what is driving, what is causing, what's behind, reason for, root cause, how come, what factors</indicators>
<action>Extract the causal question to root_cause_query. Keep VERBATIM - exact text from user.</action>
</intent>

<intent name="combined">
<description>User wants BOTH data AND causal analysis in one request</description>
<indicators>Contains both data keywords AND causal keywords</indicators>
<action>Split into data_retrieval_query AND root_cause_query. Keep both portions.</action>
</intent>

<intent name="clarification_needed">
<description>User's intent is unclear, vague, or ambiguous - you cannot determine what they want</description>
<indicators>Very short/vague input, unclear pronouns without context, incomplete thoughts</indicators>
<action>Set clarification_question asking user to be more specific.</action>
</intent>

<intent name="general_question">
<description>General questions about the system, capabilities, how to use features - not data or analysis requests</description>
<indicators>how do I, can you, what can you do, help me understand, how does this work</indicators>
<action>Set direct_response with helpful information about capabilities.</action>
</intent>

<intent name="off_topic">
<description>User is asking about unrelated topics not connected to data, analytics, or business questions</description>
<indicators>Questions about weather, sports, entertainment, personal topics unrelated to business/data</indicators>
<action>Set direct_response politely redirecting to business/data topics.</action>
</intent>

</intent_categories>

<CRITICAL_CLASSIFICATION_RULES>

 RULE 1: NEVER DO THE WORK - ONLY CLASSIFY
You are NOT a data analyst. You are NOT an answering agent. You ONLY identify intent type.
Do NOT retrieve data. Do NOT answer analytical questions. ONLY classify and route.

 RULE 2: CAUSAL KEYWORD DETECTION
These ALWAYS indicate root_cause_analysis intent:
- "what is driving"
- "what is causing"
- "what's driving"  
- "what's causing"
- "why is/are"
- "explain why"
- "reason for"
- "root cause"
- "what factors"
- "what's behind"
- "how come"

 RULE 3: DATA KEYWORD DETECTION  
These ALWAYS indicate data_retrieval intent:
- "show me"
- "list"
- "get"
- "display"
- "find all"
- "what is the value/total/count of"
- "how many"

 RULE 4: DIRECT RESPONSE ONLY FOR SIMPLE CASES
Use direct_response ONLY for:
- Greetings (hi, hello, thanks)
- General system questions (what can you do)
- Off-topic redirects

Do NOT use direct_response for data or analytical questions - those need agent processing.

 RULE 5: VERBATIM PRESERVATION FOR ROOT CAUSE
For root_cause_query: Copy EXACT text from user. No paraphrasing, no summarizing.

 RULE 6: NO SQL CODE GENERATION
NEVER write SELECT/FROM/WHERE statements. Keep everything as natural language.

 RULE 7: CONFIDENCE SCORING
- high: Intent is crystal clear
- medium: Intent is likely but has some ambiguity
- low: Intent is very unclear, might need clarification


Examples:

Example 1: Data Retrieval
Input: "What was the total revenue for Q3?"
Output:
{
  "intent_type": "data_retrieval",
  "data_retrieval": "What was the total revenue for Q3?",
  "root_cause": null,
  "clarification": null,
  "confidence": "high",
  "reasoning": "User is asking for a specific absolute value (ID 2).",
  "secondary_category": [2]
}

Example 2: Root Cause Analysis
Input: "Why did sales drop in November?"
Output:
{
  "intent_type": "root_cause_analysis",
  "data_retrieval": null,
  "root_cause": "Why did sales drop in November?",
  "clarification": null,
  "confidence": "high",
  "reasoning": "User is inquiring about the driver behind a negative trend (ID 12).",
  "secondary_category": [12]
}

Example 3: Combined
Input: "Show me the churn rate and explain the main driver for the increase."
Output:

{
  "intent_type": "combined",
  "data_retrieval": "Show me the churn rate",
  "root_cause": "explain the main driver for the increase",
  "clarification": null,
  "confidence": "high",
  "reasoning": "Query requests a specific metric (ID 2) and an explanation of the driver (ID 12).",
  "secondary_category": [2, 12]
}

Example 4: Clarification Needed
Input: "Show me the data."
Output:
{
  "intent_type": "clarification_needed",
  "data_retrieval": null,
  "root_cause": null,
  "clarification": "The user has not specified which metric, time period, or entity to retrieve.",
  "confidence": "high",
  "reasoning": "The request is too vague to map to a database query.",
  "secondary_category": [22]
}

Example 5: Follow-up
Input: "And for the North region?"
Output:

{
  "intent_type": "follow_up",
  "data_retrieval": "And for the North region?",
  "root_cause": null,
  "clarification": null,
  "confidence": "high",
  "reasoning": "Contextual continuation applying a filter (ID 17) to previous turn.",
  "secondary_category": [17, 21]
}



</CRITICAL_CLASSIFICATION_RULES>
</intent_classification_instructions>
"""



{'original': 'Why is the NSAID Market Volume rising in Internal Medicine while Tramadol Brand Volume is falling in the same specialty? ', 'processed': 'Compare NSAID Category and Tramadol Brand prescription volume trends in Internal Medicine specialty over the last 12 months, including new starts, refills, number of prescribers, and year-over-year growth rates', 'intent': {'intent_type': 'data_retrieval', 'data_retrieval_query': 'Compare NSAID Category and Tramadol Brand prescription volume trends in Internal Medicine specialty over the last 12 months, including new starts, refills, number of prescribers, and year-over-year growth rates', 'root_cause_query': None, 'direct_response': None, 'clarification_question': None, 'confidence': 'high', 'reasoning': 'User is requesting a comparative trend analysis of prescription data for two specific medication types (NSAID Category vs Tramadol Brand) within a defined specialty (Internal Medicine) over a specific time period (last 12 months) with multiple specific metrics (new starts, refills, prescriber counts, YoY growth rates). This is a clear data retrieval request requiring prescription analytics.'}, 'results': []}
Databases
Worksheets
Data products
Search objects
7 more Databases
Pinned (1)









PROMPT_ROOT_CAUSE_ORCHESTRATION = f"""
<root_cause_orchestration_prompt>
    <role_and_objective>
        You are an **Autonomous Root Cause Analysis Agent** designed to traverse a metric decision tree from the root node down to the leaf nodes. Your goal is to identify specific "bad" metrics driving a business problem by systematically drilling down into the data.
        
        ALWAYS USE tree_id as {CONFIG.diagnostic_tree_id}.
    </role_and_objective>

    <phase_1_clarification_check>
        **CRITICAL:** Before running any tools, analyze the USER_QUERY against the MASTER SCHEMA dimensions.
        
        MASTER SCHEMA:

        {CONFIG.cortex_analyst_object_master}
        
        IF the user asks a generic question like "Why is revenue down?" or "Explain the drop":
        1. You cannot run the tool efficiently without a starting point (Root Node context).
        2. Look at available schema dimensions (Region, Product, Specialty, Time).
        3. **STOP** and return a `clarifying_question`.
            Example: "To analyze the revenue drop, should I compare performance by Region, Product Class, or Customer Specialty?"
        You can mention examples also like 
        IF the query contains specific context (e.g., "Why is Tylenol down in NY?"), PROCEED to Phase 2.
    </phase_1_clarification_check>

    
<root_cause_orchestration_prompt>
    <role_and_objective>
        You are an **Autonomous Root Cause Analysis Agent** designed to traverse a metric decision tree from the root node down to the leaf nodes. Your goal is to identify specific "bad" metrics driving a business problem by systematically drilling down into the data.
        
        ALWAYS USE tree_id as Pharma_Master_v4.
    </role_and_objective>

    <tools>
        You have access to `Diagnostic_tool(USER_QUERY, TARGET_NODES_JSON, TREE_ID)`.
    </tools>

    <operational_procedure>
        You must strictly follow this recursive logic for every user request:

        **Step 1: Initialization (Find the Root)**
        * If this is the start of the conversation, call the tool in **Search Mode**.
        * **Action:** Call `Diagnostic_tool(USER_QUERY="Original User Question", TARGET_NODES_JSON=NULL, TREE_ID="Pharma_Master_v1")`.
        * **Next:** Proceed to Step 2 with the results.

        **Step 2: Status Evaluation & Decision**
        Analyze the list of nodes returned. Focus **only** on nodes where `"status": "bad"`.

        * **Logic for 'Bad' Status:** - A node is "bad" if its performance contradicts the business goal (e.g., Sales are down, Cost is up).
          - The tool calculates this, but you must verify it against the user's intent.
        
        * **Decision Rule:**
          - **Check:** For every "bad" node, do you see its children in the current list?
          - **Condition A (Drill Needed):** If a node is "bad" and you do **not** see its children, you must drill down.
          - **Condition B (Keep Going):** If a node is "bad" but you **already** see its children, ignore it and evaluate the children instead.
          - **Condition C (Stop):** If a "bad" node has no children (empty results from a drill), it is a **Root Cause**.

        **Step 3: Execution (Drill Down)**
        * If Condition A occurred, you must drill down into the specific "bad" nodes.
        * **CRITICAL:** You must formulate a specific SQL-ready question for EACH child node you want to investigate.
            * **Rule:** Transplant the filters (Time, Location, Segment) from the *Original User Question* into the new specific question for that node.
            * *Example:* If User asked "Why is Profit down in **Arizona**?", and you drill into "Tramadol Sales" (K5), the question must be "What are Tramadol Sales in **Arizona**?".
        
        * **Action:** Construct the JSON payload and call the tool.
          `Diagnostic_tool(USER_QUERY=NULL, TARGET_NODES_JSON=''[''{"id": "K5", "question": "What is Tramadol Volume in Arizona?"}, {"id": "K6", "question": "..."}'']'', TREE_ID="Pharma_Master_v1")`

        * **Next:** Recursively repeat Step 2 with the new output.
    </operational_procedure>

    <constraints>
        * **CRITICAL:** ONLY EXECUTE 8 TOOL CALLS AT MOST.
        * **Never** guess the status of a metric; always use the tool.
        * **Never** stop at a "bad" node if it has unexplored children; you must find the leaf node.
    </constraints>

    <self_evaluation_instructions>
    Perform a rigorous, in-depth analysis of the root cause diagnosis. 
    Ensure the identified node is a true mathematical driver (Leaf Node) and the logic is sound.
    **CRITICAL:** Append this evaluation at the end of your response text.
    </self_evaluation_instructions>
</root_cause_orchestration_prompt>

    <self_evaluation_instructions>
    You MUST perform a rigorous self-critique of your root cause logic.
    1. **Logic (Score 1-10):** Is the causal chain (Root -> Leaf) mathematically sound?
    2. **Driver Isolation:** Did we truly find the leaf node, or did we stop too early?
    3. **Completeness:** Did we explore all "bad" branches?
    </self_evaluation_instructions>
</root_cause_orchestration_prompt>
"""

PROMPT_ROOT_CAUSE_RESPONSE = """
<response_structure_prompt>
    

    
        ** Diagnostic Executive Summary**
        * **Tone:** Professional, constructive, and polite.
        * **Headline:** State the Root Cause clearly.
        * **The Narrative:** Briefly explain the chain of events in simple English.
        * **Actionable Insight:** Based on the metadata or description of the root node, suggest a generic, helpful next step.
    

    
        ** React Flow JSON Artifact**
        You must generate a valid JSON object inside a Markdown code block (json ...).
        
        **4. JSON Schema (Must Follow Exactly):**
        {
          "nodes": [
            {
              "id": "N0",
              "type": "default",
              "data": { "label": "Metric Name: Value" },
              "position": { "x": 0, "y": 0 },
              "style": { "background": "#FFE2E5", "width": 180, "color": "#333", "border": "1px solid #777", "borderRadius": "8px" }
            }
          ],
          "edges": [
            {
              "id": "e-N0-N1",
              "source": "N0",
              "target": "N1",
              "label": "driven by",
              "animated": true,
              "style": { "stroke": "#555", "strokeWidth": 2 }
            }
          ]
        }
    
  
    
    **CRITICAL** : YOU MUST ONLY EXECUTE ATMOST 8 TOOL CALLS.
    
    <output_format>
    YOU MUST output a JSON block STRICTLY in below format as final output:
    ```json
    {
      "clean_summary_text": "Executive summary...",
      "clarifying_question": null,
      "react_flow_json": { "nodes": [], "edges": [] },
      "evaluation": { "score": 9, "reasoning": "Found root cause." }
    }
    ```
    </output_format>
</response_structure_prompt>
"""



# --- REPHRASER ---
PROMPT_REPHRASER_SYSTEM = "You are a sophisticated Query Refinement Engine. Be polite, professional, and friendly. Be direct and unambiguous."

PROMPT_REPHRASER_ORCHESTRATION = """
<query_refinement_instructions>
<objective>
Transform the user's input into a standalone, context-complete query that can be understood without prior conversation history.
</objective>

<core_rules>
<rule id="1">Resolve all pronouns (it, they, that, this, those) to their specific referents based on chat history.</rule>
<rule id="2">Preserve ALL metrics, entity names, IDs, and numerical values EXACTLY as stated.</rule>
<rule id="3">Maintain the original intent and scope - do not expand or narrow the question.</rule>
<rule id="4">Keep technical terminology and domain-specific language intact.</rule>
<rule id="5">Ensure the output is grammatically correct and reads naturally.</rule>
</core_rules>

<follow_up_handling_rules>
<rule id="6">IF previous Bot response contained Data (e.g., "Sales are down") AND User asks "Why?", REPHRASE to "Why are sales down?"</rule>
<rule id="7">IF previous Bot response was a Clarification (e.g., "By region?"), AND User answers "Region", REPHRASE to combine them.</rule>
</follow_up_handling_rules>

<transformation_examples>
<example>
<input>What about Arizona?</input>
<context>Previous discussion about sales performance in Texas</context>
<output>What is the sales performance in Arizona?</output>
</example>

<example>
<input>Why is it down?</input>
<context>Previous mention of Q4 revenue</context>
<output>Why is Q4 revenue down?</output>
</example>
</transformation_examples>
</query_refinement_instructions>
"""

PROMPT_REPHRASER_RESPONSE = """
<output_format>
At the VERY END of your text response, YOU MUST output a JSON block STRICTLY in below format: 
Example: { "refined_query": "What is the sales performance in Arizona?" }
Do not include any other text or markdown outside the JSON object.
</output_format>
"""



'@"DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB"."AI_POC"."CUSTOM_PACKAGES"/vl-convert-python.zip'
Import Failed: No module named 'vl_convert.vl_convert' (Path: /tmp/vl_convert_lib/my_packages)


Import Error: No module named 'vl_convert.vl_convert'
Files found in vl_convert: ['__init__.py', '__init__.pyi', 'py.typed', 'vl_convert.abi3.so']


CRITICAL FAILURE: No module named 'vl_convert.vl_convert'. The Warehouse is blocking the binary.






CREATE OR REPLACE PROCEDURE DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.AI_POC.DIAGNOSTIC_TOOL_V2(
    "USER_QUERY" VARCHAR, 
    "TARGET_NODES_JSON" VARCHAR, 
    "TREE_ID" VARCHAR
)
RETURNS VARCHAR
LANGUAGE PYTHON
RUNTIME_VERSION = '3.10'
PACKAGES = ('snowflake-snowpark-python','pandas','simplejson','pydantic')
HANDLER = 'main'
EXECUTE AS OWNER
AS $$
import simplejson as json
import concurrent.futures
import traceback
from pydantic import BaseModel, Field
from snowflake.snowpark import Session

# ==========================================
# 0. SCHEMA CONTEXT (COMPLETE)
# ==========================================
SCHEMA_CONTEXT = """
<schema_context>
    <table_name>MASTER_TABLE_V1</table_name>
    <description>Healthcare provider prescribing data with demographic and transaction metrics.</description>
    <columns>
        <!-- DIMENSIONS -->
        <dimension>HCO_NAME (VARCHAR): Health Organization Name (e.g., BAPTIST HEALTHCARE)</dimension>
        <dimension>HCP_FIRST_NAME (VARCHAR): Provider First Name</dimension>
        <dimension>HCP_LAST_NAME (VARCHAR): Provider Last Name</dimension>
        <dimension>HCP_ID (VARCHAR): Internal Unique Provider ID</dimension>
        <dimension>ONEKEY_HCP_ID (VARCHAR): External OneKey ID</dimension>
        <dimension>HCP_SPECIALTY (VARCHAR): e.g., INTERNAL MEDICINE, ORTHOPEDIC SURGERY, NURSE PRACTITIONER</dimension>
        <dimension>PROD_CAT_CD (VARCHAR): Product Category (e.g., OPIOID, NSAID)</dimension>
        <dimension>PROD_FAMGRP_CD (VARCHAR): Product Family (e.g., TRAMADOL, DICLOFENAC)</dimension>
        <dimension>PTAM_TERRITORY_ID (VARCHAR): Sales Territory ID</dimension>
        <dimension>ZIP_CODE (VARCHAR): Provider Postal Code</dimension>
        <dimension>HCP_STATE (VARCHAR): Provider State (e.g., AZ, NY)</dimension>
        <dimension>HCP_CITY (VARCHAR): Provider City</dimension>

        <!-- METRICS: NEW PRESCRIPTIONS (NRX) -->
        <metric>ACUTE_NRX_XPO_1W (NUMBER): New Prescriptions (1 Week)</metric>
        <metric>ACUTE_NRX_XPO_2W (NUMBER): New Prescriptions (2 Weeks)</metric>
        <metric>ACUTE_NRX_XPO_3W (NUMBER): New Prescriptions (3 Weeks)</metric>
        <metric>ACUTE_NRX_XPO_1M (NUMBER): New Prescriptions (1 Month)</metric>
        <metric>ACUTE_NRX_XPO_3M (NUMBER): New Prescriptions (3 Months)</metric>
        <metric>ACUTE_NRX_XPO_6M (NUMBER): New Prescriptions (6 Months)</metric>
        <metric>ACUTE_NRX_XPO_12M (NUMBER): New Prescriptions (12 Months - Annual)</metric>

        <!-- METRICS: TOTAL PRESCRIPTIONS (TRX) -->
        <metric>ACUTE_TRX_XPO_1W (NUMBER): Total Prescriptions (1 Week)</metric>
        <metric>ACUTE_TRX_XPO_2W (NUMBER): Total Prescriptions (2 Weeks)</metric>
        <metric>ACUTE_TRX_XPO_3W (NUMBER): Total Prescriptions (3 Weeks)</metric>
        <metric>ACUTE_TRX_XPO_1M (NUMBER): Total Prescriptions (1 Month)</metric>
        <metric>ACUTE_TRX_XPO_3M (NUMBER): Total Prescriptions (3 Months)</metric>
        <metric>ACUTE_TRX_XPO_6M (NUMBER): Total Prescriptions (6 Months)</metric>
        <metric>ACUTE_TRX_XPO_12M (NUMBER): Total Prescriptions (12 Months - Annual)</metric>

        <!-- METRICS: LEFT ANTERIOR DESCENDING ARTERY TRANSACTIONS (LAAD) -->
        <metric>ACUTE_TRX_LAAD_1W (NUMBER): LAAD Transactions (1 Week)</metric>
        <metric>ACUTE_TRX_LAAD_2W (NUMBER): LAAD Transactions (2 Weeks)</metric>
        <metric>ACUTE_TRX_LAAD_3W (NUMBER): LAAD Transactions (3 Weeks)</metric>
        <metric>ACUTE_TRX_LAAD_1M (NUMBER): LAAD Transactions (1 Month)</metric>
        <metric>ACUTE_TRX_LAAD_3M (NUMBER): LAAD Transactions (3 Months)</metric>
        <metric>ACUTE_TRX_LAAD_6M (NUMBER): LAAD Transactions (6 Months)</metric>
        <metric>ACUTE_TRX_LAAD_12M (NUMBER): LAAD Transactions (12 Months)</metric>
    </columns>
</schema_context>
"""

# ==========================================
# 1. DATA MODELS
# ==========================================
class SqlGenerationResponse(BaseModel):
    sql_query: str = Field(description="The executable Snowflake SQL query")
    filters_applied: list[str] = Field(description="List of specific filters applied from the user request")

class StatusCheckResponse(BaseModel):
    is_bad: bool = Field(description="True if the metric value indicates a negative business outcome")
    reason: str = Field(description="Concise business reason (max 10 words)")

# ==========================================
# 2. HELPER FUNCTIONS
# ==========================================
def log_debug(session: Session, step_name: str, message: str):
    """Logs debug information to the database securely using Dollar Quoting."""
    try:
        DQ = "$" + "$"
        safe_msg = str(message)[:100000]
        safe_step = str(step_name)[:50]
        # Using string formatting for safer SQL injection in logging
        query = f"INSERT INTO DEBUG_LOGS_NEW (STEP_NAME, LOG_MESSAGE) VALUES ({DQ}{safe_step}{DQ}, {DQ}{safe_msg}{DQ})"
        session.sql(query).collect()
    except Exception:
        pass 

# ==========================================
# 3. WORKER LOGIC
# ==========================================
def process_node(session: Session, node: dict, specific_question: str, meta_map: dict) -> dict:
    metric_name = node['metric']
    node_id = node['id']
    polarity = node.get('polarity', 0)
    DQ = "$" + "$"

    # Validation
    meta = meta_map.get(metric_name)
    if not meta: return {"id": node_id, "status": "error", "error": f"Metadata missing for: {metric_name}"}

    static_query = meta['SQL_QUERY']
    final_query = static_query
    query_type = "static"

    # --- Dynamic SQL Generation ---
    if specific_question and len(specific_question) > 5:
        try:
            # Build Few-Shot Examples
            examples_text = ""
            ex_json = meta.get('FEW_SHOT_EXAMPLES')
            if ex_json:
                ex_list = json.loads(ex_json) if isinstance(ex_json, str) else ex_json
                for i, ex in enumerate(ex_list):
                    examples_text += f"\n<example_{i+1}>\n<user_request>{ex['question']}</user_request>\n<sql>{ex['sql']}</sql>\n</example_{i+1}>"

            prompt_content = f"""
<sql_generation_prompt>
    <role>You are an expert Snowflake SQL Architect.</role>
    <goal>Adapt a Standard SQL Logic to answer a specific User Request.</goal>
    
    {SCHEMA_CONTEXT}

    <task_context>
        <metric_name>{metric_name}</metric_name>
        <standard_logic>{static_query}</standard_logic>
        <user_request>{specific_question}</user_request>
    </task_context>

    <guidelines>
        <rule>Apply filters from the User Request (Region, Time, Product, Specialty) to the Standard Logic.</rule>
        <rule>Use ONLY columns from Schema Context.</rule>
        <rule>If the User Request implies a specific time window (e.g. 'last 3 months'), REPLACE the default metric column with the correct time-windowed column (e.g. use ACUTE_TRX_XPO_3M instead of ACUTE_TRX_XPO_12M).</rule>
        <rule>Ensure string literals in WHERE clauses are correct (e.g., proper casing for states 'AZ', 'NY').</rule>
        <rule>Do not hallucinate columns. If a dimension is not in Schema Context, do not filter by it.</rule>
    </guidelines>

    <reference_examples>
        {examples_text}
    </reference_examples>
</sql_generation_prompt>
"""
            safe_prompt = prompt_content.replace(DQ, "")
            options_str = json.dumps({
                "type": "json",
                "schema": SqlGenerationResponse.model_json_schema()
            })

            cmd = (
                "SELECT AI_COMPLETE("
                "model => 'claude-sonnet-4-5', "
                "prompt => " + DQ + safe_prompt + DQ + ", "
                "response_format => PARSE_JSON(" + DQ + options_str + DQ + ")"
                ")"
            )
            
            resp = session.sql(cmd).collect()
            parsed = SqlGenerationResponse.model_validate_json(resp[0][0])
            final_query = parsed.sql_query
            query_type = "dynamic"
            
        except Exception as e:
            final_query = static_query
            query_type = "static_fallback"

    # --- Execution ---
    val = "No Data"
    try:
        df = session.sql(final_query).to_pandas()
        val = df.iloc[0,0] if not df.empty else "No Data"
    except:
        try:
            df = session.sql(static_query).to_pandas()
            val = df.iloc[0,0] if not df.empty else "No Data"
            query_type = "static_recovery"
        except Exception as e2:
            return {"id": node_id, "status": "error", "error": f"Execution failed: {str(e2)}"}

    # --- Status Analysis ---
    try:
        pol_txt = "Higher is BAD" if polarity == -1 else "Lower is BAD" if polarity == 1 else "Context dependent"
        
        status_prompt = f"""
<status_check_prompt>
    <task>Analyze Metric Status to identify if it contributes to the user's reported issue.</task>
    <metric>{metric_name}</metric>
    <value>{val}</value>
    <default_polarity>{pol_txt}</default_polarity>
    <user_context>{specific_question}</user_context>
    <logic>
        Determine if this node is 'Bad' (contributing to the problem).
        CRITICAL: Align 'Bad' with the direction implied in the User Context.
        
        <rules>
        1. If User asks "Why did X drop?", then a DROP in this metric is 'Bad' (True).
        2. If User asks "Why did Y rise?", then a RISE in this metric is 'Bad' (True).
        3. If the metric is a "Cost" or "Expense" and User asks about "Profit drop", then HIGH value is 'Bad'.
        4. If the metric is "Revenue" or "Volume" and User asks about "Profit drop", then LOW value is 'Bad'.
        5. If the value is "No Data" or 0, consider if that represents a failure (Bad) or just absence (Good/Neutral). Usually 0 volume is Bad.
        </rules>

        <examples>
        - User: "Why Tramadol dropped?" | Metric: "Tramadol Volume" | Value: "Down 5%" -> Bad (Driver)
        - User: "Why Tramadol dropped?" | Metric: "Tramadol Price" | Value: "Stable" -> Good (Not Driver)
        - User: "Why Costs are high?" | Metric: "Shipping Cost" | Value: "High" -> Bad (Driver)
        </examples>
    </logic>
    <question>Is this result 'Bad' / a driver of the issue?</question>
</status_check_prompt>
"""
        safe_status = status_prompt.replace(DQ, "")
        status_opts = json.dumps({"type": "json", "schema": StatusCheckResponse.model_json_schema()})

        cmd = (
            "SELECT AI_COMPLETE("
            "model => 'claude-sonnet-4-5', "
            "prompt => " + DQ + safe_status + DQ + ", "
            "response_format => PARSE_JSON(" + DQ + status_opts + DQ + ")"
            ")"
        )
        
        resp = session.sql(cmd).collect()
        status_obj = StatusCheckResponse.model_validate_json(resp[0][0])
        status = "bad" if status_obj.is_bad else "good"
        
        return {
            "id": node_id, "name": metric_name, "value": str(val), "status": status,
            "reason": status_obj.reason, "query_type": query_type, "executed_sql": final_query
        }
    except Exception as e:
        return {"id": node_id, "status": "error", "error": f"Status check failed: {str(e)}"}

# ==========================================
# 4. BATCH EXECUTOR
# ==========================================
def execute_batch_with_context(session: Session, execution_list: list) -> list:
    if not execution_list: return []
    
    metrics = [item['node']['metric'] for item in execution_list]
    DQ = "$" + "$"
    safe_names = [f"{DQ}{m}{DQ}" for m in metrics]
    names_str = ",".join(safe_names)
    
    meta_sql = f"SELECT METRIC_NAME, SQL_QUERY, FEW_SHOT_EXAMPLES FROM KPI_KNOWLEDGE_BASE_NEW WHERE METRIC_NAME IN ({names_str})"
    meta_df = session.sql(meta_sql).to_pandas()
    meta_map = {row['METRIC_NAME']: row.to_dict() for _, row in meta_df.iterrows()}
    
    results = []
    with concurrent.futures.ThreadPoolExecutor(max_workers=16) as executor:
        futures = [
            executor.submit(process_node, session, item['node'], item['query'], meta_map) 
            for item in execution_list
        ]
        for f in concurrent.futures.as_completed(futures):
            results.append(f.result())
            
    return results

# ==========================================
# 5. MAIN ENTRY POINT
# ==========================================
def main(session: Session, user_query: str, target_nodes_json: str, tree_id: str):
    try:
        log_debug(session, "MAIN_ENTRY", f"Tree: {tree_id}, Query: {user_query}, Targets: {target_nodes_json}")

        # 1. Load Tree
        tree_row = session.sql("SELECT GRAPH_JSON FROM DECISION_TREE_STORE_NEW WHERE TREE_ID = ?", params=[tree_id]).collect()
        if not tree_row: return json.dumps({"error": f"Tree ID not found: {tree_id}"})
        
        full_json = json.loads(tree_row[0]['GRAPH_JSON'])
        graph = full_json.get('graph', full_json)
        name_to_node = {n['metric']: n for n in graph.get('nodes', [])}
        all_nodes_map = {n['id']: n for n in graph.get('nodes', [])}
        
        execution_list = [] 

        # 2. Determine Strategy
        has_targets = (target_nodes_json and target_nodes_json != '[]' and target_nodes_json != 'NULL')

        if has_targets:
            # --- DRILL MODE ---
            try:
                targets = json.loads(target_nodes_json)
                for t in targets:
                    if t.get('id') in all_nodes_map:
                        execution_list.append({
                            "node": all_nodes_map[t.get('id')],
                            "query": t.get('question') 
                        })
            except: pass
        
        elif user_query:
            # --- SEARCH MODE ---
            vec_sql = """
            SELECT METRIC_NAME FROM KPI_KNOWLEDGE_BASE_NEW 
            ORDER BY VECTOR_L2_DISTANCE(SNOWFLAKE.CORTEX.EMBED_TEXT_768('snowflake-arctic-embed-m-v1.5', ?), KPI_EMBEDDING) ASC 
            LIMIT 1
            """
            kb_row = session.sql(vec_sql, params=[user_query]).collect()
            if kb_row and kb_row[0]['METRIC_NAME'] in name_to_node:
                execution_list.append({
                    "node": name_to_node[kb_row[0]['METRIC_NAME']],
                    "query": user_query 
                })

        # 3. Execute
        results = execute_batch_with_context(session, execution_list)

        return json.dumps({
            "nodes_analyzed": results,
            "edges_traversed": [] 
        })

    except Exception as e:
        return json.dumps({"error": str(e), "trace": traceback.format_exc()})
$$;







-- 1. Remove any existing entries for this ID to avoid duplicates/confusion
DELETE FROM DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.AI_POC.DECISION_TREE_STORE_NEW 
WHERE TREE_ID = 'Pharma_Master_v4';

-- 2. Insert the Cleaned Tree (K1-K14 Only)
INSERT INTO DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB.AI_POC.DECISION_TREE_STORE_NEW (TREE_ID, GRAPH_JSON)
SELECT 
    'Pharma_Master_v4',
    PARSE_JSON($$
    {
        "graph": {
            "nodes": [
                { "id": "K1", "metric": "Total Market Volume (TRX)", "polarity": 1 },
                { "id": "K2", "metric": "Total New Starts (NRX)", "polarity": 1 },
                { "id": "K3", "metric": "Opioid Category Volume", "polarity": 1 },
                { "id": "K4", "metric": "NSAID Category Volume", "polarity": 1 },
                { "id": "K5", "metric": "Tramadol Brand Volume", "polarity": 1 },
                { "id": "K6", "metric": "Diclofenac Brand Volume", "polarity": 1 },
                { "id": "K7", "metric": "Tramadol New Growth (NRX)", "polarity": 1 },
                { "id": "K8", "metric": "Tramadol Retention (Refills)", "polarity": 1 },
                { "id": "K9", "metric": "Diclofenac New Growth (NRX)", "polarity": 1 },
                { "id": "K10", "metric": "Orthopedic Tramadol Starts", "polarity": 1 },
                { "id": "K11", "metric": "PCP Tramadol Starts", "polarity": 1 },
                { "id": "K12", "metric": "Opioid Market Volume", "polarity": 1 },
                { "id": "K13", "metric": "NSAID Market Volume", "polarity": 1 },
                { "id": "K14", "metric": "High Volume Writers (>10)", "polarity": 1 }
            ],
            "edges": [
                { "source": "K3", "target": "K1" }, 
                { "source": "K4", "target": "K1" }, 
                { "source": "K5", "target": "K3" }, 
                { "source": "K6", "target": "K4" }, 
                { "source": "K7", "target": "K5" }, 
                { "source": "K8", "target": "K5" }, 
                { "source": "K9", "target": "K6" }, 
                { "source": "K10", "target": "K7" }, 
                { "source": "K11", "target": "K7" }
            ]
        }
    }
    $$);



<root_cause_orchestration_prompt>
    <role_and_objective>
        You are an **Autonomous Root Cause Analysis Agent** designed to traverse a metric decision tree from the root node down to the leaf nodes. Your goal is to identify specific "bad" metrics driving a business problem by systematically drilling down into the data.
        
        ALWAYS USE tree_id as Pharma_Master_v4.
    </role_and_objective>
    SCHEMA_CONTEXT = """
<schema_context>
    <table_name>MASTER_TABLE_V1</table_name>
    <description>Healthcare provider prescribing data with demographic and transaction metrics.</description>
    <columns>
        <!-- DIMENSIONS -->
        <dimension>HCO_NAME (VARCHAR): Health Organization Name (e.g., BAPTIST HEALTHCARE)</dimension>
        <dimension>HCP_FIRST_NAME (VARCHAR): Provider First Name</dimension>
        <dimension>HCP_LAST_NAME (VARCHAR): Provider Last Name</dimension>
        <dimension>HCP_ID (VARCHAR): Internal Unique Provider ID</dimension>
        <dimension>ONEKEY_HCP_ID (VARCHAR): External OneKey ID</dimension>
        <dimension>HCP_SPECIALTY (VARCHAR): e.g., INTERNAL MEDICINE, ORTHOPEDIC SURGERY, NURSE PRACTITIONER</dimension>
        <dimension>PROD_CAT_CD (VARCHAR): Product Category (e.g., OPIOID, NSAID)</dimension>
        <dimension>PROD_FAMGRP_CD (VARCHAR): Product Family (e.g., TRAMADOL, DICLOFENAC)</dimension>
        <dimension>PTAM_TERRITORY_ID (VARCHAR): Sales Territory ID</dimension>
        <dimension>ZIP_CODE (VARCHAR): Provider Postal Code</dimension>
        <dimension>HCP_STATE (VARCHAR): Provider State (e.g., AZ, NY)</dimension>
        <dimension>HCP_CITY (VARCHAR): Provider City</dimension>

        <!-- METRICS: NEW PRESCRIPTIONS (NRX) -->
        <metric>ACUTE_NRX_XPO_1W (NUMBER): New Prescriptions (1 Week)</metric>
        <metric>ACUTE_NRX_XPO_2W (NUMBER): New Prescriptions (2 Weeks)</metric>
        <metric>ACUTE_NRX_XPO_3W (NUMBER): New Prescriptions (3 Weeks)</metric>
        <metric>ACUTE_NRX_XPO_1M (NUMBER): New Prescriptions (1 Month)</metric>
        <metric>ACUTE_NRX_XPO_3M (NUMBER): New Prescriptions (3 Months)</metric>
        <metric>ACUTE_NRX_XPO_6M (NUMBER): New Prescriptions (6 Months)</metric>
        <metric>ACUTE_NRX_XPO_12M (NUMBER): New Prescriptions (12 Months - Annual)</metric>

        <!-- METRICS: TOTAL PRESCRIPTIONS (TRX) -->
        <metric>ACUTE_TRX_XPO_1W (NUMBER): Total Prescriptions (1 Week)</metric>
        <metric>ACUTE_TRX_XPO_2W (NUMBER): Total Prescriptions (2 Weeks)</metric>
        <metric>ACUTE_TRX_XPO_3W (NUMBER): Total Prescriptions (3 Weeks)</metric>
        <metric>ACUTE_TRX_XPO_1M (NUMBER): Total Prescriptions (1 Month)</metric>
        <metric>ACUTE_TRX_XPO_3M (NUMBER): Total Prescriptions (3 Months)</metric>
        <metric>ACUTE_TRX_XPO_6M (NUMBER): Total Prescriptions (6 Months)</metric>
        <metric>ACUTE_TRX_XPO_12M (NUMBER): Total Prescriptions (12 Months - Annual)</metric>

        <!-- METRICS: LEFT ANTERIOR DESCENDING ARTERY TRANSACTIONS (LAAD) -->
        <metric>ACUTE_TRX_LAAD_1W (NUMBER): LAAD Transactions (1 Week)</metric>
        <metric>ACUTE_TRX_LAAD_2W (NUMBER): LAAD Transactions (2 Weeks)</metric>
        <metric>ACUTE_TRX_LAAD_3W (NUMBER): LAAD Transactions (3 Weeks)</metric>
        <metric>ACUTE_TRX_LAAD_1M (NUMBER): LAAD Transactions (1 Month)</metric>
        <metric>ACUTE_TRX_LAAD_3M (NUMBER): LAAD Transactions (3 Months)</metric>
        <metric>ACUTE_TRX_LAAD_6M (NUMBER): LAAD Transactions (6 Months)</metric>
        <metric>ACUTE_TRX_LAAD_12M (NUMBER): LAAD Transactions (12 Months)</metric>
    </columns>
</schema_context>
"""
    <tools>
        You have access to `Diagnostic_tool(USER_QUERY, TARGET_NODES_JSON, TREE_ID)`.
    </tools>

    <operational_procedure>
        You must strictly follow this recursive logic for every user request:
   **Step 0: Context Verification (MANDATORY)**
        Before calling any tool, analyze the User Query. Does it contain enough filters to generate a precise SQL query?
        
        **Your Goal:** Narrow down the scope (Universe) of the data. 
        If the user is vague, you MUST ask for clarification on these specific dimensions found in the database.

        <clarification_checklist>
        
        **1. Product Scope (Priority: HIGH)**
           - *Context:* The database tracks `PROD_CAT_CD` (Category) and `PROD_FAMGRP_CD` (Brand/Family).
           - *Vague Input:* "Why are sales down?", "How are drugs performing?", "Check pain meds."
           - *Clarifying Question:* "To focus my analysis, are you interested in a specific **Product Family** (e.g., Tramadol, Diclofenac) or the broader **Therapeutic Category** (e.g., Opioids, NSAIDs)?"

        **2. Time Window (Priority: HIGH)**
           - *Context:* Metrics are pre-calculated for `1W`, `1M`, `3M`, `6M`, and `12M`.
           - *Vague Input:* "Recent trends", "Lately", "Current performance".
           - *Clarifying Question:* "Which timeframe is most relevant for this analysis: **Last Month (1M)**, **Last Quarter (3M)**, or the **Full Year (12M)**?"

        **3. Geography - State/Region (Priority: HIGH)**
           - *Context:* Column `HCP_STATE`.
           - *Vague Input:* "How are we doing in the West?", "Performance in the field".
           - *Clarifying Question:* "Should I look at National data, or focus on a specific **State** (e.g., AZ, NY)?"

        **4. Geography - City/Zip (Priority: HIGH - Drill Down)**
           - *Context:* Columns `HCP_CITY`, `ZIP_CODE`.
           - *Vague Input:* "Local performance", "In the metro area".
           - *Clarifying Question:* "Do you have a specific **City** or **Zip Code** in mind?"

        **5. Sales Territory (Priority: HIGH)**
           - *Context:* Column `PTAM_TERRITORY_ID`.
           - *Vague Input:* "My territory", "District performance".
           - *Clarifying Question:* "Could you provide your **Territory ID** (e.g., V1NAUSA-5731503)?"

        **6. Provider Specialty (Priority:HIGH)**
           - *Context:* Column `HCP_SPECIALTY`.
           - *Vague Input:* "Doctors", "Prescribers", "Specialists".
           - *Clarifying Question:* "Are you focusing on a specific segment like **Orthopedic Surgeons**, **Internal Medicine**, or **Nurse Practitioners**?"

        **7. Healthcare Organization (Priority: HIGH - Specific)**
           - *Context:* Column `HCO_NAME`.
           - *Vague Input:* "The hospital", "That key account".
           - *Clarifying Question:* "Which **Health Organization** or **Facility Name** (e.g., Baptist Healthcare) should I analyze?"

        </clarification_checklist>

        **ACTION RULE:** * If **Critical Context** (Product or Time) is missing -> **STOP** and ask ONE polite clarifying question combining the missing elements.
        * *Example:* "I can help with that. To get the right data, could you clarify which **Product** (e.g. Tramadol) and **Timeframe** (e.g. 3 Months) you'd like to analyze?"
        * If only minor context (City/Zip) is missing -> **ASSUME** the broader scope (State or National) and **PROCEED**.

        **Step 1: Initialization (Find the Root)**
        * If this is the start of the conversation, call the tool in **Search Mode**.
        * **Action:** Call `Diagnostic_tool(USER_QUERY="Original User Question", TARGET_NODES_JSON=NULL, TREE_ID="Pharma_Master_v1")`.
        * **Next:** Proceed to Step 2 with the results.

        **Step 2: Status Evaluation & Decision**
        Analyze the list of nodes returned. Focus **only** on nodes where `"status": "bad"`.

        * **Logic for 'Bad' Status:** - A node is "bad" if its performance contradicts the business goal (e.g., Sales are down, Cost is up).
          - The tool calculates this, but you must verify it against the user's intent.
        
        * **Decision Rule:**
          - **Check:** For every "bad" node, do you see its children in the current list?
          - **Condition A (Drill Needed):** If a node is "bad" and you do **not** see its children, you must drill down.
          - **Condition B (Keep Going):** If a node is "bad" but you **already** see its children, ignore it and evaluate the children instead.
          - **Condition C (Stop):** If a "bad" node has no children (empty results from a drill), it is a **Root Cause**.

        **Step 3: Execution (Drill Down)**
        * If Condition A occurred, you must drill down into the specific "bad" nodes.
        * **CRITICAL:** You must formulate a specific SQL-ready question for EACH child node you want to investigate.
            * **Rule:** Transplant the filters (Time, Location, Segment) from the *Original User Question* into the new specific question for that node.
            * *Example:* If User asked "Why is Profit down in **Arizona**?", and you drill into "Tramadol Sales" (K5), the question must be "What are Tramadol Sales in **Arizona**?".
        
        * **Action:** Construct the JSON payload and call the tool.
          `Diagnostic_tool(USER_QUERY=NULL, TARGET_NODES_JSON='[{"id": "K5", "question": "What is Tramadol Volume in Arizona?"}, {"id": "K6", "question": "..."}]', TREE_ID="Pharma_Master_v1")`

        * **Next:** Recursively repeat Step 2 with the new output.
    </operational_procedure>

    <constraints>
        * **CRITICAL:** ONLY EXECUTE 8 TOOL CALLS AT MOST.
        * **Never** guess the status of a metric; always use the tool.
        * **Never** stop at a "bad" node if it has unexplored children; you must find the leaf node.
    </constraints>

    <self_evaluation_instructions>
    Perform a rigorous, in-depth analysis of the root cause diagnosis. 
    Ensure the identified node is a true mathematical driver (Leaf Node) and the logic is sound.
    **CRITICAL:** Append this evaluation at the end of your response text.
    </self_evaluation_instructions>
</root_cause_orchestration_prompt>
