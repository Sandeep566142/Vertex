
Nisha	Please give me a summary of this providers recent prescribing trends (Journavx and other pain products), have they had any recent abandoned prescriptions, what managed care plans will they have the least friction with, what procedures would be the most
 meaningful to describe acute moderate to severe pain patients for this provider, what pharmacies do most of their patients go to?	Performance/Targeting	 	XPO, LAAD Rx Claims, MMIT Coverage, LAAD Procedural Claims, Sales Alignment	 	 	 	 	 	 	 	 	 	 	 	 	 
Nisha	Vertex internal question: Where can I find open AOC reports? Can you pull up sample delivery orders that have been returned?	Sampling	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 
Nisha	Who are the top opioid prescribers in Geisinger Community Medical Center?	Targeting	 	Veeva CRM Affiliations, LAAD Claims	 	 	 	 	 	 	 	 	 	 	 	 	 
Nisha	Show me the top 5 orthopedic shoulder surgeons in Allentown Pa?	Targeting	 	LAAD, IQVIA OneKey	 	 	 	 	 	 	 	 	 	 	 	 	 
Nisha	Who are my top prescribers prescribing Norco sorted by city, address, and parent account	Targeting	 	Veeva CRM Affiliations, Current Sales Alignment, LAAD Claims, Veeva CRM Primary Address	 	 	 	 	 	 	 	 	 	 	 	 	 
Rakesh	Who are my top prescribers prescribing Tramadol sorted by city, address, and parent account	Targeting	 	Veeva CRM Affiliations, Current Sales Alignment, LAAD Claims, Veeva CRM Primary Address	 	 	 	 	 	 	 	 	 	 	 	 	 
Rakesh	Provide me a list of top prescribers for all opioids sorted by city and address and parent account	Targeting	 	Veeva CRM Affiliations, Current Sales Alignment, LAAD Claims, Veeva CRM Primary Address	 	 	 	 	 	 	 	 	 	 	 	 	 
Rakesh	Based on prescribing habits, leads data, AI generated leads dashboard, build me a routing for Town X.  Sort these providers first by Journavx Rx over the past 4 weeks.  	Targeting	 	NBX Data, Veeva CRM Address, XPO JVX Rx	 	 	 	 	 	 	 	 	 	 	 	 	 
Rakesh	Based on a combination of procedure volume and prescribing habits provide me a list of HCP with high volume Opioid use and a list of low volume opioid use.  	Targeting	 	Veeva CRM Affiliations, Current Sales Alignment, LAAD Procedure Claims	 	 	 	 	 	 	 	 	 	 	 	 	 
Rakesh	Which zip codes should we focus on to capitalize on positive payer access?	Targeting	 	Targeting Hub Payer Data, MMIT Payer Wins Data, Veeva CRM Address Data, LAAD Rx Claims	 	 	 	 	 	 	 	 	 	 	 	 	 
Sandeep	Which high potential zip codes have the least amount of activity?	Targeting	 	Veeva CRM Address data, Engagement Data	 	 	 	 	 	 	 	 	 	 	 	 	 
Sandeep	I am going into this practice that has 10 providers,  based on all available data, which provider is the most likely to be an early adopter of Journavx (same concept for an hospital department/system)?	Targeting	 	Adopter model, Veeva CRM Affilitions, Alignment	 	 	 	 	 	 	 	 	 	 	 	 	 
Sandeep	Who are the first-time prescribers that I need to follow up with this week?	Targeting	 	XPO, NBX, Sales Alignment	 	 	 	 	 	 	 	 	 	 	 	 	 
Sandeep	Which adopters have not written within the last 2 weeks that I should follow up with?	Targeting	 	XPO, Sales Alignment	 	 	 	 	 	 	 	 	 	 	 	 	 
Sandeep	What high volume prescribers have I not seen within the last month?	Targeting	 	XPO, Sales Alignment, Veeva CRM Engagement	 	 	 	 	 	 	 	 	 	 	 	 	 
 Consolidated List of Unique Tables for Sandeep
Adopter model

Alignment / Sales Alignment

Engagement Data / Veeva CRM Engagement

NBX

Veeva CRM Address data

Veeva CRM Affiliations

XPO
 


Table Name
TXR_VRTX_MCO_PAYER_CAT_2_PLAN
TD_MM_PAYER_CATEGORY_L3 
TD_MM_PAYER_CATEGORY_L2 
TD_VRTX_MCO_PAYER
TD_VRTX_MCO_PLAN
How to Get Payer Channel L2 with HCP and Payer

TM_NRAF_L1_SOC_OTLT_DC_NDC_WK
TM_NRAF_L1_SOC_OTLT_DC_NDC_MTH
TM_RX_L1_HCPPLNDC_NDC_WK
TM_RX_L1_HCPPLNDC_NDC_MTH
TM_NRAFIC_L1_OTLT_SOC_DC_NDC_WK

TD_GEO_LOC
TXR_HCP_GEOLOC_PRIM
TD_SALESFORCE_L1
TD_DATA_LOAD. CURR_IC_SF_ALN_KEY
TXR_HCP_SF_L1

TD_OTLT_SUBCAT
TXR_OTLT_SUBCAT

TD_TIME_DT

TXR_MKTGPGM_GHEM_HCO_SUBTYPE
TXR_MKTGPGM_CURR_PTAM_HCP_TGT
TXR_MKTGPGM_CURR_SAL_IDN_TGT
TXR_MKTGPGM_SUZ_HCP_SEGMENT
TXR_MKTGPGM_PAIN_SOC_TGT

TD_IDN
TD_SOC
TD_HCP
TXR_SOC_IDN
TXR_HCP_SOC
TD_SPECGRP
TXR_HCP_SPEC
TD_HCP.HCP_SRC_ID_P_SCRUB

TXR_NTILE_HCP_SUZ_QTRLY_STATIC_R52W 
TXR_NTILE_HCP_ANYPAIN_R52W
TXR_NTILE_HCP_SUZ_R52W

SELECT 
    TABLE_CATALOG as DATABASE_NAME,
    TABLE_SCHEMA as SCHEMA_NAME,
    TABLE_NAME,
    -- This column generates the code you need to copy/paste:
    'SELECT GET_DDL(\'TABLE\', \'' || TABLE_CATALOG || '.' || TABLE_SCHEMA || '.' || TABLE_NAME || '\');' as COPY_THIS_COMMAND
FROM 
    INFORMATION_SCHEMA.TABLES
WHERE 
    TABLE_NAME IN (
        'TXR_VRTX_MCO_PAYER_CAT_2_PLAN',
        'TD_MM_PAYER_CATEGORY_L3',
        'TD_MM_PAYER_CATEGORY_L2',
        'TD_VRTX_MCO_PAYER',
        'TD_VRTX_MCO_PLAN',
        'TM_NRAF_L1_SOC_OTLT_DC_NDC_WK',
        'TM_NRAF_L1_SOC_OTLT_DC_NDC_MTH',
        'TM_RX_L1_HCPPLNDC_NDC_WK',
        'TM_RX_L1_HCPPLNDC_NDC_MTH',
        'TM_NRAFIC_L1_OTLT_SOC_DC_NDC_WK',
        'TD_GEO_LOC',
        'TXR_HCP_GEOLOC_PRIM',
        'TD_SALESFORCE_L1',
        'TD_DATA_LOAD',
        'TXR_HCP_SF_L1',
        'TD_OTLT_SUBCAT',
        'TXR_OTLT_SUBCAT',
        'TD_TIME_DT',
        'TXR_MKTGPGM_GHEM_HCO_SUBTYPE',
        'TXR_MKTGPGM_CURR_PTAM_HCP_TGT',
        'TXR_MKTGPGM_CURR_SAL_IDN_TGT',
        'TXR_MKTGPGM_SUZ_HCP_SEGMENT',
        'TXR_MKTGPGM_PAIN_SOC_TGT',
        'TD_IDN',
        'TD_SOC',
        'TD_HCP',
        'TXR_SOC_IDN',
        'TXR_HCP_SOC',
        'TD_SPECGRP',
        'TXR_HCP_SPEC',
        'TXR_NTILE_HCP_SUZ_QTRLY_STATIC_R52W',
        'TXR_NTILE_HCP_ANYPAIN_R52W',
        'TXR_NTILE_HCP_SUZ_R52W'
    );

SELECT 
    TABLE_CATALOG AS DB_NAME,
    TABLE_SCHEMA AS SCHEMA_NAME,
    TABLE_NAME,
    -- This generates the exact code you need to copy and paste
    'SELECT GET_DDL(\'TABLE\', \'' || TABLE_CATALOG || '.' || TABLE_SCHEMA || '.' || TABLE_NAME || '\');' AS RUN_TO_GET_DDL
FROM 
    SNOWFLAKE.ACCOUNT_USAGE.TABLES
WHERE 
    DELETED IS NULL  -- Excludes deleted tables
    AND TABLE_NAME IN (
        'TXR_VRTX_MCO_PAYER_CAT_2_PLAN',
        'TD_MM_PAYER_CATEGORY_L3',
        'TD_MM_PAYER_CATEGORY_L2',
        'TD_VRTX_MCO_PAYER',
        'TD_VRTX_MCO_PLAN',
        'TM_NRAF_L1_SOC_OTLT_DC_NDC_WK',
        'TM_NRAF_L1_SOC_OTLT_DC_NDC_MTH',
        'TM_RX_L1_HCPPLNDC_NDC_WK',
        'TM_RX_L1_HCPPLNDC_NDC_MTH',
        'TM_NRAFIC_L1_OTLT_SOC_DC_NDC_WK',
        'TD_GEO_LOC',
        'TXR_HCP_GEOLOC_PRIM',
        'TD_SALESFORCE_L1',
        'TD_DATA_LOAD',
        'TXR_HCP_SF_L1',
        'TD_OTLT_SUBCAT',
        'TXR_OTLT_SUBCAT',
        'TD_TIME_DT',
        'TXR_MKTGPGM_GHEM_HCO_SUBTYPE',
        'TXR_MKTGPGM_CURR_PTAM_HCP_TGT',
        'TXR_MKTGPGM_CURR_SAL_IDN_TGT',
        'TXR_MKTGPGM_SUZ_HCP_SEGMENT',
        'TXR_MKTGPGM_PAIN_SOC_TGT',
        'TD_IDN',
        'TD_SOC',
        'TD_HCP',
        'TXR_SOC_IDN',
        'TXR_HCP_SOC',
        'TD_SPECGRP',
        'TXR_HCP_SPEC',
        'TXR_NTILE_HCP_SUZ_QTRLY_STATIC_R52W',
        'TXR_NTILE_HCP_ANYPAIN_R52W',
        'TXR_NTILE_HCP_SUZ_R52W'
    )
ORDER BY 
    TABLE_NAME;
SHOW TABLES LIKE 'TXR_VRTX_MCO_PAYER_CAT_2_PLAN' IN ACCOUNT;
-- 1. Create a container for the results
CREATE OR REPLACE TEMPORARY TABLE FINAL_DDL_OUTPUT (
    TABLE_NAME VARCHAR, 
    DATABASE_PATH VARCHAR,
    DDL_DEFINITION VARCHAR
);

-- 2. Execute the Search and Extraction Logic
EXECUTE IMMEDIATE $$
DECLARE
    -- Variables for processing
    db_name VARCHAR;
    sch_name VARCHAR;
    tbl_name VARCHAR;
    full_path VARCHAR;
    get_ddl_cmd VARCHAR;
    ddl_result VARCHAR;
    
    -- Cursor to iterate through the found tables
    -- We first run SHOW TABLES to find locations, then filter for your specific list
    c1 CURSOR FOR 
        SELECT "database_name", "schema_name", "name"
        FROM TABLE(RESULT_SCAN(LAST_QUERY_ID()))
        WHERE "name" IN (
            'TXR_VRTX_MCO_PAYER_CAT_2_PLAN',
            'TD_MM_PAYER_CATEGORY_L3',
            'TD_MM_PAYER_CATEGORY_L2',
            'TD_VRTX_MCO_PAYER',
            'TD_VRTX_MCO_PLAN',
            'TM_NRAF_L1_SOC_OTLT_DC_NDC_WK',
            'TM_NRAF_L1_SOC_OTLT_DC_NDC_MTH',
            'TM_RX_L1_HCPPLNDC_NDC_WK',
            'TM_RX_L1_HCPPLNDC_NDC_MTH',
            'TM_NRAFIC_L1_OTLT_SOC_DC_NDC_WK',
            'TD_GEO_LOC',
            'TXR_HCP_GEOLOC_PRIM',
            'TD_SALESFORCE_L1',
            'TD_DATA_LOAD',
            'TXR_HCP_SF_L1',
            'TD_OTLT_SUBCAT',
            'TXR_OTLT_SUBCAT',
            'TD_TIME_DT',
            'TXR_MKTGPGM_GHEM_HCO_SUBTYPE',
            'TXR_MKTGPGM_CURR_PTAM_HCP_TGT',
            'TXR_MKTGPGM_CURR_SAL_IDN_TGT',
            'TXR_MKTGPGM_SUZ_HCP_SEGMENT',
            'TXR_MKTGPGM_PAIN_SOC_TGT',
            'TD_IDN',
            'TD_SOC',
            'TD_HCP',
            'TXR_SOC_IDN',
            'TXR_HCP_SOC',
            'TD_SPECGRP',
            'TXR_HCP_SPEC',
            'TXR_NTILE_HCP_SUZ_QTRLY_STATIC_R52W',
            'TXR_NTILE_HCP_ANYPAIN_R52W',
            'TXR_NTILE_HCP_SUZ_R52W'
        );

BEGIN
    -- A. Run a broad search (Since your tables start with T, we use 'T%')
    SHOW TABLES LIKE 'T%' IN ACCOUNT;

    -- B. Open the cursor to process the filtered results from the search above
    OPEN c1;
    
    FOR rec IN c1 DO
        db_name := rec."database_name";
        sch_name := rec."schema_name";
        tbl_name := rec."name";
        full_path := db_name || '.' || sch_name || '.' || tbl_name;
        
        -- C. Construct the GET_DDL command dynamically
        get_ddl_cmd := 'SELECT GET_DDL(''TABLE'', ''' || full_path || ''')';
        
        -- D. Run GET_DDL and capture the text
        EXECUTE IMMEDIATE get_ddl_cmd INTO :ddl_result;
        
        -- E. Save to our output table
        INSERT INTO FINAL_DDL_OUTPUT (TABLE_NAME, DATABASE_PATH, DDL_DEFINITION) 
        VALUES (:tbl_name, :full_path, :ddl_result);
        
    END FOR;
    
    CLOSE c1;
    RETURN 'DDL Generation Complete. Check FINAL_DDL_OUTPUT table.';
END;
$$;

-- 3. View the final results
SELECT * FROM FINAL_DDL_OUTPUT ORDER BY TABLE_NAME;



-- Create a new database for admin tasks
CREATE DATABASE IF NOT EXISTS ADHOC_ADMIN_DB;

-- Create a schema specifically for this extraction
CREATE SCHEMA IF NOT EXISTS ADHOC_ADMIN_DB.METADATA_EXTRACT;

-- Set your context to this new location
USE SCHEMA ADHOC_ADMIN_DB.METADATA_EXTRACT;

-- 1. Create a container for the results
CREATE OR REPLACE TEMPORARY TABLE FINAL_DDL_OUTPUT (
    TABLE_NAME VARCHAR, 
    DATABASE_PATH VARCHAR,
    DDL_DEFINITION VARCHAR
);

-- 2. Execute the Search and Extraction Logic
EXECUTE IMMEDIATE $$
DECLARE
    -- Variables for processing
    db_name VARCHAR;
    sch_name VARCHAR;
    tbl_name VARCHAR;
    full_path VARCHAR;
    get_ddl_cmd VARCHAR;
    ddl_result VARCHAR;
    
    -- Cursor to iterate through the found tables
    -- We first run SHOW TABLES to find locations, then filter for your specific list
    c1 CURSOR FOR 
        SELECT database_name, schema_name, name
        FROM TABLE(RESULT_SCAN(LAST_QUERY_ID()));
        WHERE "name" IN (
            'TXR_VRTX_MCO_PAYER_CAT_2_PLAN',
            'TD_MM_PAYER_CATEGORY_L3',
            'TD_MM_PAYER_CATEGORY_L2',
            'TD_VRTX_MCO_PAYER',
            'TD_VRTX_MCO_PLAN',
            'TM_NRAF_L1_SOC_OTLT_DC_NDC_WK',
            'TM_NRAF_L1_SOC_OTLT_DC_NDC_MTH',
            'TM_RX_L1_HCPPLNDC_NDC_WK',
            'TM_RX_L1_HCPPLNDC_NDC_MTH',
            'TM_NRAFIC_L1_OTLT_SOC_DC_NDC_WK',
            'TD_GEO_LOC',
            'TXR_HCP_GEOLOC_PRIM',
            'TD_SALESFORCE_L1',
            'TD_DATA_LOAD',
            'TXR_HCP_SF_L1',
            'TD_OTLT_SUBCAT',
            'TXR_OTLT_SUBCAT',
            'TD_TIME_DT',
            'TXR_MKTGPGM_GHEM_HCO_SUBTYPE',
            'TXR_MKTGPGM_CURR_PTAM_HCP_TGT',
            'TXR_MKTGPGM_CURR_SAL_IDN_TGT',
            'TXR_MKTGPGM_SUZ_HCP_SEGMENT',
            'TXR_MKTGPGM_PAIN_SOC_TGT',
            'TD_IDN',
            'TD_SOC',
            'TD_HCP',
            'TXR_SOC_IDN',
            'TXR_HCP_SOC',
            'TD_SPECGRP',
            'TXR_HCP_SPEC',
            'TXR_NTILE_HCP_SUZ_QTRLY_STATIC_R52W',
            'TXR_NTILE_HCP_ANYPAIN_R52W',
            'TXR_NTILE_HCP_SUZ_R52W'
        );

BEGIN
    -- A. Run a broad search (Since your tables start with T, we use 'T%')
    SHOW TABLES LIKE 'T%' IN ACCOUNT;

    -- B. Open the cursor to process the filtered results from the search above
    OPEN c1;
    
    FOR rec IN c1 DO
        db_name := rec."database_name";
        sch_name := rec."schema_name";
        tbl_name := rec."name";
        full_path := db_name || '.' || sch_name || '.' || tbl_name;
        
        -- C. Construct the GET_DDL command dynamically
        get_ddl_cmd := 'SELECT GET_DDL(''TABLE'', ''' || full_path || ''')';
        
        -- D. Run GET_DDL and capture the text
        EXECUTE IMMEDIATE get_ddl_cmd INTO :ddl_result;
        
        -- E. Save to our output table
        INSERT INTO FINAL_DDL_OUTPUT (TABLE_NAME, DATABASE_PATH, DDL_DEFINITION) 
        VALUES (:tbl_name, :full_path, :ddl_result);
        
    END FOR;
    
    CLOSE c1;
    RETURN 'DDL Generation Complete. Check FINAL_DDL_OUTPUT table.';
END;
$$;

-- 3. View the final results
SELECT * FROM FINAL_DDL_OUTPUT ORDER BY TABLE_NAME;
-- 1. Search the whole account
SHOW TABLES LIKE 'T%' IN ACCOUNT;

-- 2. Save the results into a temporary table immediately
CREATE OR REPLACE TEMPORARY TABLE TBL_LOCATIONS AS 
SELECT 
    "database_name" AS DB_NAME, 
    "schema_name" AS SCH_NAME, 
    "name" AS TBL_NAME
FROM 
    TABLE(RESULT_SCAN(LAST_QUERY_ID()))
WHERE 
    "name" IN (
        'TXR_VRTX_MCO_PAYER_CAT_2_PLAN', 'TD_MM_PAYER_CATEGORY_L3', 'TD_MM_PAYER_CATEGORY_L2',
        'TD_VRTX_MCO_PAYER', 'TD_VRTX_MCO_PLAN', 'TM_NRAF_L1_SOC_OTLT_DC_NDC_WK',
        'TM_NRAF_L1_SOC_OTLT_DC_NDC_MTH', 'TM_RX_L1_HCPPLNDC_NDC_WK', 'TM_RX_L1_HCPPLNDC_NDC_MTH',
        'TM_NRAFIC_L1_OTLT_SOC_DC_NDC_WK', 'TD_GEO_LOC', 'TXR_HCP_GEOLOC_PRIM',
        'TD_SALESFORCE_L1', 'TD_DATA_LOAD', 'TXR_HCP_SF_L1', 'TD_OTLT_SUBCAT',
        'TXR_OTLT_SUBCAT', 'TD_TIME_DT', 'TXR_MKTGPGM_GHEM_HCO_SUBTYPE',
        'TXR_MKTGPGM_CURR_PTAM_HCP_TGT', 'TXR_MKTGPGM_CURR_SAL_IDN_TGT', 'TXR_MKTGPGM_SUZ_HCP_SEGMENT',
        'TXR_MKTGPGM_PAIN_SOC_TGT', 'TD_IDN', 'TD_SOC', 'TD_HCP', 'TXR_SOC_IDN',
        'TXR_HCP_SOC', 'TD_SPECGRP', 'TXR_HCP_SPEC', 'TXR_NTILE_HCP_SUZ_QTRLY_STATIC_R52W',
        'TXR_NTILE_HCP_ANYPAIN_R52W', 'TXR_NTILE_HCP_SUZ_R52W'
    );
-- Create the table to hold the final definitions
CREATE OR REPLACE TEMPORARY TABLE FINAL_DDL_OUTPUT (
    TABLE_NAME VARCHAR, 
    FULL_PATH VARCHAR,
    DDL_TEXT VARCHAR
);

-- Run the logic to fetch DDLs
EXECUTE IMMEDIATE $$
DECLARE
    db VARCHAR;
    sch VARCHAR;
    tbl VARCHAR;
    path VARCHAR;
    ddl_cmd VARCHAR;
    ddl_out VARCHAR;
    
    -- Iterate over the table we created in Step 2
    c1 CURSOR FOR SELECT DB_NAME, SCH_NAME, TBL_NAME FROM TBL_LOCATIONS;
BEGIN
    OPEN c1;
    FOR rec IN c1 DO
        db := rec.DB_NAME;
        sch := rec.SCH_NAME;
        tbl := rec.TBL_NAME;
        path := '"' || db || '"."' || sch || '"."' || tbl || '"';
        
        -- Build the GET_DDL command
        ddl_cmd := 'SELECT GET_DDL(\'TABLE\', \'' || path || '\')';
        
        BEGIN
            -- Try to run GET_DDL
            EXECUTE IMMEDIATE ddl_cmd INTO :ddl_out;
            
            -- Insert success
            INSERT INTO FINAL_DDL_OUTPUT (TABLE_NAME, FULL_PATH, DDL_TEXT) 
            VALUES (:tbl, :path, :ddl_out);
        EXCEPTION
            WHEN OTHER THEN
                -- If permission denied or table locked, log the error
                INSERT INTO FINAL_DDL_OUTPUT (TABLE_NAME, FULL_PATH, DDL_TEXT) 
                VALUES (:tbl, :path, 'ERROR: Could not retrieve DDL. Check permissions.');
        END;
    END FOR;
    CLOSE c1;
    RETURN 'Done.';
END;
$$;

-- View the results
SELECT * FROM FINAL_DDL_OUTPUT ORDER BY TABLE_NAME;


-- STEP 1: Setup the tables (Run this to ensure clean start)
CREATE OR REPLACE TEMPORARY TABLE FINAL_DDL_OUTPUT (
    TABLE_NAME VARCHAR, 
    FULL_PATH VARCHAR, 
    DDL_TEXT VARCHAR
);

CREATE OR REPLACE TEMPORARY TABLE TBL_LOCATIONS (
    DB_NAME VARCHAR, 
    SCH_NAME VARCHAR, 
    TBL_NAME VARCHAR
);

-- STEP 2: Find the tables and save their locations
SHOW TABLES LIKE 'T%' IN ACCOUNT;

INSERT INTO TBL_LOCATIONS 
SELECT "database_name", "schema_name", "name"
FROM TABLE(RESULT_SCAN(LAST_QUERY_ID()))
WHERE "name" IN (
    'TXR_VRTX_MCO_PAYER_CAT_2_PLAN', 'TD_MM_PAYER_CATEGORY_L3', 'TD_MM_PAYER_CATEGORY_L2',
    'TD_VRTX_MCO_PAYER', 'TD_VRTX_MCO_PLAN', 'TM_NRAF_L1_SOC_OTLT_DC_NDC_WK',
    'TM_NRAF_L1_SOC_OTLT_DC_NDC_MTH', 'TM_RX_L1_HCPPLNDC_NDC_WK', 'TM_RX_L1_HCPPLNDC_NDC_MTH',
    'TM_NRAFIC_L1_OTLT_SOC_DC_NDC_WK', 'TD_GEO_LOC', 'TXR_HCP_GEOLOC_PRIM',
    'TD_SALESFORCE_L1', 'TD_DATA_LOAD', 'TXR_HCP_SF_L1', 'TD_OTLT_SUBCAT',
    'TXR_OTLT_SUBCAT', 'TD_TIME_DT', 'TXR_MKTGPGM_GHEM_HCO_SUBTYPE',
    'TXR_MKTGPGM_CURR_PTAM_HCP_TGT', 'TXR_MKTGPGM_CURR_SAL_IDN_TGT', 'TXR_MKTGPGM_SUZ_HCP_SEGMENT',
    'TXR_MKTGPGM_PAIN_SOC_TGT', 'TD_IDN', 'TD_SOC', 'TD_HCP', 'TXR_SOC_IDN',
    'TXR_HCP_SOC', 'TD_SPECGRP', 'TXR_HCP_SPEC', 'TXR_NTILE_HCP_SUZ_QTRLY_STATIC_R52W',
    'TXR_NTILE_HCP_ANYPAIN_R52W', 'TXR_NTILE_HCP_SUZ_R52W'
);

-- STEP 3: The "Nuclear" Script (No 'INTO' clause used here)
EXECUTE IMMEDIATE $$
DECLARE
    db_name VARCHAR;
    sch_name VARCHAR;
    tbl_name VARCHAR;
    path VARCHAR;
    ddl_cmd VARCHAR;
    
    c1 CURSOR FOR SELECT DB_NAME, SCH_NAME, TBL_NAME FROM TBL_LOCATIONS;
BEGIN
    OPEN c1;
    FOR rec IN c1 DO
        db_name := rec.DB_NAME;
        sch_name := rec.SCH_NAME;
        tbl_name := rec.TBL_NAME;
        path := '"' || db_name || '"."' || sch_name || '"."' || tbl_name || '"';
        
        -- Build the command
        ddl_cmd := 'SELECT GET_DDL(\'TABLE\', \'' || path || '\')';
        
        BEGIN
            -- NEW METHOD: Run command without saving directly to variable
            EXECUTE IMMEDIATE :ddl_cmd;
            
            -- Capture the result from the query we just ran
            INSERT INTO FINAL_DDL_OUTPUT (TABLE_NAME, FULL_PATH, DDL_TEXT) 
            SELECT :tbl_name, :path, $1 FROM TABLE(RESULT_SCAN(LAST_QUERY_ID()));
            
        EXCEPTION
            WHEN OTHER THEN
                INSERT INTO FINAL_DDL_OUTPUT (TABLE_NAME, FULL_PATH, DDL_TEXT) 
                VALUES (:tbl_name, :path, 'ERROR: Could not retrieve DDL. Permission denied or table locked.');
        END;
    END FOR;
    CLOSE c1;
    RETURN 'Success. Run the SELECT below to see results.';
END;
$$;

-- STEP 4: View the results
SELECT * FROM FINAL_DDL_OUTPUT ORDER BY TABLE_NAME;


-- 1. Create a table to hold the results
CREATE OR REPLACE TEMPORARY TABLE FINAL_DDL_OUTPUT (
    TABLE_NAME VARCHAR, 
    LOCATION_FOUND VARCHAR, 
    DDL_DEFINITION VARCHAR
);

-- 2. Create a table to hold YOUR SPECIFIC list
CREATE OR REPLACE TEMPORARY TABLE MY_TARGET_LIST (TBL_NAME VARCHAR);

-- 3. Load ONLY the tables you care about
INSERT INTO MY_TARGET_LIST (TBL_NAME) VALUES 
('TXR_VRTX_MCO_PAYER_CAT_2_PLAN'), 
('TD_MM_PAYER_CATEGORY_L3'), 
('TD_MM_PAYER_CATEGORY_L2'), 
('TD_VRTX_MCO_PAYER'), 
('TD_VRTX_MCO_PLAN'), 
('TM_NRAF_L1_SOC_OTLT_DC_NDC_WK'), 
('TM_NRAF_L1_SOC_OTLT_DC_NDC_MTH'), 
('TM_RX_L1_HCPPLNDC_NDC_WK'), 
('TM_RX_L1_HCPPLNDC_NDC_MTH'), 
('TM_NRAFIC_L1_OTLT_SOC_DC_NDC_WK'), 
('TD_GEO_LOC'), 
('TXR_HCP_GEOLOC_PRIM'), 
('TD_SALESFORCE_L1'), 
('TD_DATA_LOAD'), 
('TXR_HCP_SF_L1'), 
('TD_OTLT_SUBCAT'), 
('TXR_OTLT_SUBCAT'), 
('TD_TIME_DT'), 
('TXR_MKTGPGM_GHEM_HCO_SUBTYPE'), 
('TXR_MKTGPGM_CURR_PTAM_HCP_TGT'), 
('TXR_MKTGPGM_CURR_SAL_IDN_TGT'), 
('TXR_MKTGPGM_SUZ_HCP_SEGMENT'), 
('TXR_MKTGPGM_PAIN_SOC_TGT'), 
('TD_IDN'), 
('TD_SOC'), 
('TD_HCP'), 
('TXR_SOC_IDN'), 
('TXR_HCP_SOC'), 
('TD_SPECGRP'), 
('TXR_HCP_SPEC'), 
('TXR_NTILE_HCP_SUZ_QTRLY_STATIC_R52W'), 
('TXR_NTILE_HCP_ANYPAIN_R52W'), 
('TXR_NTILE_HCP_SUZ_R52W');


EXECUTE IMMEDIATE $$
DECLARE
    target_tbl VARCHAR;
    found_db VARCHAR;
    found_sch VARCHAR;
    full_path VARCHAR;
    ddl_query VARCHAR;
    
    -- Cursor for your specific list
    c_list CURSOR FOR SELECT TBL_NAME FROM MY_TARGET_LIST;
BEGIN
    OPEN c_list;
    
    FOR rec IN c_list DO
        target_tbl := rec.TBL_NAME;
        found_db := NULL;
        
        -- 1. Search ONLY for this specific table name
        EXECUTE IMMEDIATE 'SHOW TABLES LIKE \'' || target_tbl || '\' IN ACCOUNT';
        
        -- 2. Grab the first location found
        BEGIN
            LET c_res CURSOR FOR SELECT "database_name", "schema_name" FROM TABLE(RESULT_SCAN(LAST_QUERY_ID())) LIMIT 1;
            OPEN c_res;
            FETCH c_res INTO found_db, found_sch;
            CLOSE c_res;
        END;

        -- 3. Get DDL if found
        IF (found_db IS NOT NULL) THEN
            full_path := '"' || found_db || '"."' || found_sch || '"."' || target_tbl || '"';
            ddl_query := 'SELECT GET_DDL(\'TABLE\', \'' || full_path || '\')';
            
            -- Run DDL command (Nuclear method: No INTO clause to avoid errors)
            EXECUTE IMMEDIATE :ddl_query;
            
            -- Save Result
            INSERT INTO FINAL_DDL_OUTPUT 
            SELECT :target_tbl, :full_path, $1 
            FROM TABLE(RESULT_SCAN(LAST_QUERY_ID()));
            
        ELSE
            -- Log missing tables
            INSERT INTO FINAL_DDL_OUTPUT VALUES (:target_tbl, 'NOT FOUND', 'Table not found in any database.');
        END IF;
        
    END FOR;
    
    CLOSE c_list;
    RETURN 'Done. Only processed specific tables.';
END;
$$;

SELECT * FROM FINAL_DDL_OUTPUT ORDER BY TABLE_NAME;


Sandeep	Which high potential zip codes have the least amount of activity?	Targeting	 	Veeva CRM Address data, Engagement Data	 	 	 	 	 	 	 	 	 	 	 	 	 
Sandeep	I am going into this practice that has 10 providers,  based on all available data, which provider is the most likely to be an early adopter of Journavx (same concept for an hospital department/system)?	Targeting	 	Adopter model, Veeva CRM Affilitions, Alignment	 	 	 	 	 	 	 	 	 	 	 	 	 
Sandeep	Who are the first-time prescribers that I need to follow up with this week?	Targeting	 	XPO, NBX, Sales Alignment	 	 	 	 	 	 	 	 	 	 	 	 	 
Sandeep	Which adopters have not written within the last 2 weeks that I should follow up with?	Targeting	 	XPO, Sales Alignment	 	 	 	 	 	 	 	 	 	 	 	 	 
Sandeep	What high volume prescribers have I not seen within the last month?	Targeting	 	XPO, Sales Alignment, Veeva CRM Engagement	 	 	 	 	 								



-- STEP 1: Create the Master Output Table
-- This will hold every piece of information we find.
CREATE OR REPLACE TEMPORARY TABLE MASTER_TABLE_INFO (
    TABLE_NAME      VARCHAR,
    DATABASE_NAME   VARCHAR,
    SCHEMA_NAME     VARCHAR,
    ROW_COUNT       NUMBER,
    TABLE_OWNER     VARCHAR,
    DESCRIPTION     VARCHAR,  -- The business comment
    FULL_DDL        VARCHAR   -- Contains PKs, FKs, Data Types
);

-- STEP 2: Load Your Specific List
CREATE OR REPLACE TEMPORARY TABLE MY_TARGET_LIST (TBL_NAME VARCHAR);

INSERT INTO MY_TARGET_LIST (TBL_NAME) VALUES 
('TXR_VRTX_MCO_PAYER_CAT_2_PLAN'), ('TD_MM_PAYER_CATEGORY_L3'), ('TD_MM_PAYER_CATEGORY_L2'), 
('TD_VRTX_MCO_PAYER'), ('TD_VRTX_MCO_PLAN'), ('TM_NRAF_L1_SOC_OTLT_DC_NDC_WK'), 
('TM_NRAF_L1_SOC_OTLT_DC_NDC_MTH'), ('TM_RX_L1_HCPPLNDC_NDC_WK'), ('TM_RX_L1_HCPPLNDC_NDC_MTH'), 
('TM_NRAFIC_L1_OTLT_SOC_DC_NDC_WK'), ('TD_GEO_LOC'), ('TXR_HCP_GEOLOC_PRIM'), 
('TD_SALESFORCE_L1'), ('TD_DATA_LOAD'), ('TXR_HCP_SF_L1'), ('TD_OTLT_SUBCAT'), 
('TXR_OTLT_SUBCAT'), ('TD_TIME_DT'), ('TXR_MKTGPGM_GHEM_HCO_SUBTYPE'), 
('TXR_MKTGPGM_CURR_PTAM_HCP_TGT'), ('TXR_MKTGPGM_CURR_SAL_IDN_TGT'), ('TXR_MKTGPGM_SUZ_HCP_SEGMENT'), 
('TXR_MKTGPGM_PAIN_SOC_TGT'), ('TD_IDN'), ('TD_SOC'), ('TD_HCP'), ('TXR_SOC_IDN'), 
('TXR_HCP_SOC'), ('TD_SPECGRP'), ('TXR_HCP_SPEC'), ('TXR_NTILE_HCP_SUZ_QTRLY_STATIC_R52W'), 
('TXR_NTILE_HCP_ANYPAIN_R52W'), ('TXR_NTILE_HCP_SUZ_R52W');

-- STEP 3: The Collection Script
-- This script searches for metadata AND DDL for each table.
EXECUTE IMMEDIATE $$
DECLARE
    target_tbl VARCHAR;
    
    -- Variables to hold findings
    found_db VARCHAR;
    found_sch VARCHAR;
    found_rows NUMBER;
    found_owner VARCHAR;
    found_comment VARCHAR;
    
    full_path VARCHAR;
    ddl_query VARCHAR;
    
    c_list CURSOR FOR SELECT TBL_NAME FROM MY_TARGET_LIST;
BEGIN
    OPEN c_list;
    
    FOR rec IN c_list DO
        target_tbl := rec.TBL_NAME;
        found_db := NULL; -- Reset for each loop
        
        -- A. Get Metadata (Location, Rows, Comment, Owner)
        EXECUTE IMMEDIATE 'SHOW TABLES LIKE \'' || target_tbl || '\' IN ACCOUNT';
        
        BEGIN
            -- Safely extract metadata from the SHOW command result
            LET c_meta CURSOR FOR 
                SELECT "database_name", "schema_name", "rows", "owner", "comment"
                FROM TABLE(RESULT_SCAN(LAST_QUERY_ID())) 
                LIMIT 1;
            OPEN c_meta;
            FETCH c_meta INTO found_db, found_sch, found_rows, found_owner, found_comment;
            CLOSE c_meta;
        END;

        -- B. If found, Get DDL and Insert
        IF (found_db IS NOT NULL) THEN
            full_path := '"' || found_db || '"."' || found_sch || '"."' || target_tbl || '"';
            
            -- Construct DDL command
            ddl_query := 'SELECT GET_DDL(\'TABLE\', \'' || full_path || '\')';
            
            -- Run DDL command
            EXECUTE IMMEDIATE :ddl_query;
            
            -- Insert everything into Master Table (using Result Scan to grab the DDL text)
            INSERT INTO MASTER_TABLE_INFO 
            SELECT 
                :target_tbl, 
                :found_db, 
                :found_sch, 
                :found_rows, 
                :found_owner, 
                :found_comment, 
                $1  -- This is the DDL column from the query we just ran
            FROM TABLE(RESULT_SCAN(LAST_QUERY_ID()));
            
        ELSE
            -- Log missing table
            INSERT INTO MASTER_TABLE_INFO (TABLE_NAME, DATABASE_NAME, DESCRIPTION) 
            VALUES (:target_tbl, 'NOT FOUND', 'Could not locate table in any database');
        END IF;
        
    END FOR;
    
    CLOSE c_list;
    RETURN 'Collection Complete.';
END;
$$;

-- STEP 4: View the Final Report
SELECT * FROM MASTER_TABLE_INFO ORDER BY TABLE_NAME;


SELECT 
    H.HCP_FIRST_NAME,
    H.HCP_LAST_NAME,
    P.VRTX_PAYER_NAME,
    CAT_L2.MM_PAYER_CAT_L2_DESC AS CHANNEL_L2,
    SUM(F.TRX_CNT) AS TOTAL_TRX
FROM 
    "DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB"."DBT_ASINHA_REPORTING_LOAD"."TM_RX_L1_HCPPLNDC_NDC_MTH" F
JOIN 
    "DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB"."DBT_ASINHA_REPORTING_LOAD"."TD_HCP" H 
    ON F.HCP_KEY = H.HCP_KEY
JOIN 
    "DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB"."DBT_ASINHA_REPORTING_LOAD"."TD_VRTX_MCO_PLAN" PLAN 
    ON F.VRTX_PLAN_KEY = PLAN.VRTX_PLAN_KEY
JOIN 
    "DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB"."DBT_ASINHA_REPORTING_LOAD"."TD_VRTX_MCO_PAYER" P 
    ON PLAN.VRTX_PAYER_KEY = P.VRTX_PAYER_KEY
JOIN 
    "DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB"."DBT_ASINHA_REPORTING_LOAD"."TXR_VRTX_MCO_PAYER_CAT_2_PLAN" BRIDGE 
    ON F.VRTX_PLAN_KEY = BRIDGE.VRTX_PLAN_KEY
JOIN 
    "DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB"."DBT_ASINHA_REPORTING_LOAD"."TD_MM_PAYER_CATEGORY_L3" CAT_L3 
    ON BRIDGE.MM_PAYER_CAT_MAX_LVL_KEY = CAT_L3.MM_PAYER_CAT_L3_KEY
JOIN 
    "DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB"."DBT_ASINHA_REPORTING_LOAD"."TD_MM_PAYER_CATEGORY_L2" CAT_L2 
    ON CAT_L3.MM_PAYER_CAT_L2_KEY = CAT_L2.MM_PAYER_CAT_L2_KEY
GROUP BY 
    1, 2, 3, 4;




import _snowflake
import json
import snowflake.snowpark as snowpark

# ==========================================
# 1. HELPER: CALL AGENT (PROCESSOR MODE)
# ==========================================
def call_cortex_agent_with_data(query, mock_data, feedback_rule):
    
    # --- CONFIGURATION ---
    # Your specific endpoint
    AGENT_ENDPOINT_URL = "/api/v2/databases/DEV_P_PAIN_SALES_PERFORMANCE_ANALYTICS_DB/schemas/AI_POC/agents/FEEDBACK_NEW:run"
    TIMEOUT_MS = 180_000

    # --- BUILD THE PROMPT ---
    # We give the agent the Mock Data and the Rule, asking it to process the data.
    
    prompt = f"""
    [ROLE]
    You are a data reporting assistant. I will provide you with RAW DATA.
    Your job is to format and filter this data based on the USER RULES.

    [RAW DATA]
    {mock_data}

    [USER RULES / FEEDBACK]
    {feedback_rule}

    [USER REQUEST]
    {query}

    [INSTRUCTION]
    1. Read the RAW DATA.
    2. Apply the USER RULES strictly. 
       - If the rule says "limit to 2 rows", you must ignore the other 8 rows in the raw data.
       - If the rule says "format as %", reformat the numbers.
    3. Output the final result.
    """

    # --- PAYLOAD ---
    payload = {
        "messages": [
            {
                "role": "user", 
                "content": [{"type": "text", "text": prompt}]
            }
        ],
        "stream": False
    }

    headers = {
        "Content-Type": "application/json",
        "Accept": "application/json"
    }

    # --- API CALL ---
    try:
        response_dict = _snowflake.send_snow_api_request(
            "POST",
            AGENT_ENDPOINT_URL,
            headers,
            {}, 
            payload, 
            {}, 
            TIMEOUT_MS
        )
        
        response_content = response_dict.get("content", "")
        if not response_content: return "Error: Empty response"
            
        parsed_response = json.loads(response_content)

        # --- PARSING ---
        if isinstance(parsed_response, dict) and 'message' in parsed_response:
            content_items = parsed_response['message'].get('content', [])
            for item in reversed(content_items):
                if isinstance(item, dict) and item.get("type") == "text":
                    return item.get("text")
        
        # Fallback for list/stream format
        elif isinstance(parsed_response, list):
            for item in parsed_response:
                if item.get('event') == 'response':
                    try:
                        content_list = item.get('data', {}).get('content', [])
                        for part in content_list:
                            if part.get('type') == 'text':
                                return part.get('text')
                    except Exception: continue
            
            # Simple Text Delta reconstruction
            chunks = []
            for item in parsed_response:
                if item.get('event') == 'response.text.delta':
                    chunks.append(item.get('data', {}).get('text', ''))
            if chunks: return "".join(chunks)

        return "Could not parse response."

    except Exception as e:
        return f"API Error: {str(e)}"

# ==========================================
# 2. MAIN LOGIC
# ==========================================
def main(session: snowpark.Session):
    
    final_results = []

    # --- SCENARIO 1: TOP 10 PRESCRIBERS (LIMITING ROWS) ---
    # Mocking a full list of 10 rows
    data_1 = """
    1. Dr. Smith (NC) - 500 Rx
    2. Dr. Jones (NC) - 450 Rx
    3. Dr. Williams (NC) - 400 Rx
    4. Dr. Brown (NC) - 350 Rx
    5. Dr. Davis (NC) - 300 Rx
    6. Dr. Miller (NC) - 250 Rx
    7. Dr. Wilson (NC) - 200 Rx
    8. Dr. Moore (NC) - 150 Rx
    9. Dr. Taylor (NC) - 100 Rx
    10. Dr. Anderson (NC) - 50 Rx
    """
    
    # --- SCENARIO 2: ZIP CODES (CONCISENESS) ---
    data_2 = """
    Zip 27001 - Vol: High
    Zip 27002 - Vol: High
    Zip 27003 - Vol: High
    Zip 27004 - Vol: Med
    Zip 27005 - Vol: Med
    Zip 27006 - Vol: Med
    Zip 27007 - Vol: Low
    Zip 27008 - Vol: Low
    Zip 27009 - Vol: Low
    Zip 27010 - Vol: Low
    """

    # --- SCENARIO 3: DRUG TRENDS (NEGATIVE FORMATTING) ---
    data_3 = """
    Drug A: Sales -500 units
    Drug B: Sales +200 units
    Drug C: Sales -100 units
    Drug D: Sales +50 units
    """

    # --- SCENARIO 4: MARKET SHARE (DECIMAL PRECISION) ---
    data_4 = """
    North: 25%
    South: 30%
    East: 15%
    West: 30%
    """

    test_scenarios = [
        {
            "id": 1,
            "topic": "Row Limitation",
            "question": "Give top 10 prescriber from north carolina",
            "mock_data": data_1,
            "feedback": "Display Rule: If there are more than 5 rows, restrict the output to ONLY the top 2 rows."
        },
        {
            "id": 2,
            "topic": "Conciseness",
            "question": "Give top 10 zip codes which are outperforming the nations on prescriiton volumen",
            "mock_data": data_2,
            "feedback": "Style Rule: Make the response crisp. Do not use filler words like 'Here are the results'. Just list the items."
        },
        {
            "id": 3,
            "topic": "Negative Number Formatting",
            "question": "Which drugs have declining sales?",
            "mock_data": data_3,
            "feedback": "Formatting Rule: If a number is negative (e.g. -500), display it in parenthesis like (500) instead of using the minus sign."
        },
        {
            "id": 4,
            "topic": "Decimal Precision",
            "question": "Show market share by region",
            "mock_data": data_4,
            "feedback": "Formatting Rule: Always display percentages with exactly 1 decimal place (e.g. 25.0% instead of 25%)."
        }
    ]

    print("Starting Simulation Loop...")

    for test in test_scenarios:
        print(f"Running Scenario {test['id']}...")
        
        # 1. RESPONSE BEFORE (Simulated)
        # This is just the raw data agent would normally return
        response_before = f"[Raw Data Returned]:\n{test['mock_data']}"

        # 2. RESPONSE AFTER (Agent Processing)
        # We pass the raw data + feedback to the agent
        response_after = call_cortex_agent_with_data(
            test['question'], 
            test['mock_data'], 
            test['feedback']
        )

        # 3. SAVE RESULTS
        final_results.append({
            "Scenario_ID": test['id'],
            "Topic": test['topic'],
            "Question": test['question'],
            "Feedback_Rule": test['feedback'],
            "Response_BEFORE": response_before,
            "Response_AFTER": response_after
        })

    # Output to DataFrame
    df = session.create_dataframe(final_results)
    return df
